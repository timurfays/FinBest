{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e98dfc85",
   "metadata": {},
   "source": [
    "1. Мини-EDA анализа данных\n",
    "Загрузим файлы data/clients.csv и data/bank_transactions.csv и соберём базовую статистику: количество записей, уникальных значений, распределение категорий, максимальное повторение и соотношение типов транзакций.\n",
    "\n",
    "Описание:\n",
    "\n",
    "Загружаем файлы и выводим количество строк, уникальных значений, типы данных и первые строки.\n",
    "Анализируем распределение transaction_type (включая p2p и withdrawal).\n",
    "Проверяем максимальное повторение по ключевым полям (client_id, merchant, ip_network), чтобы понять, какие связи доминируют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загружаем данные\n",
    "clients = pd.read_csv('data/clients.csv')\n",
    "transactions = pd.read_csv('data/bank_transactions.csv')\n",
    "\n",
    "# Базовая статистика по clients\n",
    "print(\"=== Статистика по clients.csv ===\")\n",
    "print(f\"Количество строк: {len(clients)}\")\n",
    "print(f\"Количество уникальных клиентов (client_id): {clients['client_id'].nunique()}\")\n",
    "print(\"\\nСтолбцы и их типы:\")\n",
    "print(clients.dtypes)\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "display(clients.head())\n",
    "print(\"\\nУникальные значения по столбцам:\")\n",
    "for column in clients.columns:\n",
    "    print(f\"{column}: {clients[column].nunique()} уникальных значений\")\n",
    "\n",
    "# Базовая статистика по transactions\n",
    "print(\"\\n=== Статистика по bank_transactions.csv ===\")\n",
    "print(f\"Количество строк: {len(transactions)}\")\n",
    "print(f\"Количество уникальных транзакций (transaction_id): {transactions['transaction_id'].nunique()}\")\n",
    "print(\"\\nСтолбцы и их типы:\")\n",
    "print(transactions.dtypes)\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "display(transactions.head())\n",
    "print(\"\\nУникальные значения по столбцам:\")\n",
    "for column in transactions.columns:\n",
    "    print(f\"{column}: {transactions[column].nunique()} уникальных значений\")\n",
    "\n",
    "# Распределение типов транзакций\n",
    "print(\"\\n=== Распределение типов транзакций ===\")\n",
    "transaction_type_counts = transactions['transaction_type'].value_counts()\n",
    "print(transaction_type_counts)\n",
    "print(f\"Доля P2P: {transaction_type_counts.get('p2p', 0) / len(transactions) * 100:.2f}%\")\n",
    "print(f\"Доля withdrawal: {transaction_type_counts.get('withdrawal', 0) / len(transactions) * 100:.2f}%\")\n",
    "print(f\"Доля deposit: {transaction_type_counts.get('deposit', 0) / len(transactions) * 100:.2f}%\")\n",
    "\n",
    "# Максимальное повторение по ключевым полям\n",
    "print(\"\\n=== Максимальное повторение ===\")\n",
    "print(f\"Максимальное повторение client_id: {transactions['client_id'].value_counts().max()}\")\n",
    "print(f\"Максимальное повторение merchant: {transactions['merchant'].value_counts().dropna().max()}\")\n",
    "print(f\"Максимальное повторение ip_address: {transactions['ip_address'].value_counts().dropna().max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6af1ff",
   "metadata": {},
   "source": [
    "Ячейка 2: Подробный анализ связей\n",
    "Проверим, как часто клиенты пересекаются по различным полям, чтобы понять потенциальные рёбра.\n",
    "\n",
    "Описание:\n",
    "\n",
    "Проверяем распределение клиентов по мерчантам, чтобы выявить крупных игроков.\n",
    "Анализируем P2P и withdrawal, включая уникальные recipient_id_hash и client_id.\n",
    "Проверяем, насколько session_id может генерировать рёбра.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ пересечений по мерчантам\n",
    "merchant_pairs = transactions[transactions['merchant'].notna()].groupby('merchant')['client_id'].nunique().reset_index(name='client_count')\n",
    "print(\"\\n=== Количество клиентов по мерчантам ===\")\n",
    "print(merchant_pairs.sort_values('client_count', ascending=False).head(10))\n",
    "\n",
    "# Анализ P2P и withdrawal\n",
    "p2p_data = transactions[transactions['transaction_type'] == 'p2p']\n",
    "withdrawal_data = transactions[transactions['transaction_type'] == 'withdrawal']\n",
    "print(f\"\\nКоличество P2P-транзакций: {len(p2p_data)}\")\n",
    "print(f\"Количество withdrawal-транзакций: {len(withdrawal_data)}\")\n",
    "print(f\"Уникальных recipient_id в P2P: {p2p_data['recipient_id'].nunique()}\")\n",
    "print(f\"Уникальных client_id в withdrawal: {withdrawal_data['client_id'].nunique()}\")\n",
    "\n",
    "# Анализ session_id\n",
    "session_counts = transactions.groupby('session_id')['client_id'].nunique().reset_index(name='client_count')\n",
    "session_multiple = session_counts[session_counts['client_count'] > 1]\n",
    "print(f\"\\nКоличество session_id, используемых несколькими клиентами: {len(session_multiple)}\")\n",
    "print(\"Топ-5 session_id по количеству клиентов:\")\n",
    "print(session_multiple.sort_values('client_count', ascending=False).head())\n",
    "\n",
    "# Анализ регионов и стран\n",
    "print(f\"\\nУникальных регионов: {transactions['region'].nunique()}\")\n",
    "print(f\"Уникальных стран: {transactions['country_code'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0cf8b6",
   "metadata": {},
   "source": [
    "Описание:\n",
    "\n",
    "Строим граф с нуля на основе bank_transactions.csv.\n",
    "Добавляем рёбра по мерчантам (с фильтром до 100 клиентов), P2P и session_id.\n",
    "Используем Label Propagation для кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Загружаем данные\n",
    "transactions = pd.read_csv('data/bank_transactions.csv')\n",
    "transactions['datetime'] = pd.to_datetime(transactions['datetime'])\n",
    "\n",
    "# Создаём граф\n",
    "G = nx.Graph()\n",
    "\n",
    "# Добавляем узлы\n",
    "clients_set = set(transactions['client_id'])\n",
    "for client in clients_set:\n",
    "    G.add_node(client)\n",
    "\n",
    "# Создаём рёбра\n",
    "edges = []\n",
    "\n",
    "# Рёбра по общим мерчантам (только соседние по времени в пределах 1 дня)\n",
    "merchant_groups = transactions[transactions['merchant'].notna()].sort_values('datetime')\n",
    "for merchant, group in merchant_groups.groupby('merchant'):\n",
    "    if len(group) <= 100:  # Фильтр по количеству клиентов\n",
    "        for i in range(len(group) - 1):\n",
    "            curr_client = group.iloc[i]['client_id']\n",
    "            next_client = group.iloc[i + 1]['client_id']\n",
    "            curr_time = group.iloc[i]['datetime']\n",
    "            next_time = group.iloc[i + 1]['datetime']\n",
    "            if next_time - curr_time <= timedelta(days=1) and curr_client != next_client:\n",
    "                edges.append((curr_client, next_client, {'weight': 1.0, 'relationship': 'merchant_shared'}))\n",
    "\n",
    "# Рёбра по P2P\n",
    "p2p_edges = transactions[transactions['transaction_type'] == 'p2p']\n",
    "for _, row in p2p_edges.iterrows():\n",
    "    if pd.notna(row['recipient_id']) and row['client_id'] < row['recipient_id']:\n",
    "        edges.append((row['client_id'], row['recipient_id'], {'weight': 10.0, 'relationship': 'p2p'}))\n",
    "\n",
    "# Рёбра по session_id (только если более 5 клиентов)\n",
    "session_groups = transactions.groupby('session_id')['client_id'].apply(list).reset_index(name='clients')\n",
    "for _, row in session_groups.iterrows():\n",
    "    clients_list = row['clients']\n",
    "    if len(clients_list) > 5:\n",
    "        for i in range(len(clients_list)):\n",
    "            for j in range(i + 1, len(clients_list)):\n",
    "                edges.append((clients_list[i], clients_list[j], {'weight': 0.5, 'relationship': 'session_shared'}))\n",
    "\n",
    "# Рёбра по withdrawal (клиенты в одном регионе и дате)\n",
    "withdrawal_groups = transactions[transactions['transaction_type'] == 'withdrawal'].groupby(['region', 'datetime'])['client_id'].apply(list).reset_index(name='clients')\n",
    "for _, row in withdrawal_groups.iterrows():\n",
    "    clients_list = row['clients']\n",
    "    if len(clients_list) > 1:\n",
    "        for i in range(len(clients_list)):\n",
    "            for j in range(i + 1, len(clients_list)):\n",
    "                edges.append((clients_list[i], clients_list[j], {'weight': 2.0, 'relationship': 'withdrawal_shared'}))\n",
    "\n",
    "# Добавляем рёбра в граф\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "print(f\"Создан граф с {G.number_of_nodes()} узлами и {G.number_of_edges()} рёбрами\")\n",
    "\n",
    "# Кластеризация с Label Propagation\n",
    "from networkx.algorithms.community import label_propagation_communities\n",
    "communities = list(label_propagation_communities(G))\n",
    "print(f\"Найдено {len(communities)} сообществ\")\n",
    "\n",
    "# Статистика\n",
    "community_sizes = [len(c) for c in communities]\n",
    "community_sizes.sort(reverse=True)\n",
    "print(f\"Топ-5 размеров сообществ: {community_sizes[:5]}\")\n",
    "print(f\"Доля крупнейшего сообщества: {community_sizes[0] / sum(community_sizes) * 100:.2f}%\")\n",
    "\n",
    "# Установка и использование Louvain\n",
    "try:\n",
    "    import community as community_louvain\n",
    "    partition = community_louvain.best_partition(G)\n",
    "    community_sizes_louvain = {comm: list(partition.values()).count(comm) for comm in set(partition.values())}\n",
    "    community_sizes_louvain = dict(sorted(community_sizes_louvain.items(), key=lambda x: x[1], reverse=True))\n",
    "    print(f\"\\nТоп-5 размеров сообществ (Louvain): {list(community_sizes_louvain.values())[:5]}\")\n",
    "    print(f\"Доля крупнейшего сообщества (Louvain): {list(community_sizes_louvain.values())[0] / sum(community_sizes_louvain.values()) * 100:.2f}%\")\n",
    "except ImportError:\n",
    "    print(\"Библиотека community не установлена. Установите её с помощью 'pip install python-louvain'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaaaa1c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUAL_ANALYTICS.PY\n",
    "# -------------------\n",
    "import networkx as nx, pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from networkx.algorithms.community import label_propagation_communities\n",
    "from pylab import rcParams\n",
    "from community import modularity         # из python-louvain\n",
    "import random, warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---- 1. сообщества Louvain (уже считаны ранее) --------------\n",
    "louvain = nx.get_node_attributes(G, 'louvain_comm')      # из прошлого скрипта\n",
    "\n",
    "# если не считано – считаем\n",
    "if not louvain:\n",
    "    import community as community_louvain\n",
    "    louvain = community_louvain.best_partition(G, weight='weight')\n",
    "    nx.set_node_attributes(G, louvain, 'louvain_comm')\n",
    "\n",
    "# ---- 2. Label Propagation -----------------------------------\n",
    "if 'lp_comm' not in nx.get_node_attributes(G, 'lp_comm'):\n",
    "    lp_raw = list(label_propagation_communities(G))\n",
    "    lp_map = {}\n",
    "    for i, comm in enumerate(lp_raw):\n",
    "        for node in comm:\n",
    "            lp_map[node] = i\n",
    "    nx.set_node_attributes(G, lp_map, 'lp_comm')\n",
    "else:\n",
    "    lp_map = nx.get_node_attributes(G, 'lp_comm')\n",
    "\n",
    "# ---- 3. Метрики графа ---------------------------------------\n",
    "n  = G.number_of_nodes();  m = G.number_of_edges()\n",
    "density      = nx.density(G)\n",
    "avg_deg      = round(2*m/n, 2)\n",
    "avg_clust    = nx.average_clustering(G, weight='weight')\n",
    "largest_cc   = max(nx.connected_components(G), key=len)\n",
    "diameter_lcc = nx.diameter(G.subgraph(largest_cc))\n",
    "lou_mod      = modularity(louvain, G, weight='weight')\n",
    "lp_mod       = modularity(lp_map, G, weight='weight')\n",
    "\n",
    "metrics = pd.Series({\n",
    "    'nodes'              : n,\n",
    "    'edges'              : m,\n",
    "    'density'            : density,\n",
    "    'avg_weighted_degree': avg_deg,\n",
    "    'avg_clustering'     : avg_clust,\n",
    "    'diameter_LCC'       : diameter_lcc,\n",
    "    'modularity_louvain' : lou_mod,\n",
    "    'modularity_lp'      : lp_mod\n",
    "})\n",
    "print(metrics.to_markdown())\n",
    "\n",
    "# ---- 4. Pie-chart размеров сообществ (Louvain) --------------\n",
    "sizes = pd.Series(louvain).value_counts().sort_values(ascending=False)\n",
    "top10 = sizes.head(10)\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.pie(top10, labels=[f'C{c}' for c in top10.index],\n",
    "       autopct='%1.1f%%', pctdistance=0.8, startangle=90)\n",
    "ax.set_title('Top-10 community share (Louvain)')\n",
    "plt.show()\n",
    "\n",
    "# ---- 5. Гистограмма лог-взвешенной степени ------------------\n",
    "deg = pd.Series(dict(G.degree(weight='weight')))\n",
    "sns.displot(np.log1p(deg), kde=True, height=4, aspect=1.6)\n",
    "plt.title('Histogram of log-weighted degrees')\n",
    "plt.xlabel('log1p(weighted degree)');  plt.ylabel('freq')\n",
    "plt.show()\n",
    "\n",
    "# ---- 6. Функция выборочной визуализации графа ---------------\n",
    "def draw_subgraph(comm_attr, comm_name, k=700):\n",
    "    # берём k случайных узлов + их соседей\n",
    "    base_nodes = random.sample(list(G.nodes), min(k, len(G)))\n",
    "    nbrs = set(base_nodes)\n",
    "    for n in base_nodes:\n",
    "        nbrs.update(G[n])\n",
    "    SG = G.subgraph(nbrs).copy()\n",
    "\n",
    "    # выбираем цвет по сообществу\n",
    "    comms = nx.get_node_attributes(G, comm_attr)\n",
    "    colors = [comms.get(v, -1) for v in SG.nodes()]\n",
    "    cmap = plt.cm.get_cmap('tab20')\n",
    "\n",
    "    pos = nx.spring_layout(SG, seed=42, k=0.2)\n",
    "    rcParams['figure.figsize'] = 10,8\n",
    "    plt.figure()\n",
    "    nx.draw_networkx_nodes(SG, pos,\n",
    "                           node_size=40,\n",
    "                           node_color=colors,\n",
    "                           cmap=cmap,\n",
    "                           alpha=0.9)\n",
    "    nx.draw_networkx_edges(SG, pos,\n",
    "                           width=0.3,\n",
    "                           alpha=0.4)\n",
    "    plt.title(f\"Sampled graph coloured by {comm_name} communities\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "draw_subgraph('louvain_comm', 'Louvain')\n",
    "draw_subgraph('lp_comm',      'Label Propagation')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
