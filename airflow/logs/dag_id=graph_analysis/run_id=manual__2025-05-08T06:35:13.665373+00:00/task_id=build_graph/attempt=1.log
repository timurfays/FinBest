[2025-05-08T06:35:21.466+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-08T06:35:13.665373+00:00 [queued]>
[2025-05-08T06:35:21.472+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-08T06:35:13.665373+00:00 [queued]>
[2025-05-08T06:35:21.472+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2025-05-08T06:35:21.480+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): build_graph> on 2025-05-08 06:35:13.665373+00:00
[2025-05-08T06:35:21.484+0000] {standard_task_runner.py:57} INFO - Started process 1246 to run task
[2025-05-08T06:35:21.486+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'graph_analysis', 'build_graph', 'manual__2025-05-08T06:35:13.665373+00:00', '--job-id', '345', '--raw', '--subdir', 'DAGS_FOLDER/graph_analysis.py', '--cfg-path', '/tmp/tmp67upqxfd']
[2025-05-08T06:35:21.486+0000] {standard_task_runner.py:85} INFO - Job 345: Subtask build_graph
[2025-05-08T06:35:21.498+0000] {logging_mixin.py:150} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-08T06:35:21.525+0000] {task_command.py:410} INFO - Running <TaskInstance: graph_analysis.build_graph manual__2025-05-08T06:35:13.665373+00:00 [running]> on host f2a432e4376a
[2025-05-08T06:35:21.592+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='finbest' AIRFLOW_CTX_DAG_ID='graph_analysis' AIRFLOW_CTX_TASK_ID='build_graph' AIRFLOW_CTX_EXECUTION_DATE='2025-05-08T06:35:13.665373+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-08T06:35:13.665373+00:00'
[2025-05-08T06:35:21.600+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-05-08T06:35:21.601+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******
[2025-05-08T06:35:21.613+0000] {spark_submit.py:571} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-05-08T06:35:22.522+0000] {spark_submit.py:571} INFO - Using properties file: null
[2025-05-08T06:35:22.601+0000] {spark_submit.py:571} INFO - WARNING: An illegal reflective access operation has occurred
[2025-05-08T06:35:22.602+0000] {spark_submit.py:571} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2025-05-08T06:35:22.602+0000] {spark_submit.py:571} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2025-05-08T06:35:22.602+0000] {spark_submit.py:571} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-05-08T06:35:22.602+0000] {spark_submit.py:571} INFO - WARNING: All illegal access operations will be denied in a future release
[2025-05-08T06:35:22.638+0000] {spark_submit.py:571} INFO - Parsed arguments:
[2025-05-08T06:35:22.639+0000] {spark_submit.py:571} INFO - master                  spark://spark-master:7077
[2025-05-08T06:35:22.639+0000] {spark_submit.py:571} INFO - deployMode              null
[2025-05-08T06:35:22.639+0000] {spark_submit.py:571} INFO - executorMemory          1g
[2025-05-08T06:35:22.639+0000] {spark_submit.py:571} INFO - executorCores           1
[2025-05-08T06:35:22.639+0000] {spark_submit.py:571} INFO - totalExecutorCores      null
[2025-05-08T06:35:22.639+0000] {spark_submit.py:571} INFO - propertiesFile          null
[2025-05-08T06:35:22.639+0000] {spark_submit.py:571} INFO - driverMemory            1g
[2025-05-08T06:35:22.639+0000] {spark_submit.py:571} INFO - driverCores             null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - driverExtraClassPath    null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - driverExtraLibraryPath  null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - driverExtraJavaOptions  null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - supervise               false
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - queue                   null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - numExecutors            null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - files                   null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - pyFiles                 null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - archives                null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - mainClass               null
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - primaryResource         file:/opt/airflow/spark/build_graph.py
[2025-05-08T06:35:22.640+0000] {spark_submit.py:571} INFO - name                    arrow-spark
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - childArgs               [--jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ***]
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - jars                    null
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - packages                org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - packagesExclusions      null
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - repositories            null
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - verbose                 true
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - 
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - Spark properties used, including those specified through
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - --conf and those from the properties file null:
[2025-05-08T06:35:22.641+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-08T06:35:22.642+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-08T06:35:22.642+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-08T06:35:22.642+0000] {spark_submit.py:571} INFO - 
[2025-05-08T06:35:22.642+0000] {spark_submit.py:571} INFO - 
[2025-05-08T06:35:22.747+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-08T06:35:22.819+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-05-08T06:35:22.819+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-05-08T06:35:22.823+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql added as a dependency
[2025-05-08T06:35:22.824+0000] {spark_submit.py:571} INFO - graphframes#graphframes added as a dependency
[2025-05-08T06:35:22.824+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-1d2ffcda-effd-4304-9a63-4abc39026c80;1.0
[2025-05-08T06:35:22.824+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-08T06:35:22.916+0000] {spark_submit.py:571} INFO - found org.postgresql#postgresql;42.6.0 in central
[2025-05-08T06:35:22.939+0000] {spark_submit.py:571} INFO - found org.checkerframework#checker-qual;3.31.0 in central
[2025-05-08T06:35:22.960+0000] {spark_submit.py:571} INFO - found graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages
[2025-05-08T06:35:22.984+0000] {spark_submit.py:571} INFO - found org.slf4j#slf4j-api;1.7.16 in central
[2025-05-08T06:35:23.009+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 174ms :: artifacts dl 11ms
[2025-05-08T06:35:23.009+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-05-08T06:35:23.009+0000] {spark_submit.py:571} INFO - graphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]
[2025-05-08T06:35:23.010+0000] {spark_submit.py:571} INFO - org.checkerframework#checker-qual;3.31.0 from central in [default]
[2025-05-08T06:35:23.010+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql;42.6.0 from central in [default]
[2025-05-08T06:35:23.010+0000] {spark_submit.py:571} INFO - org.slf4j#slf4j-api;1.7.16 from central in [default]
[2025-05-08T06:35:23.010+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-08T06:35:23.010+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-05-08T06:35:23.010+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-08T06:35:23.010+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-08T06:35:23.010+0000] {spark_submit.py:571} INFO - |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
[2025-05-08T06:35:23.010+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-08T06:35:23.014+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-1d2ffcda-effd-4304-9a63-4abc39026c80
[2025-05-08T06:35:23.014+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-08T06:35:23.019+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 4 already retrieved (0kB/5ms)
[2025-05-08T06:35:23.197+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-08T06:35:23.393+0000] {spark_submit.py:571} INFO - Main class:
[2025-05-08T06:35:23.394+0000] {spark_submit.py:571} INFO - org.apache.spark.deploy.PythonRunner
[2025-05-08T06:35:23.394+0000] {spark_submit.py:571} INFO - Arguments:
[2025-05-08T06:35:23.394+0000] {spark_submit.py:571} INFO - file:/opt/airflow/spark/build_graph.py
[2025-05-08T06:35:23.394+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-08T06:35:23.394+0000] {spark_submit.py:571} INFO - --jdbc
[2025-05-08T06:35:23.394+0000] {spark_submit.py:571} INFO - jdbc:postgresql://postgres:5432/finbest
[2025-05-08T06:35:23.394+0000] {spark_submit.py:571} INFO - --user
[2025-05-08T06:35:23.394+0000] {spark_submit.py:571} INFO - finbest
[2025-05-08T06:35:23.395+0000] {spark_submit.py:571} INFO - --password
[2025-05-08T06:35:23.395+0000] {spark_submit.py:571} INFO - ***
[2025-05-08T06:35:23.397+0000] {spark_submit.py:571} INFO - Spark config:
[2025-05-08T06:35:23.398+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-08T06:35:23.398+0000] {spark_submit.py:571} INFO - (spark.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-08T06:35:23.398+0000] {spark_submit.py:571} INFO - (spark.app.name,arrow-spark)
[2025-05-08T06:35:23.398+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - (spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,/home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,/home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,/home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - (spark.files,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - (spark.submit.deployMode,client)
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - (spark.master,spark://spark-master:7077)
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - (spark.executor.memory,1g)
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - (spark.executor.cores,1)
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - (spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - Classpath elements:
[2025-05-08T06:35:23.399+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar
[2025-05-08T06:35:23.400+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-08T06:35:23.400+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-08T06:35:23.400+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-08T06:35:23.400+0000] {spark_submit.py:571} INFO - 
[2025-05-08T06:35:23.400+0000] {spark_submit.py:571} INFO - 
[2025-05-08T06:35:24.619+0000] {spark_submit.py:571} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2025-05-08T06:35:24.625+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO SparkContext: Running Spark version 3.2.4
[2025-05-08T06:35:24.641+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO ResourceUtils: ==============================================================
[2025-05-08T06:35:24.641+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-08T06:35:24.641+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO ResourceUtils: ==============================================================
[2025-05-08T06:35:24.642+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO SparkContext: Submitted application: FinBestGraphAnalysis
[2025-05-08T06:35:24.662+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-08T06:35:24.673+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-05-08T06:35:24.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-08T06:35:24.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO SecurityManager: Changing view acls to: airflow
[2025-05-08T06:35:24.722+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO SecurityManager: Changing modify acls to: airflow
[2025-05-08T06:35:24.722+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO SecurityManager: Changing view acls groups to:
[2025-05-08T06:35:24.723+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO SecurityManager: Changing modify acls groups to:
[2025-05-08T06:35:24.723+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(airflow); groups with view permissions: Set(); users  with modify permissions: Set(airflow); groups with modify permissions: Set()
[2025-05-08T06:35:24.963+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO Utils: Successfully started service 'sparkDriver' on port 36669.
[2025-05-08T06:35:24.984+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:24 INFO SparkEnv: Registering MapOutputTracker
[2025-05-08T06:35:25.015+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-08T06:35:25.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-08T06:35:25.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-08T06:35:25.043+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-08T06:35:25.070+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4ea41f2a-95be-4a24-a600-8e7dce70a994
[2025-05-08T06:35:25.095+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-08T06:35:25.113+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-08T06:35:25.279+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-08T06:35:25.316+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://f2a432e4376a:4040
[2025-05-08T06:35:25.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://f2a432e4376a:36669/jars/org.postgresql_postgresql-42.6.0.jar with timestamp 1746686124617
[2025-05-08T06:35:25.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://f2a432e4376a:36669/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746686124617
[2025-05-08T06:35:25.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://f2a432e4376a:36669/jars/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746686124617
[2025-05-08T06:35:25.327+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://f2a432e4376a:36669/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746686124617
[2025-05-08T06:35:25.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://f2a432e4376a:36669/files/org.postgresql_postgresql-42.6.0.jar with timestamp 1746686124617
[2025-05-08T06:35:25.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO Utils: Copying /home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar to /tmp/spark-b4ff2d5f-ebaa-4292-a3c1-c3211f63aae7/userFiles-d9f37a2d-96d6-41d4-9f55-662bade87b9e/org.postgresql_postgresql-42.6.0.jar
[2025-05-08T06:35:25.337+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://f2a432e4376a:36669/files/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746686124617
[2025-05-08T06:35:25.337+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO Utils: Copying /home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar to /tmp/spark-b4ff2d5f-ebaa-4292-a3c1-c3211f63aae7/userFiles-d9f37a2d-96d6-41d4-9f55-662bade87b9e/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-08T06:35:25.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://f2a432e4376a:36669/files/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746686124617
[2025-05-08T06:35:25.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO Utils: Copying /home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar to /tmp/spark-b4ff2d5f-ebaa-4292-a3c1-c3211f63aae7/userFiles-d9f37a2d-96d6-41d4-9f55-662bade87b9e/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-08T06:35:25.344+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://f2a432e4376a:36669/files/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746686124617
[2025-05-08T06:35:25.344+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO Utils: Copying /home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-b4ff2d5f-ebaa-4292-a3c1-c3211f63aae7/userFiles-d9f37a2d-96d6-41d4-9f55-662bade87b9e/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-08T06:35:25.470+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-05-08T06:35:25.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 20 ms (0 ms spent in bootstraps)
[2025-05-08T06:35:25.579+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250508063525-0002
[2025-05-08T06:35:25.581+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250508063525-0002/0 on worker-20250508061515-172.20.0.5-45383 (172.20.0.5:45383) with 1 core(s)
[2025-05-08T06:35:25.582+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20250508063525-0002/0 on hostPort 172.20.0.5:45383 with 1 core(s), 1024.0 MiB RAM
[2025-05-08T06:35:25.584+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46195.
[2025-05-08T06:35:25.584+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO NettyBlockTransferService: Server created on f2a432e4376a:46195
[2025-05-08T06:35:25.586+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-08T06:35:25.591+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f2a432e4376a, 46195, None)
[2025-05-08T06:35:25.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO BlockManagerMasterEndpoint: Registering block manager f2a432e4376a:46195 with 434.4 MiB RAM, BlockManagerId(driver, f2a432e4376a, 46195, None)
[2025-05-08T06:35:25.595+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f2a432e4376a, 46195, None)
[2025-05-08T06:35:25.596+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f2a432e4376a, 46195, None)
[2025-05-08T06:35:25.623+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508063525-0002/0 is now RUNNING
[2025-05-08T06:35:25.763+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-05-08T06:35:25.935+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-08T06:35:25.936+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:25 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-05-08T06:35:26.663+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:26,663 [INFO] SparkSession создана
[2025-05-08T06:35:26.663+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:26,663 [INFO] Загружаем клиентов и транзакции
[2025-05-08T06:35:28.055+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:28 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:43674) with ID 0,  ResourceProfileId 0
[2025-05-08T06:35:28.214+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:28 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:41027 with 434.4 MiB RAM, BlockManagerId(0, 172.20.0.5, 41027, None)
[2025-05-08T06:35:29.325+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO CodeGenerator: Code generated in 107.221141 ms
[2025-05-08T06:35:29.366+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-05-08T06:35:29.369+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:29.369+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:29.369+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:29.370+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:29.372+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:29.464+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-08T06:35:29.497+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-08T06:35:29.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on f2a432e4376a:46195 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:29.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:29.522+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:29.522+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-08T06:35:29.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:29.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.5:41027 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:30.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 952 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:30.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-08T06:35:30.507+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.123 s
[2025-05-08T06:35:30.508+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:30.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:30.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:30.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:30.536+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO CodeGenerator: Code generated in 8.594069 ms
[2025-05-08T06:35:30.563+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-08T06:35:30.565+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:30.565+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:30.565+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-08T06:35:30.566+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:30.567+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:30.574+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-08T06:35:30.577+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-08T06:35:30.578+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on f2a432e4376a:46195 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:30.578+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:30.580+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:30.580+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-08T06:35:30.584+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:30.604+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:30.668+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.20.0.5:43674
[2025-05-08T06:35:30.752+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 169 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:30.752+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-08T06:35:30.753+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.181 s
[2025-05-08T06:35:30.754+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:30.754+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-08T06:35:30.756+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.192450 s
[2025-05-08T06:35:30.800+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Registering RDD 8 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-05-08T06:35:30.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:30.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:30.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:30.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:30.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:30.805+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-08T06:35:30.807+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.3 MiB)
[2025-05-08T06:35:30.809+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on f2a432e4376a:46195 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:30.809+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:30.810+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:30.810+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-05-08T06:35:30.811+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:30.830+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.0.5:41027 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:30.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 56 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:30.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-08T06:35:30.869+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.066 s
[2025-05-08T06:35:30.869+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:30.870+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:30.870+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:30.870+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:30.898+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-08T06:35:30.900+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:30.900+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:30.900+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-08T06:35:30.900+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:30.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:30.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-08T06:35:30.906+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.3 MiB)
[2025-05-08T06:35:30.906+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on f2a432e4376a:46195 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:30.907+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:30.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:30.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-08T06:35:30.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:30.933+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:30.941+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.20.0.5:43674
[2025-05-08T06:35:30.951+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 41 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:30.951+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-08T06:35:30.952+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.049 s
[2025-05-08T06:35:30.952+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:30.952+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-05-08T06:35:30.952+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:30 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.053842 s
[2025-05-08T06:35:30.953+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:30,953 [INFO] Загружено 4652 транзакций и 1200 клиентов
[2025-05-08T06:35:31.018+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on f2a432e4376a:46195 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:31.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.5:41027 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:31.034+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:31 INFO BlockManagerInfo: Removed broadcast_0_piece0 on f2a432e4376a:46195 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:31.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:31 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.0.5:41027 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:31.044+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on f2a432e4376a:46195 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:31.047+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.5:41027 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:31.053+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:31 INFO BlockManagerInfo: Removed broadcast_2_piece0 on f2a432e4376a:46195 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:31.056+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:31 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.0.5:41027 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:31.140+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:31,139 [INFO] Создаем вершины двудольного графа
[2025-05-08T06:35:31.501+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:31,501 [INFO] Создаем ATM-хабы
[2025-05-08T06:35:31.713+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:31,712 [INFO] Объединяем ребра двудольного графа
[2025-05-08T06:35:31.811+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:31,811 [INFO] Создаем P2P-слой
[2025-05-08T06:35:31.848+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:31,848 [INFO] Создаем проекцию клиент-клиент
[2025-05-08T06:35:32.417+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:32,417 [INFO] Вычисляем метрики графа
[2025-05-08T06:35:32.875+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO CodeGenerator: Code generated in 16.70333 ms
[2025-05-08T06:35:32.881+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO DAGScheduler: Registering RDD 15 (rdd at GraphFrame.scala:187) as input to shuffle 2
[2025-05-08T06:35:32.884+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO DAGScheduler: Got map stage job 4 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-08T06:35:32.884+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (rdd at GraphFrame.scala:187)
[2025-05-08T06:35:32.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:32.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:32.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T06:35:32.902+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
[2025-05-08T06:35:32.903+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.4 MiB)
[2025-05-08T06:35:32.906+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on f2a432e4376a:46195 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-08T06:35:32.907+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:32.907+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:32.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-05-08T06:35:32.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:32.953+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.5:41027 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-08T06:35:33.119+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 210 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:33.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-05-08T06:35:33.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: ShuffleMapStage 6 (rdd at GraphFrame.scala:187) finished in 0.236 s
[2025-05-08T06:35:33.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:33.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:33.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:33.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:33.150+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:33.176+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on f2a432e4376a:46195 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-08T06:35:33.180+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.5:41027 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-08T06:35:33.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:33.191+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:35:33.192+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:33.192+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-08T06:35:33.192+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:33.193+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:33.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-08T06:35:33.197+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-08T06:35:33.198+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:33.198+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:33.199+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:33.199+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-08T06:35:33.200+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:33.218+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:33.226+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.20.0.5:43674
[2025-05-08T06:35:33.237+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 37 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:33.237+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-08T06:35:33.237+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.042 s
[2025-05-08T06:35:33.238+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:33.238+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-08T06:35:33.238+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.048121 s
[2025-05-08T06:35:33.261+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO CodeGenerator: Code generated in 9.095073 ms
[2025-05-08T06:35:33.275+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-08T06:35:33.281+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.8 KiB, free 432.3 MiB)
[2025-05-08T06:35:33.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on f2a432e4376a:46195 (size: 28.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:33.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO SparkContext: Created broadcast 6 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:33.315+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO CodeGenerator: Code generated in 14.020128 ms
[2025-05-08T06:35:33.318+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:33.319+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:33.351+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO CodeGenerator: Code generated in 24.616983 ms
[2025-05-08T06:35:33.359+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO CodeGenerator: Code generated in 5.703993 ms
[2025-05-08T06:35:33.394+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#995 - id.nullCount#994) > 0)
[2025-05-08T06:35:33.624+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:33.631+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:33.882+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO CodeGenerator: Code generated in 5.049301 ms
[2025-05-08T06:35:33.887+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO CodeGenerator: Code generated in 3.691063 ms
[2025-05-08T06:35:33.893+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO CodeGenerator: Code generated in 4.22239 ms
[2025-05-08T06:35:33.907+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO CodeGenerator: Code generated in 7.507969 ms
[2025-05-08T06:35:33.913+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:33 INFO CodeGenerator: Code generated in 3.512247 ms
[2025-05-08T06:35:34.097+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 10.920271 ms
[2025-05-08T06:35:34.116+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 11.238783 ms
[2025-05-08T06:35:34.133+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 10.470581 ms
[2025-05-08T06:35:34.148+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 10.298516 ms
[2025-05-08T06:35:34.164+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 9.747687 ms
[2025-05-08T06:35:34.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 11.804669 ms
[2025-05-08T06:35:34.199+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Registering RDD 60 (collect at GraphFrame.scala:574) as input to shuffle 4
[2025-05-08T06:35:34.199+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Got map stage job 6 (collect at GraphFrame.scala:574) with 6 output partitions
[2025-05-08T06:35:34.199+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:34.199+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:34.199+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:34.202+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:34.209+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 36.4 KiB, free 432.3 MiB)
[2025-05-08T06:35:34.212+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 11.135068 ms
[2025-05-08T06:35:34.212+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 432.3 MiB)
[2025-05-08T06:35:34.213+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on f2a432e4376a:46195 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-08T06:35:34.213+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:34.214+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:35:34.214+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSchedulerImpl: Adding task set 9.0 with 6 tasks resource profile 0
[2025-05-08T06:35:34.215+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Registering RDD 62 (collect at GraphFrame.scala:574) as input to shuffle 5
[2025-05-08T06:35:34.216+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:34.216+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Got map stage job 7 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T06:35:34.216+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:34.216+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:34.216+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:34.218+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:34.218+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:34.223+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.6 KiB, free 432.3 MiB)
[2025-05-08T06:35:34.234+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 432.2 MiB)
[2025-05-08T06:35:34.235+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on f2a432e4376a:46195 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-08T06:35:34.236+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:34.236+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:34.237+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2025-05-08T06:35:34.249+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.5:41027 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-08T06:35:34.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 27.647991 ms
[2025-05-08T06:35:34.262+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Registering RDD 64 (collect at GraphFrame.scala:574) as input to shuffle 6
[2025-05-08T06:35:34.263+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Got map stage job 8 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T06:35:34.264+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:34.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:34.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:34.268+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:34.272+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:34.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 27.3 KiB, free 432.2 MiB)
[2025-05-08T06:35:34.285+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.2 MiB)
[2025-05-08T06:35:34.304+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-08T06:35:34.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:34.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:34.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-05-08T06:35:34.314+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 45.378286 ms
[2025-05-08T06:35:34.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Registering RDD 66 (collect at GraphFrame.scala:574) as input to shuffle 7
[2025-05-08T06:35:34.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Got map stage job 9 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T06:35:34.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:34.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:34.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:34.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:34.337+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:34.356+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 28.5 KiB, free 432.2 MiB)
[2025-05-08T06:35:34.389+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 432.2 MiB)
[2025-05-08T06:35:34.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on f2a432e4376a:46195 (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-08T06:35:34.396+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:34.398+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:34.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-05-08T06:35:34.408+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 71.200324 ms
[2025-05-08T06:35:34.413+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:34.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Registering RDD 68 (collect at GraphFrame.scala:574) as input to shuffle 8
[2025-05-08T06:35:34.419+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Got map stage job 10 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T06:35:34.419+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:34.419+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:34.420+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:34.429+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:34.432+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 7) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:34.437+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-08T06:35:34.438+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 432.1 MiB)
[2025-05-08T06:35:34.438+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 223 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:35:34.444+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-08T06:35:34.455+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:34.455+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:34.456+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-05-08T06:35:34.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 23.839698 ms
[2025-05-08T06:35:34.483+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:34.486+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Registering RDD 70 (collect at GraphFrame.scala:574) as input to shuffle 9
[2025-05-08T06:35:34.488+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Got map stage job 11 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T06:35:34.489+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:34.492+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:34.495+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:34.496+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:34.503+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 27.4 KiB, free 432.1 MiB)
[2025-05-08T06:35:34.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.1 MiB)
[2025-05-08T06:35:34.513+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-08T06:35:34.514+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:34.516+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:34.516+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-05-08T06:35:34.534+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 41.905137 ms
[2025-05-08T06:35:34.543+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Registering RDD 72 (collect at GraphFrame.scala:574) as input to shuffle 10
[2025-05-08T06:35:34.547+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Got map stage job 12 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T06:35:34.551+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:34.551+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:34.552+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:34.553+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:34.555+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:34.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 8) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:34.560+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 7) in 127 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:35:34.566+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-08T06:35:34.587+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 432.0 MiB)
[2025-05-08T06:35:34.588+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on f2a432e4376a:46195 (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-08T06:35:34.592+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:34.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:34.616+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-05-08T06:35:34.640+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO CodeGenerator: Code generated in 75.337164 ms
[2025-05-08T06:35:34.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 9) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:34.678+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 8) in 117 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:35:34.702+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Registering RDD 74 (collect at GraphFrame.scala:574) as input to shuffle 11
[2025-05-08T06:35:34.703+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Got map stage job 13 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T06:35:34.703+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:34.703+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:34.703+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:34.704+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:34.709+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.7 KiB, free 432.0 MiB)
[2025-05-08T06:35:34.723+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 432.0 MiB)
[2025-05-08T06:35:34.726+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on f2a432e4376a:46195 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-08T06:35:34.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:34.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:34.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-05-08T06:35:34.792+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 10) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:34.795+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 9) in 118 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:35:34.865+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 11) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:34.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:34 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 10) in 79 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:35:35.381+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 12) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:35.382+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 11) in 518 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:35:35.382+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-05-08T06:35:35.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: ShuffleMapStage 9 (collect at GraphFrame.scala:574) finished in 1.182 s
[2025-05-08T06:35:35.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:35.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 10, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-08T06:35:35.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:35.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:35.397+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.5:41027 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-08T06:35:35.408+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:35.412+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:35.444+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 13) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:35.445+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 12) in 65 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:35.448+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-05-08T06:35:35.449+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: ShuffleMapStage 10 (collect at GraphFrame.scala:574) finished in 1.231 s
[2025-05-08T06:35:35.450+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:35.450+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-08T06:35:35.450+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:35.451+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:35.473+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:35.475+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:35:35.475+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Final stage: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:35.475+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-05-08T06:35:35.476+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:35.482+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[77] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:35.483+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-08T06:35:35.486+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-08T06:35:35.505+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-08T06:35:35.512+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:35.515+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:35.515+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:35.519+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Removed broadcast_8_piece0 on f2a432e4376a:46195 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-08T06:35:35.519+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[77] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:35.519+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-05-08T06:35:35.528+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.20.0.5:41027 in memory (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-08T06:35:35.551+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Removed broadcast_7_piece0 on f2a432e4376a:46195 in memory (size: 11.2 KiB, free: 434.3 MiB)
[2025-05-08T06:35:35.555+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.20.0.5:41027 in memory (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-08T06:35:35.583+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:35.585+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:35:35.585+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Final stage: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:35.585+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2025-05-08T06:35:35.585+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:35.590+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:35.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-08T06:35:35.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-08T06:35:35.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:35.617+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:35.618+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:35.618+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2025-05-08T06:35:35.771+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 14) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:35.773+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 13) in 329 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:35.773+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-05-08T06:35:35.776+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: ShuffleMapStage 11 (collect at GraphFrame.scala:574) finished in 1.502 s
[2025-05-08T06:35:35.776+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:35.776+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-08T06:35:35.776+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:35.776+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:35.806+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.5:41027 (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:35.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 15) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:35.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 14) in 132 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:35.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-05-08T06:35:35.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: ShuffleMapStage 12 (collect at GraphFrame.scala:574) finished in 1.570 s
[2025-05-08T06:35:35.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:35.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-08T06:35:35.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:35.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:35.934+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-08T06:35:35.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 16) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:35.990+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 15) in 89 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:35.991+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-05-08T06:35:35.991+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: ShuffleMapStage 13 (collect at GraphFrame.scala:574) finished in 1.559 s
[2025-05-08T06:35:35.991+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:35.991+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-08T06:35:35.991+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:35.991+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:35 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:36.007+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.063+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 17) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.064+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 16) in 74 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:36.064+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-05-08T06:35:36.065+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: ShuffleMapStage 14 (collect at GraphFrame.scala:574) finished in 1.573 s
[2025-05-08T06:35:36.065+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:36.065+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-08T06:35:36.066+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:36.066+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:36.075+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.5:41027 (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.119+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 17) in 56 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:36.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-08T06:35:36.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: ShuffleMapStage 15 (collect at GraphFrame.scala:574) finished in 1.566 s
[2025-05-08T06:35:36.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:36.121+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: running: Set(ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-08T06:35:36.121+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:36.121+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:36.136+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:41027 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 19) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.212+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 92 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:36.212+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-05-08T06:35:36.212+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: ShuffleMapStage 16 (collect at GraphFrame.scala:574) finished in 1.507 s
[2025-05-08T06:35:36.213+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:36.213+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: running: Set(ResultStage 20, ResultStage 18)
[2025-05-08T06:35:36.213+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:36.213+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:36.228+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.229+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO ShufflePartitionsUtil: For shuffle(6, 7, 8, 9, 10, 11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:36.237+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.20.0.5:43674
[2025-05-08T06:35:36.247+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_12_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.251+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.269+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_14_piece0 on f2a432e4376a:46195 in memory (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.302+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.303+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.20.0.5:41027 in memory (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.303+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 19) in 92 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:36.303+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-05-08T06:35:36.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.823 s
[2025-05-08T06:35:36.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:36.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-05-08T06:35:36.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.831513 s
[2025-05-08T06:35:36.322+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_10_piece0 on f2a432e4376a:46195 in memory (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.324+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.20.0.5:41027 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.338+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:43674
[2025-05-08T06:35:36.340+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO CodeGenerator: Code generated in 8.479975 ms
[2025-05-08T06:35:36.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_9_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.344+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO CodeGenerator: Code generated in 9.536204 ms
[2025-05-08T06:35:36.353+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:36.354+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 53 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:36.355+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-05-08T06:35:36.356+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.763 s
[2025-05-08T06:35:36.357+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:36.357+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2025-05-08T06:35:36.357+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.772323 s
[2025-05-08T06:35:36.358+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_11_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.359+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.373+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-08T06:35:36.374+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 430.2 MiB)
[2025-05-08T06:35:36.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on f2a432e4376a:46195 (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:36.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO CodeGenerator: Code generated in 26.879972 ms
[2025-05-08T06:35:36.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_16_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.404+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:36.408+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_15_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:36.408+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.409+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 5.0 MiB, free 425.2 MiB)
[2025-05-08T06:35:36.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_13_piece0 on f2a432e4376a:46195 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.425+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.20.0.5:41027 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.428+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO CodeGenerator: Code generated in 19.97115 ms
[2025-05-08T06:35:36.445+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 424.7 MiB)
[2025-05-08T06:35:36.447+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on f2a432e4376a:46195 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-08T06:35:36.449+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO SparkContext: Created broadcast 18 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:36.453+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:36.469+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO CodeGenerator: Code generated in 13.512114 ms
[2025-05-08T06:35:36.475+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:36.488+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO CodeGenerator: Code generated in 9.791585 ms
[2025-05-08T06:35:36.495+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:36.508+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO CodeGenerator: Code generated in 10.33018 ms
[2025-05-08T06:35:36.516+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:36.530+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO CodeGenerator: Code generated in 11.922252 ms
[2025-05-08T06:35:36.557+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:36.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Got job 16 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-08T06:35:36.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Final stage: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:36.560+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24, ShuffleMapStage 21, ShuffleMapStage 25, ShuffleMapStage 22, ShuffleMapStage 26, ShuffleMapStage 23)
[2025-05-08T06:35:36.560+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:36.561+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[104] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:36.568+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 91.7 KiB, free 424.6 MiB)
[2025-05-08T06:35:36.578+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 424.6 MiB)
[2025-05-08T06:35:36.580+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on f2a432e4376a:46195 (size: 30.3 KiB, free: 433.8 MiB)
[2025-05-08T06:35:36.581+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:36.582+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 27 (MapPartitionsRDD[104] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:35:36.582+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSchedulerImpl: Adding task set 27.0 with 6 tasks resource profile 0
[2025-05-08T06:35:36.582+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.598+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.20.0.5:41027 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-08T06:35:36.623+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.20.0.5:43674
[2025-05-08T06:35:36.650+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 22) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.651+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 69 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:35:36.665+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.20.0.5:43674
[2025-05-08T06:35:36.704+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 23) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.704+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 22) in 54 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:35:36.733+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.20.0.5:43674
[2025-05-08T06:35:36.765+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 24) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.767+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 23) in 64 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:35:36.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.20.0.5:43674
[2025-05-08T06:35:36.836+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 25) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.865+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 24) in 91 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:35:36.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.20.0.5:43674
[2025-05-08T06:35:36.950+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 26) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:36.951+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 25) in 116 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:35:36.963+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:43674
[2025-05-08T06:35:37.003+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 26) in 51 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:35:37.004+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-05-08T06:35:37.005+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.438 s
[2025-05-08T06:35:37.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:37.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-05-08T06:35:37.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: Job 16 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.445923 s
[2025-05-08T06:35:37.024+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO BlockManagerInfo: Removed broadcast_19_piece0 on f2a432e4376a:46195 in memory (size: 30.3 KiB, free: 433.9 MiB)
[2025-05-08T06:35:37.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.20.0.5:41027 in memory (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-08T06:35:37.040+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 2.3 MiB, free 422.5 MiB)
[2025-05-08T06:35:37.050+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 422.4 MiB)
[2025-05-08T06:35:37.051+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on f2a432e4376a:46195 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-08T06:35:37.051+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO SparkContext: Created broadcast 20 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:37.201+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO CodeGenerator: Code generated in 43.541055 ms
[2025-05-08T06:35:37.202+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:37.275+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO CodeGenerator: Code generated in 41.348282 ms
[2025-05-08T06:35:37.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO CodeGenerator: Code generated in 6.340161 ms
[2025-05-08T06:35:37.345+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: Registering RDD 111 (collect at GraphFrame.scala:574) as input to shuffle 12
[2025-05-08T06:35:37.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: Got map stage job 17 (collect at GraphFrame.scala:574) with 11 output partitions
[2025-05-08T06:35:37.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:37.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
[2025-05-08T06:35:37.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:37.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[111] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:37.352+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 141.0 KiB, free 422.2 MiB)
[2025-05-08T06:35:37.359+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 49.7 KiB, free 422.2 MiB)
[2025-05-08T06:35:37.363+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on f2a432e4376a:46195 (size: 49.7 KiB, free: 433.7 MiB)
[2025-05-08T06:35:37.363+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:37.363+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[111] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-08T06:35:37.364+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSchedulerImpl: Adding task set 29.0 with 11 tasks resource profile 0
[2025-05-08T06:35:37.364+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 27) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:37.380+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.20.0.5:41027 (size: 49.7 KiB, free: 434.4 MiB)
[2025-05-08T06:35:37.481+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:43674
[2025-05-08T06:35:37.541+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.20.0.5:41027 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-08T06:35:37.579+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.20.0.5:41027 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-08T06:35:37.628+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.20.0.5:41027 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-08T06:35:37.772+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 28) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:37.773+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 27) in 408 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-08T06:35:37.824+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 29) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:37.826+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 28) in 56 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-08T06:35:37.880+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 30) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:37.880+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 29) in 56 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-08T06:35:37.924+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 31) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:37.924+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 30) in 45 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-08T06:35:37.967+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 32) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:37.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:37 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 31) in 47 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-08T06:35:38.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Starting task 6.0 in stage 29.0 (TID 33) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:38.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 32) in 70 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-08T06:35:38.071+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Starting task 7.0 in stage 29.0 (TID 34) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:38.072+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Finished task 6.0 in stage 29.0 (TID 33) in 37 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-08T06:35:38.115+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Starting task 8.0 in stage 29.0 (TID 35) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:38.117+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Finished task 7.0 in stage 29.0 (TID 34) in 45 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-08T06:35:38.154+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Starting task 9.0 in stage 29.0 (TID 36) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:38.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Finished task 8.0 in stage 29.0 (TID 35) in 40 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-08T06:35:38.191+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Starting task 10.0 in stage 29.0 (TID 37) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:38.191+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Finished task 9.0 in stage 29.0 (TID 36) in 38 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-08T06:35:38.272+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Finished task 10.0 in stage 29.0 (TID 37) in 82 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-08T06:35:38.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-05-08T06:35:38.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: ShuffleMapStage 29 (collect at GraphFrame.scala:574) finished in 0.925 s
[2025-05-08T06:35:38.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:38.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:38.274+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:38.274+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:38.279+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:38.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:38.325+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO CodeGenerator: Code generated in 20.329883 ms
[2025-05-08T06:35:38.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Registering RDD 114 (collect at GraphFrame.scala:574) as input to shuffle 13
[2025-05-08T06:35:38.347+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Got map stage job 18 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T06:35:38.347+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:38.347+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
[2025-05-08T06:35:38.347+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:38.347+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[114] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:38.353+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 129.7 KiB, free 422.1 MiB)
[2025-05-08T06:35:38.363+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 44.3 KiB, free 422.0 MiB)
[2025-05-08T06:35:38.366+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on f2a432e4376a:46195 (size: 44.3 KiB, free: 433.7 MiB)
[2025-05-08T06:35:38.369+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Removed broadcast_21_piece0 on f2a432e4376a:46195 in memory (size: 49.7 KiB, free: 433.7 MiB)
[2025-05-08T06:35:38.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:38.372+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[114] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:38.373+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-05-08T06:35:38.373+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 38) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:38.374+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.20.0.5:41027 in memory (size: 49.7 KiB, free: 433.8 MiB)
[2025-05-08T06:35:38.391+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.20.0.5:41027 (size: 44.3 KiB, free: 433.7 MiB)
[2025-05-08T06:35:38.427+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:43674
[2025-05-08T06:35:38.539+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 38) in 169 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:38.539+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-05-08T06:35:38.541+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: ShuffleMapStage 32 (collect at GraphFrame.scala:574) finished in 0.193 s
[2025-05-08T06:35:38.542+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:38.542+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:38.543+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:38.543+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:38.547+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:38.563+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:38.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO CodeGenerator: Code generated in 6.232313 ms
[2025-05-08T06:35:38.592+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO SparkContext: Starting job: collect at GraphFrame.scala:574
[2025-05-08T06:35:38.593+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Got job 19 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T06:35:38.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Final stage: ResultStage 36 (collect at GraphFrame.scala:574)
[2025-05-08T06:35:38.595+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-05-08T06:35:38.595+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:38.595+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[117] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T06:35:38.600+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 122.6 KiB, free 422.1 MiB)
[2025-05-08T06:35:38.607+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 41.9 KiB, free 422.0 MiB)
[2025-05-08T06:35:38.608+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on f2a432e4376a:46195 (size: 41.9 KiB, free: 433.7 MiB)
[2025-05-08T06:35:38.608+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:38.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[117] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:38.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-05-08T06:35:38.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Removed broadcast_22_piece0 on f2a432e4376a:46195 in memory (size: 44.3 KiB, free: 433.7 MiB)
[2025-05-08T06:35:38.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.20.0.5:41027 in memory (size: 44.3 KiB, free: 433.8 MiB)
[2025-05-08T06:35:38.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 39) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:38.630+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.20.0.5:41027 (size: 41.9 KiB, free: 433.7 MiB)
[2025-05-08T06:35:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:43674
[2025-05-08T06:35:38.687+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 39) in 72 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:38.688+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-05-08T06:35:38.698+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: ResultStage 36 (collect at GraphFrame.scala:574) finished in 0.098 s
[2025-05-08T06:35:38.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:38.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-05-08T06:35:38.702+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO DAGScheduler: Job 19 finished: collect at GraphFrame.scala:574, took 0.107424 s
[2025-05-08T06:35:38.963+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Removed broadcast_23_piece0 on f2a432e4376a:46195 in memory (size: 41.9 KiB, free: 433.7 MiB)
[2025-05-08T06:35:38.966+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:38 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.20.0.5:41027 in memory (size: 41.9 KiB, free: 433.8 MiB)
[2025-05-08T06:35:39.312+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Registering RDD 148 (rdd at GraphFrame.scala:188) as input to shuffle 14
[2025-05-08T06:35:39.313+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got map stage job 20 (rdd at GraphFrame.scala:188) with 6 output partitions
[2025-05-08T06:35:39.313+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:39.313+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:39.313+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.313+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[148] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:39.316+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 36.4 KiB, free 422.3 MiB)
[2025-05-08T06:35:39.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 422.3 MiB)
[2025-05-08T06:35:39.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:39.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on f2a432e4376a:46195 (size: 11.2 KiB, free: 433.7 MiB)
[2025-05-08T06:35:39.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[148] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:35:39.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 37.0 with 6 tasks resource profile 0
[2025-05-08T06:35:39.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Registering RDD 150 (rdd at GraphFrame.scala:188) as input to shuffle 15
[2025-05-08T06:35:39.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got map stage job 21 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T06:35:39.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 40) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:39.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:39.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.333+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[150] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:39.340+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:39.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 12.6 KiB, free 422.3 MiB)
[2025-05-08T06:35:39.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 422.3 MiB)
[2025-05-08T06:35:39.350+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on f2a432e4376a:46195 (size: 6.8 KiB, free: 433.7 MiB)
[2025-05-08T06:35:39.351+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.351+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[150] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:39.351+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
[2025-05-08T06:35:39.355+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:39.355+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Registering RDD 152 (rdd at GraphFrame.scala:188) as input to shuffle 16
[2025-05-08T06:35:39.355+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got map stage job 22 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T06:35:39.355+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:39.355+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:39.355+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.359+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[152] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:39.363+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.20.0.5:41027 (size: 11.2 KiB, free: 433.8 MiB)
[2025-05-08T06:35:39.365+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:39.366+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 27.3 KiB, free 422.3 MiB)
[2025-05-08T06:35:39.368+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 422.3 MiB)
[2025-05-08T06:35:39.368+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-08T06:35:39.369+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[152] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:39.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-05-08T06:35:39.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Registering RDD 154 (rdd at GraphFrame.scala:188) as input to shuffle 17
[2025-05-08T06:35:39.373+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got map stage job 23 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T06:35:39.374+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:39.374+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:39.374+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.375+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[154] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:39.379+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-08T06:35:39.381+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 422.2 MiB)
[2025-05-08T06:35:39.382+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on f2a432e4376a:46195 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-08T06:35:39.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:39.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[154] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:39.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-05-08T06:35:39.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Registering RDD 156 (rdd at GraphFrame.scala:188) as input to shuffle 18
[2025-05-08T06:35:39.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got map stage job 24 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T06:35:39.388+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:39.388+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:39.388+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.397+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:39.400+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:39.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-08T06:35:39.403+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 422.2 MiB)
[2025-05-08T06:35:39.404+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-08T06:35:39.406+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 41) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 40) in 76 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:35:39.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:39.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-05-08T06:35:39.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Registering RDD 158 (rdd at GraphFrame.scala:188) as input to shuffle 19
[2025-05-08T06:35:39.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got map stage job 25 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T06:35:39.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:39.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:39.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.430+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[158] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:39.444+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 27.4 KiB, free 422.2 MiB)
[2025-05-08T06:35:39.449+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 422.1 MiB)
[2025-05-08T06:35:39.450+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-08T06:35:39.450+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.450+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[158] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:39.450+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-05-08T06:35:39.455+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_20_piece0 on f2a432e4376a:46195 in memory (size: 114.2 KiB, free: 433.8 MiB)
[2025-05-08T06:35:39.458+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Registering RDD 160 (rdd at GraphFrame.scala:188) as input to shuffle 20
[2025-05-08T06:35:39.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got map stage job 26 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T06:35:39.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:39.463+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:39.465+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.466+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 42) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.466+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 41) in 55 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:35:39.466+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:39.466+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.20.0.5:41027 in memory (size: 114.2 KiB, free: 433.9 MiB)
[2025-05-08T06:35:39.470+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 28.5 KiB, free 424.5 MiB)
[2025-05-08T06:35:39.487+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 424.5 MiB)
[2025-05-08T06:35:39.493+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on f2a432e4376a:46195 (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-08T06:35:39.498+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.499+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:39.503+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
[2025-05-08T06:35:39.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_17_piece0 on f2a432e4376a:46195 in memory (size: 20.6 KiB, free: 433.8 MiB)
[2025-05-08T06:35:39.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Registering RDD 162 (rdd at GraphFrame.scala:188) as input to shuffle 21
[2025-05-08T06:35:39.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got map stage job 27 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T06:35:39.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ShuffleMapStage 44 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:39.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:39.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.510+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[162] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:39.511+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 43) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.513+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.20.0.5:41027 in memory (size: 20.6 KiB, free: 433.9 MiB)
[2025-05-08T06:35:39.517+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 31.7 KiB, free 426.5 MiB)
[2025-05-08T06:35:39.519+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 426.5 MiB)
[2025-05-08T06:35:39.520+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 42) in 57 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:35:39.520+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on f2a432e4376a:46195 (size: 14.9 KiB, free: 433.8 MiB)
[2025-05-08T06:35:39.520+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.520+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[162] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:39.520+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-05-08T06:35:39.526+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_18_piece0 on f2a432e4376a:46195 in memory (size: 502.1 KiB, free: 434.3 MiB)
[2025-05-08T06:35:39.532+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.20.0.5:41027 in memory (size: 502.1 KiB, free: 434.4 MiB)
[2025-05-08T06:35:39.595+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 44) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.598+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 43) in 88 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:35:39.637+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 45) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.638+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 44) in 43 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:35:39.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 46) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.676+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 45) in 38 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:35:39.676+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-05-08T06:35:39.676+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: ShuffleMapStage 37 (rdd at GraphFrame.scala:188) finished in 0.362 s
[2025-05-08T06:35:39.676+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:39.676+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: running: Set(ShuffleMapStage 38, ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-08T06:35:39.677+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:39.677+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:39.691+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.20.0.5:41027 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:39.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:39.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:39.719+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 46) in 44 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:39.720+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2025-05-08T06:35:39.720+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 47) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: ShuffleMapStage 38 (rdd at GraphFrame.scala:188) finished in 0.387 s
[2025-05-08T06:35:39.722+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:39.722+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: running: Set(ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-08T06:35:39.722+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:39.722+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:39.728+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:39.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:35:39.731+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:39.731+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
[2025-05-08T06:35:39.731+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.731+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[165] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:39.733+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-08T06:35:39.749+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 432.0 MiB)
[2025-05-08T06:35:39.750+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on f2a432e4376a:46195 (size: 3.9 KiB, free: 434.3 MiB)
[2025-05-08T06:35:39.751+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.751+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[165] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:39.754+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-05-08T06:35:39.755+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_25_piece0 on f2a432e4376a:46195 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:39.756+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.20.0.5:41027 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T06:35:39.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.20.0.5:41027 in memory (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-08T06:35:39.769+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Removed broadcast_24_piece0 on f2a432e4376a:46195 in memory (size: 11.2 KiB, free: 434.3 MiB)
[2025-05-08T06:35:39.769+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-08T06:35:39.776+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:39.777+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:39.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:39.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:39.802+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:35:39.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:39.806+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-05-08T06:35:39.807+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:39.808+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[168] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:39.812+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-08T06:35:39.842+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-08T06:35:39.843+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 48) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.843+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:39.844+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 47) in 121 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:39.844+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-05-08T06:35:39.844+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:39.845+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[168] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:39.845+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-05-08T06:35:39.854+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: ShuffleMapStage 39 (rdd at GraphFrame.scala:188) finished in 0.494 s
[2025-05-08T06:35:39.854+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:39.855+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-08T06:35:39.855+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:39.858+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:39.862+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.20.0.5:41027 (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:39.900+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 49) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.900+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 48) in 60 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:39.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-05-08T06:35:39.902+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: ShuffleMapStage 40 (rdd at GraphFrame.scala:188) finished in 0.527 s
[2025-05-08T06:35:39.902+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:39.903+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-08T06:35:39.903+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:39.903+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:39.918+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-08T06:35:39.956+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 50) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:39.956+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 49) in 57 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:39.961+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-05-08T06:35:39.962+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: ShuffleMapStage 41 (rdd at GraphFrame.scala:188) finished in 0.562 s
[2025-05-08T06:35:39.962+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:39.963+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-08T06:35:39.963+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:39.963+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:39.974+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.000+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:39 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 51) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.000+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 50) in 45 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:40.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-05-08T06:35:40.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: ShuffleMapStage 42 (rdd at GraphFrame.scala:188) finished in 0.570 s
[2025-05-08T06:35:40.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:40.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-08T06:35:40.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:40.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:40.008+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.20.0.5:41027 (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 52) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.040+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 51) in 40 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:40.040+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-05-08T06:35:40.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: ShuffleMapStage 43 (rdd at GraphFrame.scala:188) finished in 0.578 s
[2025-05-08T06:35:40.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:40.043+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 44)
[2025-05-08T06:35:40.043+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:40.043+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:40.051+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.20.0.5:41027 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.096+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 53) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.097+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 52) in 59 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:40.097+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-05-08T06:35:40.098+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: ShuffleMapStage 44 (rdd at GraphFrame.scala:188) finished in 0.590 s
[2025-05-08T06:35:40.098+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:40.098+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46)
[2025-05-08T06:35:40.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:40.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:40.110+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.20.0.5:41027 (size: 3.9 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.114+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:43674
[2025-05-08T06:35:40.119+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO ShufflePartitionsUtil: For shuffle(16, 17, 18, 19, 20, 21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:40.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 54) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 53) in 38 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:40.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-05-08T06:35:40.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.403 s
[2025-05-08T06:35:40.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:40.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
[2025-05-08T06:35:40.136+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.407649 s
[2025-05-08T06:35:40.141+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO CodeGenerator: Code generated in 7.277782 ms
[2025-05-08T06:35:40.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:40.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.148+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:43674
[2025-05-08T06:35:40.154+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 54) in 21 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:40.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-05-08T06:35:40.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.347 s
[2025-05-08T06:35:40.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO CodeGenerator: Code generated in 11.872008 ms
[2025-05-08T06:35:40.157+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:40.157+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-05-08T06:35:40.157+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.355171 s
[2025-05-08T06:35:40.165+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:40.166+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 2.1 MiB, free 430.0 MiB)
[2025-05-08T06:35:40.176+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 430.0 MiB)
[2025-05-08T06:35:40.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on f2a432e4376a:46195 (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 5.0 MiB, free 425.0 MiB)
[2025-05-08T06:35:40.178+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO SparkContext: Created broadcast 34 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:40.182+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_27_piece0 on f2a432e4376a:46195 in memory (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.185+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.20.0.5:41027 in memory (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.193+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO CodeGenerator: Code generated in 26.301307 ms
[2025-05-08T06:35:40.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.197+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_33_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.199+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 424.5 MiB)
[2025-05-08T06:35:40.201+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on f2a432e4376a:46195 (size: 502.1 KiB, free: 433.8 MiB)
[2025-05-08T06:35:40.203+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:40.204+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:40.219+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_29_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 433.8 MiB)
[2025-05-08T06:35:40.220+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.225+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:40.233+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_32_piece0 on f2a432e4376a:46195 in memory (size: 3.9 KiB, free: 433.8 MiB)
[2025-05-08T06:35:40.235+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.20.0.5:41027 in memory (size: 3.9 KiB, free: 434.3 MiB)
[2025-05-08T06:35:40.240+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO CodeGenerator: Code generated in 11.533751 ms
[2025-05-08T06:35:40.248+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:40.270+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_26_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 433.8 MiB)
[2025-05-08T06:35:40.274+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-08T06:35:40.278+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO CodeGenerator: Code generated in 27.229982 ms
[2025-05-08T06:35:40.285+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_31_piece0 on f2a432e4376a:46195 in memory (size: 14.9 KiB, free: 433.8 MiB)
[2025-05-08T06:35:40.296+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:40.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.20.0.5:41027 in memory (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-08T06:35:40.301+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_30_piece0 on f2a432e4376a:46195 in memory (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-08T06:35:40.303+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.20.0.5:41027 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-08T06:35:40.304+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO CodeGenerator: Code generated in 13.220906 ms
[2025-05-08T06:35:40.311+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_28_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 433.9 MiB)
[2025-05-08T06:35:40.314+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-08T06:35:40.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:40.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-08T06:35:40.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:40.333+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 49, ShuffleMapStage 53, ShuffleMapStage 50, ShuffleMapStage 54)
[2025-05-08T06:35:40.333+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:40.333+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:40.337+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 91.7 KiB, free 424.6 MiB)
[2025-05-08T06:35:40.338+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 424.6 MiB)
[2025-05-08T06:35:40.339+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on f2a432e4376a:46195 (size: 30.3 KiB, free: 433.8 MiB)
[2025-05-08T06:35:40.339+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:40.340+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 55 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:35:40.340+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Adding task set 55.0 with 6 tasks resource profile 0
[2025-05-08T06:35:40.340+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.354+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.20.0.5:41027 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-08T06:35:40.361+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:43674
[2025-05-08T06:35:40.429+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 56) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.444+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:43674
[2025-05-08T06:35:40.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 118 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:35:40.480+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 57) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.481+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 56) in 51 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:35:40.488+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:43674
[2025-05-08T06:35:40.500+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 58) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 57) in 23 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:35:40.508+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.20.0.5:43674
[2025-05-08T06:35:40.534+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 4.0 in stage 55.0 (TID 59) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.534+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 58) in 34 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:35:40.547+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.20.0.5:43674
[2025-05-08T06:35:40.571+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 5.0 in stage 55.0 (TID 60) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.572+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 4.0 in stage 55.0 (TID 59) in 39 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:35:40.583+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.20.0.5:43674
[2025-05-08T06:35:40.616+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 5.0 in stage 55.0 (TID 60) in 44 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:35:40.617+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-05-08T06:35:40.619+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.284 s
[2025-05-08T06:35:40.619+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:40.619+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-05-08T06:35:40.620+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.290677 s
[2025-05-08T06:35:40.631+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 2.3 MiB, free 422.4 MiB)
[2025-05-08T06:35:40.648+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 422.3 MiB)
[2025-05-08T06:35:40.649+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on f2a432e4376a:46195 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-08T06:35:40.649+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO SparkContext: Created broadcast 37 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:40.661+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.20.0.5:41027 in memory (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-08T06:35:40.663+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Removed broadcast_36_piece0 on f2a432e4376a:46195 in memory (size: 30.3 KiB, free: 433.7 MiB)
[2025-05-08T06:35:40.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:40.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO CodeGenerator: Code generated in 39.903606 ms
[2025-05-08T06:35:40.837+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO CodeGenerator: Code generated in 6.185118 ms
[2025-05-08T06:35:40.845+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Registering RDD 198 (rdd at GraphFrame.scala:188) as input to shuffle 22
[2025-05-08T06:35:40.845+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Got map stage job 31 (rdd at GraphFrame.scala:188) with 11 output partitions
[2025-05-08T06:35:40.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Final stage: ShuffleMapStage 57 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:40.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-05-08T06:35:40.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:40.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[198] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:40.856+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 129.6 KiB, free 422.2 MiB)
[2025-05-08T06:35:40.857+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 44.9 KiB, free 422.2 MiB)
[2025-05-08T06:35:40.857+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on f2a432e4376a:46195 (size: 44.9 KiB, free: 433.7 MiB)
[2025-05-08T06:35:40.857+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:40.858+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[198] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-08T06:35:40.858+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSchedulerImpl: Adding task set 57.0 with 11 tasks resource profile 0
[2025-05-08T06:35:40.859+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 61) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.869+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.20.0.5:41027 (size: 44.9 KiB, free: 434.4 MiB)
[2025-05-08T06:35:40.889+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:43674
[2025-05-08T06:35:40.923+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:41027 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-08T06:35:40.941+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.20.0.5:41027 (size: 114.2 KiB, free: 433.8 MiB)
[2025-05-08T06:35:40.959+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.20.0.5:41027 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-08T06:35:40.992+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 62) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:40.992+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:40 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 61) in 133 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-08T06:35:41.023+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 63) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.024+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 62) in 32 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-08T06:35:41.076+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 64) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.077+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 63) in 52 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-08T06:35:41.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 4.0 in stage 57.0 (TID 65) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.124+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 64) in 51 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-08T06:35:41.169+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 5.0 in stage 57.0 (TID 66) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.172+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 4.0 in stage 57.0 (TID 65) in 52 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-08T06:35:41.197+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 6.0 in stage 57.0 (TID 67) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.198+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 5.0 in stage 57.0 (TID 66) in 29 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-08T06:35:41.222+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 7.0 in stage 57.0 (TID 68) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.223+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 6.0 in stage 57.0 (TID 67) in 26 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-08T06:35:41.245+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 8.0 in stage 57.0 (TID 69) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.246+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 7.0 in stage 57.0 (TID 68) in 25 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-08T06:35:41.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 9.0 in stage 57.0 (TID 70) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.269+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 8.0 in stage 57.0 (TID 69) in 24 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-08T06:35:41.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 10.0 in stage 57.0 (TID 71) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.298+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 9.0 in stage 57.0 (TID 70) in 31 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-08T06:35:41.574+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 10.0 in stage 57.0 (TID 71) in 278 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-08T06:35:41.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-05-08T06:35:41.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: ShuffleMapStage 57 (rdd at GraphFrame.scala:188) finished in 0.727 s
[2025-05-08T06:35:41.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:41.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:41.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:41.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:41.584+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:41.608+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO CodeGenerator: Code generated in 10.470053 ms
[2025-05-08T06:35:41.634+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:41.637+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Got job 32 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:35:41.637+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Final stage: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:41.637+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
[2025-05-08T06:35:41.637+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:41.638+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[202] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:41.640+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 116.0 KiB, free 422.1 MiB)
[2025-05-08T06:35:41.650+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 39.4 KiB, free 422.2 MiB)
[2025-05-08T06:35:41.651+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO BlockManagerInfo: Removed broadcast_38_piece0 on f2a432e4376a:46195 in memory (size: 44.9 KiB, free: 433.7 MiB)
[2025-05-08T06:35:41.651+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on f2a432e4376a:46195 (size: 39.4 KiB, free: 433.7 MiB)
[2025-05-08T06:35:41.652+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:41.653+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[202] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:41.653+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
[2025-05-08T06:35:41.653+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 72) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.656+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.20.0.5:41027 in memory (size: 44.9 KiB, free: 433.8 MiB)
[2025-05-08T06:35:41.668+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.20.0.5:41027 (size: 39.4 KiB, free: 433.7 MiB)
[2025-05-08T06:35:41.677+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.20.0.5:43674
[2025-05-08T06:35:41.788+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 72) in 135 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:41.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-08T06:35:41.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.153 s
[2025-05-08T06:35:41.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:41.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
[2025-05-08T06:35:41.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Job 32 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.154872 s
[2025-05-08T06:35:41.797+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 2.0 MiB, free 420.2 MiB)
[2025-05-08T06:35:41.822+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 96.0 KiB, free 420.1 MiB)
[2025-05-08T06:35:41.823+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on f2a432e4376a:46195 (size: 96.0 KiB, free: 433.6 MiB)
[2025-05-08T06:35:41.823+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO SparkContext: Created broadcast 40 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:41.831+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO BlockManagerInfo: Removed broadcast_39_piece0 on f2a432e4376a:46195 in memory (size: 39.4 KiB, free: 433.7 MiB)
[2025-05-08T06:35:41.832+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.20.0.5:41027 in memory (size: 39.4 KiB, free: 433.8 MiB)
[2025-05-08T06:35:41.890+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO CodeGenerator: Code generated in 31.710215 ms
[2025-05-08T06:35:41.891+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1528 - id.nullCount#1527) > 0)
[2025-05-08T06:35:41.945+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Registering RDD 19 (rdd at GraphFrame.scala:187) as input to shuffle 3
[2025-05-08T06:35:41.956+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Registering RDD 207 (rdd at GraphFrame.scala:188) as input to shuffle 23
[2025-05-08T06:35:41.957+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Got map stage job 33 (rdd at GraphFrame.scala:188) with 10 output partitions
[2025-05-08T06:35:41.958+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (rdd at GraphFrame.scala:188)
[2025-05-08T06:35:41.961+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
[2025-05-08T06:35:41.964+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
[2025-05-08T06:35:41.966+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T06:35:41.967+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.6 KiB, free 420.2 MiB)
[2025-05-08T06:35:41.967+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 420.2 MiB)
[2025-05-08T06:35:41.970+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on f2a432e4376a:46195 (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-08T06:35:41.971+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:41.972+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:41.973+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
[2025-05-08T06:35:41.974+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 73) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:41.991+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:41 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.20.0.5:41027 (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-08T06:35:42.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 73) in 64 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:42.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool
[2025-05-08T06:35:42.037+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: ShuffleMapStage 61 (rdd at GraphFrame.scala:187) finished in 0.073 s
[2025-05-08T06:35:42.037+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:42.037+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:42.037+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: waiting: Set(ShuffleMapStage 62)
[2025-05-08T06:35:42.037+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:42.040+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[207] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T06:35:42.061+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 51.0 KiB, free 420.2 MiB)
[2025-05-08T06:35:42.072+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 420.2 MiB)
[2025-05-08T06:35:42.073+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on f2a432e4376a:46195 (size: 21.8 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.073+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:42.073+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[207] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:42.073+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSchedulerImpl: Adding task set 62.0 with 10 tasks resource profile 0
[2025-05-08T06:35:42.079+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 74) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.092+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.20.0.5:41027 (size: 21.8 KiB, free: 433.8 MiB)
[2025-05-08T06:35:42.148+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:43674
[2025-05-08T06:35:42.202+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.20.0.5:41027 (size: 2.0 KiB, free: 433.7 MiB)
[2025-05-08T06:35:42.246+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.20.0.5:41027 (size: 96.0 KiB, free: 433.7 MiB)
[2025-05-08T06:35:42.258+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 75) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.258+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 74) in 180 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:42.285+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.20.0.5:41027 (size: 2.5 KiB, free: 433.7 MiB)
[2025-05-08T06:35:42.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 76) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 75) in 49 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:42.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 77) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 76) in 35 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:42.359+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.20.0.5:41027 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 4.0 in stage 62.0 (TID 78) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 77) in 30 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:42.389+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.20.0.5:41027 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.400+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 5.0 in stage 62.0 (TID 79) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 4.0 in stage 62.0 (TID 78) in 30 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:42.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.20.0.5:41027 (size: 2.0 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.423+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 6.0 in stage 62.0 (TID 80) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.424+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 5.0 in stage 62.0 (TID 79) in 23 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:42.438+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.20.0.5:41027 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.449+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 7.0 in stage 62.0 (TID 81) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.449+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 6.0 in stage 62.0 (TID 80) in 26 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:42.465+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.20.0.5:41027 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.475+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 8.0 in stage 62.0 (TID 82) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.476+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 7.0 in stage 62.0 (TID 81) in 28 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:42.493+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.20.0.5:41027 (size: 2.4 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.505+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 9.0 in stage 62.0 (TID 83) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.506+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 8.0 in stage 62.0 (TID 82) in 30 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:42.520+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.20.0.5:41027 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.529+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 9.0 in stage 62.0 (TID 83) in 25 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:42.531+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-05-08T06:35:42.531+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: ShuffleMapStage 62 (rdd at GraphFrame.scala:188) finished in 0.486 s
[2025-05-08T06:35:42.531+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:42.531+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:42.531+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:42.531+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:42.539+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:42.546+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:42.549+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Got job 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:35:42.550+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Final stage: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:42.550+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
[2025-05-08T06:35:42.550+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:42.551+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[209] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:42.552+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.2 KiB, free 420.2 MiB)
[2025-05-08T06:35:42.560+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 420.1 MiB)
[2025-05-08T06:35:42.562+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.562+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:42.562+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[209] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:42.562+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
[2025-05-08T06:35:42.564+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 84) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.568+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Removed broadcast_42_piece0 on f2a432e4376a:46195 in memory (size: 21.8 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.570+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.20.0.5:41027 in memory (size: 21.8 KiB, free: 433.7 MiB)
[2025-05-08T06:35:42.581+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Removed broadcast_41_piece0 on f2a432e4376a:46195 in memory (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-08T06:35:42.583+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-08T06:35:42.584+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.20.0.5:41027 in memory (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-08T06:35:42.587+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.20.0.5:43674
[2025-05-08T06:35:42.596+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 84) in 33 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:42.596+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool
[2025-05-08T06:35:42.597+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.047 s
[2025-05-08T06:35:42.598+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:42.598+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
[2025-05-08T06:35:42.598+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Job 34 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.050802 s
[2025-05-08T06:35:42.603+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 2.0 MiB, free 418.2 MiB)
[2025-05-08T06:35:42.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 98.0 KiB, free 418.1 MiB)
[2025-05-08T06:35:42.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on f2a432e4376a:46195 (size: 98.0 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO SparkContext: Created broadcast 44 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:42.631+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO CodeGenerator: Code generated in 6.332981 ms
[2025-05-08T06:35:42.631+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1538 - id.nullCount#1537) > 0)
[2025-05-08T06:35:42.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T06:35:42.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Registering RDD 31 (map at GraphFrame.scala:187) as input to shuffle 25
[2025-05-08T06:35:42.733+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Registering RDD 222 (mapPartitions at VertexRDD.scala:356) as input to shuffle 28
[2025-05-08T06:35:42.733+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Registering RDD 248 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 26
[2025-05-08T06:35:42.733+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Registering RDD 244 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 24
[2025-05-08T06:35:42.733+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Registering RDD 252 (mapPartitions at GraphImpl.scala:208) as input to shuffle 27
[2025-05-08T06:35:42.734+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Got job 35 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T06:35:42.734+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Final stage: ResultStage 72 (fold at VertexRDDImpl.scala:90)
[2025-05-08T06:35:42.734+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-08T06:35:42.734+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-08T06:35:42.735+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[31] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-08T06:35:42.749+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 59.1 KiB, free 418.1 MiB)
[2025-05-08T06:35:42.756+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 418.0 MiB)
[2025-05-08T06:35:42.757+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on f2a432e4376a:46195 (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:42.759+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:42.759+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Removed broadcast_43_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 433.5 MiB)
[2025-05-08T06:35:42.759+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[31] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:42.759+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSchedulerImpl: Adding task set 67.0 with 10 tasks resource profile 0
[2025-05-08T06:35:42.761+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Submitting ShuffleMapStage 68 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[222] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-08T06:35:42.765+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-08T06:35:42.766+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 85) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:42.778+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.20.0.5:41027 (size: 26.0 KiB, free: 433.6 MiB)
[2025-05-08T06:35:42.799+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 158.2 KiB, free 417.9 MiB)
[2025-05-08T06:35:42.800+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 55.7 KiB, free 417.8 MiB)
[2025-05-08T06:35:42.800+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on f2a432e4376a:46195 (size: 55.7 KiB, free: 433.5 MiB)
[2025-05-08T06:35:42.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:42.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 68 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[222] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:42.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO TaskSchedulerImpl: Adding task set 68.0 with 10 tasks resource profile 0
[2025-05-08T06:35:42.888+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.5:41027 (size: 28.8 KiB, free: 433.6 MiB)
[2025-05-08T06:35:43.668+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 86) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.669+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 85) in 906 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:43.684+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 87) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.685+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 86) in 17 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:43.704+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 88) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.705+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 2.0 in stage 67.0 (TID 87) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:43.731+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 4.0 in stage 67.0 (TID 89) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 3.0 in stage 67.0 (TID 88) in 27 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:43.750+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 5.0 in stage 67.0 (TID 90) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.750+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 4.0 in stage 67.0 (TID 89) in 19 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:43.768+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 6.0 in stage 67.0 (TID 91) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.768+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 5.0 in stage 67.0 (TID 90) in 19 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:43.778+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 7.0 in stage 67.0 (TID 92) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.779+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 6.0 in stage 67.0 (TID 91) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:43.792+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 8.0 in stage 67.0 (TID 93) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.792+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 7.0 in stage 67.0 (TID 92) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:43.804+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 9.0 in stage 67.0 (TID 94) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.805+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 8.0 in stage 67.0 (TID 93) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:43.819+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 95) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.819+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 9.0 in stage 67.0 (TID 94) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:43.819+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool
[2025-05-08T06:35:43.822+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO DAGScheduler: ShuffleMapStage 67 (map at GraphFrame.scala:187) finished in 1.083 s
[2025-05-08T06:35:43.822+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:43.822+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO DAGScheduler: running: Set(ShuffleMapStage 68)
[2025-05-08T06:35:43.823+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-08T06:35:43.823+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:43.826+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:41027 (size: 55.7 KiB, free: 433.6 MiB)
[2025-05-08T06:35:43.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.20.0.5:41027 (size: 98.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:43.936+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 96) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.936+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 95) in 117 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:43.955+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 97) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.956+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 96) in 20 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:43.970+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 98) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.970+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 97) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:43.985+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 4.0 in stage 68.0 (TID 99) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:43.985+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 98) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:43.999+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Starting task 5.0 in stage 68.0 (TID 100) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.000+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:43 INFO TaskSetManager: Finished task 4.0 in stage 68.0 (TID 99) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:44.015+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 6.0 in stage 68.0 (TID 101) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.016+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 5.0 in stage 68.0 (TID 100) in 18 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:44.035+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 7.0 in stage 68.0 (TID 102) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.035+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 6.0 in stage 68.0 (TID 101) in 20 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:44.054+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 8.0 in stage 68.0 (TID 103) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.055+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 7.0 in stage 68.0 (TID 102) in 20 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:44.073+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 9.0 in stage 68.0 (TID 104) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.073+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 8.0 in stage 68.0 (TID 103) in 19 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:44.098+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 9.0 in stage 68.0 (TID 104) in 25 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:44.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool
[2025-05-08T06:35:44.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: ShuffleMapStage 68 (mapPartitions at VertexRDD.scala:356) finished in 1.335 s
[2025-05-08T06:35:44.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:44.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:44.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-08T06:35:44.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:44.100+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: Submitting ShuffleMapStage 70 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[244] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:44.111+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 10.3 KiB, free 417.8 MiB)
[2025-05-08T06:35:44.121+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.8 MiB)
[2025-05-08T06:35:44.121+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on f2a432e4376a:46195 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.121+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Removed broadcast_45_piece0 on f2a432e4376a:46195 in memory (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.122+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:44.122+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 70 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[244] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:44.122+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSchedulerImpl: Adding task set 70.0 with 10 tasks resource profile 0
[2025-05-08T06:35:44.123+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: Submitting ShuffleMapStage 69 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[248] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:44.124+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 105) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.125+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 9.9 KiB, free 417.9 MiB)
[2025-05-08T06:35:44.126+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 417.9 MiB)
[2025-05-08T06:35:44.126+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on f2a432e4376a:46195 (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.127+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:44.131+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.20.0.5:41027 in memory (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 69 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[248] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:44.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSchedulerImpl: Adding task set 69.0 with 10 tasks resource profile 0
[2025-05-08T06:35:44.140+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.20.0.5:41027 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.20.0.5:43674
[2025-05-08T06:35:44.206+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Removed broadcast_46_piece0 on f2a432e4376a:46195 in memory (size: 55.7 KiB, free: 433.6 MiB)
[2025-05-08T06:35:44.209+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.20.0.5:41027 in memory (size: 55.7 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.20.0.5:43674
[2025-05-08T06:35:44.433+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_0 in memory on 172.20.0.5:41027 (size: 18.6 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.436+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_0 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.438+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.441+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 106) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 105) in 338 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:44.482+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.20.0.5:41027 (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.490+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 107) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.490+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 106) in 30 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:44.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_1 in memory on 172.20.0.5:41027 (size: 18.6 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.511+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_1 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.514+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.516+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.521+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 108) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.521+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 107) in 32 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:44.537+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_2 in memory on 172.20.0.5:41027 (size: 18.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.539+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_2 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.541+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.543+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.549+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 109) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.549+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 108) in 29 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:44.565+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_3 in memory on 172.20.0.5:41027 (size: 18.2 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.568+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_3 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.569+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.572+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.577+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 110) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.577+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 109) in 28 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:44.592+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_4 in memory on 172.20.0.5:41027 (size: 18.8 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_4 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.596+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.600+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:44.605+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 111) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.606+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 110) in 29 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:44.622+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_5 in memory on 172.20.0.5:41027 (size: 18.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.624+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_5 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.626+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.628+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.635+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 6.0 in stage 69.0 (TID 112) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.635+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 111) in 30 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:44.650+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_6 in memory on 172.20.0.5:41027 (size: 18.4 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.653+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_6 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.655+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.657+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.663+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 7.0 in stage 69.0 (TID 113) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.664+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 6.0 in stage 69.0 (TID 112) in 29 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:44.676+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_7 in memory on 172.20.0.5:41027 (size: 18.4 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.678+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_7 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.680+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.684+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-08T06:35:44.688+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 8.0 in stage 69.0 (TID 114) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.689+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 7.0 in stage 69.0 (TID 113) in 27 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:44.702+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_8 in memory on 172.20.0.5:41027 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-08T06:35:44.704+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_8 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-08T06:35:44.706+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-08T06:35:44.707+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-08T06:35:44.712+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 9.0 in stage 69.0 (TID 115) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 8.0 in stage 69.0 (TID 114) in 24 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:44.727+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_225_9 in memory on 172.20.0.5:41027 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-08T06:35:44.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_230_9 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-08T06:35:44.733+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_236_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-08T06:35:44.735+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_240_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-08T06:35:44.741+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 116) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.742+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 9.0 in stage 69.0 (TID 115) in 30 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:44.742+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-08T06:35:44.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: ShuffleMapStage 69 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.618 s
[2025-05-08T06:35:44.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:44.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: running: Set(ShuffleMapStage 70)
[2025-05-08T06:35:44.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-08T06:35:44.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:44.757+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 117) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.757+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 116) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:44.767+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 118) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.768+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 117) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:44.777+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 119) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.777+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 118) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:44.786+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 5.0 in stage 70.0 (TID 120) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.786+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 119) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:44.793+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 6.0 in stage 70.0 (TID 121) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.793+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 5.0 in stage 70.0 (TID 120) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:44.802+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 7.0 in stage 70.0 (TID 122) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 6.0 in stage 70.0 (TID 121) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:44.809+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 8.0 in stage 70.0 (TID 123) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.809+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 7.0 in stage 70.0 (TID 122) in 7 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:44.818+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 9.0 in stage 70.0 (TID 124) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.819+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 8.0 in stage 70.0 (TID 123) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:44.826+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 9.0 in stage 70.0 (TID 124) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:44.826+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-05-08T06:35:44.826+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: ShuffleMapStage 70 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.724 s
[2025-05-08T06:35:44.826+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:44.827+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:44.827+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-08T06:35:44.827+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:44.827+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: Submitting ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[252] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:44.836+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 162.8 KiB, free 417.9 MiB)
[2025-05-08T06:35:44.847+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 57.5 KiB, free 417.9 MiB)
[2025-05-08T06:35:44.848+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on f2a432e4376a:46195 (size: 57.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.850+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:44.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[252] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:44.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSchedulerImpl: Adding task set 71.0 with 10 tasks resource profile 0
[2025-05-08T06:35:44.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 125) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.853+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Removed broadcast_48_piece0 on f2a432e4376a:46195 in memory (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.855+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.20.0.5:41027 in memory (size: 4.9 KiB, free: 433.2 MiB)
[2025-05-08T06:35:44.860+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.20.0.5:41027 (size: 57.5 KiB, free: 433.1 MiB)
[2025-05-08T06:35:44.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_228_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:44.911+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_232_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:44.915+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_238_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:44.917+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.20.0.5:43674
[2025-05-08T06:35:44.922+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_246_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:44.923+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.20.0.5:43674
[2025-05-08T06:35:44.938+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Removed broadcast_47_piece0 on f2a432e4376a:46195 in memory (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:44.938+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.20.0.5:41027 in memory (size: 5.0 KiB, free: 433.1 MiB)
[2025-05-08T06:35:44.944+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 126) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:44.945+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 125) in 94 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:44.966+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_228_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:44.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_232_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:44.987+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_238_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:44.995+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:44 INFO BlockManagerInfo: Added rdd_246_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.003+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 127) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.003+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 126) in 59 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:45.031+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_228_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.034+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_232_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.038+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_238_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.043+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_246_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.051+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 128) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.053+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 127) in 51 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:45.092+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_228_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.098+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_232_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.115+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_238_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.122+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_246_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.129+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 129) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.130+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 128) in 78 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:45.152+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_228_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.154+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_232_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_238_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_246_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.167+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 130) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.167+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 129) in 39 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:45.184+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_228_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.186+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_232_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.188+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_238_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.191+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_246_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.195+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 6.0 in stage 71.0 (TID 131) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 130) in 28 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:45.210+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_228_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_232_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.212+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_238_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.218+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_246_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.225+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 7.0 in stage 71.0 (TID 132) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.225+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 6.0 in stage 71.0 (TID 131) in 30 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:45.241+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_228_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.242+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_232_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.243+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_238_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.246+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_246_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.252+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 8.0 in stage 71.0 (TID 133) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.252+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 7.0 in stage 71.0 (TID 132) in 28 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:45.265+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_228_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_232_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.268+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_238_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.271+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_246_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.276+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 9.0 in stage 71.0 (TID 134) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.277+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 8.0 in stage 71.0 (TID 133) in 26 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:45.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_228_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.295+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_232_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_238_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.301+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_246_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 9.0 in stage 71.0 (TID 134) in 29 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:45.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-05-08T06:35:45.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: ShuffleMapStage 71 (mapPartitions at GraphImpl.scala:208) finished in 0.477 s
[2025-05-08T06:35:45.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:45.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:45.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: waiting: Set(ResultStage 72)
[2025-05-08T06:35:45.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:45.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[256] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T06:35:45.308+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 11.2 KiB, free 417.9 MiB)
[2025-05-08T06:35:45.318+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.9 MiB)
[2025-05-08T06:35:45.319+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on f2a432e4376a:46195 (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:45.319+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:45.319+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 72 (MapPartitionsRDD[256] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:45.319+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSchedulerImpl: Adding task set 72.0 with 10 tasks resource profile 0
[2025-05-08T06:35:45.320+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 135) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.20.0.5:41027 (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.20.0.5:43674
[2025-05-08T06:35:45.339+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_0 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 136) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 135) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:45.362+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_1 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.366+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 137) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.368+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 136) in 27 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:45.374+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_2 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:45.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 138) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.377+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 137) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:45.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_3 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:45.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 4.0 in stage 72.0 (TID 139) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 138) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:45.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_4 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:45.394+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 5.0 in stage 72.0 (TID 140) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.395+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 4.0 in stage 72.0 (TID 139) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:45.403+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_5 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:45.405+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 6.0 in stage 72.0 (TID 141) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.406+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 5.0 in stage 72.0 (TID 140) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:45.412+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_6 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:45.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 7.0 in stage 72.0 (TID 142) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 6.0 in stage 72.0 (TID 141) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:45.422+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_7 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:45.424+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 8.0 in stage 72.0 (TID 143) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.425+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 7.0 in stage 72.0 (TID 142) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:45.431+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_8 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 9.0 in stage 72.0 (TID 144) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 8.0 in stage 72.0 (TID 143) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:45.439+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_254_9 in memory on 172.20.0.5:41027 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:45.441+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 9.0 in stage 72.0 (TID 144) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:45.441+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-05-08T06:35:45.441+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: ResultStage 72 (fold at VertexRDDImpl.scala:90) finished in 0.134 s
[2025-05-08T06:35:45.442+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:45.442+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-05-08T06:35:45.442+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Job 35 finished: fold at VertexRDDImpl.scala:90, took 2.710186 s
[2025-05-08T06:35:45.443+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO ZippedPartitionsRDD2: Removing RDD 254 from persistence list
[2025-05-08T06:35:45.448+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManager: Removing RDD 254
[2025-05-08T06:35:45.655+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManager: Removing RDD 246
[2025-05-08T06:35:45.658+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Removed broadcast_50_piece0 on f2a432e4376a:46195 in memory (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:45.659+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.20.0.5:41027 in memory (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.662+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Removed broadcast_49_piece0 on f2a432e4376a:46195 in memory (size: 57.5 KiB, free: 433.6 MiB)
[2025-05-08T06:35:45.663+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.20.0.5:41027 in memory (size: 57.5 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.665+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManager: Removing RDD 254
[2025-05-08T06:35:45.706+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:45.707+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Registering RDD 259 (mapPartitions at GraphImpl.scala:208) as input to shuffle 30
[2025-05-08T06:35:45.707+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Registering RDD 277 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 31
[2025-05-08T06:35:45.707+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Registering RDD 267 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 29
[2025-05-08T06:35:45.707+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Registering RDD 281 (mapPartitions at GraphImpl.scala:208) as input to shuffle 33
[2025-05-08T06:35:45.708+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Registering RDD 289 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 32
[2025-05-08T06:35:45.708+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Got job 36 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:45.708+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Final stage: ResultStage 81 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:45.708+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78, ShuffleMapStage 73, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-08T06:35:45.708+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-08T06:35:45.709+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Submitting ShuffleMapStage 74 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[259] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:45.714+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 161.1 KiB, free 418.0 MiB)
[2025-05-08T06:35:45.720+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 56.9 KiB, free 417.9 MiB)
[2025-05-08T06:35:45.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on f2a432e4376a:46195 (size: 56.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:45.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:45.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 74 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[259] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:45.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSchedulerImpl: Adding task set 74.0 with 10 tasks resource profile 0
[2025-05-08T06:35:45.722+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 145) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.20.0.5:41027 (size: 56.9 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.769+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 146) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.770+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 145) in 47 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:45.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 147) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 146) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:45.793+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 148) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.794+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 147) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:45.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 4.0 in stage 74.0 (TID 149) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.804+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 148) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:45.813+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 5.0 in stage 74.0 (TID 150) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.813+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 4.0 in stage 74.0 (TID 149) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:45.830+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 6.0 in stage 74.0 (TID 151) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.830+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 5.0 in stage 74.0 (TID 150) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:45.842+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 7.0 in stage 74.0 (TID 152) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.843+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 6.0 in stage 74.0 (TID 151) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:45.854+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 8.0 in stage 74.0 (TID 153) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.855+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 7.0 in stage 74.0 (TID 152) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:45.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 9.0 in stage 74.0 (TID 154) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 8.0 in stage 74.0 (TID 153) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:45.883+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 9.0 in stage 74.0 (TID 154) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:45.884+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool
[2025-05-08T06:35:45.884+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: ShuffleMapStage 74 (mapPartitions at GraphImpl.scala:208) finished in 0.175 s
[2025-05-08T06:35:45.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:45.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:45.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 78, ShuffleMapStage 79, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-08T06:35:45.886+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:45.887+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Submitting ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[267] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:45.890+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 10.1 KiB, free 417.9 MiB)
[2025-05-08T06:35:45.903+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.9 MiB)
[2025-05-08T06:35:45.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on f2a432e4376a:46195 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:45.905+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:45.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[267] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:45.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSchedulerImpl: Adding task set 78.0 with 10 tasks resource profile 0
[2025-05-08T06:35:45.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Submitting ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[277] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:45.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 155) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 10.7 KiB, free 417.9 MiB)
[2025-05-08T06:35:45.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.9 MiB)
[2025-05-08T06:35:45.911+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on f2a432e4376a:46195 (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:45.911+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:45.911+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[277] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:45.912+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSchedulerImpl: Adding task set 77.0 with 10 tasks resource profile 0
[2025-05-08T06:35:45.932+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.20.0.5:41027 (size: 5.0 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.963+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.20.0.5:43674
[2025-05-08T06:35:45.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_263_0 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.975+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 156) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.976+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 155) in 67 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:45.982+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.20.0.5:41027 (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO BlockManagerInfo: Added rdd_273_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.1 MiB)
[2025-05-08T06:35:45.996+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 157) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:45.996+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:45 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 156) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:46.004+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_263_1 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-08T06:35:46.007+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_273_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.1 MiB)
[2025-05-08T06:35:46.012+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 158) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.013+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 157) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:46.022+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_263_2 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-08T06:35:46.024+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_273_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.030+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 159) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.031+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 158) in 19 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:46.040+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_263_3 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.041+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_273_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.045+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 4.0 in stage 77.0 (TID 160) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.045+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 159) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:46.053+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_263_4 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.056+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_273_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.061+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 5.0 in stage 77.0 (TID 161) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.061+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 4.0 in stage 77.0 (TID 160) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:46.071+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_263_5 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.072+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_273_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.076+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 6.0 in stage 77.0 (TID 162) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.076+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 5.0 in stage 77.0 (TID 161) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:46.086+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_263_6 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.087+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_273_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.093+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 7.0 in stage 77.0 (TID 163) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.094+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 6.0 in stage 77.0 (TID 162) in 17 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:46.102+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_263_7 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.104+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_273_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.107+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 8.0 in stage 77.0 (TID 164) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.108+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 7.0 in stage 77.0 (TID 163) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:46.115+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_263_8 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.116+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_273_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.121+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 9.0 in stage 77.0 (TID 165) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.121+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 8.0 in stage 77.0 (TID 164) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:46.127+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_263_9 in memory on 172.20.0.5:41027 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.128+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_273_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.133+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 166) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 9.0 in stage 77.0 (TID 165) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:46.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool
[2025-05-08T06:35:46.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: ShuffleMapStage 77 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.226 s
[2025-05-08T06:35:46.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:46.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: running: Set(ShuffleMapStage 78)
[2025-05-08T06:35:46.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-08T06:35:46.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:46.141+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 167) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.141+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 166) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:46.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 168) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.147+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 167) in 6 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:46.153+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 169) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.153+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 168) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:46.158+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 5.0 in stage 78.0 (TID 170) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.158+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 169) in 5 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:46.164+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 6.0 in stage 78.0 (TID 171) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.164+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 5.0 in stage 78.0 (TID 170) in 7 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:46.170+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 7.0 in stage 78.0 (TID 172) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.170+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 6.0 in stage 78.0 (TID 171) in 7 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:46.175+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 8.0 in stage 78.0 (TID 173) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.176+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 7.0 in stage 78.0 (TID 172) in 5 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:46.182+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 9.0 in stage 78.0 (TID 174) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 8.0 in stage 78.0 (TID 173) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:46.189+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 9.0 in stage 78.0 (TID 174) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:46.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-05-08T06:35:46.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: ShuffleMapStage 78 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.302 s
[2025-05-08T06:35:46.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:46.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:46.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-08T06:35:46.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:46.191+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Submitting ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[281] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:46.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 163.7 KiB, free 417.7 MiB)
[2025-05-08T06:35:46.209+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_51_piece0 on f2a432e4376a:46195 in memory (size: 56.9 KiB, free: 433.6 MiB)
[2025-05-08T06:35:46.209+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.7 MiB)
[2025-05-08T06:35:46.209+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on f2a432e4376a:46195 (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:46.210+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:46.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[281] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:46.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Adding task set 79.0 with 10 tasks resource profile 0
[2025-05-08T06:35:46.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.20.0.5:41027 in memory (size: 56.9 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.212+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 175) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.216+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_53_piece0 on f2a432e4376a:46195 in memory (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:46.218+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.20.0.5:41027 in memory (size: 5.3 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.221+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.20.0.5:41027 (size: 58.0 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.237+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.238+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:43674
[2025-05-08T06:35:46.245+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.259+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:43674
[2025-05-08T06:35:46.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 176) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.268+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 175) in 57 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:46.278+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.287+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 177) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.287+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 176) in 20 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:46.295+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.299+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.303+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 178) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.303+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 177) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:46.314+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.318+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.323+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 4.0 in stage 79.0 (TID 179) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.323+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 178) in 21 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:46.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.338+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 5.0 in stage 79.0 (TID 180) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.338+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 4.0 in stage 79.0 (TID 179) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:46.351+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.354+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.359+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 6.0 in stage 79.0 (TID 181) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.359+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 5.0 in stage 79.0 (TID 180) in 21 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:46.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.380+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 7.0 in stage 79.0 (TID 182) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 6.0 in stage 79.0 (TID 181) in 26 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:46.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.396+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 8.0 in stage 79.0 (TID 183) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 7.0 in stage 79.0 (TID 182) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:46.409+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.413+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 9.0 in stage 79.0 (TID 184) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 8.0 in stage 79.0 (TID 183) in 18 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:46.426+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_265_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.429+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_275_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 9.0 in stage 79.0 (TID 184) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:46.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-05-08T06:35:46.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: ShuffleMapStage 79 (mapPartitions at GraphImpl.scala:208) finished in 0.243 s
[2025-05-08T06:35:46.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:46.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:46.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 80)
[2025-05-08T06:35:46.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:46.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Submitting ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[289] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:46.436+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 12.0 KiB, free 417.9 MiB)
[2025-05-08T06:35:46.443+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 417.9 MiB)
[2025-05-08T06:35:46.443+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_52_piece0 on f2a432e4376a:46195 in memory (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:46.443+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on f2a432e4376a:46195 (size: 5.7 KiB, free: 433.5 MiB)
[2025-05-08T06:35:46.444+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:46.445+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[289] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:46.445+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Adding task set 80.0 with 10 tasks resource profile 0
[2025-05-08T06:35:46.447+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.20.0.5:41027 in memory (size: 5.0 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.448+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 185) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.455+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.20.0.5:41027 (size: 5.7 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.463+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:43674
[2025-05-08T06:35:46.470+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.475+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 186) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.488+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 185) in 41 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:46.497+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.503+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 187) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 186) in 28 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:46.511+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.518+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 188) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.518+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 187) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:46.527+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.533+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 4.0 in stage 80.0 (TID 189) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.534+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 188) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:46.540+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.545+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 5.0 in stage 80.0 (TID 190) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.546+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 4.0 in stage 80.0 (TID 189) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:46.556+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.561+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 6.0 in stage 80.0 (TID 191) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.561+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 5.0 in stage 80.0 (TID 190) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:46.569+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.574+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 7.0 in stage 80.0 (TID 192) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 6.0 in stage 80.0 (TID 191) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:46.584+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.591+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 8.0 in stage 80.0 (TID 193) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.591+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 7.0 in stage 80.0 (TID 192) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:46.598+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.603+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 9.0 in stage 80.0 (TID 194) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.604+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 8.0 in stage 80.0 (TID 193) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:46.610+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_285_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 9.0 in stage 80.0 (TID 194) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:46.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool
[2025-05-08T06:35:46.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: ShuffleMapStage 80 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.179 s
[2025-05-08T06:35:46.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:46.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:46.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: waiting: Set(ResultStage 81)
[2025-05-08T06:35:46.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:46.616+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Submitting ResultStage 81 (EdgeRDDImpl[292] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:46.621+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 163.6 KiB, free 417.7 MiB)
[2025-05-08T06:35:46.634+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 57.7 KiB, free 417.7 MiB)
[2025-05-08T06:35:46.635+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on f2a432e4376a:46195 (size: 57.7 KiB, free: 433.4 MiB)
[2025-05-08T06:35:46.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:46.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 81 (EdgeRDDImpl[292] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:46.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Adding task set 81.0 with 10 tasks resource profile 0
[2025-05-08T06:35:46.637+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_54_piece0 on f2a432e4376a:46195 in memory (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:46.637+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.20.0.5:41027 in memory (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.637+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 195) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.645+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.20.0.5:41027 (size: 57.7 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.659+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:43674
[2025-05-08T06:35:46.664+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:43674
[2025-05-08T06:35:46.670+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.674+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 196) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 195) in 39 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:46.693+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.696+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 197) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.696+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 196) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:46.708+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 198) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 197) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:46.724+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.727+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 199) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.728+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 198) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:46.739+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.742+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 200) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.742+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 199) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:46.753+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.757+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 6.0 in stage 81.0 (TID 201) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.757+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 200) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:46.767+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.769+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 7.0 in stage 81.0 (TID 202) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.770+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 6.0 in stage 81.0 (TID 201) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:46.782+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.784+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 8.0 in stage 81.0 (TID 203) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 7.0 in stage 81.0 (TID 202) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:46.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 9.0 in stage 81.0 (TID 204) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.804+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 8.0 in stage 81.0 (TID 203) in 19 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:46.824+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added rdd_291_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.827+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 9.0 in stage 81.0 (TID 204) in 24 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:46.827+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-05-08T06:35:46.827+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: ResultStage 81 (foreachPartition at PageRank.scala:199) finished in 0.210 s
[2025-05-08T06:35:46.828+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:46.828+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
[2025-05-08T06:35:46.828+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Job 36 finished: foreachPartition at PageRank.scala:199, took 1.121208 s
[2025-05-08T06:35:46.829+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO PageRank: PageRank finished iteration 0.
[2025-05-08T06:35:46.829+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MapPartitionsRDD: Removing RDD 273 from persistence list
[2025-05-08T06:35:46.830+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MapPartitionsRDD: Removing RDD 275 from persistence list
[2025-05-08T06:35:46.831+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManager: Removing RDD 273
[2025-05-08T06:35:46.832+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManager: Removing RDD 275
[2025-05-08T06:35:46.844+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:46.845+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Registering RDD 293 (mapPartitions at GraphImpl.scala:208) as input to shuffle 35
[2025-05-08T06:35:46.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Registering RDD 301 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 34
[2025-05-08T06:35:46.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Got job 37 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:46.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Final stage: ResultStage 92 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:46.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82, ShuffleMapStage 89, ShuffleMapStage 86, ShuffleMapStage 87, ShuffleMapStage 91)
[2025-05-08T06:35:46.847+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
[2025-05-08T06:35:46.848+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Submitting ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[293] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:46.854+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 164.0 KiB, free 417.7 MiB)
[2025-05-08T06:35:46.864+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-08T06:35:46.866+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on f2a432e4376a:46195 (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-08T06:35:46.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:46.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[293] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:46.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSchedulerImpl: Adding task set 90.0 with 10 tasks resource profile 0
[2025-05-08T06:35:46.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_56_piece0 on f2a432e4376a:46195 in memory (size: 57.7 KiB, free: 433.5 MiB)
[2025-05-08T06:35:46.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.20.0.5:41027 in memory (size: 57.7 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 205) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.869+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_55_piece0 on f2a432e4376a:46195 in memory (size: 5.7 KiB, free: 433.5 MiB)
[2025-05-08T06:35:46.873+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.20.0.5:41027 in memory (size: 5.7 KiB, free: 433.0 MiB)
[2025-05-08T06:35:46.877+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.20.0.5:41027 (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-08T06:35:46.893+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 206) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.894+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 205) in 27 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:46.911+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 207) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.915+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 206) in 19 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:46.939+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 208) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 207) in 31 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:46.954+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 4.0 in stage 90.0 (TID 209) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.956+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 208) in 18 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:46.966+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 5.0 in stage 90.0 (TID 210) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.967+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 4.0 in stage 90.0 (TID 209) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:46.975+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 6.0 in stage 90.0 (TID 211) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.975+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 5.0 in stage 90.0 (TID 210) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:46.983+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 7.0 in stage 90.0 (TID 212) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.983+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 6.0 in stage 90.0 (TID 211) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:46.992+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Starting task 8.0 in stage 90.0 (TID 213) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:46.992+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:46 INFO TaskSetManager: Finished task 7.0 in stage 90.0 (TID 212) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:47.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 9.0 in stage 90.0 (TID 214) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 8.0 in stage 90.0 (TID 213) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:47.010+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 9.0 in stage 90.0 (TID 214) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:47.010+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-05-08T06:35:47.011+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: ShuffleMapStage 90 (mapPartitions at GraphImpl.scala:208) finished in 0.162 s
[2025-05-08T06:35:47.011+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:47.011+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:47.011+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 91, ResultStage 92)
[2025-05-08T06:35:47.011+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:47.011+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[301] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:47.013+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.8 KiB, free 417.9 MiB)
[2025-05-08T06:35:47.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 417.9 MiB)
[2025-05-08T06:35:47.029+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on f2a432e4376a:46195 (size: 5.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:47.029+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:47.029+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[301] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:47.029+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Adding task set 91.0 with 10 tasks resource profile 0
[2025-05-08T06:35:47.030+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 215) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.037+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.20.0.5:41027 (size: 5.9 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.044+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:43674
[2025-05-08T06:35:47.050+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.058+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 216) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.058+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 215) in 28 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:47.067+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.084+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 217) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.084+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 216) in 27 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:47.092+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.098+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 218) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.098+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 217) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:47.108+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.112+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 219) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.112+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 218) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:47.119+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.124+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 220) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.125+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 219) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:47.131+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 221) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.136+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 220) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:47.143+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.147+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 222) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.148+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 221) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:47.154+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.159+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 8.0 in stage 91.0 (TID 223) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.159+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 222) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:47.166+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.172+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 9.0 in stage 91.0 (TID 224) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.173+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 8.0 in stage 91.0 (TID 223) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:47.181+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_297_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.187+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 9.0 in stage 91.0 (TID 224) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:47.187+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-05-08T06:35:47.187+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: ShuffleMapStage 91 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.175 s
[2025-05-08T06:35:47.187+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: waiting: Set(ResultStage 92)
[2025-05-08T06:35:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting ResultStage 92 (EdgeRDDImpl[304] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:47.194+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 163.8 KiB, free 417.7 MiB)
[2025-05-08T06:35:47.208+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_57_piece0 on f2a432e4376a:46195 in memory (size: 58.1 KiB, free: 433.6 MiB)
[2025-05-08T06:35:47.208+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 57.6 KiB, free 417.9 MiB)
[2025-05-08T06:35:47.208+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on f2a432e4376a:46195 (size: 57.6 KiB, free: 433.5 MiB)
[2025-05-08T06:35:47.208+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:47.209+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 92 (EdgeRDDImpl[304] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:47.209+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Adding task set 92.0 with 10 tasks resource profile 0
[2025-05-08T06:35:47.210+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 225) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.20.0.5:41027 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.217+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.20.0.5:41027 (size: 57.6 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.228+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:43674
[2025-05-08T06:35:47.233+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.237+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 226) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.238+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 225) in 27 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:47.259+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.262+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 227) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.263+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 226) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:47.274+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.277+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 228) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.277+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 227) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:47.291+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 229) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.295+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 228) in 18 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:47.306+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.308+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 5.0 in stage 92.0 (TID 230) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.309+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 229) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:47.327+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 6.0 in stage 92.0 (TID 231) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 5.0 in stage 92.0 (TID 230) in 22 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:47.339+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 7.0 in stage 92.0 (TID 232) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 6.0 in stage 92.0 (TID 231) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:47.354+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.357+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 8.0 in stage 92.0 (TID 233) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.357+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 7.0 in stage 92.0 (TID 232) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:47.369+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 9.0 in stage 92.0 (TID 234) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 8.0 in stage 92.0 (TID 233) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:47.379+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_303_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 9.0 in stage 92.0 (TID 234) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:47.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool
[2025-05-08T06:35:47.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: ResultStage 92 (foreachPartition at PageRank.scala:199) finished in 0.195 s
[2025-05-08T06:35:47.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:47.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
[2025-05-08T06:35:47.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Job 37 finished: foreachPartition at PageRank.scala:199, took 0.539467 s
[2025-05-08T06:35:47.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO PageRank: PageRank finished iteration 1.
[2025-05-08T06:35:47.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO ZippedPartitionsRDD2: Removing RDD 285 from persistence list
[2025-05-08T06:35:47.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManager: Removing RDD 285
[2025-05-08T06:35:47.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO ZippedPartitionsRDD2: Removing RDD 291 from persistence list
[2025-05-08T06:35:47.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManager: Removing RDD 291
[2025-05-08T06:35:47.397+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:47.399+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Registering RDD 305 (mapPartitions at GraphImpl.scala:208) as input to shuffle 37
[2025-05-08T06:35:47.399+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Registering RDD 313 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 36
[2025-05-08T06:35:47.399+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Got job 38 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:47.399+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Final stage: ResultStage 105 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:47.399+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 100, ShuffleMapStage 104, ShuffleMapStage 93, ShuffleMapStage 97, ShuffleMapStage 98)
[2025-05-08T06:35:47.400+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
[2025-05-08T06:35:47.400+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[305] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:47.405+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 164.3 KiB, free 417.7 MiB)
[2025-05-08T06:35:47.413+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.7 MiB)
[2025-05-08T06:35:47.414+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_58_piece0 on f2a432e4376a:46195 in memory (size: 5.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:47.414+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on f2a432e4376a:46195 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-08T06:35:47.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:47.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[305] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:47.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Adding task set 103.0 with 10 tasks resource profile 0
[2025-05-08T06:35:47.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.20.0.5:41027 in memory (size: 5.9 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 235) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_59_piece0 on f2a432e4376a:46195 in memory (size: 57.6 KiB, free: 433.5 MiB)
[2025-05-08T06:35:47.419+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.20.0.5:41027 in memory (size: 57.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:47.422+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.20.0.5:41027 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 236) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 235) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:47.446+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 237) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.447+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 236) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:47.463+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 238) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.464+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 237) in 18 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:47.476+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 239) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.477+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 238) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:47.487+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 240) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.488+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 239) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:47.498+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 6.0 in stage 103.0 (TID 241) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.499+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 240) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:47.507+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 7.0 in stage 103.0 (TID 242) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.507+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 6.0 in stage 103.0 (TID 241) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:47.515+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 8.0 in stage 103.0 (TID 243) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.516+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 7.0 in stage 103.0 (TID 242) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:47.523+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 9.0 in stage 103.0 (TID 244) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.524+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 8.0 in stage 103.0 (TID 243) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:47.531+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 9.0 in stage 103.0 (TID 244) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:47.532+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-05-08T06:35:47.532+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: ShuffleMapStage 103 (mapPartitions at GraphImpl.scala:208) finished in 0.132 s
[2025-05-08T06:35:47.532+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:47.532+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:47.532+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 104, ResultStage 105)
[2025-05-08T06:35:47.532+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:47.533+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[313] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:47.534+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 13.5 KiB, free 417.9 MiB)
[2025-05-08T06:35:47.539+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.9 MiB)
[2025-05-08T06:35:47.540+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on f2a432e4376a:46195 (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-08T06:35:47.540+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:47.540+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[313] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:47.540+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Adding task set 104.0 with 10 tasks resource profile 0
[2025-05-08T06:35:47.541+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 245) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.547+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.20.0.5:41027 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.552+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:43674
[2025-05-08T06:35:47.557+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.561+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 246) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.562+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 245) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:47.570+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.582+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 247) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.583+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 246) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:47.590+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 248) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 247) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:47.602+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.605+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 4.0 in stage 104.0 (TID 249) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.606+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 248) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:47.612+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.616+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 5.0 in stage 104.0 (TID 250) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.617+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 4.0 in stage 104.0 (TID 249) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:47.623+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.627+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 6.0 in stage 104.0 (TID 251) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.628+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 5.0 in stage 104.0 (TID 250) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:47.635+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.639+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 7.0 in stage 104.0 (TID 252) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.639+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 6.0 in stage 104.0 (TID 251) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:47.644+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.649+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 8.0 in stage 104.0 (TID 253) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.649+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 7.0 in stage 104.0 (TID 252) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:47.655+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.662+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 9.0 in stage 104.0 (TID 254) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.663+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 8.0 in stage 104.0 (TID 253) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:47.670+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_309_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.674+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 9.0 in stage 104.0 (TID 254) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:47.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool
[2025-05-08T06:35:47.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: ShuffleMapStage 104 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.141 s
[2025-05-08T06:35:47.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:47.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:47.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: waiting: Set(ResultStage 105)
[2025-05-08T06:35:47.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:47.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting ResultStage 105 (EdgeRDDImpl[316] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:47.679+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 164.1 KiB, free 417.7 MiB)
[2025-05-08T06:35:47.694+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 57.8 KiB, free 417.9 MiB)
[2025-05-08T06:35:47.694+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_60_piece0 on f2a432e4376a:46195 in memory (size: 58.2 KiB, free: 433.6 MiB)
[2025-05-08T06:35:47.695+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on f2a432e4376a:46195 (size: 57.8 KiB, free: 433.5 MiB)
[2025-05-08T06:35:47.695+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:47.695+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 105 (EdgeRDDImpl[316] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:47.695+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Adding task set 105.0 with 10 tasks resource profile 0
[2025-05-08T06:35:47.696+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 255) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.697+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.20.0.5:41027 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.704+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.20.0.5:41027 (size: 57.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.714+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:43674
[2025-05-08T06:35:47.719+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.723+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 256) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.723+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 255) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:47.748+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.753+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 257) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.753+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 256) in 31 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:47.765+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.769+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 258) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.769+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 257) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:47.777+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 4.0 in stage 105.0 (TID 259) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 258) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:47.789+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.791+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 5.0 in stage 105.0 (TID 260) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.792+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 4.0 in stage 105.0 (TID 259) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:47.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.806+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 6.0 in stage 105.0 (TID 261) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.806+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 5.0 in stage 105.0 (TID 260) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:47.814+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.818+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 7.0 in stage 105.0 (TID 262) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.818+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 6.0 in stage 105.0 (TID 261) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:47.826+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.828+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 8.0 in stage 105.0 (TID 263) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.828+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 7.0 in stage 105.0 (TID 262) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:47.836+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.838+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 9.0 in stage 105.0 (TID 264) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.839+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 8.0 in stage 105.0 (TID 263) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:47.850+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added rdd_315_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.853+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 9.0 in stage 105.0 (TID 264) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:47.853+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool
[2025-05-08T06:35:47.853+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: ResultStage 105 (foreachPartition at PageRank.scala:199) finished in 0.177 s
[2025-05-08T06:35:47.853+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:47.854+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
[2025-05-08T06:35:47.854+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Job 38 finished: foreachPartition at PageRank.scala:199, took 0.456319 s
[2025-05-08T06:35:47.854+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO PageRank: PageRank finished iteration 2.
[2025-05-08T06:35:47.854+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO ZippedPartitionsRDD2: Removing RDD 297 from persistence list
[2025-05-08T06:35:47.854+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManager: Removing RDD 297
[2025-05-08T06:35:47.855+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO ZippedPartitionsRDD2: Removing RDD 303 from persistence list
[2025-05-08T06:35:47.855+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManager: Removing RDD 303
[2025-05-08T06:35:47.866+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:47.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Registering RDD 317 (mapPartitions at GraphImpl.scala:208) as input to shuffle 39
[2025-05-08T06:35:47.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Registering RDD 325 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 38
[2025-05-08T06:35:47.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Got job 39 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:47.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Final stage: ResultStage 120 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:47.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 115, ShuffleMapStage 119, ShuffleMapStage 111, ShuffleMapStage 106, ShuffleMapStage 113, ShuffleMapStage 110)
[2025-05-08T06:35:47.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
[2025-05-08T06:35:47.869+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[317] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:47.872+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 164.6 KiB, free 417.7 MiB)
[2025-05-08T06:35:47.880+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.7 MiB)
[2025-05-08T06:35:47.882+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_62_piece0 on f2a432e4376a:46195 in memory (size: 57.8 KiB, free: 433.6 MiB)
[2025-05-08T06:35:47.882+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on f2a432e4376a:46195 (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-08T06:35:47.883+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:47.883+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.20.0.5:41027 in memory (size: 57.8 KiB, free: 433.0 MiB)
[2025-05-08T06:35:47.883+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[317] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:47.883+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Adding task set 118.0 with 10 tasks resource profile 0
[2025-05-08T06:35:47.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 265) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.886+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_61_piece0 on f2a432e4376a:46195 in memory (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-08T06:35:47.887+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.20.0.5:41027 in memory (size: 6.1 KiB, free: 433.0 MiB)
[2025-05-08T06:35:47.891+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.20.0.5:41027 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.900+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 266) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 265) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:47.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 267) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 266) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:47.918+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 268) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.918+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 267) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:47.934+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 269) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.935+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 268) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:47.943+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 270) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.943+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 269) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:47.953+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 271) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.953+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 270) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:47.960+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 272) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.961+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 271) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:47.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 8.0 in stage 118.0 (TID 273) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 272) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:47.977+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 9.0 in stage 118.0 (TID 274) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.977+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 8.0 in stage 118.0 (TID 273) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:47.986+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Finished task 9.0 in stage 118.0 (TID 274) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:47.986+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-05-08T06:35:47.986+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: ShuffleMapStage 118 (mapPartitions at GraphImpl.scala:208) finished in 0.117 s
[2025-05-08T06:35:47.986+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:47.986+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:47.986+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 119, ResultStage 120)
[2025-05-08T06:35:47.987+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:47.987+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[325] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:47.988+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 14.2 KiB, free 417.9 MiB)
[2025-05-08T06:35:47.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.9 MiB)
[2025-05-08T06:35:47.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on f2a432e4376a:46195 (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-08T06:35:47.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:47.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[325] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:47.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSchedulerImpl: Adding task set 119.0 with 10 tasks resource profile 0
[2025-05-08T06:35:47.990+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 275) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:47.994+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.20.0.5:41027 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-08T06:35:47.997+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:43674
[2025-05-08T06:35:48.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.005+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 276) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 275) in 15 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:48.012+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.020+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 277) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.021+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 276) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:48.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.031+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 278) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.033+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 277) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:48.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.052+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 4.0 in stage 119.0 (TID 279) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.053+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 278) in 22 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:48.059+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.064+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 5.0 in stage 119.0 (TID 280) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.065+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 4.0 in stage 119.0 (TID 279) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:48.075+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.078+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 6.0 in stage 119.0 (TID 281) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.079+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 5.0 in stage 119.0 (TID 280) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:48.087+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.093+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 7.0 in stage 119.0 (TID 282) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.093+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 6.0 in stage 119.0 (TID 281) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:48.103+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.108+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 8.0 in stage 119.0 (TID 283) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.108+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 7.0 in stage 119.0 (TID 282) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:48.116+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.122+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 9.0 in stage 119.0 (TID 284) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.122+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 8.0 in stage 119.0 (TID 283) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:48.130+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_321_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.136+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 9.0 in stage 119.0 (TID 284) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:48.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-05-08T06:35:48.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: ShuffleMapStage 119 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.150 s
[2025-05-08T06:35:48.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:48.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:48.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: waiting: Set(ResultStage 120)
[2025-05-08T06:35:48.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:48.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting ResultStage 120 (EdgeRDDImpl[328] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:48.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 164.4 KiB, free 417.7 MiB)
[2025-05-08T06:35:48.143+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 57.7 KiB, free 417.7 MiB)
[2025-05-08T06:35:48.143+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on f2a432e4376a:46195 (size: 57.7 KiB, free: 433.4 MiB)
[2025-05-08T06:35:48.144+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:48.144+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 120 (EdgeRDDImpl[328] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:48.144+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Adding task set 120.0 with 10 tasks resource profile 0
[2025-05-08T06:35:48.145+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 285) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.152+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.20.0.5:41027 (size: 57.7 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:43674
[2025-05-08T06:35:48.165+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.168+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 286) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.169+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 285) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:48.178+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.181+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 287) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.182+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 286) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:48.191+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.194+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 288) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.194+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 287) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:48.207+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.210+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 4.0 in stage 120.0 (TID 289) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 288) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:48.225+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.227+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 5.0 in stage 120.0 (TID 290) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.228+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 4.0 in stage 120.0 (TID 289) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:48.237+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.240+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 6.0 in stage 120.0 (TID 291) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.240+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 5.0 in stage 120.0 (TID 290) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:48.251+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.254+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 7.0 in stage 120.0 (TID 292) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.254+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 6.0 in stage 120.0 (TID 291) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:48.264+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.266+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 8.0 in stage 120.0 (TID 293) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 7.0 in stage 120.0 (TID 292) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:48.275+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.277+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 9.0 in stage 120.0 (TID 294) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.277+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 8.0 in stage 120.0 (TID 293) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:48.287+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_327_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.290+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 9.0 in stage 120.0 (TID 294) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:48.290+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool
[2025-05-08T06:35:48.290+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: ResultStage 120 (foreachPartition at PageRank.scala:199) finished in 0.152 s
[2025-05-08T06:35:48.290+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:48.291+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished
[2025-05-08T06:35:48.291+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Job 39 finished: foreachPartition at PageRank.scala:199, took 0.424882 s
[2025-05-08T06:35:48.291+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO PageRank: PageRank finished iteration 3.
[2025-05-08T06:35:48.291+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO ZippedPartitionsRDD2: Removing RDD 309 from persistence list
[2025-05-08T06:35:48.291+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManager: Removing RDD 309
[2025-05-08T06:35:48.292+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO ZippedPartitionsRDD2: Removing RDD 315 from persistence list
[2025-05-08T06:35:48.292+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManager: Removing RDD 315
[2025-05-08T06:35:48.308+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:48.310+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Registering RDD 329 (mapPartitions at GraphImpl.scala:208) as input to shuffle 41
[2025-05-08T06:35:48.311+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Registering RDD 337 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 40
[2025-05-08T06:35:48.311+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Got job 40 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:48.311+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Final stage: ResultStage 137 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:48.311+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132, ShuffleMapStage 121, ShuffleMapStage 136, ShuffleMapStage 125, ShuffleMapStage 126, ShuffleMapStage 130, ShuffleMapStage 134, ShuffleMapStage 128)
[2025-05-08T06:35:48.311+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
[2025-05-08T06:35:48.312+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[329] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:48.318+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 164.9 KiB, free 417.5 MiB)
[2025-05-08T06:35:48.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_65_piece0 on f2a432e4376a:46195 in memory (size: 57.7 KiB, free: 433.5 MiB)
[2025-05-08T06:35:48.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.7 MiB)
[2025-05-08T06:35:48.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on f2a432e4376a:46195 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-08T06:35:48.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:48.327+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[329] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:48.327+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Adding task set 135.0 with 10 tasks resource profile 0
[2025-05-08T06:35:48.327+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.20.0.5:41027 in memory (size: 57.7 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 295) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.20.0.5:41027 in memory (size: 58.2 KiB, free: 433.0 MiB)
[2025-05-08T06:35:48.333+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_63_piece0 on f2a432e4376a:46195 in memory (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-08T06:35:48.334+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_64_piece0 on f2a432e4376a:46195 in memory (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-08T06:35:48.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.20.0.5:41027 in memory (size: 6.1 KiB, free: 433.0 MiB)
[2025-05-08T06:35:48.336+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.20.0.5:41027 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.349+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 296) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.351+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 295) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:48.362+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 297) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.363+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 296) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:48.378+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 298) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.379+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 297) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:48.391+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 4.0 in stage 135.0 (TID 299) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 298) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:48.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 5.0 in stage 135.0 (TID 300) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 4.0 in stage 135.0 (TID 299) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:48.412+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 6.0 in stage 135.0 (TID 301) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.412+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 5.0 in stage 135.0 (TID 300) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:48.421+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 7.0 in stage 135.0 (TID 302) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.422+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 6.0 in stage 135.0 (TID 301) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:48.430+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 8.0 in stage 135.0 (TID 303) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.431+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 7.0 in stage 135.0 (TID 302) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:48.447+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 9.0 in stage 135.0 (TID 304) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.449+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 8.0 in stage 135.0 (TID 303) in 19 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:48.458+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 9.0 in stage 135.0 (TID 304) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:48.458+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool
[2025-05-08T06:35:48.458+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: ShuffleMapStage 135 (mapPartitions at GraphImpl.scala:208) finished in 0.146 s
[2025-05-08T06:35:48.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:48.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:48.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 136, ResultStage 137)
[2025-05-08T06:35:48.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:48.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[337] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:48.460+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 14.9 KiB, free 417.9 MiB)
[2025-05-08T06:35:48.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 417.9 MiB)
[2025-05-08T06:35:48.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on f2a432e4376a:46195 (size: 6.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:48.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:48.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[337] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:48.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Adding task set 136.0 with 10 tasks resource profile 0
[2025-05-08T06:35:48.462+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 305) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.467+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.20.0.5:41027 (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.471+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:43674
[2025-05-08T06:35:48.474+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 306) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 305) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:48.484+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.489+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 2.0 in stage 136.0 (TID 307) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.489+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 306) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:48.494+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.498+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 3.0 in stage 136.0 (TID 308) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.499+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 2.0 in stage 136.0 (TID 307) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:48.505+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 4.0 in stage 136.0 (TID 309) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 3.0 in stage 136.0 (TID 308) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:48.515+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.518+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 5.0 in stage 136.0 (TID 310) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.518+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 4.0 in stage 136.0 (TID 309) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:48.524+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.528+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 6.0 in stage 136.0 (TID 311) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.529+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 5.0 in stage 136.0 (TID 310) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:48.534+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.538+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 7.0 in stage 136.0 (TID 312) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.538+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 6.0 in stage 136.0 (TID 311) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:48.543+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.546+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 8.0 in stage 136.0 (TID 313) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.546+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 7.0 in stage 136.0 (TID 312) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:48.553+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.557+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 9.0 in stage 136.0 (TID 314) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.558+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 8.0 in stage 136.0 (TID 313) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:48.567+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_333_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.572+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 9.0 in stage 136.0 (TID 314) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:48.572+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-05-08T06:35:48.572+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: ShuffleMapStage 136 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.113 s
[2025-05-08T06:35:48.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:48.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:48.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: waiting: Set(ResultStage 137)
[2025-05-08T06:35:48.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:48.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting ResultStage 137 (EdgeRDDImpl[340] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:48.577+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 164.7 KiB, free 417.7 MiB)
[2025-05-08T06:35:48.578+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 57.9 KiB, free 417.7 MiB)
[2025-05-08T06:35:48.578+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on f2a432e4376a:46195 (size: 57.9 KiB, free: 433.4 MiB)
[2025-05-08T06:35:48.579+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:48.579+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 137 (EdgeRDDImpl[340] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:48.579+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Adding task set 137.0 with 10 tasks resource profile 0
[2025-05-08T06:35:48.580+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 315) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.586+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.20.0.5:41027 (size: 57.9 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.595+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:43674
[2025-05-08T06:35:48.599+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.601+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 316) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.602+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 315) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:48.610+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.612+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 2.0 in stage 137.0 (TID 317) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.613+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 316) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:48.623+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.625+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 3.0 in stage 137.0 (TID 318) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.625+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 2.0 in stage 137.0 (TID 317) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:48.634+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 4.0 in stage 137.0 (TID 319) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.637+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 3.0 in stage 137.0 (TID 318) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:48.645+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.649+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 5.0 in stage 137.0 (TID 320) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.649+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 4.0 in stage 137.0 (TID 319) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:48.658+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.660+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 6.0 in stage 137.0 (TID 321) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.661+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 5.0 in stage 137.0 (TID 320) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:48.669+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.671+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 7.0 in stage 137.0 (TID 322) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.672+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 6.0 in stage 137.0 (TID 321) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:48.680+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.683+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 8.0 in stage 137.0 (TID 323) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.683+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 7.0 in stage 137.0 (TID 322) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:48.695+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.698+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 9.0 in stage 137.0 (TID 324) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 8.0 in stage 137.0 (TID 323) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:48.707+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_339_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:48.709+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 9.0 in stage 137.0 (TID 324) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:48.709+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool
[2025-05-08T06:35:48.709+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: ResultStage 137 (foreachPartition at PageRank.scala:199) finished in 0.136 s
[2025-05-08T06:35:48.709+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:48.710+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
[2025-05-08T06:35:48.710+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Job 40 finished: foreachPartition at PageRank.scala:199, took 0.401156 s
[2025-05-08T06:35:48.710+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO PageRank: PageRank finished iteration 4.
[2025-05-08T06:35:48.710+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO ZippedPartitionsRDD2: Removing RDD 321 from persistence list
[2025-05-08T06:35:48.710+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManager: Removing RDD 321
[2025-05-08T06:35:48.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO ZippedPartitionsRDD2: Removing RDD 327 from persistence list
[2025-05-08T06:35:48.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManager: Removing RDD 327
[2025-05-08T06:35:48.723+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:48.725+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Registering RDD 341 (mapPartitions at GraphImpl.scala:208) as input to shuffle 43
[2025-05-08T06:35:48.725+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Registering RDD 349 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 42
[2025-05-08T06:35:48.725+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Got job 41 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:48.725+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Final stage: ResultStage 156 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:48.725+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143, ShuffleMapStage 153, ShuffleMapStage 147, ShuffleMapStage 151, ShuffleMapStage 155, ShuffleMapStage 138, ShuffleMapStage 145, ShuffleMapStage 142, ShuffleMapStage 149)
[2025-05-08T06:35:48.725+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 155)
[2025-05-08T06:35:48.726+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[341] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:48.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 165.2 KiB, free 417.5 MiB)
[2025-05-08T06:35:48.747+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_68_piece0 on f2a432e4376a:46195 in memory (size: 57.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:48.748+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.5 MiB)
[2025-05-08T06:35:48.748+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on f2a432e4376a:46195 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:48.748+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:48.748+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[341] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:48.748+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Adding task set 154.0 with 10 tasks resource profile 0
[2025-05-08T06:35:48.750+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.20.0.5:41027 in memory (size: 57.9 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.750+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 325) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.756+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_67_piece0 on f2a432e4376a:46195 in memory (size: 6.3 KiB, free: 433.4 MiB)
[2025-05-08T06:35:48.758+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.20.0.5:41027 in memory (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.760+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.20.0.5:41027 (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.761+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_66_piece0 on f2a432e4376a:46195 in memory (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-08T06:35:48.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.20.0.5:41027 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.778+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 326) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.778+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 325) in 29 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:48.807+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 327) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.808+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 326) in 28 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:48.835+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 328) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.836+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 327) in 28 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:48.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 329) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.852+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 328) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:48.859+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 5.0 in stage 154.0 (TID 330) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.859+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 329) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:48.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 6.0 in stage 154.0 (TID 331) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 5.0 in stage 154.0 (TID 330) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:48.875+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 7.0 in stage 154.0 (TID 332) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.875+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 6.0 in stage 154.0 (TID 331) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:48.884+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 8.0 in stage 154.0 (TID 333) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.884+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 7.0 in stage 154.0 (TID 332) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:48.891+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 9.0 in stage 154.0 (TID 334) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.891+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 8.0 in stage 154.0 (TID 333) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:48.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 9.0 in stage 154.0 (TID 334) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:48.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool
[2025-05-08T06:35:48.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: ShuffleMapStage 154 (mapPartitions at GraphImpl.scala:208) finished in 0.175 s
[2025-05-08T06:35:48.902+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:48.902+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:48.902+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 155, ResultStage 156)
[2025-05-08T06:35:48.902+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:48.902+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[349] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:48.903+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 15.6 KiB, free 417.9 MiB)
[2025-05-08T06:35:48.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 417.9 MiB)
[2025-05-08T06:35:48.905+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on f2a432e4376a:46195 (size: 6.4 KiB, free: 433.5 MiB)
[2025-05-08T06:35:48.905+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:48.905+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[349] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:48.905+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSchedulerImpl: Adding task set 155.0 with 10 tasks resource profile 0
[2025-05-08T06:35:48.906+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 335) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.20.0.5:41027 (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.914+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:43674
[2025-05-08T06:35:48.920+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_345_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.923+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 336) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.924+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 335) in 18 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:48.929+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_345_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.934+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 337) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.935+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 336) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:48.940+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_345_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.945+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 338) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.946+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 337) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:48.953+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_345_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.957+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 4.0 in stage 155.0 (TID 339) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.957+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 338) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:48.965+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_345_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.970+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 5.0 in stage 155.0 (TID 340) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.971+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 4.0 in stage 155.0 (TID 339) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:48.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_345_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.986+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 6.0 in stage 155.0 (TID 341) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.986+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 5.0 in stage 155.0 (TID 340) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:48.992+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO BlockManagerInfo: Added rdd_345_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:48.997+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Starting task 7.0 in stage 155.0 (TID 342) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:48.998+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:48 INFO TaskSetManager: Finished task 6.0 in stage 155.0 (TID 341) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:49.004+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_345_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.008+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 8.0 in stage 155.0 (TID 343) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.008+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 7.0 in stage 155.0 (TID 342) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:49.013+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_345_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.017+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 9.0 in stage 155.0 (TID 344) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.017+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 8.0 in stage 155.0 (TID 343) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:49.024+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_345_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 9.0 in stage 155.0 (TID 344) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:49.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool
[2025-05-08T06:35:49.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: ShuffleMapStage 155 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.125 s
[2025-05-08T06:35:49.028+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:49.028+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:49.028+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: waiting: Set(ResultStage 156)
[2025-05-08T06:35:49.028+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:49.028+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting ResultStage 156 (EdgeRDDImpl[352] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:49.032+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 165.0 KiB, free 417.7 MiB)
[2025-05-08T06:35:49.033+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.7 MiB)
[2025-05-08T06:35:49.033+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on f2a432e4376a:46195 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-08T06:35:49.033+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:49.033+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 156 (EdgeRDDImpl[352] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:49.034+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Adding task set 156.0 with 10 tasks resource profile 0
[2025-05-08T06:35:49.034+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 345) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.038+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.20.0.5:41027 (size: 58.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.044+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:43674
[2025-05-08T06:35:49.048+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.051+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 346) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.051+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 345) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:49.058+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.060+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 347) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.060+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 346) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:49.069+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.070+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 348) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.071+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 347) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:49.078+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.080+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 4.0 in stage 156.0 (TID 349) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.081+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 348) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:49.089+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.091+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 5.0 in stage 156.0 (TID 350) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.091+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 4.0 in stage 156.0 (TID 349) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:49.103+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.106+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 6.0 in stage 156.0 (TID 351) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.106+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 5.0 in stage 156.0 (TID 350) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:49.126+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.128+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 7.0 in stage 156.0 (TID 352) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.128+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 6.0 in stage 156.0 (TID 351) in 22 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:49.139+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.140+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 8.0 in stage 156.0 (TID 353) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.141+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 7.0 in stage 156.0 (TID 352) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:49.149+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.152+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 9.0 in stage 156.0 (TID 354) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.152+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 8.0 in stage 156.0 (TID 353) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:49.159+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_351_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.161+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 9.0 in stage 156.0 (TID 354) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:49.161+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool
[2025-05-08T06:35:49.162+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: ResultStage 156 (foreachPartition at PageRank.scala:199) finished in 0.133 s
[2025-05-08T06:35:49.162+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:49.162+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished
[2025-05-08T06:35:49.162+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Job 41 finished: foreachPartition at PageRank.scala:199, took 0.439192 s
[2025-05-08T06:35:49.162+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO PageRank: PageRank finished iteration 5.
[2025-05-08T06:35:49.162+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO ZippedPartitionsRDD2: Removing RDD 333 from persistence list
[2025-05-08T06:35:49.163+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManager: Removing RDD 333
[2025-05-08T06:35:49.163+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO ZippedPartitionsRDD2: Removing RDD 339 from persistence list
[2025-05-08T06:35:49.164+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManager: Removing RDD 339
[2025-05-08T06:35:49.174+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:49.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Registering RDD 353 (mapPartitions at GraphImpl.scala:208) as input to shuffle 45
[2025-05-08T06:35:49.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Registering RDD 361 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 44
[2025-05-08T06:35:49.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Got job 42 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:49.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Final stage: ResultStage 177 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:49.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 161, ShuffleMapStage 168, ShuffleMapStage 157, ShuffleMapStage 172, ShuffleMapStage 166, ShuffleMapStage 176, ShuffleMapStage 170, ShuffleMapStage 162, ShuffleMapStage 174, ShuffleMapStage 164)
[2025-05-08T06:35:49.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 176)
[2025-05-08T06:35:49.178+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[353] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:49.182+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 165.5 KiB, free 417.5 MiB)
[2025-05-08T06:35:49.189+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_71_piece0 on f2a432e4376a:46195 in memory (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-08T06:35:49.189+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 417.5 MiB)
[2025-05-08T06:35:49.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on f2a432e4376a:46195 (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-08T06:35:49.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:49.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[353] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:49.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Adding task set 175.0 with 10 tasks resource profile 0
[2025-05-08T06:35:49.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.20.0.5:41027 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 355) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.193+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_69_piece0 on f2a432e4376a:46195 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:49.194+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.20.0.5:41027 in memory (size: 58.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:49.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_70_piece0 on f2a432e4376a:46195 in memory (size: 6.4 KiB, free: 433.5 MiB)
[2025-05-08T06:35:49.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.20.0.5:41027 in memory (size: 6.4 KiB, free: 433.0 MiB)
[2025-05-08T06:35:49.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.20.0.5:41027 (size: 58.4 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.206+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 1.0 in stage 175.0 (TID 356) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.206+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 355) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:49.213+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 2.0 in stage 175.0 (TID 357) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.214+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 1.0 in stage 175.0 (TID 356) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:49.231+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 3.0 in stage 175.0 (TID 358) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.232+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 2.0 in stage 175.0 (TID 357) in 19 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:49.239+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 4.0 in stage 175.0 (TID 359) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.240+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 3.0 in stage 175.0 (TID 358) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:49.248+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 5.0 in stage 175.0 (TID 360) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.249+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 4.0 in stage 175.0 (TID 359) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:49.256+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 6.0 in stage 175.0 (TID 361) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.257+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 5.0 in stage 175.0 (TID 360) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:49.266+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 7.0 in stage 175.0 (TID 362) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 6.0 in stage 175.0 (TID 361) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:49.274+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 8.0 in stage 175.0 (TID 363) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.275+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 7.0 in stage 175.0 (TID 362) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:49.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 9.0 in stage 175.0 (TID 364) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.283+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 8.0 in stage 175.0 (TID 363) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:49.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 9.0 in stage 175.0 (TID 364) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:49.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool
[2025-05-08T06:35:49.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: ShuffleMapStage 175 (mapPartitions at GraphImpl.scala:208) finished in 0.116 s
[2025-05-08T06:35:49.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:49.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:49.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 176, ResultStage 177)
[2025-05-08T06:35:49.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:49.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[361] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:49.296+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 16.4 KiB, free 417.9 MiB)
[2025-05-08T06:35:49.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 417.9 MiB)
[2025-05-08T06:35:49.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on f2a432e4376a:46195 (size: 6.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:49.298+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:49.299+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[361] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:49.299+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Adding task set 176.0 with 10 tasks resource profile 0
[2025-05-08T06:35:49.300+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 365) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.304+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.20.0.5:41027 (size: 6.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.308+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:43674
[2025-05-08T06:35:49.310+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.314+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 1.0 in stage 176.0 (TID 366) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.315+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 365) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:49.321+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.324+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 2.0 in stage 176.0 (TID 367) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.325+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 1.0 in stage 176.0 (TID 366) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:49.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.334+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 3.0 in stage 176.0 (TID 368) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 2.0 in stage 176.0 (TID 367) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:49.339+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.343+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 4.0 in stage 176.0 (TID 369) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.343+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 3.0 in stage 176.0 (TID 368) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:49.350+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.354+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 5.0 in stage 176.0 (TID 370) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.354+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 4.0 in stage 176.0 (TID 369) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:49.360+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.366+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 6.0 in stage 176.0 (TID 371) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.366+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 5.0 in stage 176.0 (TID 370) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:49.372+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 7.0 in stage 176.0 (TID 372) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 6.0 in stage 176.0 (TID 371) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:49.382+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 8.0 in stage 176.0 (TID 373) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 7.0 in stage 176.0 (TID 372) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:49.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.396+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 9.0 in stage 176.0 (TID 374) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.396+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 8.0 in stage 176.0 (TID 373) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:49.402+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_357_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.406+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 9.0 in stage 176.0 (TID 374) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:49.406+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool
[2025-05-08T06:35:49.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: ShuffleMapStage 176 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.111 s
[2025-05-08T06:35:49.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:49.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:49.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: waiting: Set(ResultStage 177)
[2025-05-08T06:35:49.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:49.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting ResultStage 177 (EdgeRDDImpl[364] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:49.410+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 165.3 KiB, free 417.7 MiB)
[2025-05-08T06:35:49.412+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.7 MiB)
[2025-05-08T06:35:49.412+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on f2a432e4376a:46195 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-08T06:35:49.412+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:49.412+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 177 (EdgeRDDImpl[364] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:49.412+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Adding task set 177.0 with 10 tasks resource profile 0
[2025-05-08T06:35:49.413+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 375) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.422+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.20.0.5:41027 (size: 58.3 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.429+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:43674
[2025-05-08T06:35:49.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.437+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 376) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.439+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 375) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:49.460+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.463+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 2.0 in stage 177.0 (TID 377) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.464+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 376) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:49.474+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.476+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 3.0 in stage 177.0 (TID 378) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.476+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 2.0 in stage 177.0 (TID 377) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:49.489+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.492+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 4.0 in stage 177.0 (TID 379) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.492+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 3.0 in stage 177.0 (TID 378) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:49.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.505+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 5.0 in stage 177.0 (TID 380) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.505+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 4.0 in stage 177.0 (TID 379) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:49.514+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.517+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 6.0 in stage 177.0 (TID 381) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.518+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 5.0 in stage 177.0 (TID 380) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:49.526+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.528+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 7.0 in stage 177.0 (TID 382) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.529+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 6.0 in stage 177.0 (TID 381) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:49.539+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.542+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 8.0 in stage 177.0 (TID 383) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.542+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 7.0 in stage 177.0 (TID 382) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:49.555+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.558+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 9.0 in stage 177.0 (TID 384) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 8.0 in stage 177.0 (TID 383) in 17 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:49.569+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_363_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.572+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 9.0 in stage 177.0 (TID 384) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:49.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool
[2025-05-08T06:35:49.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: ResultStage 177 (foreachPartition at PageRank.scala:199) finished in 0.166 s
[2025-05-08T06:35:49.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:49.574+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished
[2025-05-08T06:35:49.574+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Job 42 finished: foreachPartition at PageRank.scala:199, took 0.399108 s
[2025-05-08T06:35:49.574+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO PageRank: PageRank finished iteration 6.
[2025-05-08T06:35:49.574+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO ZippedPartitionsRDD2: Removing RDD 345 from persistence list
[2025-05-08T06:35:49.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManager: Removing RDD 345
[2025-05-08T06:35:49.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO ZippedPartitionsRDD2: Removing RDD 351 from persistence list
[2025-05-08T06:35:49.575+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManager: Removing RDD 351
[2025-05-08T06:35:49.586+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:49.589+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Registering RDD 365 (mapPartitions at GraphImpl.scala:208) as input to shuffle 47
[2025-05-08T06:35:49.589+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Registering RDD 373 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 46
[2025-05-08T06:35:49.589+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Got job 43 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:49.589+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Final stage: ResultStage 200 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:49.590+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 197, ShuffleMapStage 183, ShuffleMapStage 187, ShuffleMapStage 191, ShuffleMapStage 195, ShuffleMapStage 189, ShuffleMapStage 199, ShuffleMapStage 178, ShuffleMapStage 193, ShuffleMapStage 185, ShuffleMapStage 182)
[2025-05-08T06:35:49.590+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 199)
[2025-05-08T06:35:49.590+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[365] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:49.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 165.8 KiB, free 417.5 MiB)
[2025-05-08T06:35:49.601+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_74_piece0 on f2a432e4376a:46195 in memory (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:49.602+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.7 MiB)
[2025-05-08T06:35:49.602+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on f2a432e4376a:46195 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:49.603+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:49.603+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[365] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:49.603+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Adding task set 198.0 with 10 tasks resource profile 0
[2025-05-08T06:35:49.603+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.20.0.5:41027 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.603+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 385) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.607+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_73_piece0 on f2a432e4376a:46195 in memory (size: 6.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:49.610+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.20.0.5:41027 in memory (size: 6.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.611+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_72_piece0 on f2a432e4376a:46195 in memory (size: 58.4 KiB, free: 433.5 MiB)
[2025-05-08T06:35:49.612+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.20.0.5:41027 (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.613+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.20.0.5:41027 in memory (size: 58.4 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.628+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 1.0 in stage 198.0 (TID 386) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.629+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 385) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:49.641+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 2.0 in stage 198.0 (TID 387) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.642+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 1.0 in stage 198.0 (TID 386) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:49.656+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 3.0 in stage 198.0 (TID 388) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.656+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 2.0 in stage 198.0 (TID 387) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:49.664+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 4.0 in stage 198.0 (TID 389) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.665+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 3.0 in stage 198.0 (TID 388) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:49.672+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 5.0 in stage 198.0 (TID 390) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.673+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 4.0 in stage 198.0 (TID 389) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:49.681+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 6.0 in stage 198.0 (TID 391) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.681+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 5.0 in stage 198.0 (TID 390) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:49.689+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 7.0 in stage 198.0 (TID 392) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.689+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 6.0 in stage 198.0 (TID 391) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:49.697+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 8.0 in stage 198.0 (TID 393) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.698+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 7.0 in stage 198.0 (TID 392) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:49.704+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 9.0 in stage 198.0 (TID 394) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.705+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 8.0 in stage 198.0 (TID 393) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:49.712+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 9.0 in stage 198.0 (TID 394) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:49.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool
[2025-05-08T06:35:49.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: ShuffleMapStage 198 (mapPartitions at GraphImpl.scala:208) finished in 0.123 s
[2025-05-08T06:35:49.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:49.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:49.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 199, ResultStage 200)
[2025-05-08T06:35:49.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:49.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[373] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:49.715+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 17.1 KiB, free 417.9 MiB)
[2025-05-08T06:35:49.716+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 417.9 MiB)
[2025-05-08T06:35:49.716+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on f2a432e4376a:46195 (size: 6.6 KiB, free: 433.5 MiB)
[2025-05-08T06:35:49.716+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:49.716+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[373] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:49.717+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Adding task set 199.0 with 10 tasks resource profile 0
[2025-05-08T06:35:49.717+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 395) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.20.0.5:41027 (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.724+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:43674
[2025-05-08T06:35:49.728+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.734+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 1.0 in stage 199.0 (TID 396) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.734+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 395) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:49.740+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 2.0 in stage 199.0 (TID 397) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 1.0 in stage 199.0 (TID 396) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:49.752+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.757+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 3.0 in stage 199.0 (TID 398) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.757+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 2.0 in stage 199.0 (TID 397) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:49.770+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.775+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 4.0 in stage 199.0 (TID 399) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.775+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 3.0 in stage 199.0 (TID 398) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:49.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 5.0 in stage 199.0 (TID 400) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 4.0 in stage 199.0 (TID 399) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:49.805+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.809+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 6.0 in stage 199.0 (TID 401) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.809+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 5.0 in stage 199.0 (TID 400) in 19 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:49.817+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.821+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 7.0 in stage 199.0 (TID 402) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.821+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 6.0 in stage 199.0 (TID 401) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:49.826+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.831+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 8.0 in stage 199.0 (TID 403) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.832+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 7.0 in stage 199.0 (TID 402) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:49.837+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.840+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 9.0 in stage 199.0 (TID 404) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.840+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 8.0 in stage 199.0 (TID 403) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:49.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_369_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.850+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 9.0 in stage 199.0 (TID 404) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:49.850+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool
[2025-05-08T06:35:49.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: ShuffleMapStage 199 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.136 s
[2025-05-08T06:35:49.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:49.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:49.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: waiting: Set(ResultStage 200)
[2025-05-08T06:35:49.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:49.851+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting ResultStage 200 (EdgeRDDImpl[376] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:49.856+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 165.6 KiB, free 417.7 MiB)
[2025-05-08T06:35:49.857+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.7 MiB)
[2025-05-08T06:35:49.858+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on f2a432e4376a:46195 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-08T06:35:49.858+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:49.858+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 200 (EdgeRDDImpl[376] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:49.858+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSchedulerImpl: Adding task set 200.0 with 10 tasks resource profile 0
[2025-05-08T06:35:49.859+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 405) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.864+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.20.0.5:41027 (size: 58.3 KiB, free: 432.8 MiB)
[2025-05-08T06:35:49.870+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:43674
[2025-05-08T06:35:49.877+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_75_piece0 on f2a432e4376a:46195 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:49.879+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.20.0.5:41027 in memory (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.882+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_76_piece0 on f2a432e4376a:46195 in memory (size: 6.6 KiB, free: 433.5 MiB)
[2025-05-08T06:35:49.882+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.883+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.20.0.5:41027 in memory (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 406) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 405) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:49.893+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.897+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 2.0 in stage 200.0 (TID 407) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.898+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 406) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:49.907+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 3.0 in stage 200.0 (TID 408) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 2.0 in stage 200.0 (TID 407) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:49.926+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.929+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 4.0 in stage 200.0 (TID 409) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.929+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 3.0 in stage 200.0 (TID 408) in 21 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:49.941+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.943+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 5.0 in stage 200.0 (TID 410) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.943+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 4.0 in stage 200.0 (TID 409) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:49.956+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.958+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 6.0 in stage 200.0 (TID 411) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.959+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 5.0 in stage 200.0 (TID 410) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:49.967+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 7.0 in stage 200.0 (TID 412) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 6.0 in stage 200.0 (TID 411) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:49.977+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 8.0 in stage 200.0 (TID 413) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 7.0 in stage 200.0 (TID 412) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:49.988+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:49.990+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Starting task 9.0 in stage 200.0 (TID 414) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:49.990+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO TaskSetManager: Finished task 8.0 in stage 200.0 (TID 413) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:49.998+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:49 INFO BlockManagerInfo: Added rdd_375_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.000+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 9.0 in stage 200.0 (TID 414) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:50.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool
[2025-05-08T06:35:50.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: ResultStage 200 (foreachPartition at PageRank.scala:199) finished in 0.150 s
[2025-05-08T06:35:50.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:50.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished
[2025-05-08T06:35:50.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 43 finished: foreachPartition at PageRank.scala:199, took 0.414765 s
[2025-05-08T06:35:50.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO PageRank: PageRank finished iteration 7.
[2025-05-08T06:35:50.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO ZippedPartitionsRDD2: Removing RDD 357 from persistence list
[2025-05-08T06:35:50.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManager: Removing RDD 357
[2025-05-08T06:35:50.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO ZippedPartitionsRDD2: Removing RDD 363 from persistence list
[2025-05-08T06:35:50.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManager: Removing RDD 363
[2025-05-08T06:35:50.012+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:50.015+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Registering RDD 377 (mapPartitions at GraphImpl.scala:208) as input to shuffle 49
[2025-05-08T06:35:50.016+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Registering RDD 385 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 48
[2025-05-08T06:35:50.016+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Got job 44 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:50.016+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Final stage: ResultStage 225 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:50.016+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 212, ShuffleMapStage 222, ShuffleMapStage 201, ShuffleMapStage 216, ShuffleMapStage 208, ShuffleMapStage 205, ShuffleMapStage 220, ShuffleMapStage 224, ShuffleMapStage 206, ShuffleMapStage 210, ShuffleMapStage 214, ShuffleMapStage 218)
[2025-05-08T06:35:50.016+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 224)
[2025-05-08T06:35:50.017+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[377] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:50.021+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 166.1 KiB, free 417.7 MiB)
[2025-05-08T06:35:50.022+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.7 MiB)
[2025-05-08T06:35:50.022+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on f2a432e4376a:46195 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-08T06:35:50.022+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:50.023+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[377] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:50.023+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Adding task set 223.0 with 10 tasks resource profile 0
[2025-05-08T06:35:50.023+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 415) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.028+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.20.0.5:41027 (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 1.0 in stage 223.0 (TID 416) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 415) in 13 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:50.043+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 2.0 in stage 223.0 (TID 417) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.043+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 1.0 in stage 223.0 (TID 416) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:50.050+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 3.0 in stage 223.0 (TID 418) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.051+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 2.0 in stage 223.0 (TID 417) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:50.057+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 4.0 in stage 223.0 (TID 419) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.057+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 3.0 in stage 223.0 (TID 418) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:50.065+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 5.0 in stage 223.0 (TID 420) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.066+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 4.0 in stage 223.0 (TID 419) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:50.073+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 6.0 in stage 223.0 (TID 421) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.073+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 5.0 in stage 223.0 (TID 420) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:50.084+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 7.0 in stage 223.0 (TID 422) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.084+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 6.0 in stage 223.0 (TID 421) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:50.091+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 8.0 in stage 223.0 (TID 423) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.092+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 7.0 in stage 223.0 (TID 422) in 7 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:50.100+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 9.0 in stage 223.0 (TID 424) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.101+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 8.0 in stage 223.0 (TID 423) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:50.117+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 9.0 in stage 223.0 (TID 424) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:50.117+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool
[2025-05-08T06:35:50.118+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: ShuffleMapStage 223 (mapPartitions at GraphImpl.scala:208) finished in 0.099 s
[2025-05-08T06:35:50.118+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:50.118+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:50.118+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 224, ResultStage 225)
[2025-05-08T06:35:50.118+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:50.118+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[385] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:50.119+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 17.8 KiB, free 417.7 MiB)
[2025-05-08T06:35:50.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.7 MiB)
[2025-05-08T06:35:50.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on f2a432e4376a:46195 (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-08T06:35:50.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:50.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[385] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:50.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Adding task set 224.0 with 10 tasks resource profile 0
[2025-05-08T06:35:50.121+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 425) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.125+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.20.0.5:41027 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.128+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:43674
[2025-05-08T06:35:50.132+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 1.0 in stage 224.0 (TID 426) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.136+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 425) in 14 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:50.141+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.144+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 2.0 in stage 224.0 (TID 427) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.144+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 1.0 in stage 224.0 (TID 426) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:50.151+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 3.0 in stage 224.0 (TID 428) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 2.0 in stage 224.0 (TID 427) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:50.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.163+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 4.0 in stage 224.0 (TID 429) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.164+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 3.0 in stage 224.0 (TID 428) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:50.171+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.174+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 5.0 in stage 224.0 (TID 430) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.174+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 4.0 in stage 224.0 (TID 429) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:50.179+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 6.0 in stage 224.0 (TID 431) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 5.0 in stage 224.0 (TID 430) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:50.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-08T06:35:50.194+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 7.0 in stage 224.0 (TID 432) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.195+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 6.0 in stage 224.0 (TID 431) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:50.202+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-08T06:35:50.207+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 8.0 in stage 224.0 (TID 433) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.207+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 7.0 in stage 224.0 (TID 432) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:50.213+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-08T06:35:50.218+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 9.0 in stage 224.0 (TID 434) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.219+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 8.0 in stage 224.0 (TID 433) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:50.225+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_381_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-08T06:35:50.229+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 9.0 in stage 224.0 (TID 434) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:50.229+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool
[2025-05-08T06:35:50.230+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: ShuffleMapStage 224 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.111 s
[2025-05-08T06:35:50.230+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:50.230+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:50.230+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: waiting: Set(ResultStage 225)
[2025-05-08T06:35:50.230+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:50.230+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting ResultStage 225 (EdgeRDDImpl[388] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:50.234+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 165.9 KiB, free 417.5 MiB)
[2025-05-08T06:35:50.243+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_78_piece0 on f2a432e4376a:46195 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:50.243+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.7 MiB)
[2025-05-08T06:35:50.243+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on f2a432e4376a:46195 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-08T06:35:50.243+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:50.244+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.20.0.5:41027 in memory (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.244+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 225 (EdgeRDDImpl[388] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:50.244+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Adding task set 225.0 with 10 tasks resource profile 0
[2025-05-08T06:35:50.245+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 435) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.245+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_77_piece0 on f2a432e4376a:46195 in memory (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:50.248+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.20.0.5:41027 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.254+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.20.0.5:41027 (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.260+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.20.0.5:43674
[2025-05-08T06:35:50.264+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.268+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 1.0 in stage 225.0 (TID 436) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.269+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 435) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:50.279+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.285+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 2.0 in stage 225.0 (TID 437) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.285+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 1.0 in stage 225.0 (TID 436) in 18 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:50.302+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.304+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 3.0 in stage 225.0 (TID 438) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.305+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 2.0 in stage 225.0 (TID 437) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:50.317+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.320+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 4.0 in stage 225.0 (TID 439) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.320+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 3.0 in stage 225.0 (TID 438) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:50.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 5.0 in stage 225.0 (TID 440) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 4.0 in stage 225.0 (TID 439) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:50.340+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 6.0 in stage 225.0 (TID 441) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 5.0 in stage 225.0 (TID 440) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:50.351+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.353+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 7.0 in stage 225.0 (TID 442) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.353+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 6.0 in stage 225.0 (TID 441) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:50.361+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.362+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 8.0 in stage 225.0 (TID 443) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.362+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 7.0 in stage 225.0 (TID 442) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:50.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.373+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 9.0 in stage 225.0 (TID 444) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.373+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 8.0 in stage 225.0 (TID 443) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:50.380+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_387_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 9.0 in stage 225.0 (TID 444) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:50.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool
[2025-05-08T06:35:50.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: ResultStage 225 (foreachPartition at PageRank.scala:199) finished in 0.154 s
[2025-05-08T06:35:50.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:50.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished
[2025-05-08T06:35:50.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 44 finished: foreachPartition at PageRank.scala:199, took 0.372248 s
[2025-05-08T06:35:50.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO PageRank: PageRank finished iteration 8.
[2025-05-08T06:35:50.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO ZippedPartitionsRDD2: Removing RDD 369 from persistence list
[2025-05-08T06:35:50.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManager: Removing RDD 369
[2025-05-08T06:35:50.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO ZippedPartitionsRDD2: Removing RDD 375 from persistence list
[2025-05-08T06:35:50.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManager: Removing RDD 375
[2025-05-08T06:35:50.395+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T06:35:50.398+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Registering RDD 389 (mapPartitions at GraphImpl.scala:208) as input to shuffle 51
[2025-05-08T06:35:50.398+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Registering RDD 397 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 50
[2025-05-08T06:35:50.398+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Got job 45 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T06:35:50.398+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Final stage: ResultStage 252 (foreachPartition at PageRank.scala:199)
[2025-05-08T06:35:50.398+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 233, ShuffleMapStage 230, ShuffleMapStage 251, ShuffleMapStage 237, ShuffleMapStage 249, ShuffleMapStage 241, ShuffleMapStage 235, ShuffleMapStage 245, ShuffleMapStage 239, ShuffleMapStage 231, ShuffleMapStage 243, ShuffleMapStage 247, ShuffleMapStage 226)
[2025-05-08T06:35:50.399+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 251)
[2025-05-08T06:35:50.399+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[389] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T06:35:50.406+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 166.3 KiB, free 417.7 MiB)
[2025-05-08T06:35:50.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 58.6 KiB, free 417.7 MiB)
[2025-05-08T06:35:50.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on f2a432e4376a:46195 (size: 58.6 KiB, free: 433.4 MiB)
[2025-05-08T06:35:50.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:50.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[389] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:50.408+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Adding task set 250.0 with 10 tasks resource profile 0
[2025-05-08T06:35:50.408+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 0.0 in stage 250.0 (TID 445) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.413+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.20.0.5:41027 (size: 58.6 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.423+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 1.0 in stage 250.0 (TID 446) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.423+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 0.0 in stage 250.0 (TID 445) in 15 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:50.432+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 2.0 in stage 250.0 (TID 447) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.432+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 1.0 in stage 250.0 (TID 446) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:50.440+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 3.0 in stage 250.0 (TID 448) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.440+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 2.0 in stage 250.0 (TID 447) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:50.455+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 4.0 in stage 250.0 (TID 449) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.456+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 3.0 in stage 250.0 (TID 448) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:50.463+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 5.0 in stage 250.0 (TID 450) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.463+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 4.0 in stage 250.0 (TID 449) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:50.471+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 6.0 in stage 250.0 (TID 451) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.471+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 5.0 in stage 250.0 (TID 450) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:50.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 7.0 in stage 250.0 (TID 452) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 6.0 in stage 250.0 (TID 451) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:50.485+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 8.0 in stage 250.0 (TID 453) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.485+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 7.0 in stage 250.0 (TID 452) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:50.493+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 9.0 in stage 250.0 (TID 454) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.493+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 8.0 in stage 250.0 (TID 453) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:50.500+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 9.0 in stage 250.0 (TID 454) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:50.500+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool
[2025-05-08T06:35:50.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: ShuffleMapStage 250 (mapPartitions at GraphImpl.scala:208) finished in 0.101 s
[2025-05-08T06:35:50.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:50.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:50.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 251, ResultStage 252)
[2025-05-08T06:35:50.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:50.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[397] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T06:35:50.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 18.5 KiB, free 417.6 MiB)
[2025-05-08T06:35:50.503+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 417.6 MiB)
[2025-05-08T06:35:50.503+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on f2a432e4376a:46195 (size: 6.8 KiB, free: 433.4 MiB)
[2025-05-08T06:35:50.503+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:50.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[397] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:50.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Adding task set 251.0 with 10 tasks resource profile 0
[2025-05-08T06:35:50.505+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 455) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.20.0.5:41027 (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.511+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.20.0.5:43674
[2025-05-08T06:35:50.518+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_79_piece0 on f2a432e4376a:46195 in memory (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-08T06:35:50.519+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.20.0.5:41027 in memory (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.520+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_80_piece0 on f2a432e4376a:46195 in memory (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:50.522+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.20.0.5:41027 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.522+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.523+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_81_piece0 on f2a432e4376a:46195 in memory (size: 58.6 KiB, free: 433.6 MiB)
[2025-05-08T06:35:50.524+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.20.0.5:41027 in memory (size: 58.6 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.526+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 1.0 in stage 251.0 (TID 456) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.526+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 455) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:50.532+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.536+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 2.0 in stage 251.0 (TID 457) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.537+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 1.0 in stage 251.0 (TID 456) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:50.542+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.545+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 3.0 in stage 251.0 (TID 458) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.546+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 2.0 in stage 251.0 (TID 457) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:50.561+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.567+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 4.0 in stage 251.0 (TID 459) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.568+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 3.0 in stage 251.0 (TID 458) in 22 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:50.573+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.578+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 5.0 in stage 251.0 (TID 460) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.579+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 4.0 in stage 251.0 (TID 459) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:50.586+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.589+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 6.0 in stage 251.0 (TID 461) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.590+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 5.0 in stage 251.0 (TID 460) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:50.595+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.601+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 7.0 in stage 251.0 (TID 462) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.601+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 6.0 in stage 251.0 (TID 461) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:50.609+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.612+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 8.0 in stage 251.0 (TID 463) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.613+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 7.0 in stage 251.0 (TID 462) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:50.623+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.627+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 9.0 in stage 251.0 (TID 464) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.627+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 8.0 in stage 251.0 (TID 463) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:50.634+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_393_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.638+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 9.0 in stage 251.0 (TID 464) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:50.638+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool
[2025-05-08T06:35:50.638+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: ShuffleMapStage 251 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.137 s
[2025-05-08T06:35:50.639+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:50.639+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:50.639+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: waiting: Set(ResultStage 252)
[2025-05-08T06:35:50.639+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:50.639+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting ResultStage 252 (EdgeRDDImpl[400] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T06:35:50.643+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 166.1 KiB, free 417.9 MiB)
[2025-05-08T06:35:50.644+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.9 MiB)
[2025-05-08T06:35:50.644+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on f2a432e4376a:46195 (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:50.645+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:50.645+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 252 (EdgeRDDImpl[400] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:50.645+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Adding task set 252.0 with 10 tasks resource profile 0
[2025-05-08T06:35:50.646+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 0.0 in stage 252.0 (TID 465) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.652+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.20.0.5:41027 (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.659+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:43674
[2025-05-08T06:35:50.662+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_0 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.664+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 1.0 in stage 252.0 (TID 466) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.665+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 0.0 in stage 252.0 (TID 465) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:50.674+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_1 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.676+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 2.0 in stage 252.0 (TID 467) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.677+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 1.0 in stage 252.0 (TID 466) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:50.685+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_2 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.687+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 3.0 in stage 252.0 (TID 468) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.687+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 2.0 in stage 252.0 (TID 467) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:50.695+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_3 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.697+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 4.0 in stage 252.0 (TID 469) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.697+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 3.0 in stage 252.0 (TID 468) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:50.707+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_4 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.709+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 5.0 in stage 252.0 (TID 470) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.709+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 4.0 in stage 252.0 (TID 469) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:50.723+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_5 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.725+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 6.0 in stage 252.0 (TID 471) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.726+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 5.0 in stage 252.0 (TID 470) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:50.739+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_6 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.742+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 7.0 in stage 252.0 (TID 472) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 6.0 in stage 252.0 (TID 471) in 18 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:50.770+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_7 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.773+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 8.0 in stage 252.0 (TID 473) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.774+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 7.0 in stage 252.0 (TID 472) in 31 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:50.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_8 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.787+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 9.0 in stage 252.0 (TID 474) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.787+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 8.0 in stage 252.0 (TID 473) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:50.795+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added rdd_399_9 in memory on 172.20.0.5:41027 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.797+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 9.0 in stage 252.0 (TID 474) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:50.798+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool
[2025-05-08T06:35:50.798+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: ResultStage 252 (foreachPartition at PageRank.scala:199) finished in 0.158 s
[2025-05-08T06:35:50.798+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:50.799+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished
[2025-05-08T06:35:50.799+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 45 finished: foreachPartition at PageRank.scala:199, took 0.403710 s
[2025-05-08T06:35:50.799+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO PageRank: PageRank finished iteration 9.
[2025-05-08T06:35:50.800+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO ZippedPartitionsRDD2: Removing RDD 381 from persistence list
[2025-05-08T06:35:50.800+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManager: Removing RDD 381
[2025-05-08T06:35:50.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO ZippedPartitionsRDD2: Removing RDD 387 from persistence list
[2025-05-08T06:35:50.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManager: Removing RDD 387
[2025-05-08T06:35:50.816+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Starting job: sum at PageRank.scala:503
[2025-05-08T06:35:50.819+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Got job 46 (sum at PageRank.scala:503) with 10 output partitions
[2025-05-08T06:35:50.819+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Final stage: ResultStage 278 (sum at PageRank.scala:503)
[2025-05-08T06:35:50.819+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 269, ShuffleMapStage 263, ShuffleMapStage 273, ShuffleMapStage 255, ShuffleMapStage 267, ShuffleMapStage 277, ShuffleMapStage 256, ShuffleMapStage 271, ShuffleMapStage 259, ShuffleMapStage 275, ShuffleMapStage 261, ShuffleMapStage 265, ShuffleMapStage 254)
[2025-05-08T06:35:50.820+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:50.820+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting ResultStage 278 (MapPartitionsRDD[401] at values at PageRank.scala:503), which has no missing parents
[2025-05-08T06:35:50.821+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 18.9 KiB, free 417.9 MiB)
[2025-05-08T06:35:50.822+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 417.9 MiB)
[2025-05-08T06:35:50.822+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on f2a432e4376a:46195 (size: 7.1 KiB, free: 433.5 MiB)
[2025-05-08T06:35:50.823+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:50.823+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 278 (MapPartitionsRDD[401] at values at PageRank.scala:503) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:50.823+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Adding task set 278.0 with 10 tasks resource profile 0
[2025-05-08T06:35:50.824+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 475) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.828+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.20.0.5:41027 (size: 7.1 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.855+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 1.0 in stage 278.0 (TID 476) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.857+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 475) in 32 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:50.860+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 2.0 in stage 278.0 (TID 477) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.861+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 1.0 in stage 278.0 (TID 476) in 6 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:50.866+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 3.0 in stage 278.0 (TID 478) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 2.0 in stage 278.0 (TID 477) in 6 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:50.871+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 4.0 in stage 278.0 (TID 479) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.872+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 3.0 in stage 278.0 (TID 478) in 5 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:50.876+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 5.0 in stage 278.0 (TID 480) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.876+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 4.0 in stage 278.0 (TID 479) in 5 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:50.880+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 6.0 in stage 278.0 (TID 481) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.880+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 5.0 in stage 278.0 (TID 480) in 5 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:50.884+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 7.0 in stage 278.0 (TID 482) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 6.0 in stage 278.0 (TID 481) in 6 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:50.889+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 8.0 in stage 278.0 (TID 483) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.889+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 7.0 in stage 278.0 (TID 482) in 5 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:50.894+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 9.0 in stage 278.0 (TID 484) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.894+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 8.0 in stage 278.0 (TID 483) in 6 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:50.900+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 9.0 in stage 278.0 (TID 484) in 6 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:50.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool
[2025-05-08T06:35:50.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: ResultStage 278 (sum at PageRank.scala:503) finished in 0.080 s
[2025-05-08T06:35:50.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:50.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 278: Stage finished
[2025-05-08T06:35:50.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 46 finished: sum at PageRank.scala:503, took 0.084677 s
[2025-05-08T06:35:50.906+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T06:35:50.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Got job 47 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T06:35:50.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Final stage: ResultStage 304 (fold at VertexRDDImpl.scala:90)
[2025-05-08T06:35:50.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 287, ShuffleMapStage 299, ShuffleMapStage 281, ShuffleMapStage 291, ShuffleMapStage 303, ShuffleMapStage 285, ShuffleMapStage 289, ShuffleMapStage 293, ShuffleMapStage 282, ShuffleMapStage 297, ShuffleMapStage 301, ShuffleMapStage 280, ShuffleMapStage 295)
[2025-05-08T06:35:50.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:50.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting ResultStage 304 (MapPartitionsRDD[402] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T06:35:50.911+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 18.7 KiB, free 417.8 MiB)
[2025-05-08T06:35:50.920+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 417.8 MiB)
[2025-05-08T06:35:50.921+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on f2a432e4376a:46195 (size: 6.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:50.921+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:50.924+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 304 (MapPartitionsRDD[402] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:50.924+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Adding task set 304.0 with 10 tasks resource profile 0
[2025-05-08T06:35:50.924+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.20.0.5:41027 in memory (size: 7.1 KiB, free: 432.9 MiB)
[2025-05-08T06:35:50.925+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_84_piece0 on f2a432e4376a:46195 in memory (size: 7.1 KiB, free: 433.5 MiB)
[2025-05-08T06:35:50.925+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 485) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.930+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_83_piece0 on f2a432e4376a:46195 in memory (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:50.935+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.20.0.5:41027 in memory (size: 58.0 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.937+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.20.0.5:41027 (size: 6.9 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.938+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_82_piece0 on f2a432e4376a:46195 in memory (size: 6.8 KiB, free: 433.6 MiB)
[2025-05-08T06:35:50.939+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.20.0.5:41027 in memory (size: 6.8 KiB, free: 433.0 MiB)
[2025-05-08T06:35:50.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 1.0 in stage 304.0 (TID 486) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 485) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:50.946+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 2.0 in stage 304.0 (TID 487) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.946+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 1.0 in stage 304.0 (TID 486) in 5 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:50.951+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 3.0 in stage 304.0 (TID 488) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.951+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 2.0 in stage 304.0 (TID 487) in 6 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:50.956+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 4.0 in stage 304.0 (TID 489) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.956+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 3.0 in stage 304.0 (TID 488) in 5 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:50.960+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 5.0 in stage 304.0 (TID 490) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.960+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 4.0 in stage 304.0 (TID 489) in 4 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:50.963+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 6.0 in stage 304.0 (TID 491) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.963+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 5.0 in stage 304.0 (TID 490) in 4 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:50.976+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 7.0 in stage 304.0 (TID 492) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.976+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 6.0 in stage 304.0 (TID 491) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:50.980+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 8.0 in stage 304.0 (TID 493) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.980+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 7.0 in stage 304.0 (TID 492) in 5 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:50.985+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Starting task 9.0 in stage 304.0 (TID 494) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:50.985+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 8.0 in stage 304.0 (TID 493) in 6 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:50.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSetManager: Finished task 9.0 in stage 304.0 (TID 494) in 3 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:50.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool
[2025-05-08T06:35:50.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: ResultStage 304 (fold at VertexRDDImpl.scala:90) finished in 0.080 s
[2025-05-08T06:35:50.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:50.990+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 304: Stage finished
[2025-05-08T06:35:50.990+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:50 INFO DAGScheduler: Job 47 finished: fold at VertexRDDImpl.scala:90, took 0.083749 s
[2025-05-08T06:35:51.333+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:51 INFO BlockManagerInfo: Removed broadcast_85_piece0 on f2a432e4376a:46195 in memory (size: 6.9 KiB, free: 433.6 MiB)
[2025-05-08T06:35:51.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:51 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.20.0.5:41027 in memory (size: 6.9 KiB, free: 433.0 MiB)
[2025-05-08T06:35:51.365+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:51,364 [INFO] Экспортируем граф в GraphML
[2025-05-08T06:35:52.126+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 5.912161 ms
[2025-05-08T06:35:52.126+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#2025 - id.nullCount#2024) > 0)
[2025-05-08T06:35:52.138+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:52.138+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got job 48 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-08T06:35:52.138+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ResultStage 306 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.139+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 305)
[2025-05-08T06:35:52.139+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.139+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ResultStage 306 (MapPartitionsRDD[441] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.141+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 43.9 KiB, free 418.1 MiB)
[2025-05-08T06:35:52.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 418.1 MiB)
[2025-05-08T06:35:52.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on f2a432e4376a:46195 (size: 19.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.143+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 306 (MapPartitionsRDD[441] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:52.143+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 306.0 with 10 tasks resource profile 0
[2025-05-08T06:35:52.143+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 0.0 in stage 306.0 (TID 495) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 14.633323 ms
[2025-05-08T06:35:52.151+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.20.0.5:41027 (size: 19.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.152+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 444 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 53
[2025-05-08T06:35:52.153+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 49 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-08T06:35:52.153+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 309 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.153+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 307, ShuffleMapStage 308)
[2025-05-08T06:35:52.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 309 (MapPartitionsRDD[444] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 23.3 KiB, free 418.0 MiB)
[2025-05-08T06:35:52.161+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 418.0 MiB)
[2025-05-08T06:35:52.161+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on f2a432e4376a:46195 (size: 9.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.162+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.162+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 309 (MapPartitionsRDD[444] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:52.162+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 309.0 with 10 tasks resource profile 0
[2025-05-08T06:35:52.171+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 13.185193 ms
[2025-05-08T06:35:52.174+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 1.0 in stage 306.0 (TID 496) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.176+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 0.0 in stage 306.0 (TID 495) in 32 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:52.178+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 447 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 54
[2025-05-08T06:35:52.178+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 50 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-08T06:35:52.178+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 332 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.179+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 317, ShuffleMapStage 321, ShuffleMapStage 310, ShuffleMapStage 325, ShuffleMapStage 307, ShuffleMapStage 329, ShuffleMapStage 308, ShuffleMapStage 323, ShuffleMapStage 315, ShuffleMapStage 327, ShuffleMapStage 319, ShuffleMapStage 331, ShuffleMapStage 313)
[2025-05-08T06:35:52.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 332 (MapPartitionsRDD[447] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.185+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 2.0 in stage 306.0 (TID 497) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.185+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 1.0 in stage 306.0 (TID 496) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:52.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 11.272388 ms
[2025-05-08T06:35:52.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 31.6 KiB, free 418.0 MiB)
[2025-05-08T06:35:52.191+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 418.0 MiB)
[2025-05-08T06:35:52.191+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on f2a432e4376a:46195 (size: 11.8 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.195+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 3.0 in stage 306.0 (TID 498) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 2.0 in stage 306.0 (TID 497) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:52.198+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.201+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 332 (MapPartitionsRDD[447] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:52.201+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 332.0 with 10 tasks resource profile 0
[2025-05-08T06:35:52.205+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 10.25055 ms
[2025-05-08T06:35:52.219+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 4.0 in stage 306.0 (TID 499) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.221+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 3.0 in stage 306.0 (TID 498) in 25 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:52.222+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 8.759346 ms
[2025-05-08T06:35:52.228+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 5.0 in stage 306.0 (TID 500) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.228+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 4.0 in stage 306.0 (TID 499) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:52.236+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 9.662287 ms
[2025-05-08T06:35:52.246+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 6.0 in stage 306.0 (TID 501) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.246+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 5.0 in stage 306.0 (TID 500) in 19 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:52.254+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 7.0 in stage 306.0 (TID 502) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.254+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 6.0 in stage 306.0 (TID 501) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:52.256+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 6.720174 ms
[2025-05-08T06:35:52.259+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 8.0 in stage 306.0 (TID 503) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.260+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 7.0 in stage 306.0 (TID 502) in 6 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:52.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 9.0 in stage 306.0 (TID 504) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 8.0 in stage 306.0 (TID 503) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:52.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 11.573225 ms
[2025-05-08T06:35:52.274+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 505) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.274+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 9.0 in stage 306.0 (TID 504) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:52.274+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool
[2025-05-08T06:35:52.275+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: ResultStage 306 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.136 s
[2025-05-08T06:35:52.276+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:52.277+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 306: Stage finished
[2025-05-08T06:35:52.277+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Job 48 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.137557 s
[2025-05-08T06:35:52.278+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 455 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 55
[2025-05-08T06:35:52.278+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 51 (toPandas at /opt/airflow/spark/build_graph.py:207) with 6 output partitions
[2025-05-08T06:35:52.279+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 333 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.279+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.280+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.280+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 333 (MapPartitionsRDD[455] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.281+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 36.4 KiB, free 418.0 MiB)
[2025-05-08T06:35:52.283+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 417.9 MiB)
[2025-05-08T06:35:52.283+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on f2a432e4376a:46195 (size: 11.2 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.284+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.284+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 333 (MapPartitionsRDD[455] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:35:52.284+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 333.0 with 6 tasks resource profile 0
[2025-05-08T06:35:52.286+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 7.453743 ms
[2025-05-08T06:35:52.286+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.20.0.5:41027 (size: 9.9 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.289+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 11.339249 ms
[2025-05-08T06:35:52.290+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 2.1 MiB, free 415.9 MiB)
[2025-05-08T06:35:52.291+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 415.9 MiB)
[2025-05-08T06:35:52.292+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on f2a432e4376a:46195 (size: 27.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.293+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 90 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:52.295+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 457 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 56
[2025-05-08T06:35:52.295+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:52.296+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 52 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.296+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 334 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.296+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.296+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 334 (MapPartitionsRDD[457] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 12.7 KiB, free 415.8 MiB)
[2025-05-08T06:35:52.308+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 415.8 MiB)
[2025-05-08T06:35:52.309+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on f2a432e4376a:46195 (size: 6.8 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.312+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.313+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 334 (MapPartitionsRDD[457] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.313+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 334.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.313+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Removed broadcast_86_piece0 on f2a432e4376a:46195 in memory (size: 19.5 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.313+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.20.0.5:41027 in memory (size: 19.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.321+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 13.217404 ms
[2025-05-08T06:35:52.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:52.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 459 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 57
[2025-05-08T06:35:52.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 53 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 335 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 335 (MapPartitionsRDD[459] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.333+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 27.3 KiB, free 415.9 MiB)
[2025-05-08T06:35:52.334+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 415.9 MiB)
[2025-05-08T06:35:52.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 335 (MapPartitionsRDD[459] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 335.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.351+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 1.0 in stage 309.0 (TID 506) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.352+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 19.469294 ms
[2025-05-08T06:35:52.353+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 505) in 76 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:52.356+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:52.357+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 461 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 58
[2025-05-08T06:35:52.358+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 54 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.358+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 336 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.358+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.358+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.359+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 336 (MapPartitionsRDD[461] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.362+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 28.5 KiB, free 415.8 MiB)
[2025-05-08T06:35:52.363+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 2.0 in stage 309.0 (TID 507) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.364+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 1.0 in stage 309.0 (TID 506) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:52.366+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 415.8 MiB)
[2025-05-08T06:35:52.370+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 336 (MapPartitionsRDD[461] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 336.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 3.0 in stage 309.0 (TID 508) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.388+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 2.0 in stage 309.0 (TID 507) in 25 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:52.398+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 32.226547 ms
[2025-05-08T06:35:52.400+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 4.0 in stage 309.0 (TID 509) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 463 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 59
[2025-05-08T06:35:52.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 55 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 337 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.402+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.402+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:52.402+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 337 (MapPartitionsRDD[463] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.403+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 3.0 in stage 309.0 (TID 508) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:52.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 28.5 KiB, free 415.8 MiB)
[2025-05-08T06:35:52.416+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 415.8 MiB)
[2025-05-08T06:35:52.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-08T06:35:52.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 337 (MapPartitionsRDD[463] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 337.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 5.0 in stage 309.0 (TID 510) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.419+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 4.0 in stage 309.0 (TID 509) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:52.419+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 13.247565 ms
[2025-05-08T06:35:52.425+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:52.426+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 465 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 60
[2025-05-08T06:35:52.426+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 56 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.426+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 338 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.427+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.427+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.427+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 338 (MapPartitionsRDD[465] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.428+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 27.4 KiB, free 415.7 MiB)
[2025-05-08T06:35:52.429+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 415.7 MiB)
[2025-05-08T06:35:52.429+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 433.4 MiB)
[2025-05-08T06:35:52.433+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 338 (MapPartitionsRDD[465] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 338.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 6.0 in stage 309.0 (TID 511) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 5.0 in stage 309.0 (TID 510) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:52.449+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 19.299145 ms
[2025-05-08T06:35:52.452+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:52.457+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 467 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 61
[2025-05-08T06:35:52.458+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 57 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 339 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.460+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 339 (MapPartitionsRDD[467] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.460+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 7.0 in stage 309.0 (TID 512) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 28.5 KiB, free 415.7 MiB)
[2025-05-08T06:35:52.477+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 415.7 MiB)
[2025-05-08T06:35:52.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-08T06:35:52.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 339 (MapPartitionsRDD[467] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 339.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 6.0 in stage 309.0 (TID 511) in 46 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:52.481+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 8.0 in stage 309.0 (TID 513) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.482+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 7.0 in stage 309.0 (TID 512) in 24 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:52.493+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 35.898648 ms
[2025-05-08T06:35:52.495+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 9.0 in stage 309.0 (TID 514) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.499+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 8.0 in stage 309.0 (TID 513) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:52.500+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 469 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 62
[2025-05-08T06:35:52.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 58 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 340 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.503+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.503+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 340 (MapPartitionsRDD[469] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.505+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 31.7 KiB, free 415.7 MiB)
[2025-05-08T06:35:52.507+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 0.0 in stage 332.0 (TID 515) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.508+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 9.0 in stage 309.0 (TID 514) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:52.508+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool
[2025-05-08T06:35:52.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 415.6 MiB)
[2025-05-08T06:35:52.509+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on f2a432e4376a:46195 (size: 14.9 KiB, free: 433.4 MiB)
[2025-05-08T06:35:52.510+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.511+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 340 (MapPartitionsRDD[469] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.511+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 340.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.512+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: ShuffleMapStage 309 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.356 s
[2025-05-08T06:35:52.512+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:52.512+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ShuffleMapStage 332, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ShuffleMapStage 333, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-08T06:35:52.513+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:52.513+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:52.543+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.20.0.5:41027 (size: 11.8 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.590+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_0 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.612+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 1.0 in stage 332.0 (TID 516) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.617+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 0.0 in stage 332.0 (TID 515) in 111 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:52.622+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_1 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.630+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 2.0 in stage 332.0 (TID 517) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.630+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 8.226259 ms
[2025-05-08T06:35:52.630+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 1.0 in stage 332.0 (TID 516) in 19 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:52.635+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 475 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 63
[2025-05-08T06:35:52.635+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 59 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 341 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 341 (MapPartitionsRDD[475] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.643+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 16.6 KiB, free 415.6 MiB)
[2025-05-08T06:35:52.643+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_2 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.662+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 415.6 MiB)
[2025-05-08T06:35:52.663+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on f2a432e4376a:46195 (size: 8.3 KiB, free: 433.4 MiB)
[2025-05-08T06:35:52.665+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Removed broadcast_87_piece0 on f2a432e4376a:46195 in memory (size: 9.9 KiB, free: 433.4 MiB)
[2025-05-08T06:35:52.669+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.670+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 341 (MapPartitionsRDD[475] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.670+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 341.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.671+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO CodeGenerator: Code generated in 30.970835 ms
[2025-05-08T06:35:52.672+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.20.0.5:41027 in memory (size: 9.9 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.673+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Registering RDD 477 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 64
[2025-05-08T06:35:52.674+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got map stage job 60 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.674+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ShuffleMapStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:52.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ShuffleMapStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.678+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 3.0 in stage 332.0 (TID 518) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.683+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 15.0 KiB, free 415.6 MiB)
[2025-05-08T06:35:52.684+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 415.6 MiB)
[2025-05-08T06:35:52.685+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 2.0 in stage 332.0 (TID 517) in 52 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:52.686+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on f2a432e4376a:46195 (size: 7.7 KiB, free: 433.4 MiB)
[2025-05-08T06:35:52.686+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.687+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.687+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 342.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.691+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_3 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.704+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:52.705+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:52.705+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 4.0 in stage 332.0 (TID 519) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.706+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 3.0 in stage 332.0 (TID 518) in 25 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:52.712+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_4 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.720+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 5.0 in stage 332.0 (TID 520) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 4.0 in stage 332.0 (TID 519) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:52.742+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_5 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.751+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 6.0 in stage 332.0 (TID 521) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.751+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 5.0 in stage 332.0 (TID 520) in 31 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:52.761+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_6 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.769+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 6.0 in stage 332.0 (TID 521) in 19 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:52.771+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 7.0 in stage 332.0 (TID 522) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.779+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_7 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-08T06:35:52.787+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 8.0 in stage 332.0 (TID 523) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.787+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 7.0 in stage 332.0 (TID 522) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:52.788+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:52.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got job 61 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ResultStage 344 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 343)
[2025-05-08T06:35:52.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ResultStage 344 (MapPartitionsRDD[480] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.791+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-08T06:35:52.802+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-08T06:35:52.802+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-08T06:35:52.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_8 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:52.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 344 (MapPartitionsRDD[480] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 344.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.810+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 9.0 in stage 332.0 (TID 524) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.811+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 8.0 in stage 332.0 (TID 523) in 25 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:52.818+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added rdd_403_9 in memory on 172.20.0.5:41027 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:52.824+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 0.0 in stage 333.0 (TID 525) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.824+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 9.0 in stage 332.0 (TID 524) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:52.825+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Removed TaskSet 332.0, whose tasks have all completed, from pool
[2025-05-08T06:35:52.825+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: ShuffleMapStage 332 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.645 s
[2025-05-08T06:35:52.825+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:52.825+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 333, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-08T06:35:52.825+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:52.825+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:52.829+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.20.0.5:41027 (size: 11.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:52.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO ShufflePartitionsUtil: For shuffle(54), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:52.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 1.0 in stage 333.0 (TID 526) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.885+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 0.0 in stage 333.0 (TID 525) in 61 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:35:52.904+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:52.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Got job 62 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:52.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Final stage: ResultStage 368 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:52.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 367)
[2025-05-08T06:35:52.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:52.910+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting ResultStage 368 (MapPartitionsRDD[483] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:52.912+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-08T06:35:52.928+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-08T06:35:52.929+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-08T06:35:52.934+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:52.935+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 368 (MapPartitionsRDD[483] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:52.936+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSchedulerImpl: Adding task set 368.0 with 1 tasks resource profile 0
[2025-05-08T06:35:52.936+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 2.0 in stage 333.0 (TID 527) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.936+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 1.0 in stage 333.0 (TID 526) in 49 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:35:52.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Starting task 3.0 in stage 333.0 (TID 528) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:52.980+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO TaskSetManager: Finished task 2.0 in stage 333.0 (TID 527) in 47 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:35:52.997+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Removed broadcast_88_piece0 on f2a432e4376a:46195 in memory (size: 11.8 KiB, free: 433.4 MiB)
[2025-05-08T06:35:52.998+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:52 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.20.0.5:41027 in memory (size: 11.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.015+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 4.0 in stage 333.0 (TID 529) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.016+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 3.0 in stage 333.0 (TID 528) in 36 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:35:53.044+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 5.0 in stage 333.0 (TID 530) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.044+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 4.0 in stage 333.0 (TID 529) in 30 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:35:53.088+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 334.0 (TID 531) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.089+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 5.0 in stage 333.0 (TID 530) in 45 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:35:53.089+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.089+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 333 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.811 s
[2025-05-08T06:35:53.089+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.089+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-08T06:35:53.089+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.090+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.093+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.20.0.5:41027 (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.107+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:53.108+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:53.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 335.0 (TID 532) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.136+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 334.0 (TID 531) in 47 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.138+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 334.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.138+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 334 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.843 s
[2025-05-08T06:35:53.139+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.139+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337)
[2025-05-08T06:35:53.139+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.139+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:53.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Got job 63 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:53.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Final stage: ResultStage 370 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:53.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 369)
[2025-05-08T06:35:53.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:53.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Submitting ResultStage 370 (MapPartitionsRDD[486] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:53.157+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-08T06:35:53.168+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-08T06:35:53.169+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-08T06:35:53.169+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_91_piece0 on f2a432e4376a:46195 in memory (size: 6.8 KiB, free: 433.4 MiB)
[2025-05-08T06:35:53.170+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:53.171+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 370 (MapPartitionsRDD[486] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:53.172+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Adding task set 370.0 with 1 tasks resource profile 0
[2025-05-08T06:35:53.174+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.20.0.5:41027 in memory (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.178+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO ShufflePartitionsUtil: For shuffle(56), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:53.189+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_89_piece0 on f2a432e4376a:46195 in memory (size: 11.2 KiB, free: 433.4 MiB)
[2025-05-08T06:35:53.194+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.20.0.5:41027 in memory (size: 11.2 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 336.0 (TID 533) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.197+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 335.0 (TID 532) in 61 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.197+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 335.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.199+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 335 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.869 s
[2025-05-08T06:35:53.201+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.201+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ResultStage 370)
[2025-05-08T06:35:53.201+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.202+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:53.268+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Got job 64 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:53.269+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Final stage: ResultStage 372 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:53.271+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 371)
[2025-05-08T06:35:53.272+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:53.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Submitting ResultStage 372 (MapPartitionsRDD[489] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:53.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 7.2 KiB, free 415.7 MiB)
[2025-05-08T06:35:53.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.7 MiB)
[2025-05-08T06:35:53.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-08T06:35:53.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:53.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 372 (MapPartitionsRDD[489] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:53.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Adding task set 372.0 with 1 tasks resource profile 0
[2025-05-08T06:35:53.287+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 337.0 (TID 534) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.288+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 336.0 (TID 533) in 92 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.288+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 336.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.288+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 336 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.929 s
[2025-05-08T06:35:53.288+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.288+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ResultStage 370)
[2025-05-08T06:35:53.288+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.288+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 338.0 (TID 535) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 337.0 (TID 534) in 44 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 337 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.928 s
[2025-05-08T06:35:53.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-08T06:35:53.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.339+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.370+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 339.0 (TID 536) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 338.0 (TID 535) in 40 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 338 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.943 s
[2025-05-08T06:35:53.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-08T06:35:53.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.372+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.372+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 338.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 340.0 (TID 537) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 339.0 (TID 536) in 47 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 339.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 339 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.959 s
[2025-05-08T06:35:53.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-08T06:35:53.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.424+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.20.0.5:41027 (size: 14.9 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.482+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 341.0 (TID 538) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.483+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 340.0 (TID 537) in 66 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.483+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 340.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.483+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 340 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.983 s
[2025-05-08T06:35:53.484+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.484+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ResultStage 372, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-08T06:35:53.484+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.484+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.490+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.20.0.5:41027 (size: 8.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO ShufflePartitionsUtil: For shuffle(57, 58, 59, 60, 61, 62), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:53.534+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.20.0.5:41027 (size: 27.5 KiB, free: 432.8 MiB)
[2025-05-08T06:35:53.547+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO CodeGenerator: Code generated in 4.310901 ms
[2025-05-08T06:35:53.547+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:53.561+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO CodeGenerator: Code generated in 11.308566 ms
[2025-05-08T06:35:53.563+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 342.0 (TID 539) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.563+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 341.0 (TID 538) in 82 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.563+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 341.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.563+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 341 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.924 s
[2025-05-08T06:35:53.563+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.563+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ResultStage 372, ResultStage 344, ResultStage 370)
[2025-05-08T06:35:53.564+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.564+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.564+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:53.580+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.20.0.5:41027 (size: 7.7 KiB, free: 432.8 MiB)
[2025-05-08T06:35:53.580+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO CodeGenerator: Code generated in 14.08562 ms
[2025-05-08T06:35:53.585+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:53.596+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO CodeGenerator: Code generated in 9.463758 ms
[2025-05-08T06:35:53.602+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:53.610+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 344.0 (TID 540) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.611+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 342.0 (TID 539) in 48 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.611+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 342.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.611+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ShuffleMapStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.936 s
[2025-05-08T06:35:53.611+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:53.612+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: running: Set(ResultStage 368, ResultStage 372, ResultStage 344, ResultStage 370)
[2025-05-08T06:35:53.612+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:53.612+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:53.617+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO CodeGenerator: Code generated in 11.603342 ms
[2025-05-08T06:35:53.623+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:53.626+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-08T06:35:53.629+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:43674
[2025-05-08T06:35:53.642+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_92_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 433.4 MiB)
[2025-05-08T06:35:53.648+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO CodeGenerator: Code generated in 23.209346 ms
[2025-05-08T06:35:53.649+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 368.0 (TID 541) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.651+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 344.0 (TID 540) in 39 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.651+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.651+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ResultStage 344 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.860 s
[2025-05-08T06:35:53.652+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:53.652+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 344: Stage finished
[2025-05-08T06:35:53.652+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 432.8 MiB)
[2025-05-08T06:35:53.659+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:53.664+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_97_piece0 on f2a432e4376a:46195 in memory (size: 14.9 KiB, free: 433.5 MiB)
[2025-05-08T06:35:53.666+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.20.0.5:41027 in memory (size: 14.9 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.666+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Job 61 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.868171 s
[2025-05-08T06:35:53.678+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_99_piece0 on f2a432e4376a:46195 in memory (size: 7.7 KiB, free: 433.5 MiB)
[2025-05-08T06:35:53.679+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-08T06:35:53.680+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.20.0.5:41027 in memory (size: 7.7 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.682+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO CodeGenerator: Code generated in 20.972679 ms
[2025-05-08T06:35:53.683+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.20.0.5:43674
[2025-05-08T06:35:53.687+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_93_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-08T06:35:53.689+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.693+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO CodeGenerator: Code generated in 7.887075 ms
[2025-05-08T06:35:53.698+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 370.0 (TID 542) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.700+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 368.0 (TID 541) in 51 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.702+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 368.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.702+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ResultStage 368 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.790 s
[2025-05-08T06:35:53.706+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:53.707+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 368: Stage finished
[2025-05-08T06:35:53.708+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Job 62 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.798963 s
[2025-05-08T06:35:53.708+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_98_piece0 on f2a432e4376a:46195 in memory (size: 8.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:53.709+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:53.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Got job 65 (toPandas at /opt/airflow/spark/build_graph.py:207) with 6 output partitions
[2025-05-08T06:35:53.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Final stage: ResultStage 379 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:53.714+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 374, ShuffleMapStage 375, ShuffleMapStage 376, ShuffleMapStage 373, ShuffleMapStage 377, ShuffleMapStage 378)
[2025-05-08T06:35:53.714+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:53.716+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Submitting ResultStage 379 (MapPartitionsRDD[512] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:53.718+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 1088.0 KiB, free 414.8 MiB)
[2025-05-08T06:35:53.718+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.20.0.5:41027 in memory (size: 8.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.719+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.719+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 1088.0 KiB, free 413.7 MiB)
[2025-05-08T06:35:53.719+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 91.7 KiB, free 413.7 MiB)
[2025-05-08T06:35:53.719+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 413.6 MiB)
[2025-05-08T06:35:53.719+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on f2a432e4376a:46195 (size: 30.3 KiB, free: 433.5 MiB)
[2025-05-08T06:35:53.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:53.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:43674
[2025-05-08T06:35:53.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 379 (MapPartitionsRDD[512] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:35:53.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Adding task set 379.0 with 6 tasks resource profile 0
[2025-05-08T06:35:53.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_95_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-08T06:35:53.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 413.6 MiB)
[2025-05-08T06:35:53.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 413.6 MiB)
[2025-05-08T06:35:53.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on f2a432e4376a:46195 (size: 23.7 KiB, free: 433.4 MiB)
[2025-05-08T06:35:53.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on f2a432e4376a:46195 (size: 32.6 KiB, free: 433.4 MiB)
[2025-05-08T06:35:53.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Created broadcast 105 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:53.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_96_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-08T06:35:53.731+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Created broadcast 104 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:53.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.782+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.783+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 372.0 (TID 543) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.784+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 370.0 (TID 542) in 82 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.784+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 370.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ResultStage 370 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.624 s
[2025-05-08T06:35:53.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:53.786+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 370: Stage finished
[2025-05-08T06:35:53.786+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Job 63 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.625621 s
[2025-05-08T06:35:53.791+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_94_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-08T06:35:53.807+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.812+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:53.813+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:43674
[2025-05-08T06:35:53.832+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 5.0 MiB, free 408.7 MiB)
[2025-05-08T06:35:53.848+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 408.2 MiB)
[2025-05-08T06:35:53.849+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on f2a432e4376a:46195 (size: 502.1 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.852+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Created broadcast 107 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:53.858+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 0.0 in stage 379.0 (TID 544) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.858+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 372.0 (TID 543) in 79 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:53.863+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Removed TaskSet 372.0, whose tasks have all completed, from pool
[2025-05-08T06:35:53.866+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: ResultStage 372 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.594 s
[2025-05-08T06:35:53.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:53.869+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 372: Stage finished
[2025-05-08T06:35:53.870+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Job 64 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.598498 s
[2025-05-08T06:35:53.897+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.20.0.5:41027 (size: 30.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_101_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 2.1 MiB, free 406.1 MiB)
[2025-05-08T06:35:53.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 406.1 MiB)
[2025-05-08T06:35:53.908+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on f2a432e4376a:46195 (size: 20.6 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 172.20.0.5:43674
[2025-05-08T06:35:53.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO SparkContext: Created broadcast 108 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:53.909+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.929+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_103_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.933+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.965+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Starting task 1.0 in stage 379.0 (TID 545) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:53.968+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO TaskSetManager: Finished task 0.0 in stage 379.0 (TID 544) in 109 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:35:53.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_100_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.970+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.980+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_102_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.984+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.20.0.5:43674
[2025-05-08T06:35:53.986+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO CodeGenerator: Code generated in 23.331214 ms
[2025-05-08T06:35:53.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:53.997+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Registering RDD 516 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 65
[2025-05-08T06:35:54.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Got map stage job 66 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:54.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Final stage: ShuffleMapStage 381 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:54.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 380)
[2025-05-08T06:35:54.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:54.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:53 INFO DAGScheduler: Submitting ShuffleMapStage 381 (MapPartitionsRDD[516] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:54.036+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 13.5 KiB, free 406.1 MiB)
[2025-05-08T06:35:54.041+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 406.1 MiB)
[2025-05-08T06:35:54.043+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on f2a432e4376a:46195 (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:54.048+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:54.049+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 381 (MapPartitionsRDD[516] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:54.049+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Adding task set 381.0 with 1 tasks resource profile 0
[2025-05-08T06:35:54.058+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Starting task 2.0 in stage 379.0 (TID 546) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:54.060+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Finished task 1.0 in stage 379.0 (TID 545) in 95 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:35:54.061+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:54.063+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO ShufflePartitionsUtil: For shuffle(64), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:54.069+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.20.0.5:43674
[2025-05-08T06:35:54.104+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Starting task 3.0 in stage 379.0 (TID 547) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:54.105+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Finished task 2.0 in stage 379.0 (TID 546) in 45 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:35:54.119+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 172.20.0.5:43674
[2025-05-08T06:35:54.140+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO CodeGenerator: Code generated in 7.225625 ms
[2025-05-08T06:35:54.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Registering RDD 520 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 66
[2025-05-08T06:35:54.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Got map stage job 67 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:54.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Final stage: ShuffleMapStage 382 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:54.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 380)
[2025-05-08T06:35:54.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:54.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting ShuffleMapStage 382 (MapPartitionsRDD[520] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:54.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 13.6 KiB, free 406.1 MiB)
[2025-05-08T06:35:54.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 406.1 MiB)
[2025-05-08T06:35:54.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on f2a432e4376a:46195 (size: 6.9 KiB, free: 432.9 MiB)
[2025-05-08T06:35:54.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:54.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 382 (MapPartitionsRDD[520] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:54.156+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Adding task set 382.0 with 1 tasks resource profile 0
[2025-05-08T06:35:54.173+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Starting task 4.0 in stage 379.0 (TID 548) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:54.174+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Finished task 3.0 in stage 379.0 (TID 547) in 71 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:35:54.179+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO CodeGenerator: Code generated in 28.033017 ms
[2025-05-08T06:35:54.180+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.20.0.5:43674
[2025-05-08T06:35:54.214+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Starting task 5.0 in stage 379.0 (TID 549) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:54.219+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Finished task 4.0 in stage 379.0 (TID 548) in 40 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:35:54.220+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Registering RDD 523 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 67
[2025-05-08T06:35:54.220+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Got map stage job 68 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:54.220+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Final stage: ShuffleMapStage 384 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:54.220+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 383)
[2025-05-08T06:35:54.220+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:54.220+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting ShuffleMapStage 384 (MapPartitionsRDD[523] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:54.223+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.20.0.5:43674
[2025-05-08T06:35:54.246+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 78.0 KiB, free 406.0 MiB)
[2025-05-08T06:35:54.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 406.0 MiB)
[2025-05-08T06:35:54.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on f2a432e4376a:46195 (size: 34.5 KiB, free: 432.9 MiB)
[2025-05-08T06:35:54.251+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:54.251+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 384 (MapPartitionsRDD[523] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:54.253+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Adding task set 384.0 with 1 tasks resource profile 0
[2025-05-08T06:35:54.293+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Starting task 0.0 in stage 381.0 (TID 550) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:54.295+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Finished task 5.0 in stage 379.0 (TID 549) in 85 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:35:54.296+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Removed TaskSet 379.0, whose tasks have all completed, from pool
[2025-05-08T06:35:54.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: ResultStage 379 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.586 s
[2025-05-08T06:35:54.298+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:54.301+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 379: Stage finished
[2025-05-08T06:35:54.302+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Job 65 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.593838 s
[2025-05-08T06:35:54.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Removed broadcast_106_piece0 on f2a432e4376a:46195 in memory (size: 30.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:54.343+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 2.3 MiB, free 403.9 MiB)
[2025-05-08T06:35:54.345+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 403.8 MiB)
[2025-05-08T06:35:54.348+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on f2a432e4376a:46195 (size: 114.2 KiB, free: 432.8 MiB)
[2025-05-08T06:35:54.349+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO SparkContext: Created broadcast 112 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:54.397+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.20.0.5:41027 in memory (size: 30.3 KiB, free: 432.9 MiB)
[2025-05-08T06:35:54.403+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.20.0.5:41027 (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-08T06:35:54.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 63 to 172.20.0.5:43674
[2025-05-08T06:35:54.448+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.20.0.5:41027 (size: 23.7 KiB, free: 432.9 MiB)
[2025-05-08T06:35:54.500+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO CodeGenerator: Code generated in 33.012211 ms
[2025-05-08T06:35:54.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Starting task 0.0 in stage 382.0 (TID 551) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:54.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:54.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Finished task 0.0 in stage 381.0 (TID 550) in 202 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:54.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Removed TaskSet 381.0, whose tasks have all completed, from pool
[2025-05-08T06:35:54.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: ShuffleMapStage 381 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.497 s
[2025-05-08T06:35:54.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:54.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: running: Set(ShuffleMapStage 384, ShuffleMapStage 382)
[2025-05-08T06:35:54.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:54.502+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:54.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.20.0.5:41027 (size: 6.9 KiB, free: 432.9 MiB)
[2025-05-08T06:35:54.554+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.20.0.5:41027 (size: 32.6 KiB, free: 432.9 MiB)
[2025-05-08T06:35:54.558+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO CodeGenerator: Code generated in 46.705152 ms
[2025-05-08T06:35:54.577+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Starting task 0.0 in stage 384.0 (TID 552) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:54.581+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Finished task 0.0 in stage 382.0 (TID 551) in 84 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:54.581+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Removed TaskSet 382.0, whose tasks have all completed, from pool
[2025-05-08T06:35:54.582+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: ShuffleMapStage 382 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.434 s
[2025-05-08T06:35:54.586+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:54.586+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: running: Set(ShuffleMapStage 384)
[2025-05-08T06:35:54.586+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:54.586+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:54.597+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO CodeGenerator: Code generated in 12.975318 ms
[2025-05-08T06:35:54.605+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.20.0.5:41027 (size: 34.5 KiB, free: 432.8 MiB)
[2025-05-08T06:35:54.607+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Registering RDD 530 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 68
[2025-05-08T06:35:54.608+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Got map stage job 69 (toPandas at /opt/airflow/spark/build_graph.py:207) with 11 output partitions
[2025-05-08T06:35:54.608+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Final stage: ShuffleMapStage 386 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:54.609+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 385)
[2025-05-08T06:35:54.609+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:54.610+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting ShuffleMapStage 386 (MapPartitionsRDD[530] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:54.615+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO ShufflePartitionsUtil: For shuffle(65), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:54.618+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 141.2 KiB, free 403.6 MiB)
[2025-05-08T06:35:54.643+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 49.6 KiB, free 403.6 MiB)
[2025-05-08T06:35:54.648+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on f2a432e4376a:46195 (size: 49.6 KiB, free: 432.8 MiB)
[2025-05-08T06:35:54.650+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Removed broadcast_109_piece0 on f2a432e4376a:46195 in memory (size: 6.8 KiB, free: 432.8 MiB)
[2025-05-08T06:35:54.650+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:54.652+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 386 (MapPartitionsRDD[530] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-08T06:35:54.654+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Adding task set 386.0 with 11 tasks resource profile 0
[2025-05-08T06:35:54.659+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.20.0.5:41027 in memory (size: 6.8 KiB, free: 432.8 MiB)
[2025-05-08T06:35:54.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Removed broadcast_110_piece0 on f2a432e4376a:46195 in memory (size: 6.9 KiB, free: 432.8 MiB)
[2025-05-08T06:35:54.688+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.20.0.5:43674
[2025-05-08T06:35:54.689+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.20.0.5:41027 in memory (size: 6.9 KiB, free: 432.8 MiB)
[2025-05-08T06:35:54.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:54.723+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Got job 70 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:54.724+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Final stage: ResultStage 389 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:54.724+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 388)
[2025-05-08T06:35:54.726+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:54.726+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting ResultStage 389 (MapPartitionsRDD[532] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:54.728+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 7.2 KiB, free 403.6 MiB)
[2025-05-08T06:35:54.730+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 403.6 MiB)
[2025-05-08T06:35:54.731+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-08T06:35:54.733+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:54.734+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 389 (MapPartitionsRDD[532] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:54.735+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Adding task set 389.0 with 1 tasks resource profile 0
[2025-05-08T06:35:54.824+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Starting task 0.0 in stage 386.0 (TID 553) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:54.825+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSetManager: Finished task 0.0 in stage 384.0 (TID 552) in 248 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:54.829+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Removed TaskSet 384.0, whose tasks have all completed, from pool
[2025-05-08T06:35:54.832+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: ShuffleMapStage 384 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.615 s
[2025-05-08T06:35:54.835+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:54.837+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: running: Set(ResultStage 389, ShuffleMapStage 386)
[2025-05-08T06:35:54.842+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:54.843+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:54.859+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO ShufflePartitionsUtil: For shuffle(67), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:54.901+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.20.0.5:41027 (size: 49.6 KiB, free: 432.8 MiB)
[2025-05-08T06:35:54.922+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:43674
[2025-05-08T06:35:54.924+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:54.941+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO CodeGenerator: Code generated in 10.770016 ms
[2025-05-08T06:35:54.965+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:54.968+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Got job 71 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:54.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Final stage: ResultStage 392 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:54.970+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 391)
[2025-05-08T06:35:54.971+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:54.973+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting ResultStage 392 (MapPartitionsRDD[535] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:54.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 75.2 KiB, free 403.5 MiB)
[2025-05-08T06:35:54.995+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 33.2 KiB, free 403.5 MiB)
[2025-05-08T06:35:54.996+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.20.0.5:41027 (size: 502.1 KiB, free: 432.3 MiB)
[2025-05-08T06:35:54.996+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on f2a432e4376a:46195 (size: 33.2 KiB, free: 432.7 MiB)
[2025-05-08T06:35:54.997+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:54.997+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 392 (MapPartitionsRDD[535] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:54.997+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:54 INFO TaskSchedulerImpl: Adding task set 392.0 with 1 tasks resource profile 0
[2025-05-08T06:35:55.001+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Removed broadcast_111_piece0 on f2a432e4376a:46195 in memory (size: 34.5 KiB, free: 432.8 MiB)
[2025-05-08T06:35:55.002+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.20.0.5:41027 in memory (size: 34.5 KiB, free: 432.3 MiB)
[2025-05-08T06:35:55.021+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.20.0.5:41027 (size: 114.2 KiB, free: 432.2 MiB)
[2025-05-08T06:35:55.040+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.20.0.5:41027 (size: 20.6 KiB, free: 432.2 MiB)
[2025-05-08T06:35:55.175+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 1.0 in stage 386.0 (TID 554) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.175+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 0.0 in stage 386.0 (TID 553) in 353 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-08T06:35:55.259+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 2.0 in stage 386.0 (TID 555) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.259+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 1.0 in stage 386.0 (TID 554) in 85 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-08T06:35:55.291+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 3.0 in stage 386.0 (TID 556) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.294+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 2.0 in stage 386.0 (TID 555) in 35 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-08T06:35:55.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 4.0 in stage 386.0 (TID 557) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 3.0 in stage 386.0 (TID 556) in 35 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-08T06:35:55.360+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 5.0 in stage 386.0 (TID 558) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.361+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 4.0 in stage 386.0 (TID 557) in 34 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-08T06:35:55.385+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 6.0 in stage 386.0 (TID 559) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 5.0 in stage 386.0 (TID 558) in 26 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-08T06:35:55.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 7.0 in stage 386.0 (TID 560) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 6.0 in stage 386.0 (TID 559) in 34 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-08T06:35:55.439+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 8.0 in stage 386.0 (TID 561) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.440+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 7.0 in stage 386.0 (TID 560) in 22 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-08T06:35:55.459+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 9.0 in stage 386.0 (TID 562) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.460+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 8.0 in stage 386.0 (TID 561) in 21 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-08T06:35:55.490+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 10.0 in stage 386.0 (TID 563) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.491+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 9.0 in stage 386.0 (TID 562) in 31 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-08T06:35:55.550+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 0.0 in stage 389.0 (TID 564) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.552+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 10.0 in stage 386.0 (TID 563) in 60 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-08T06:35:55.553+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool
[2025-05-08T06:35:55.553+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: ShuffleMapStage 386 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.942 s
[2025-05-08T06:35:55.553+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:55.553+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: running: Set(ResultStage 389, ResultStage 392)
[2025-05-08T06:35:55.554+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:55.554+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:55.558+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO ShufflePartitionsUtil: For shuffle(68), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:55.595+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 432.2 MiB)
[2025-05-08T06:35:55.604+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 65 to 172.20.0.5:43674
[2025-05-08T06:35:55.609+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:55.612+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 0.0 in stage 392.0 (TID 565) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.613+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 0.0 in stage 389.0 (TID 564) in 63 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:55.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSchedulerImpl: Removed TaskSet 389.0, whose tasks have all completed, from pool
[2025-05-08T06:35:55.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: ResultStage 389 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.886 s
[2025-05-08T06:35:55.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:55.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 389: Stage finished
[2025-05-08T06:35:55.614+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Job 70 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.891904 s
[2025-05-08T06:35:55.620+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 2.1 MiB, free 401.6 MiB)
[2025-05-08T06:35:55.622+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 401.5 MiB)
[2025-05-08T06:35:55.623+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on f2a432e4376a:46195 (size: 20.3 KiB, free: 432.8 MiB)
[2025-05-08T06:35:55.624+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO SparkContext: Created broadcast 116 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:55.625+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.20.0.5:41027 (size: 33.2 KiB, free: 432.2 MiB)
[2025-05-08T06:35:55.634+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 67 to 172.20.0.5:43674
[2025-05-08T06:35:55.658+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO CodeGenerator: Code generated in 35.432771 ms
[2025-05-08T06:35:55.661+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 0.0 in stage 392.0 (TID 565) in 49 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:55.662+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSchedulerImpl: Removed TaskSet 392.0, whose tasks have all completed, from pool
[2025-05-08T06:35:55.664+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: ResultStage 392 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.690 s
[2025-05-08T06:35:55.665+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:55.667+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 392: Stage finished
[2025-05-08T06:35:55.668+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Job 71 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.700692 s
[2025-05-08T06:35:55.671+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Registering RDD 538 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 69
[2025-05-08T06:35:55.672+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Got map stage job 72 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:55.672+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Final stage: ShuffleMapStage 395 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:55.672+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 394)
[2025-05-08T06:35:55.672+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:55.676+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Submitting ShuffleMapStage 395 (MapPartitionsRDD[538] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:55.681+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO CodeGenerator: Code generated in 9.764709 ms
[2025-05-08T06:35:55.685+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 1088.0 KiB, free 400.5 MiB)
[2025-05-08T06:35:55.686+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 130.2 KiB, free 400.3 MiB)
[2025-05-08T06:35:55.687+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 22.4 KiB, free 400.3 MiB)
[2025-05-08T06:35:55.687+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on f2a432e4376a:46195 (size: 22.4 KiB, free: 432.7 MiB)
[2025-05-08T06:35:55.688+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO SparkContext: Created broadcast 117 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:55.688+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 44.5 KiB, free 400.3 MiB)
[2025-05-08T06:35:55.689+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on f2a432e4376a:46195 (size: 44.5 KiB, free: 432.7 MiB)
[2025-05-08T06:35:55.689+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:55.690+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 395 (MapPartitionsRDD[538] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:55.690+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSchedulerImpl: Adding task set 395.0 with 1 tasks resource profile 0
[2025-05-08T06:35:55.691+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 0.0 in stage 395.0 (TID 566) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.697+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.20.0.5:41027 (size: 44.5 KiB, free: 432.1 MiB)
[2025-05-08T06:35:55.707+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 68 to 172.20.0.5:43674
[2025-05-08T06:35:55.816+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Finished task 0.0 in stage 395.0 (TID 566) in 124 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:55.821+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSchedulerImpl: Removed TaskSet 395.0, whose tasks have all completed, from pool
[2025-05-08T06:35:55.821+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: ShuffleMapStage 395 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.143 s
[2025-05-08T06:35:55.821+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:55.821+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:55.822+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:55.822+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:55.827+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO ShufflePartitionsUtil: For shuffle(69), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:55.891+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:55.918+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO CodeGenerator: Code generated in 20.487445 ms
[2025-05-08T06:35:55.959+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:55.960+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Got job 73 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:55.960+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Final stage: ResultStage 399 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:55.960+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 398)
[2025-05-08T06:35:55.961+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:55.965+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Submitting ResultStage 399 (MapPartitionsRDD[541] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:55.971+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 122.7 KiB, free 400.2 MiB)
[2025-05-08T06:35:55.971+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 41.9 KiB, free 400.1 MiB)
[2025-05-08T06:35:55.972+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on f2a432e4376a:46195 (size: 41.9 KiB, free: 432.6 MiB)
[2025-05-08T06:35:55.975+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:55.978+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 399 (MapPartitionsRDD[541] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:55.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSchedulerImpl: Adding task set 399.0 with 1 tasks resource profile 0
[2025-05-08T06:35:55.980+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO TaskSetManager: Starting task 0.0 in stage 399.0 (TID 567) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:55.993+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:55 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.20.0.5:41027 (size: 41.9 KiB, free: 432.1 MiB)
[2025-05-08T06:35:56.005+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 69 to 172.20.0.5:43674
[2025-05-08T06:35:56.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Finished task 0.0 in stage 399.0 (TID 567) in 59 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:56.040+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool
[2025-05-08T06:35:56.041+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: ResultStage 399 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.078 s
[2025-05-08T06:35:56.041+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:56.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 399: Stage finished
[2025-05-08T06:35:56.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Job 73 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.082368 s
[2025-05-08T06:35:56.050+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 2.1 MiB, free 398.1 MiB)
[2025-05-08T06:35:56.053+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 82.5 KiB, free 398.0 MiB)
[2025-05-08T06:35:56.054+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on f2a432e4376a:46195 (size: 82.5 KiB, free: 432.6 MiB)
[2025-05-08T06:35:56.054+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 120 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:56.058+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO ShufflePartitionsUtil: For shuffle(66), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:56.107+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO CodeGenerator: Code generated in 8.094043 ms
[2025-05-08T06:35:56.116+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-08T06:35:56.116+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got job 74 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-08T06:35:56.116+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ResultStage 402 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-08T06:35:56.117+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 401)
[2025-05-08T06:35:56.117+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.117+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ResultStage 402 (MapPartitionsRDD[544] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-08T06:35:56.119+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 15.6 KiB, free 398.0 MiB)
[2025-05-08T06:35:56.130+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_114_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 432.6 MiB)
[2025-05-08T06:35:56.131+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 398.0 MiB)
[2025-05-08T06:35:56.132+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on f2a432e4376a:46195 (size: 6.6 KiB, free: 432.6 MiB)
[2025-05-08T06:35:56.132+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 432.1 MiB)
[2025-05-08T06:35:56.132+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.132+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 402 (MapPartitionsRDD[544] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:56.132+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 402.0 with 1 tasks resource profile 0
[2025-05-08T06:35:56.134+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Starting task 0.0 in stage 402.0 (TID 568) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:56.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_115_piece0 on f2a432e4376a:46195 in memory (size: 33.2 KiB, free: 432.6 MiB)
[2025-05-08T06:35:56.138+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.20.0.5:41027 in memory (size: 33.2 KiB, free: 432.1 MiB)
[2025-05-08T06:35:56.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_113_piece0 on f2a432e4376a:46195 in memory (size: 49.6 KiB, free: 432.6 MiB)
[2025-05-08T06:35:56.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.20.0.5:41027 in memory (size: 49.6 KiB, free: 432.2 MiB)
[2025-05-08T06:35:56.143+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.20.0.5:41027 (size: 6.6 KiB, free: 432.2 MiB)
[2025-05-08T06:35:56.144+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_118_piece0 on f2a432e4376a:46195 in memory (size: 44.5 KiB, free: 432.7 MiB)
[2025-05-08T06:35:56.145+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 172.20.0.5:41027 in memory (size: 44.5 KiB, free: 432.2 MiB)
[2025-05-08T06:35:56.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 66 to 172.20.0.5:43674
[2025-05-08T06:35:56.147+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_119_piece0 on f2a432e4376a:46195 in memory (size: 41.9 KiB, free: 432.7 MiB)
[2025-05-08T06:35:56.148+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.20.0.5:41027 in memory (size: 41.9 KiB, free: 432.2 MiB)
[2025-05-08T06:35:56.165+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.20.0.5:41027 (size: 20.3 KiB, free: 432.2 MiB)
[2025-05-08T06:35:56.176+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.20.0.5:41027 (size: 82.5 KiB, free: 432.1 MiB)
[2025-05-08T06:35:56.184+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.20.0.5:41027 (size: 22.4 KiB, free: 432.1 MiB)
[2025-05-08T06:35:56.222+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Finished task 0.0 in stage 402.0 (TID 568) in 88 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:56.228+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool
[2025-05-08T06:35:56.229+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: ResultStage 402 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.106 s
[2025-05-08T06:35:56.229+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:56.229+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 402: Stage finished
[2025-05-08T06:35:56.229+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Job 74 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.109463 s
[2025-05-08T06:35:56.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Registering RDD 573 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 70
[2025-05-08T06:35:56.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got map stage job 75 (toPandas at /opt/airflow/spark/build_graph.py:216) with 6 output partitions
[2025-05-08T06:35:56.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ShuffleMapStage 403 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:56.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:56.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.711+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ShuffleMapStage 403 (MapPartitionsRDD[573] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:56.713+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 36.4 KiB, free 398.6 MiB)
[2025-05-08T06:35:56.714+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:56.714+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 398.5 MiB)
[2025-05-08T06:35:56.714+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on f2a432e4376a:46195 (size: 11.2 KiB, free: 432.7 MiB)
[2025-05-08T06:35:56.714+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.715+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 403 (MapPartitionsRDD[573] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:35:56.715+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 403.0 with 6 tasks resource profile 0
[2025-05-08T06:35:56.718+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Registering RDD 575 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 71
[2025-05-08T06:35:56.720+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got map stage job 76 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:56.720+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ShuffleMapStage 404 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:56.720+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:56.720+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ShuffleMapStage 404 (MapPartitionsRDD[575] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:56.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Starting task 0.0 in stage 403.0 (TID 569) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:56.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 12.6 KiB, free 398.5 MiB)
[2025-05-08T06:35:56.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:56.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 398.5 MiB)
[2025-05-08T06:35:56.721+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on f2a432e4376a:46195 (size: 6.7 KiB, free: 432.7 MiB)
[2025-05-08T06:35:56.722+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.725+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 404 (MapPartitionsRDD[575] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:56.726+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 404.0 with 1 tasks resource profile 0
[2025-05-08T06:35:56.726+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Registering RDD 577 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 72
[2025-05-08T06:35:56.726+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got map stage job 77 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:56.726+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ShuffleMapStage 405 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:56.727+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:56.727+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.727+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ShuffleMapStage 405 (MapPartitionsRDD[577] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:56.728+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 27.3 KiB, free 398.5 MiB)
[2025-05-08T06:35:56.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:56.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 398.5 MiB)
[2025-05-08T06:35:56.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.20.0.5:41027 (size: 11.2 KiB, free: 432.1 MiB)
[2025-05-08T06:35:56.729+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 432.7 MiB)
[2025-05-08T06:35:56.731+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.731+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 405 (MapPartitionsRDD[577] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:56.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 405.0 with 1 tasks resource profile 0
[2025-05-08T06:35:56.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Registering RDD 579 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 73
[2025-05-08T06:35:56.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got map stage job 78 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:56.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ShuffleMapStage 406 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:56.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:56.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ShuffleMapStage 406 (MapPartitionsRDD[579] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:56.733+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 28.5 KiB, free 398.5 MiB)
[2025-05-08T06:35:56.735+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:56.736+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 398.4 MiB)
[2025-05-08T06:35:56.737+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-08T06:35:56.739+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.740+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 406 (MapPartitionsRDD[579] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:56.741+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 406.0 with 1 tasks resource profile 0
[2025-05-08T06:35:56.742+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Registering RDD 581 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 74
[2025-05-08T06:35:56.744+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got map stage job 79 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:56.745+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ShuffleMapStage 407 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:56.745+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:56.746+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.746+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:56.747+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ShuffleMapStage 407 (MapPartitionsRDD[581] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:56.747+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 28.5 KiB, free 398.4 MiB)
[2025-05-08T06:35:56.747+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:56.748+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 398.4 MiB)
[2025-05-08T06:35:56.749+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-08T06:35:56.750+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.752+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 407 (MapPartitionsRDD[581] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:56.753+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 407.0 with 1 tasks resource profile 0
[2025-05-08T06:35:56.753+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Registering RDD 583 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 75
[2025-05-08T06:35:56.753+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got map stage job 80 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:56.753+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ShuffleMapStage 408 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:56.753+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:56.754+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.754+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ShuffleMapStage 408 (MapPartitionsRDD[583] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:56.757+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 27.4 KiB, free 398.4 MiB)
[2025-05-08T06:35:56.757+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 398.4 MiB)
[2025-05-08T06:35:56.759+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 432.7 MiB)
[2025-05-08T06:35:56.760+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.760+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 408 (MapPartitionsRDD[583] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:56.760+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 408.0 with 1 tasks resource profile 0
[2025-05-08T06:35:56.761+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Registering RDD 585 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 76
[2025-05-08T06:35:56.761+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got map stage job 81 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:56.761+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ShuffleMapStage 409 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:56.761+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:56.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ShuffleMapStage 409 (MapPartitionsRDD[585] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:56.763+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 28.5 KiB, free 398.3 MiB)
[2025-05-08T06:35:56.779+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 398.3 MiB)
[2025-05-08T06:35:56.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on f2a432e4376a:46195 (size: 13.5 KiB, free: 432.6 MiB)
[2025-05-08T06:35:56.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Starting task 1.0 in stage 403.0 (TID 570) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:56.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Finished task 0.0 in stage 403.0 (TID 569) in 60 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:35:56.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 409 (MapPartitionsRDD[585] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:56.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 409.0 with 1 tasks resource profile 0
[2025-05-08T06:35:56.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Registering RDD 587 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 77
[2025-05-08T06:35:56.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_121_piece0 on f2a432e4376a:46195 in memory (size: 6.6 KiB, free: 432.7 MiB)
[2025-05-08T06:35:56.780+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got map stage job 82 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:56.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ShuffleMapStage 410 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:56.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:56.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ShuffleMapStage 410 (MapPartitionsRDD[587] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:56.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.20.0.5:41027 in memory (size: 6.6 KiB, free: 432.1 MiB)
[2025-05-08T06:35:56.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 31.7 KiB, free 398.3 MiB)
[2025-05-08T06:35:56.784+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 398.3 MiB)
[2025-05-08T06:35:56.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on f2a432e4376a:46195 (size: 14.9 KiB, free: 432.6 MiB)
[2025-05-08T06:35:56.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 410 (MapPartitionsRDD[587] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:56.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 410.0 with 1 tasks resource profile 0
[2025-05-08T06:35:56.813+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Starting task 2.0 in stage 403.0 (TID 571) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:56.815+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Finished task 1.0 in stage 403.0 (TID 570) in 37 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:35:56.853+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Starting task 3.0 in stage 403.0 (TID 572) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:56.853+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Finished task 2.0 in stage 403.0 (TID 571) in 40 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:35:56.888+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Starting task 4.0 in stage 403.0 (TID 573) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:56.888+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Finished task 3.0 in stage 403.0 (TID 572) in 36 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:35:56.913+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Starting task 5.0 in stage 403.0 (TID 574) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:56.913+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Finished task 4.0 in stage 403.0 (TID 573) in 25 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:35:56.941+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Starting task 0.0 in stage 404.0 (TID 575) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:56.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Finished task 5.0 in stage 403.0 (TID 574) in 29 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:35:56.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Removed TaskSet 403.0, whose tasks have all completed, from pool
[2025-05-08T06:35:56.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: ShuffleMapStage 403 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.230 s
[2025-05-08T06:35:56.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:56.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: running: Set(ShuffleMapStage 407, ShuffleMapStage 404, ShuffleMapStage 408, ShuffleMapStage 405, ShuffleMapStage 409, ShuffleMapStage 406, ShuffleMapStage 410)
[2025-05-08T06:35:56.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:56.942+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:56.946+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.20.0.5:41027 (size: 6.7 KiB, free: 432.1 MiB)
[2025-05-08T06:35:56.956+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO ShufflePartitionsUtil: For shuffle(70), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:56.957+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO ShufflePartitionsUtil: For shuffle(70), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:56.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Finished task 0.0 in stage 404.0 (TID 575) in 37 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:56.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Removed TaskSet 404.0, whose tasks have all completed, from pool
[2025-05-08T06:35:56.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSetManager: Starting task 0.0 in stage 405.0 (TID 576) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:56.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: ShuffleMapStage 404 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.263 s
[2025-05-08T06:35:56.979+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:56.980+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: running: Set(ShuffleMapStage 407, ShuffleMapStage 408, ShuffleMapStage 405, ShuffleMapStage 409, ShuffleMapStage 406, ShuffleMapStage 410)
[2025-05-08T06:35:56.980+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:56.980+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:56.988+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-08T06:35:56.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Got job 83 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:56.990+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Final stage: ResultStage 412 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:56.990+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 411)
[2025-05-08T06:35:56.990+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:56.991+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting ResultStage 412 (MapPartitionsRDD[590] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:56.992+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO ShufflePartitionsUtil: For shuffle(71), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:56.993+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 7.2 KiB, free 398.3 MiB)
[2025-05-08T06:35:56.994+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 398.3 MiB)
[2025-05-08T06:35:56.994+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 432.6 MiB)
[2025-05-08T06:35:56.994+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 432.1 MiB)
[2025-05-08T06:35:56.994+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:56.995+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 412 (MapPartitionsRDD[590] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:56.995+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:56 INFO TaskSchedulerImpl: Adding task set 412.0 with 1 tasks resource profile 0
[2025-05-08T06:35:57.023+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-08T06:35:57.025+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Got job 84 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:57.026+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Final stage: ResultStage 414 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:57.026+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 413)
[2025-05-08T06:35:57.026+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:57.026+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Submitting ResultStage 414 (MapPartitionsRDD[593] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:57.026+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 7.2 KiB, free 398.3 MiB)
[2025-05-08T06:35:57.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 398.3 MiB)
[2025-05-08T06:35:57.028+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 432.6 MiB)
[2025-05-08T06:35:57.029+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:57.029+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 414 (MapPartitionsRDD[593] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:57.029+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Adding task set 414.0 with 1 tasks resource profile 0
[2025-05-08T06:35:57.032+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 0.0 in stage 406.0 (TID 577) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.033+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 0.0 in stage 405.0 (TID 576) in 53 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:57.033+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Removed TaskSet 405.0, whose tasks have all completed, from pool
[2025-05-08T06:35:57.035+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: ShuffleMapStage 405 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.307 s
[2025-05-08T06:35:57.037+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:57.038+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: running: Set(ShuffleMapStage 407, ShuffleMapStage 408, ResultStage 412, ShuffleMapStage 409, ShuffleMapStage 406, ShuffleMapStage 410, ResultStage 414)
[2025-05-08T06:35:57.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:57.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:57.045+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.093+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 0.0 in stage 407.0 (TID 578) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.095+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 0.0 in stage 406.0 (TID 577) in 63 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:57.096+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Removed TaskSet 406.0, whose tasks have all completed, from pool
[2025-05-08T06:35:57.097+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: ShuffleMapStage 406 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.363 s
[2025-05-08T06:35:57.097+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:57.098+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: running: Set(ShuffleMapStage 407, ShuffleMapStage 408, ResultStage 412, ShuffleMapStage 409, ShuffleMapStage 410, ResultStage 414)
[2025-05-08T06:35:57.098+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:57.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:57.105+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 0.0 in stage 408.0 (TID 579) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 0.0 in stage 407.0 (TID 578) in 67 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:57.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Removed TaskSet 407.0, whose tasks have all completed, from pool
[2025-05-08T06:35:57.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: ShuffleMapStage 407 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.419 s
[2025-05-08T06:35:57.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:57.161+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: running: Set(ShuffleMapStage 408, ResultStage 412, ShuffleMapStage 409, ShuffleMapStage 410, ResultStage 414)
[2025-05-08T06:35:57.161+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:57.161+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:57.167+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 0.0 in stage 409.0 (TID 580) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 0.0 in stage 408.0 (TID 579) in 37 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:57.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Removed TaskSet 408.0, whose tasks have all completed, from pool
[2025-05-08T06:35:57.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: ShuffleMapStage 408 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.442 s
[2025-05-08T06:35:57.196+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:57.197+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: running: Set(ResultStage 412, ShuffleMapStage 409, ShuffleMapStage 410, ResultStage 414)
[2025-05-08T06:35:57.197+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:57.197+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:57.203+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 172.20.0.5:41027 (size: 13.5 KiB, free: 432.0 MiB)
[2025-05-08T06:35:57.231+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 0.0 in stage 410.0 (TID 581) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.232+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 0.0 in stage 409.0 (TID 580) in 37 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:57.232+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Removed TaskSet 409.0, whose tasks have all completed, from pool
[2025-05-08T06:35:57.234+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: ShuffleMapStage 409 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.470 s
[2025-05-08T06:35:57.235+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:57.235+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: running: Set(ResultStage 412, ShuffleMapStage 410, ResultStage 414)
[2025-05-08T06:35:57.235+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:57.235+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:57.240+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 172.20.0.5:41027 (size: 14.9 KiB, free: 432.0 MiB)
[2025-05-08T06:35:57.281+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 0.0 in stage 412.0 (TID 582) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.281+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 0.0 in stage 410.0 (TID 581) in 50 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:57.281+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Removed TaskSet 410.0, whose tasks have all completed, from pool
[2025-05-08T06:35:57.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: ShuffleMapStage 410 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.502 s
[2025-05-08T06:35:57.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:57.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: running: Set(ResultStage 412, ResultStage 414)
[2025-05-08T06:35:57.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:57.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:57.288+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 432.0 MiB)
[2025-05-08T06:35:57.290+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO ShufflePartitionsUtil: For shuffle(72, 73, 74, 75, 76, 77), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:57.290+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 70 to 172.20.0.5:43674
[2025-05-08T06:35:57.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 0.0 in stage 414.0 (TID 583) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.307+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 0.0 in stage 412.0 (TID 582) in 26 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:57.308+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Removed TaskSet 412.0, whose tasks have all completed, from pool
[2025-05-08T06:35:57.308+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: ResultStage 412 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.317 s
[2025-05-08T06:35:57.309+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:57.309+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 412: Stage finished
[2025-05-08T06:35:57.309+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:57.309+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Job 83 finished: toPandas at /opt/airflow/spark/build_graph.py:216, took 0.320686 s
[2025-05-08T06:35:57.317+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:57.323+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:57.326+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 432.0 MiB)
[2025-05-08T06:35:57.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:57.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 5.0 MiB, free 393.3 MiB)
[2025-05-08T06:35:57.336+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:43674
[2025-05-08T06:35:57.338+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:57.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 0.0 in stage 414.0 (TID 583) in 37 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:57.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Removed TaskSet 414.0, whose tasks have all completed, from pool
[2025-05-08T06:35:57.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:57.343+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: ResultStage 414 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.317 s
[2025-05-08T06:35:57.344+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:57.344+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 414: Stage finished
[2025-05-08T06:35:57.344+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Job 84 finished: toPandas at /opt/airflow/spark/build_graph.py:216, took 0.320640 s
[2025-05-08T06:35:57.347+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 392.8 MiB)
[2025-05-08T06:35:57.348+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on f2a432e4376a:46195 (size: 502.1 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.348+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO SparkContext: Created broadcast 132 from toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-08T06:35:57.349+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 2.1 MiB, free 390.7 MiB)
[2025-05-08T06:35:57.364+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 390.7 MiB)
[2025-05-08T06:35:57.365+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on f2a432e4376a:46195 (size: 20.6 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO SparkContext: Created broadcast 133 from toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-08T06:35:57.374+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_131_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.375+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 432.0 MiB)
[2025-05-08T06:35:57.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-08T06:35:57.378+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_124_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.379+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 432.0 MiB)
[2025-05-08T06:35:57.380+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Got job 85 (toPandas at /opt/airflow/spark/build_graph.py:216) with 6 output partitions
[2025-05-08T06:35:57.381+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Final stage: ResultStage 421 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:57.381+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 419, ShuffleMapStage 420, ShuffleMapStage 416, ShuffleMapStage 417, ShuffleMapStage 418, ShuffleMapStage 415)
[2025-05-08T06:35:57.381+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:57.382+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Submitting ResultStage 421 (MapPartitionsRDD[614] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:57.389+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 91.7 KiB, free 390.7 MiB)
[2025-05-08T06:35:57.391+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 390.6 MiB)
[2025-05-08T06:35:57.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_126_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.393+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on f2a432e4376a:46195 (size: 30.3 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.394+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:57.394+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 421 (MapPartitionsRDD[614] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:35:57.395+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Adding task set 421.0 with 6 tasks resource profile 0
[2025-05-08T06:35:57.396+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 0.0 in stage 421.0 (TID 584) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.397+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.406+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 172.20.0.5:41027 in memory (size: 6.7 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.408+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_123_piece0 on f2a432e4376a:46195 in memory (size: 6.7 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.411+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 172.20.0.5:41027 (size: 30.3 KiB, free: 432.0 MiB)
[2025-05-08T06:35:57.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_125_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:43674
[2025-05-08T06:35:57.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 432.0 MiB)
[2025-05-08T06:35:57.429+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_122_piece0 on f2a432e4376a:46195 in memory (size: 11.2 KiB, free: 432.2 MiB)
[2025-05-08T06:35:57.431+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 172.20.0.5:41027 in memory (size: 11.2 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.436+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 1.0 in stage 421.0 (TID 585) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.436+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 0.0 in stage 421.0 (TID 584) in 39 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:35:57.443+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_128_piece0 on f2a432e4376a:46195 in memory (size: 13.5 KiB, free: 432.2 MiB)
[2025-05-08T06:35:57.461+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 172.20.0.5:41027 in memory (size: 13.5 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.462+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:43674
[2025-05-08T06:35:57.468+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.470+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_127_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 432.2 MiB)
[2025-05-08T06:35:57.475+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_130_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 432.2 MiB)
[2025-05-08T06:35:57.479+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.484+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_129_piece0 on f2a432e4376a:46195 in memory (size: 14.9 KiB, free: 432.2 MiB)
[2025-05-08T06:35:57.487+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 2.0 in stage 421.0 (TID 586) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.487+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 1.0 in stage 421.0 (TID 585) in 53 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:35:57.487+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 172.20.0.5:41027 in memory (size: 14.9 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.494+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:43674
[2025-05-08T06:35:57.516+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 3.0 in stage 421.0 (TID 587) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.517+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 2.0 in stage 421.0 (TID 586) in 33 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:35:57.523+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:43674
[2025-05-08T06:35:57.536+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 4.0 in stage 421.0 (TID 588) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.536+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 3.0 in stage 421.0 (TID 587) in 21 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:35:57.540+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:43674
[2025-05-08T06:35:57.546+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 5.0 in stage 421.0 (TID 589) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.546+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 4.0 in stage 421.0 (TID 588) in 10 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:35:57.551+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:43674
[2025-05-08T06:35:57.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Finished task 5.0 in stage 421.0 (TID 589) in 13 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:35:57.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Removed TaskSet 421.0, whose tasks have all completed, from pool
[2025-05-08T06:35:57.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: ResultStage 421 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.177 s
[2025-05-08T06:35:57.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:57.559+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 421: Stage finished
[2025-05-08T06:35:57.560+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Job 85 finished: toPandas at /opt/airflow/spark/build_graph.py:216, took 0.183761 s
[2025-05-08T06:35:57.565+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 2.3 MiB, free 388.7 MiB)
[2025-05-08T06:35:57.583+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_134_piece0 on f2a432e4376a:46195 in memory (size: 30.3 KiB, free: 432.2 MiB)
[2025-05-08T06:35:57.583+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 388.7 MiB)
[2025-05-08T06:35:57.583+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on f2a432e4376a:46195 (size: 114.2 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.585+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO SparkContext: Created broadcast 135 from toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-08T06:35:57.591+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 172.20.0.5:41027 in memory (size: 30.3 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.622+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:57.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO CodeGenerator: Code generated in 57.820892 ms
[2025-05-08T06:35:57.754+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO CodeGenerator: Code generated in 14.194216 ms
[2025-05-08T06:35:57.773+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Registering RDD 623 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 78
[2025-05-08T06:35:57.774+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Got map stage job 86 (toPandas at /opt/airflow/spark/build_graph.py:216) with 11 output partitions
[2025-05-08T06:35:57.774+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Final stage: ShuffleMapStage 423 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:57.774+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 422)
[2025-05-08T06:35:57.774+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:57.774+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Submitting ShuffleMapStage 423 (MapPartitionsRDD[623] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:57.785+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 129.6 KiB, free 388.5 MiB)
[2025-05-08T06:35:57.788+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 45.0 KiB, free 388.5 MiB)
[2025-05-08T06:35:57.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on f2a432e4376a:46195 (size: 45.0 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:57.791+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 423 (MapPartitionsRDD[623] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-08T06:35:57.791+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSchedulerImpl: Adding task set 423.0 with 11 tasks resource profile 0
[2025-05-08T06:35:57.793+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO TaskSetManager: Starting task 0.0 in stage 423.0 (TID 590) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:57.802+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 172.20.0.5:41027 (size: 45.0 KiB, free: 432.1 MiB)
[2025-05-08T06:35:57.810+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:43674
[2025-05-08T06:35:57.878+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 172.20.0.5:41027 (size: 502.1 KiB, free: 431.6 MiB)
[2025-05-08T06:35:57.929+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 172.20.0.5:41027 (size: 114.2 KiB, free: 431.5 MiB)
[2025-05-08T06:35:57.946+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:57 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 172.20.0.5:41027 (size: 20.6 KiB, free: 431.5 MiB)
[2025-05-08T06:35:58.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 1.0 in stage 423.0 (TID 591) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 0.0 in stage 423.0 (TID 590) in 236 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-08T06:35:58.066+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 2.0 in stage 423.0 (TID 592) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.067+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 1.0 in stage 423.0 (TID 591) in 40 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-08T06:35:58.095+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 3.0 in stage 423.0 (TID 593) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.096+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 2.0 in stage 423.0 (TID 592) in 30 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-08T06:35:58.127+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 4.0 in stage 423.0 (TID 594) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.128+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 3.0 in stage 423.0 (TID 593) in 32 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-08T06:35:58.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 5.0 in stage 423.0 (TID 595) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 4.0 in stage 423.0 (TID 594) in 28 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-08T06:35:58.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 6.0 in stage 423.0 (TID 596) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.178+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 5.0 in stage 423.0 (TID 595) in 23 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-08T06:35:58.192+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 7.0 in stage 423.0 (TID 597) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.193+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 6.0 in stage 423.0 (TID 596) in 15 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-08T06:35:58.207+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 8.0 in stage 423.0 (TID 598) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.207+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 7.0 in stage 423.0 (TID 597) in 15 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-08T06:35:58.228+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 9.0 in stage 423.0 (TID 599) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.229+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 8.0 in stage 423.0 (TID 598) in 23 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-08T06:35:58.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 10.0 in stage 423.0 (TID 600) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.253+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 9.0 in stage 423.0 (TID 599) in 22 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-08T06:35:58.369+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 10.0 in stage 423.0 (TID 600) in 120 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-08T06:35:58.370+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSchedulerImpl: Removed TaskSet 423.0, whose tasks have all completed, from pool
[2025-05-08T06:35:58.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: ShuffleMapStage 423 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.599 s
[2025-05-08T06:35:58.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:58.371+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: running: Set()
[2025-05-08T06:35:58.372+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:58.372+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:58.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO ShufflePartitionsUtil: For shuffle(78), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:58.402+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO CodeGenerator: Code generated in 8.039129 ms
[2025-05-08T06:35:58.425+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-08T06:35:58.425+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: Got job 87 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-08T06:35:58.426+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: Final stage: ResultStage 426 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-08T06:35:58.426+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 425)
[2025-05-08T06:35:58.426+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:58.426+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: Submitting ResultStage 426 (MapPartitionsRDD[627] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-08T06:35:58.429+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 113.5 KiB, free 388.4 MiB)
[2025-05-08T06:35:58.431+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 38.6 KiB, free 388.4 MiB)
[2025-05-08T06:35:58.433+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on f2a432e4376a:46195 (size: 38.6 KiB, free: 432.0 MiB)
[2025-05-08T06:35:58.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:58.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 426 (MapPartitionsRDD[627] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:58.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSchedulerImpl: Adding task set 426.0 with 1 tasks resource profile 0
[2025-05-08T06:35:58.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Starting task 0.0 in stage 426.0 (TID 601) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:58.440+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 172.20.0.5:41027 (size: 38.6 KiB, free: 431.4 MiB)
[2025-05-08T06:35:58.444+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:43674
[2025-05-08T06:35:58.477+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSetManager: Finished task 0.0 in stage 426.0 (TID 601) in 43 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:35:58.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSchedulerImpl: Removed TaskSet 426.0, whose tasks have all completed, from pool
[2025-05-08T06:35:58.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: ResultStage 426 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.052 s
[2025-05-08T06:35:58.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:58.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 426: Stage finished
[2025-05-08T06:35:58.479+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:58 INFO DAGScheduler: Job 87 finished: toPandas at /opt/airflow/spark/build_graph.py:216, took 0.053840 s
[2025-05-08T06:35:58.676+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:58,676 [INFO] Граф сохранен в /reports/client_graph.graphml
[2025-05-08T06:35:58.677+0000] {spark_submit.py:571} INFO - 2025-05-08 06:35:58,676 [INFO] Сохраняем результаты в graph.client_communities
[2025-05-08T06:35:59.172+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#2535 - id.nullCount#2534) > 0)
[2025-05-08T06:35:59.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 659 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 79
[2025-05-08T06:35:59.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 88 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-08T06:35:59.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 430 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 428, ShuffleMapStage 429)
[2025-05-08T06:35:59.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.178+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 430 (MapPartitionsRDD[659] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.180+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 23.3 KiB, free 388.3 MiB)
[2025-05-08T06:35:59.181+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 388.3 MiB)
[2025-05-08T06:35:59.181+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on f2a432e4376a:46195 (size: 9.9 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.181+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.182+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 430 (MapPartitionsRDD[659] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:59.182+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 430.0 with 10 tasks resource profile 0
[2025-05-08T06:35:59.182+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:59.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 0.0 in stage 430.0 (TID 602) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got job 89 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 10 output partitions
[2025-05-08T06:35:59.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ResultStage 431 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:59.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 427)
[2025-05-08T06:35:59.183+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.184+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ResultStage 431 (MapPartitionsRDD[657] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:59.187+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 43.9 KiB, free 388.3 MiB)
[2025-05-08T06:35:59.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 388.3 MiB)
[2025-05-08T06:35:59.211+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on f2a432e4376a:46195 (size: 19.5 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.212+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Removed broadcast_136_piece0 on f2a432e4376a:46195 in memory (size: 45.0 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.212+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.213+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 431 (MapPartitionsRDD[657] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:59.214+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 431.0 with 10 tasks resource profile 0
[2025-05-08T06:35:59.219+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 662 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 80
[2025-05-08T06:35:59.220+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 172.20.0.5:41027 in memory (size: 45.0 KiB, free: 431.5 MiB)
[2025-05-08T06:35:59.221+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 90 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-08T06:35:59.221+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 454 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.221+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 437, ShuffleMapStage 441, ShuffleMapStage 445, ShuffleMapStage 449, ShuffleMapStage 428, ShuffleMapStage 443, ShuffleMapStage 453, ShuffleMapStage 432, ShuffleMapStage 447, ShuffleMapStage 429, ShuffleMapStage 435, ShuffleMapStage 439, ShuffleMapStage 451)
[2025-05-08T06:35:59.221+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 172.20.0.5:41027 (size: 9.9 KiB, free: 431.5 MiB)
[2025-05-08T06:35:59.224+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.230+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 454 (MapPartitionsRDD[662] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.232+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 31.6 KiB, free 388.4 MiB)
[2025-05-08T06:35:59.233+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 1.0 in stage 430.0 (TID 603) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.233+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Removed broadcast_137_piece0 on f2a432e4376a:46195 in memory (size: 38.6 KiB, free: 432.1 MiB)
[2025-05-08T06:35:59.234+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 0.0 in stage 430.0 (TID 602) in 50 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:59.234+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 172.20.0.5:41027 in memory (size: 38.6 KiB, free: 431.5 MiB)
[2025-05-08T06:35:59.239+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 11.9 KiB, free 388.5 MiB)
[2025-05-08T06:35:59.242+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on f2a432e4376a:46195 (size: 11.9 KiB, free: 432.1 MiB)
[2025-05-08T06:35:59.243+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.244+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 454 (MapPartitionsRDD[662] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T06:35:59.244+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 454.0 with 10 tasks resource profile 0
[2025-05-08T06:35:59.247+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 2.0 in stage 430.0 (TID 604) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.247+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 1.0 in stage 430.0 (TID 603) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:59.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 670 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 81
[2025-05-08T06:35:59.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 91 (jdbc at NativeMethodAccessorImpl.java:0) with 6 output partitions
[2025-05-08T06:35:59.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 455 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:59.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.250+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 455 (MapPartitionsRDD[670] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.254+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 36.4 KiB, free 388.5 MiB)
[2025-05-08T06:35:59.256+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 388.5 MiB)
[2025-05-08T06:35:59.257+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on f2a432e4376a:46195 (size: 11.2 KiB, free: 432.1 MiB)
[2025-05-08T06:35:59.258+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.258+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 455 (MapPartitionsRDD[670] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:35:59.258+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 455.0 with 6 tasks resource profile 0
[2025-05-08T06:35:59.258+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:59.262+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 672 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 82
[2025-05-08T06:35:59.262+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 92 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:59.262+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 456 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.262+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:59.263+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.265+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 456 (MapPartitionsRDD[672] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.266+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 12.7 KiB, free 388.5 MiB)
[2025-05-08T06:35:59.267+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 388.5 MiB)
[2025-05-08T06:35:59.269+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on f2a432e4376a:46195 (size: 6.8 KiB, free: 432.1 MiB)
[2025-05-08T06:35:59.270+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.270+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 456 (MapPartitionsRDD[672] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.270+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 456.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 3.0 in stage 430.0 (TID 605) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.273+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 2.0 in stage 430.0 (TID 604) in 28 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:59.277+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 674 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 83
[2025-05-08T06:35:59.278+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:59.279+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 93 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:59.280+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 457 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.280+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:59.281+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.281+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 457 (MapPartitionsRDD[674] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.284+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 27.3 KiB, free 388.4 MiB)
[2025-05-08T06:35:59.286+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 4.0 in stage 430.0 (TID 606) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.287+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 3.0 in stage 430.0 (TID 605) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:59.314+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 388.4 MiB)
[2025-05-08T06:35:59.319+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.319+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:59.320+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.321+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 457 (MapPartitionsRDD[674] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.321+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 457.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.323+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 676 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 84
[2025-05-08T06:35:59.324+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 94 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:59.324+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 458 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.324+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:59.324+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:59.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 458 (MapPartitionsRDD[676] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 5.0 in stage 430.0 (TID 607) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 28.5 KiB, free 388.4 MiB)
[2025-05-08T06:35:59.335+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 388.4 MiB)
[2025-05-08T06:35:59.336+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 4.0 in stage 430.0 (TID 606) in 48 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:59.336+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.336+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.336+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 458 (MapPartitionsRDD[676] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.336+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 458.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.336+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 678 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 85
[2025-05-08T06:35:59.336+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 95 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:59.337+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 459 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.337+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:59.337+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.337+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:59.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 459 (MapPartitionsRDD[678] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.344+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 28.5 KiB, free 388.4 MiB)
[2025-05-08T06:35:59.345+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 388.4 MiB)
[2025-05-08T06:35:59.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 459 (MapPartitionsRDD[678] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.347+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:35:59.347+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 459.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.348+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 6.0 in stage 430.0 (TID 608) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.352+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 5.0 in stage 430.0 (TID 607) in 22 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:59.352+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 680 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 86
[2025-05-08T06:35:59.353+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 96 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:59.354+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 460 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.355+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:59.356+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.357+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 460 (MapPartitionsRDD[680] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.357+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 27.4 KiB, free 388.3 MiB)
[2025-05-08T06:35:59.374+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 388.3 MiB)
[2025-05-08T06:35:59.375+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on f2a432e4376a:46195 (size: 13.0 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 7.0 in stage 430.0 (TID 609) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 460 (MapPartitionsRDD[680] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 460.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 682 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 87
[2025-05-08T06:35:59.376+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 97 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:59.377+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 461 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.377+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:59.377+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.377+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 6.0 in stage 430.0 (TID 608) in 28 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:59.377+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 461 (MapPartitionsRDD[682] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.379+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 28.5 KiB, free 388.3 MiB)
[2025-05-08T06:35:59.381+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 388.3 MiB)
[2025-05-08T06:35:59.382+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on f2a432e4376a:46195 (size: 13.4 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.382+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.382+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 461 (MapPartitionsRDD[682] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 461.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 684 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 88
[2025-05-08T06:35:59.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 98 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:59.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 8.0 in stage 430.0 (TID 610) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 7.0 in stage 430.0 (TID 609) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:59.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 462 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:59.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.387+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 462 (MapPartitionsRDD[684] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.390+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 31.7 KiB, free 388.2 MiB)
[2025-05-08T06:35:59.391+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 388.2 MiB)
[2025-05-08T06:35:59.391+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on f2a432e4376a:46195 (size: 14.9 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 462 (MapPartitionsRDD[684] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 462.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.398+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 9.0 in stage 430.0 (TID 611) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.403+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 8.0 in stage 430.0 (TID 610) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:59.411+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 9.0 in stage 430.0 (TID 611) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:59.411+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Removed TaskSet 430.0, whose tasks have all completed, from pool
[2025-05-08T06:35:59.411+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 0.0 in stage 431.0 (TID 612) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.417+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: ShuffleMapStage 430 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.234 s
[2025-05-08T06:35:59.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:59.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 462, ShuffleMapStage 459, ShuffleMapStage 456, ShuffleMapStage 460, ResultStage 431, ShuffleMapStage 461, ShuffleMapStage 457, ShuffleMapStage 454)
[2025-05-08T06:35:59.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:59.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:59.422+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 172.20.0.5:41027 (size: 19.5 KiB, free: 431.5 MiB)
[2025-05-08T06:35:59.431+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 1.0 in stage 431.0 (TID 613) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.432+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 0.0 in stage 431.0 (TID 612) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:59.443+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 2.0 in stage 431.0 (TID 614) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.444+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 1.0 in stage 431.0 (TID 613) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:59.465+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 3.0 in stage 431.0 (TID 615) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.466+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 2.0 in stage 431.0 (TID 614) in 24 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:59.472+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO ShufflePartitionsUtil: For shuffle(79), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:59.475+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO ShufflePartitionsUtil: For shuffle(79), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:59.477+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 4.0 in stage 431.0 (TID 616) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.478+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 3.0 in stage 431.0 (TID 615) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:59.488+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 5.0 in stage 431.0 (TID 617) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.490+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:59.492+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 4.0 in stage 431.0 (TID 616) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:59.494+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got job 99 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:35:59.494+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ResultStage 464 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:59.494+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 463)
[2025-05-08T06:35:59.494+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.495+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ResultStage 464 (MapPartitionsRDD[690] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:59.498+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 7.2 KiB, free 388.2 MiB)
[2025-05-08T06:35:59.499+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 388.2 MiB)
[2025-05-08T06:35:59.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.503+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.505+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 464 (MapPartitionsRDD[690] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.505+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 464.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.519+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 6.0 in stage 431.0 (TID 618) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.520+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 5.0 in stage 431.0 (TID 617) in 32 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:59.530+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 6.0 in stage 431.0 (TID 618) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:59.531+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 7.0 in stage 431.0 (TID 619) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.542+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 8.0 in stage 431.0 (TID 620) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.542+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 7.0 in stage 431.0 (TID 619) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:59.554+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 9.0 in stage 431.0 (TID 621) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.554+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 8.0 in stage 431.0 (TID 620) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:59.590+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 0.0 in stage 454.0 (TID 622) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.591+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 9.0 in stage 431.0 (TID 621) in 38 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:59.592+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Removed TaskSet 431.0, whose tasks have all completed, from pool
[2025-05-08T06:35:59.593+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: ResultStage 431 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.408 s
[2025-05-08T06:35:59.593+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:35:59.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 431: Stage finished
[2025-05-08T06:35:59.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Job 89 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.410803 s
[2025-05-08T06:35:59.625+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 2.1 MiB, free 386.2 MiB)
[2025-05-08T06:35:59.628+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Removed broadcast_139_piece0 on f2a432e4376a:46195 in memory (size: 19.5 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.629+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 386.2 MiB)
[2025-05-08T06:35:59.632+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 172.20.0.5:41027 in memory (size: 19.5 KiB, free: 431.5 MiB)
[2025-05-08T06:35:59.633+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on f2a432e4376a:46195 (size: 27.5 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 172.20.0.5:41027 (size: 11.9 KiB, free: 431.5 MiB)
[2025-05-08T06:35:59.640+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 150 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:59.649+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Removed broadcast_138_piece0 on f2a432e4376a:46195 in memory (size: 9.9 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.651+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 172.20.0.5:41027 in memory (size: 9.9 KiB, free: 431.5 MiB)
[2025-05-08T06:35:59.660+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 1.0 in stage 454.0 (TID 623) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.662+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 0.0 in stage 454.0 (TID 622) in 71 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T06:35:59.680+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 2.0 in stage 454.0 (TID 624) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.681+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 1.0 in stage 454.0 (TID 623) in 18 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T06:35:59.689+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Registering RDD 696 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 89
[2025-05-08T06:35:59.692+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got map stage job 100 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:35:59.693+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ShuffleMapStage 465 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:35:59.693+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:35:59.693+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.693+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ShuffleMapStage 465 (MapPartitionsRDD[696] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:35:59.698+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 3.0 in stage 454.0 (TID 625) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.698+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 2.0 in stage 454.0 (TID 624) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T06:35:59.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 16.6 KiB, free 386.2 MiB)
[2025-05-08T06:35:59.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 386.2 MiB)
[2025-05-08T06:35:59.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on f2a432e4376a:46195 (size: 8.3 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 465 (MapPartitionsRDD[696] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.699+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 465.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.727+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 4.0 in stage 454.0 (TID 626) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.739+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 3.0 in stage 454.0 (TID 625) in 47 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T06:35:59.740+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 5.0 in stage 454.0 (TID 627) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.741+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 4.0 in stage 454.0 (TID 626) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T06:35:59.750+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 6.0 in stage 454.0 (TID 628) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.752+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 5.0 in stage 454.0 (TID 627) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T06:35:59.763+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 7.0 in stage 454.0 (TID 629) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.764+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 6.0 in stage 454.0 (TID 628) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T06:35:59.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 8.0 in stage 454.0 (TID 630) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.781+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 7.0 in stage 454.0 (TID 629) in 18 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T06:35:59.790+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 9.0 in stage 454.0 (TID 631) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.791+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 8.0 in stage 454.0 (TID 630) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T06:35:59.800+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 0.0 in stage 455.0 (TID 632) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.800+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 9.0 in stage 454.0 (TID 631) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T06:35:59.800+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Removed TaskSet 454.0, whose tasks have all completed, from pool
[2025-05-08T06:35:59.801+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: ShuffleMapStage 454 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.576 s
[2025-05-08T06:35:59.802+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:35:59.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 462, ShuffleMapStage 459, ShuffleMapStage 456, ShuffleMapStage 460, ResultStage 464, ShuffleMapStage 461, ShuffleMapStage 465, ShuffleMapStage 457)
[2025-05-08T06:35:59.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:35:59.803+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: failed: Set()
[2025-05-08T06:35:59.806+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 172.20.0.5:41027 (size: 11.2 KiB, free: 431.5 MiB)
[2025-05-08T06:35:59.828+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO ShufflePartitionsUtil: For shuffle(80), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:35:59.833+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 0.0 in stage 455.0 (TID 632) in 33 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:35:59.834+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 1.0 in stage 455.0 (TID 633) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.838+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:35:59.841+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Got job 101 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:35:59.841+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Final stage: ResultStage 489 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:35:59.842+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 488)
[2025-05-08T06:35:59.842+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:35:59.843+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting ResultStage 489 (MapPartitionsRDD[701] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:35:59.845+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 7.2 KiB, free 386.2 MiB)
[2025-05-08T06:35:59.845+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 386.2 MiB)
[2025-05-08T06:35:59.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 432.0 MiB)
[2025-05-08T06:35:59.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:35:59.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 489 (MapPartitionsRDD[701] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:35:59.846+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSchedulerImpl: Adding task set 489.0 with 1 tasks resource profile 0
[2025-05-08T06:35:59.863+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 2.0 in stage 455.0 (TID 634) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.863+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 1.0 in stage 455.0 (TID 633) in 30 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:35:59.888+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 3.0 in stage 455.0 (TID 635) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.888+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 2.0 in stage 455.0 (TID 634) in 26 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:35:59.949+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 4.0 in stage 455.0 (TID 636) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.950+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 3.0 in stage 455.0 (TID 635) in 62 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:35:59.978+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Starting task 5.0 in stage 455.0 (TID 637) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:35:59.978+0000] {spark_submit.py:571} INFO - 25/05/08 06:35:59 INFO TaskSetManager: Finished task 4.0 in stage 455.0 (TID 636) in 30 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:36:00.005+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 456.0 (TID 638) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 5.0 in stage 455.0 (TID 637) in 28 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:36:00.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 455.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 455 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.755 s
[2025-05-08T06:36:00.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 462, ShuffleMapStage 459, ShuffleMapStage 456, ResultStage 489, ShuffleMapStage 460, ResultStage 464, ShuffleMapStage 461, ShuffleMapStage 465, ShuffleMapStage 457)
[2025-05-08T06:36:00.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.007+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.013+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 172.20.0.5:41027 (size: 6.8 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.026+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO ShufflePartitionsUtil: For shuffle(81), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:00.027+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO ShufflePartitionsUtil: For shuffle(81), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:00.038+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:00.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Got job 102 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:36:00.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Final stage: ResultStage 491 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:36:00.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 490)
[2025-05-08T06:36:00.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:00.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting ResultStage 491 (MapPartitionsRDD[706] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:36:00.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 7.2 KiB, free 386.2 MiB)
[2025-05-08T06:36:00.062+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_140_piece0 on f2a432e4376a:46195 in memory (size: 11.9 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.062+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 386.2 MiB)
[2025-05-08T06:36:00.063+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.063+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:00.063+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 491 (MapPartitionsRDD[706] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:00.063+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Adding task set 491.0 with 1 tasks resource profile 0
[2025-05-08T06:36:00.065+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 457.0 (TID 639) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.065+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 456.0 (TID 638) in 60 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.066+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 456.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.069+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 456 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.804 s
[2025-05-08T06:36:00.069+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.070+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ResultStage 491, ShuffleMapStage 462, ShuffleMapStage 459, ResultStage 489, ShuffleMapStage 460, ResultStage 464, ShuffleMapStage 461, ShuffleMapStage 465, ShuffleMapStage 457)
[2025-05-08T06:36:00.070+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.070+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.073+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 172.20.0.5:41027 in memory (size: 11.9 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.078+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_141_piece0 on f2a432e4376a:46195 in memory (size: 11.2 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.087+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 172.20.0.5:41027 in memory (size: 11.2 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.088+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.106+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO ShufflePartitionsUtil: For shuffle(82), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:00.123+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 458.0 (TID 640) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.128+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 457.0 (TID 639) in 63 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.128+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 457.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.146+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 457 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.867 s
[2025-05-08T06:36:00.147+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.147+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ResultStage 491, ShuffleMapStage 462, ShuffleMapStage 459, ResultStage 489, ShuffleMapStage 460, ResultStage 464, ShuffleMapStage 461, ShuffleMapStage 465)
[2025-05-08T06:36:00.147+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.147+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.147+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:00.149+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Got job 103 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:36:00.149+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Final stage: ResultStage 493 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:36:00.149+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 492)
[2025-05-08T06:36:00.149+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:00.149+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting ResultStage 493 (MapPartitionsRDD[711] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:36:00.152+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 7.2 KiB, free 386.3 MiB)
[2025-05-08T06:36:00.153+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 386.3 MiB)
[2025-05-08T06:36:00.153+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.154+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:00.154+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 493 (MapPartitionsRDD[711] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:00.154+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Adding task set 493.0 with 1 tasks resource profile 0
[2025-05-08T06:36:00.160+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.189+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 459.0 (TID 641) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 458.0 (TID 640) in 68 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.190+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 458.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.192+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 458 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.865 s
[2025-05-08T06:36:00.192+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.192+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ResultStage 491, ShuffleMapStage 462, ShuffleMapStage 459, ResultStage 489, ShuffleMapStage 460, ResultStage 493, ResultStage 464, ShuffleMapStage 461, ShuffleMapStage 465)
[2025-05-08T06:36:00.192+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.193+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.195+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.221+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 460.0 (TID 642) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.222+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 459.0 (TID 641) in 32 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.222+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 459.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.223+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 459 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.881 s
[2025-05-08T06:36:00.223+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.223+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ResultStage 491, ShuffleMapStage 462, ResultStage 489, ShuffleMapStage 460, ResultStage 493, ResultStage 464, ShuffleMapStage 461, ShuffleMapStage 465)
[2025-05-08T06:36:00.223+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.223+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.226+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 172.20.0.5:41027 (size: 13.0 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.247+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 461.0 (TID 643) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.248+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 460.0 (TID 642) in 26 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.248+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 460.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.248+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 460 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.894 s
[2025-05-08T06:36:00.248+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.248+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ResultStage 491, ShuffleMapStage 462, ResultStage 489, ResultStage 493, ResultStage 464, ShuffleMapStage 461, ShuffleMapStage 465)
[2025-05-08T06:36:00.249+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.249+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.253+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 172.20.0.5:41027 (size: 13.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.281+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 462.0 (TID 644) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 461.0 (TID 643) in 34 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 461.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 461 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.906 s
[2025-05-08T06:36:00.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ResultStage 491, ShuffleMapStage 462, ResultStage 489, ResultStage 493, ResultStage 464, ShuffleMapStage 465)
[2025-05-08T06:36:00.282+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.283+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.289+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 172.20.0.5:41027 (size: 14.9 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 464.0 (TID 645) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 462.0 (TID 644) in 47 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 462.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 462 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.940 s
[2025-05-08T06:36:00.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ResultStage 491, ResultStage 489, ResultStage 493, ResultStage 464, ShuffleMapStage 465)
[2025-05-08T06:36:00.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.332+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.333+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:43674
[2025-05-08T06:36:00.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 465.0 (TID 646) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 464.0 (TID 645) in 13 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 464.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ResultStage 464 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.850 s
[2025-05-08T06:36:00.341+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:36:00.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 464: Stage finished
[2025-05-08T06:36:00.342+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Job 99 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.853382 s
[2025-05-08T06:36:00.345+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 172.20.0.5:41027 (size: 8.3 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.346+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 1088.0 KiB, free 385.2 MiB)
[2025-05-08T06:36:00.361+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO ShufflePartitionsUtil: For shuffle(83, 84, 85, 86, 87, 88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:00.362+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_145_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.362+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 385.2 MiB)
[2025-05-08T06:36:00.366+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on f2a432e4376a:46195 (size: 32.6 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.367+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.367+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 155 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:00.368+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 172.20.0.5:41027 (size: 27.5 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.381+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_146_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.382+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO CodeGenerator: Code generated in 11.961634 ms
[2025-05-08T06:36:00.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.383+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 489.0 (TID 647) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 465.0 (TID 646) in 43 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 465.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.384+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:00.386+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 465 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.693 s
[2025-05-08T06:36:00.388+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.390+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ResultStage 491, ResultStage 489, ResultStage 493)
[2025-05-08T06:36:00.392+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.394+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.395+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_143_piece0 on f2a432e4376a:46195 in memory (size: 13.0 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.397+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 172.20.0.5:41027 in memory (size: 13.0 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.402+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.402+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO CodeGenerator: Code generated in 12.79588 ms
[2025-05-08T06:36:00.407+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_147_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.410+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:00.413+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:43674
[2025-05-08T06:36:00.414+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.420+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO CodeGenerator: Code generated in 16.711625 ms
[2025-05-08T06:36:00.427+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_149_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.427+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Registering RDD 736 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 90
[2025-05-08T06:36:00.428+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Got map stage job 104 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:36:00.428+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Final stage: ShuffleMapStage 494 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:36:00.429+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:36:00.430+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:00.431+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting ShuffleMapStage 494 (MapPartitionsRDD[736] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:36:00.432+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 491.0 (TID 648) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.433+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 17.6 KiB, free 385.3 MiB)
[2025-05-08T06:36:00.433+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 489.0 (TID 647) in 47 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.434+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 489.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 385.3 MiB)
[2025-05-08T06:36:00.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO CodeGenerator: Code generated in 20.244768 ms
[2025-05-08T06:36:00.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on f2a432e4376a:46195 (size: 8.3 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:00.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 494 (MapPartitionsRDD[736] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:00.435+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Adding task set 494.0 with 1 tasks resource profile 0
[2025-05-08T06:36:00.451+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:00.462+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.463+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO CodeGenerator: Code generated in 9.902713 ms
[2025-05-08T06:36:00.463+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 172.20.0.5:41027 in memory (size: 13.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.464+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:43674
[2025-05-08T06:36:00.464+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ResultStage 489 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.621 s
[2025-05-08T06:36:00.465+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:36:00.466+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 489: Stage finished
[2025-05-08T06:36:00.466+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:00.466+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_144_piece0 on f2a432e4376a:46195 in memory (size: 13.4 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.471+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Job 101 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.632091 s
[2025-05-08T06:36:00.488+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 1088.0 KiB, free 384.3 MiB)
[2025-05-08T06:36:00.489+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO CodeGenerator: Code generated in 17.995514 ms
[2025-05-08T06:36:00.491+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:00.493+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 384.3 MiB)
[2025-05-08T06:36:00.494+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_142_piece0 on f2a432e4376a:46195 in memory (size: 6.8 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.496+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on f2a432e4376a:46195 (size: 23.7 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.497+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 172.20.0.5:41027 in memory (size: 6.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.500+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 157 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:00.501+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO CodeGenerator: Code generated in 43.069816 ms
[2025-05-08T06:36:00.504+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:00.507+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Registering RDD 745 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 91
[2025-05-08T06:36:00.508+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Got map stage job 105 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:36:00.510+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Final stage: ShuffleMapStage 495 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:36:00.511+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T06:36:00.512+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:00.513+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting ShuffleMapStage 495 (MapPartitionsRDD[745] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:36:00.513+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_148_piece0 on f2a432e4376a:46195 in memory (size: 14.9 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.514+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 172.20.0.5:41027 in memory (size: 14.9 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.514+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 78.0 KiB, free 384.2 MiB)
[2025-05-08T06:36:00.549+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 384.2 MiB)
[2025-05-08T06:36:00.555+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 493.0 (TID 649) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.561+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 491.0 (TID 648) in 118 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.562+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 491.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.564+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on f2a432e4376a:46195 (size: 33.9 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.567+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO ShufflePartitionsUtil: For shuffle(89), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:00.568+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:00.569+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 495 (MapPartitionsRDD[745] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:00.569+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Adding task set 495.0 with 1 tasks resource profile 0
[2025-05-08T06:36:00.569+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ResultStage 491 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.525 s
[2025-05-08T06:36:00.569+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO CodeGenerator: Code generated in 54.837283 ms
[2025-05-08T06:36:00.570+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:36:00.570+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 491: Stage finished
[2025-05-08T06:36:00.570+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Job 102 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.529389 s
[2025-05-08T06:36:00.570+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_151_piece0 on f2a432e4376a:46195 in memory (size: 8.3 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.570+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 172.20.0.5:41027 in memory (size: 8.3 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.596+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_152_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.597+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.603+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.604+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:43674
[2025-05-08T06:36:00.605+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Registering RDD 755 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 92
[2025-05-08T06:36:00.605+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Got map stage job 106 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:36:00.605+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Final stage: ShuffleMapStage 497 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:36:00.605+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 496)
[2025-05-08T06:36:00.605+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:00.605+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting ShuffleMapStage 497 (MapPartitionsRDD[755] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:36:00.608+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 13.8 KiB, free 384.2 MiB)
[2025-05-08T06:36:00.609+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:00.609+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 384.2 MiB)
[2025-05-08T06:36:00.609+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on f2a432e4376a:46195 (size: 6.9 KiB, free: 432.0 MiB)
[2025-05-08T06:36:00.609+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:00.610+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 497 (MapPartitionsRDD[755] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:00.610+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Adding task set 497.0 with 1 tasks resource profile 0
[2025-05-08T06:36:00.617+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Got job 107 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-08T06:36:00.617+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Final stage: ResultStage 504 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:36:00.618+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 502, ShuffleMapStage 503, ShuffleMapStage 499, ShuffleMapStage 500, ShuffleMapStage 501, ShuffleMapStage 498)
[2025-05-08T06:36:00.618+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:00.618+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting ResultStage 504 (MapPartitionsRDD[753] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:36:00.618+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 494.0 (TID 650) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.618+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 493.0 (TID 649) in 74 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.618+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 493.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.622+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 91.7 KiB, free 384.1 MiB)
[2025-05-08T06:36:00.624+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 30.4 KiB, free 384.1 MiB)
[2025-05-08T06:36:00.624+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on f2a432e4376a:46195 (size: 30.4 KiB, free: 431.9 MiB)
[2025-05-08T06:36:00.625+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:00.625+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 504 (MapPartitionsRDD[753] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-08T06:36:00.626+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Adding task set 504.0 with 6 tasks resource profile 0
[2025-05-08T06:36:00.627+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ResultStage 493 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.477 s
[2025-05-08T06:36:00.628+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:36:00.629+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 493: Stage finished
[2025-05-08T06:36:00.633+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Job 103 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.483105 s
[2025-05-08T06:36:00.634+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 5.0 MiB, free 379.1 MiB)
[2025-05-08T06:36:00.636+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 172.20.0.5:41027 (size: 8.3 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.639+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 2.1 MiB, free 377.0 MiB)
[2025-05-08T06:36:00.647+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 377.0 MiB)
[2025-05-08T06:36:00.648+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 376.5 MiB)
[2025-05-08T06:36:00.649+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on f2a432e4376a:46195 (size: 20.6 KiB, free: 431.9 MiB)
[2025-05-08T06:36:00.650+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on f2a432e4376a:46195 (size: 502.1 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.652+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 162 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:00.653+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 161 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:00.695+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 172.20.0.5:41027 (size: 32.6 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.732+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 495.0 (TID 651) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.736+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 494.0 (TID 650) in 121 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.738+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 494.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.739+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 494 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.307 s
[2025-05-08T06:36:00.740+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.742+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ShuffleMapStage 495, ShuffleMapStage 497, ResultStage 504)
[2025-05-08T06:36:00.743+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.744+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.748+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 172.20.0.5:41027 (size: 33.9 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.862+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Starting task 0.0 in stage 497.0 (TID 652) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:00.863+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSetManager: Finished task 0.0 in stage 495.0 (TID 651) in 130 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:00.864+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Removed TaskSet 495.0, whose tasks have all completed, from pool
[2025-05-08T06:36:00.864+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: ShuffleMapStage 495 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.354 s
[2025-05-08T06:36:00.865+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:00.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: running: Set(ShuffleMapStage 497, ResultStage 504)
[2025-05-08T06:36:00.867+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:00.868+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:00.875+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 172.20.0.5:41027 (size: 6.9 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.884+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO ShufflePartitionsUtil: For shuffle(91), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:00.893+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:00.913+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO CodeGenerator: Code generated in 25.063303 ms
[2025-05-08T06:36:00.918+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:43674
[2025-05-08T06:36:00.954+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_153_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.960+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.964+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:00.965+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_158_piece0 on f2a432e4376a:46195 in memory (size: 33.9 KiB, free: 431.5 MiB)
[2025-05-08T06:36:00.966+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 172.20.0.5:41027 (size: 23.7 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.966+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Got job 108 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:36:00.967+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Final stage: ResultStage 506 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:36:00.967+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 505)
[2025-05-08T06:36:00.967+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:00.968+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 172.20.0.5:41027 in memory (size: 33.9 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.969+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting ResultStage 506 (MapPartitionsRDD[762] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:36:00.974+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 73.5 KiB, free 376.6 MiB)
[2025-05-08T06:36:00.977+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 376.6 MiB)
[2025-05-08T06:36:00.977+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on f2a432e4376a:46195 (size: 32.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.977+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:00.978+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 506 (MapPartitionsRDD[762] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:00.978+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO TaskSchedulerImpl: Adding task set 506.0 with 1 tasks resource profile 0
[2025-05-08T06:36:00.996+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_154_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:00.997+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:00 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.003+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_156_piece0 on f2a432e4376a:46195 in memory (size: 8.3 KiB, free: 431.5 MiB)
[2025-05-08T06:36:01.004+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 172.20.0.5:41027 in memory (size: 8.3 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.008+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 0.0 in stage 504.0 (TID 653) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.014+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 0.0 in stage 497.0 (TID 652) in 152 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:01.016+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Removed TaskSet 497.0, whose tasks have all completed, from pool
[2025-05-08T06:36:01.018+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: ShuffleMapStage 497 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.413 s
[2025-05-08T06:36:01.021+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:01.023+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: running: Set(ResultStage 506, ResultStage 504)
[2025-05-08T06:36:01.023+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:01.025+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:01.026+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 172.20.0.5:41027 (size: 30.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.048+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:43674
[2025-05-08T06:36:01.061+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO ShufflePartitionsUtil: For shuffle(92), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:01.075+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:01.078+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Got job 109 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:36:01.079+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Final stage: ResultStage 509 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:36:01.079+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 508)
[2025-05-08T06:36:01.079+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:01.080+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Submitting ResultStage 509 (MapPartitionsRDD[765] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:36:01.086+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 7.2 KiB, free 376.6 MiB)
[2025-05-08T06:36:01.087+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 376.6 MiB)
[2025-05-08T06:36:01.088+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on f2a432e4376a:46195 (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.090+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:01.091+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 509 (MapPartitionsRDD[765] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:01.091+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Adding task set 509.0 with 1 tasks resource profile 0
[2025-05-08T06:36:01.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 1.0 in stage 504.0 (TID 654) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.099+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 0.0 in stage 504.0 (TID 653) in 92 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-08T06:36:01.106+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:43674
[2025-05-08T06:36:01.117+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_159_piece0 on f2a432e4376a:46195 in memory (size: 6.9 KiB, free: 431.5 MiB)
[2025-05-08T06:36:01.120+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 172.20.0.5:41027 in memory (size: 6.9 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 2.0 in stage 504.0 (TID 655) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.138+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 1.0 in stage 504.0 (TID 654) in 39 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-08T06:36:01.141+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:43674
[2025-05-08T06:36:01.154+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 3.0 in stage 504.0 (TID 656) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.155+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 2.0 in stage 504.0 (TID 655) in 19 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-08T06:36:01.158+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:43674
[2025-05-08T06:36:01.171+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 4.0 in stage 504.0 (TID 657) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.172+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 3.0 in stage 504.0 (TID 656) in 18 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-08T06:36:01.176+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:43674
[2025-05-08T06:36:01.194+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 5.0 in stage 504.0 (TID 658) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.195+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 4.0 in stage 504.0 (TID 657) in 23 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-08T06:36:01.198+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:43674
[2025-05-08T06:36:01.224+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 0.0 in stage 506.0 (TID 659) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.225+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 5.0 in stage 504.0 (TID 658) in 31 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-08T06:36:01.225+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Removed TaskSet 504.0, whose tasks have all completed, from pool
[2025-05-08T06:36:01.226+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: ResultStage 504 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.611 s
[2025-05-08T06:36:01.226+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:36:01.226+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 504: Stage finished
[2025-05-08T06:36:01.226+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Job 107 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.617656 s
[2025-05-08T06:36:01.233+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 2.3 MiB, free 374.3 MiB)
[2025-05-08T06:36:01.234+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 374.2 MiB)
[2025-05-08T06:36:01.235+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on f2a432e4376a:46195 (size: 114.2 KiB, free: 431.3 MiB)
[2025-05-08T06:36:01.235+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 172.20.0.5:41027 (size: 32.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.236+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO SparkContext: Created broadcast 165 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:01.243+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:43674
[2025-05-08T06:36:01.263+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 172.20.0.5:41027 in memory (size: 30.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.264+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_160_piece0 on f2a432e4376a:46195 in memory (size: 30.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.286+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 0.0 in stage 509.0 (TID 660) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.290+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 0.0 in stage 506.0 (TID 659) in 62 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:01.292+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Removed TaskSet 506.0, whose tasks have all completed, from pool
[2025-05-08T06:36:01.296+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: ResultStage 506 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.317 s
[2025-05-08T06:36:01.296+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:36:01.297+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 506: Stage finished
[2025-05-08T06:36:01.298+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Job 108 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.323883 s
[2025-05-08T06:36:01.298+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 1088.0 KiB, free 373.3 MiB)
[2025-05-08T06:36:01.298+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 22.4 KiB, free 373.3 MiB)
[2025-05-08T06:36:01.298+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on f2a432e4376a:46195 (size: 22.4 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.298+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO SparkContext: Created broadcast 166 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:01.305+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 172.20.0.5:41027 (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-08T06:36:01.309+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO CodeGenerator: Code generated in 35.074843 ms
[2025-05-08T06:36:01.309+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:01.310+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:43674
[2025-05-08T06:36:01.320+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 0.0 in stage 509.0 (TID 660) in 35 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:01.321+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Removed TaskSet 509.0, whose tasks have all completed, from pool
[2025-05-08T06:36:01.324+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: ResultStage 509 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.240 s
[2025-05-08T06:36:01.325+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:36:01.325+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 509: Stage finished
[2025-05-08T06:36:01.327+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Job 109 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.251546 s
[2025-05-08T06:36:01.329+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 2.1 MiB, free 371.2 MiB)
[2025-05-08T06:36:01.330+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 371.2 MiB)
[2025-05-08T06:36:01.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on f2a432e4376a:46195 (size: 20.3 KiB, free: 431.3 MiB)
[2025-05-08T06:36:01.331+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO SparkContext: Created broadcast 167 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:01.369+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO CodeGenerator: Code generated in 43.354806 ms
[2025-05-08T06:36:01.388+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO CodeGenerator: Code generated in 6.176578 ms
[2025-05-08T06:36:01.394+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Registering RDD 772 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 93
[2025-05-08T06:36:01.395+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Got map stage job 110 (jdbc at NativeMethodAccessorImpl.java:0) with 11 output partitions
[2025-05-08T06:36:01.395+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Final stage: ShuffleMapStage 511 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:36:01.395+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 510)
[2025-05-08T06:36:01.395+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:01.395+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Submitting ShuffleMapStage 511 (MapPartitionsRDD[772] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:36:01.401+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 141.2 KiB, free 371.1 MiB)
[2025-05-08T06:36:01.404+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 49.6 KiB, free 371.0 MiB)
[2025-05-08T06:36:01.405+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on f2a432e4376a:46195 (size: 49.6 KiB, free: 431.3 MiB)
[2025-05-08T06:36:01.405+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:01.405+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 511 (MapPartitionsRDD[772] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-08T06:36:01.405+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Adding task set 511.0 with 11 tasks resource profile 0
[2025-05-08T06:36:01.406+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 0.0 in stage 511.0 (TID 661) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.410+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 172.20.0.5:41027 (size: 49.6 KiB, free: 431.3 MiB)
[2025-05-08T06:36:01.414+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:43674
[2025-05-08T06:36:01.438+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 172.20.0.5:41027 (size: 502.1 KiB, free: 430.8 MiB)
[2025-05-08T06:36:01.448+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 172.20.0.5:41027 (size: 114.2 KiB, free: 430.7 MiB)
[2025-05-08T06:36:01.455+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 172.20.0.5:41027 (size: 20.6 KiB, free: 430.7 MiB)
[2025-05-08T06:36:01.543+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 1.0 in stage 511.0 (TID 662) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.544+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 0.0 in stage 511.0 (TID 661) in 137 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-08T06:36:01.576+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 2.0 in stage 511.0 (TID 663) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.576+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 1.0 in stage 511.0 (TID 662) in 33 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-08T06:36:01.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 3.0 in stage 511.0 (TID 664) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.594+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 2.0 in stage 511.0 (TID 663) in 19 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-08T06:36:01.607+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 4.0 in stage 511.0 (TID 665) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.607+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 3.0 in stage 511.0 (TID 664) in 14 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-08T06:36:01.631+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 5.0 in stage 511.0 (TID 666) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.632+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 4.0 in stage 511.0 (TID 665) in 24 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-08T06:36:01.644+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 6.0 in stage 511.0 (TID 667) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.645+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 5.0 in stage 511.0 (TID 666) in 14 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-08T06:36:01.661+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 7.0 in stage 511.0 (TID 668) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.662+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 6.0 in stage 511.0 (TID 667) in 17 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-08T06:36:01.674+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 8.0 in stage 511.0 (TID 669) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.675+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 7.0 in stage 511.0 (TID 668) in 14 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-08T06:36:01.685+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 9.0 in stage 511.0 (TID 670) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.688+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 8.0 in stage 511.0 (TID 669) in 12 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-08T06:36:01.712+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 10.0 in stage 511.0 (TID 671) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.712+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 9.0 in stage 511.0 (TID 670) in 27 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-08T06:36:01.761+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 10.0 in stage 511.0 (TID 671) in 49 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-08T06:36:01.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Removed TaskSet 511.0, whose tasks have all completed, from pool
[2025-05-08T06:36:01.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: ShuffleMapStage 511 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.366 s
[2025-05-08T06:36:01.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:01.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: running: Set()
[2025-05-08T06:36:01.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:01.762+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:01.766+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO ShufflePartitionsUtil: For shuffle(93), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:01.768+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:01.799+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO CodeGenerator: Code generated in 24.428985 ms
[2025-05-08T06:36:01.809+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Registering RDD 775 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 94
[2025-05-08T06:36:01.810+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Got map stage job 111 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:36:01.810+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Final stage: ShuffleMapStage 514 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:36:01.810+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 513)
[2025-05-08T06:36:01.810+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:01.810+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Submitting ShuffleMapStage 514 (MapPartitionsRDD[775] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:36:01.814+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 130.2 KiB, free 370.9 MiB)
[2025-05-08T06:36:01.829+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_164_piece0 on f2a432e4376a:46195 in memory (size: 3.8 KiB, free: 431.3 MiB)
[2025-05-08T06:36:01.829+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 44.5 KiB, free 370.8 MiB)
[2025-05-08T06:36:01.829+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on f2a432e4376a:46195 (size: 44.5 KiB, free: 431.2 MiB)
[2025-05-08T06:36:01.829+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:01.830+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 514 (MapPartitionsRDD[775] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:01.830+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Adding task set 514.0 with 1 tasks resource profile 0
[2025-05-08T06:36:01.830+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Starting task 0.0 in stage 514.0 (TID 672) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:01.830+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 172.20.0.5:41027 in memory (size: 3.8 KiB, free: 430.7 MiB)
[2025-05-08T06:36:01.834+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_168_piece0 on f2a432e4376a:46195 in memory (size: 49.6 KiB, free: 431.3 MiB)
[2025-05-08T06:36:01.835+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 172.20.0.5:41027 in memory (size: 49.6 KiB, free: 430.8 MiB)
[2025-05-08T06:36:01.837+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 172.20.0.5:41027 (size: 44.5 KiB, free: 430.7 MiB)
[2025-05-08T06:36:01.838+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_163_piece0 on f2a432e4376a:46195 in memory (size: 32.4 KiB, free: 431.3 MiB)
[2025-05-08T06:36:01.840+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 172.20.0.5:41027 in memory (size: 32.4 KiB, free: 430.8 MiB)
[2025-05-08T06:36:01.845+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:43674
[2025-05-08T06:36:01.926+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSetManager: Finished task 0.0 in stage 514.0 (TID 672) in 96 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:01.927+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO TaskSchedulerImpl: Removed TaskSet 514.0, whose tasks have all completed, from pool
[2025-05-08T06:36:01.928+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: ShuffleMapStage 514 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.118 s
[2025-05-08T06:36:01.928+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T06:36:01.928+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: running: Set()
[2025-05-08T06:36:01.928+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: waiting: Set()
[2025-05-08T06:36:01.928+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: failed: Set()
[2025-05-08T06:36:01.943+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO ShufflePartitionsUtil: For shuffle(94), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:01.948+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T06:36:01.972+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO CodeGenerator: Code generated in 14.141553 ms
[2025-05-08T06:36:01.988+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:01.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Got job 112 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T06:36:01.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Final stage: ResultStage 518 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T06:36:01.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 517)
[2025-05-08T06:36:01.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:01.989+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO DAGScheduler: Submitting ResultStage 518 (MapPartitionsRDD[778] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T06:36:01.994+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:01 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 122.7 KiB, free 371.0 MiB)
[2025-05-08T06:36:02.003+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 41.9 KiB, free 371.0 MiB)
[2025-05-08T06:36:02.004+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Removed broadcast_169_piece0 on f2a432e4376a:46195 in memory (size: 44.5 KiB, free: 431.4 MiB)
[2025-05-08T06:36:02.004+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on f2a432e4376a:46195 (size: 41.9 KiB, free: 431.3 MiB)
[2025-05-08T06:36:02.005+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:02.005+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 518 (MapPartitionsRDD[778] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:02.005+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSchedulerImpl: Adding task set 518.0 with 1 tasks resource profile 0
[2025-05-08T06:36:02.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 172.20.0.5:41027 in memory (size: 44.5 KiB, free: 430.8 MiB)
[2025-05-08T06:36:02.006+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSetManager: Starting task 0.0 in stage 518.0 (TID 673) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:02.011+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 172.20.0.5:41027 (size: 41.9 KiB, free: 430.8 MiB)
[2025-05-08T06:36:02.019+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:43674
[2025-05-08T06:36:02.041+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSetManager: Finished task 0.0 in stage 518.0 (TID 673) in 35 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:02.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSchedulerImpl: Removed TaskSet 518.0, whose tasks have all completed, from pool
[2025-05-08T06:36:02.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: ResultStage 518 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.052 s
[2025-05-08T06:36:02.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:36:02.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 518: Stage finished
[2025-05-08T06:36:02.042+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Job 112 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.054019 s
[2025-05-08T06:36:02.045+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 2.1 MiB, free 369.1 MiB)
[2025-05-08T06:36:02.046+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 82.5 KiB, free 369.0 MiB)
[2025-05-08T06:36:02.047+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on f2a432e4376a:46195 (size: 82.5 KiB, free: 431.2 MiB)
[2025-05-08T06:36:02.047+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO SparkContext: Created broadcast 171 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T06:36:02.049+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO ShufflePartitionsUtil: For shuffle(90), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T06:36:02.081+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO CodeGenerator: Code generated in 6.904721 ms
[2025-05-08T06:36:02.103+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-05-08T06:36:02.104+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Got job 113 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T06:36:02.104+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Final stage: ResultStage 520 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-08T06:36:02.104+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 519)
[2025-05-08T06:36:02.104+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Missing parents: List()
[2025-05-08T06:36:02.105+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Submitting ResultStage 520 (MapPartitionsRDD[783] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T06:36:02.126+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 204.3 KiB, free 368.8 MiB)
[2025-05-08T06:36:02.133+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Removed broadcast_170_piece0 on f2a432e4376a:46195 in memory (size: 41.9 KiB, free: 431.3 MiB)
[2025-05-08T06:36:02.135+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 72.2 KiB, free 368.9 MiB)
[2025-05-08T06:36:02.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on f2a432e4376a:46195 (size: 72.2 KiB, free: 431.2 MiB)
[2025-05-08T06:36:02.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1474
[2025-05-08T06:36:02.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 520 (MapPartitionsRDD[783] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T06:36:02.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSchedulerImpl: Adding task set 520.0 with 1 tasks resource profile 0
[2025-05-08T06:36:02.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSetManager: Starting task 0.0 in stage 520.0 (TID 674) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-08T06:36:02.137+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 172.20.0.5:41027 in memory (size: 41.9 KiB, free: 430.8 MiB)
[2025-05-08T06:36:02.142+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 172.20.0.5:41027 (size: 72.2 KiB, free: 430.7 MiB)
[2025-05-08T06:36:02.154+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:43674
[2025-05-08T06:36:02.166+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 172.20.0.5:41027 (size: 20.3 KiB, free: 430.7 MiB)
[2025-05-08T06:36:02.171+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 172.20.0.5:41027 (size: 82.5 KiB, free: 430.6 MiB)
[2025-05-08T06:36:02.177+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 172.20.0.5:41027 (size: 22.4 KiB, free: 430.6 MiB)
[2025-05-08T06:36:02.327+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSetManager: Finished task 0.0 in stage 520.0 (TID 674) in 192 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T06:36:02.327+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSchedulerImpl: Removed TaskSet 520.0, whose tasks have all completed, from pool
[2025-05-08T06:36:02.327+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: ResultStage 520 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.222 s
[2025-05-08T06:36:02.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Job 113 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T06:36:02.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 520: Stage finished
[2025-05-08T06:36:02.328+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO DAGScheduler: Job 113 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.224587 s
[2025-05-08T06:36:02.344+0000] {spark_submit.py:571} INFO - 2025-05-08 06:36:02,344 [INFO] Анализ графа успешно завершен
[2025-05-08T06:36:02.357+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO SparkUI: Stopped Spark web UI at http://f2a432e4376a:4040
[2025-05-08T06:36:02.360+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-05-08T06:36:02.361+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2025-05-08T06:36:02.381+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-08T06:36:02.414+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO MemoryStore: MemoryStore cleared
[2025-05-08T06:36:02.415+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManager: BlockManager stopped
[2025-05-08T06:36:02.418+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-08T06:36:02.424+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-08T06:36:02.430+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:02 INFO SparkContext: Successfully stopped SparkContext
[2025-05-08T06:36:02.878+0000] {spark_submit.py:571} INFO - 2025-05-08 06:36:02,877 [INFO] SparkSession остановлена
[2025-05-08T06:36:03.033+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:03 INFO ShutdownHookManager: Shutdown hook called
[2025-05-08T06:36:03.033+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:03 INFO ShutdownHookManager: Deleting directory /tmp/spark-b4ff2d5f-ebaa-4292-a3c1-c3211f63aae7/pyspark-31f84546-86f2-47b7-92f2-924994c1921c
[2025-05-08T06:36:03.037+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:03 INFO ShutdownHookManager: Deleting directory /tmp/spark-ef1cb87f-ea1f-4276-9275-231f0da7c107
[2025-05-08T06:36:03.039+0000] {spark_submit.py:571} INFO - 25/05/08 06:36:03 INFO ShutdownHookManager: Deleting directory /tmp/spark-b4ff2d5f-ebaa-4292-a3c1-c3211f63aae7
[2025-05-08T06:36:03.295+0000] {taskinstance.py:1345} INFO - Marking task as SUCCESS. dag_id=graph_analysis, task_id=build_graph, execution_date=20250508T063513, start_date=20250508T063521, end_date=20250508T063603
[2025-05-08T06:36:03.405+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2025-05-08T06:36:03.557+0000] {taskinstance.py:2653} INFO - 1 downstream tasks scheduled from follow-on schedule check
