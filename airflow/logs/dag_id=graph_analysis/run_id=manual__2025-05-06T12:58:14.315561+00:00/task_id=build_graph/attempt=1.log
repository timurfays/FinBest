[2025-05-06T12:58:21.614+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-06T12:58:14.315561+00:00 [queued]>
[2025-05-06T12:58:21.622+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-06T12:58:14.315561+00:00 [queued]>
[2025-05-06T12:58:21.622+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 2
[2025-05-06T12:58:21.632+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): build_graph> on 2025-05-06 12:58:14.315561+00:00
[2025-05-06T12:58:21.639+0000] {standard_task_runner.py:57} INFO - Started process 1272 to run task
[2025-05-06T12:58:21.641+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'graph_analysis', 'build_graph', 'manual__2025-05-06T12:58:14.315561+00:00', '--job-id', '196', '--raw', '--subdir', 'DAGS_FOLDER/graph_analysis.py', '--cfg-path', '/tmp/tmpzevccubv']
[2025-05-06T12:58:21.642+0000] {standard_task_runner.py:85} INFO - Job 196: Subtask build_graph
[2025-05-06T12:58:21.653+0000] {logging_mixin.py:150} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-06T12:58:21.680+0000] {task_command.py:410} INFO - Running <TaskInstance: graph_analysis.build_graph manual__2025-05-06T12:58:14.315561+00:00 [running]> on host 016737cbcc7e
[2025-05-06T12:58:21.743+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='finbest' AIRFLOW_CTX_DAG_ID='graph_analysis' AIRFLOW_CTX_TASK_ID='build_graph' AIRFLOW_CTX_EXECUTION_DATE='2025-05-06T12:58:14.315561+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-06T12:58:14.315561+00:00'
[2025-05-06T12:58:21.750+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-05-06T12:58:21.751+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --jars /opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar --packages org.postgresql:postgresql:42.6.0 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******
[2025-05-06T12:58:21.770+0000] {spark_submit.py:571} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-05-06T12:58:22.725+0000] {spark_submit.py:571} INFO - Using properties file: null
[2025-05-06T12:58:22.806+0000] {spark_submit.py:571} INFO - WARNING: An illegal reflective access operation has occurred
[2025-05-06T12:58:22.807+0000] {spark_submit.py:571} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2025-05-06T12:58:22.807+0000] {spark_submit.py:571} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2025-05-06T12:58:22.807+0000] {spark_submit.py:571} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-05-06T12:58:22.807+0000] {spark_submit.py:571} INFO - WARNING: All illegal access operations will be denied in a future release
[2025-05-06T12:58:22.861+0000] {spark_submit.py:571} INFO - Parsed arguments:
[2025-05-06T12:58:22.862+0000] {spark_submit.py:571} INFO - master                  spark://spark-master:7077
[2025-05-06T12:58:22.862+0000] {spark_submit.py:571} INFO - deployMode              null
[2025-05-06T12:58:22.862+0000] {spark_submit.py:571} INFO - executorMemory          1g
[2025-05-06T12:58:22.862+0000] {spark_submit.py:571} INFO - executorCores           1
[2025-05-06T12:58:22.862+0000] {spark_submit.py:571} INFO - totalExecutorCores      null
[2025-05-06T12:58:22.862+0000] {spark_submit.py:571} INFO - propertiesFile          null
[2025-05-06T12:58:22.862+0000] {spark_submit.py:571} INFO - driverMemory            1g
[2025-05-06T12:58:22.862+0000] {spark_submit.py:571} INFO - driverCores             null
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - driverExtraClassPath    null
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - driverExtraLibraryPath  null
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - driverExtraJavaOptions  null
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - supervise               false
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - queue                   null
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - numExecutors            null
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - files                   null
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - pyFiles                 null
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - archives                null
[2025-05-06T12:58:22.863+0000] {spark_submit.py:571} INFO - mainClass               null
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - primaryResource         file:/opt/airflow/spark/build_graph.py
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - name                    arrow-spark
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - childArgs               [--jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ***]
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - jars                    file:/opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - packages                org.postgresql:postgresql:42.6.0
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - packagesExclusions      null
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - repositories            null
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - verbose                 true
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - 
[2025-05-06T12:58:22.864+0000] {spark_submit.py:571} INFO - Spark properties used, including those specified through
[2025-05-06T12:58:22.865+0000] {spark_submit.py:571} INFO - --conf and those from the properties file null:
[2025-05-06T12:58:22.865+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-06T12:58:22.865+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-06T12:58:22.865+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-06T12:58:22.865+0000] {spark_submit.py:571} INFO - 
[2025-05-06T12:58:22.865+0000] {spark_submit.py:571} INFO - 
[2025-05-06T12:58:22.985+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-06T12:58:23.060+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-05-06T12:58:23.060+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-05-06T12:58:23.063+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql added as a dependency
[2025-05-06T12:58:23.064+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-8966703a-270c-4e63-a9ac-6d157baa205a;1.0
[2025-05-06T12:58:23.064+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-06T12:58:24.551+0000] {spark_submit.py:571} INFO - found org.postgresql#postgresql;42.6.0 in central
[2025-05-06T12:58:25.268+0000] {spark_submit.py:571} INFO - found org.checkerframework#checker-qual;3.31.0 in central
[2025-05-06T12:58:25.280+0000] {spark_submit.py:571} INFO - downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.6.0/postgresql-42.6.0.jar ...
[2025-05-06T12:58:26.612+0000] {spark_submit.py:571} INFO - [SUCCESSFUL ] org.postgresql#postgresql;42.6.0!postgresql.jar (1332ms)
[2025-05-06T12:58:26.614+0000] {spark_submit.py:571} INFO - downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.31.0/checker-qual-3.31.0.jar ...
[2025-05-06T12:58:26.766+0000] {spark_submit.py:571} INFO - [SUCCESSFUL ] org.checkerframework#checker-qual;3.31.0!checker-qual.jar (152ms)
[2025-05-06T12:58:26.768+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 2215ms :: artifacts dl 1489ms
[2025-05-06T12:58:26.768+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-05-06T12:58:26.768+0000] {spark_submit.py:571} INFO - org.checkerframework#checker-qual;3.31.0 from central in [default]
[2025-05-06T12:58:26.769+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql;42.6.0 from central in [default]
[2025-05-06T12:58:26.769+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-06T12:58:26.769+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-05-06T12:58:26.769+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-06T12:58:26.770+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-06T12:58:26.770+0000] {spark_submit.py:571} INFO - |      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
[2025-05-06T12:58:26.770+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-06T12:58:26.775+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-8966703a-270c-4e63-a9ac-6d157baa205a
[2025-05-06T12:58:26.776+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-06T12:58:26.784+0000] {spark_submit.py:571} INFO - 2 artifacts copied, 0 already retrieved (1274kB/9ms)
[2025-05-06T12:58:26.938+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-06T12:58:27.102+0000] {spark_submit.py:571} INFO - Main class:
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - org.apache.spark.deploy.PythonRunner
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - Arguments:
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - file:/opt/airflow/spark/build_graph.py
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - --jdbc
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - jdbc:postgresql://postgres:5432/finbest
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - --user
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - finbest
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - --password
[2025-05-06T12:58:27.103+0000] {spark_submit.py:571} INFO - ***
[2025-05-06T12:58:27.104+0000] {spark_submit.py:571} INFO - Spark config:
[2025-05-06T12:58:27.105+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-06T12:58:27.105+0000] {spark_submit.py:571} INFO - (spark.jars,file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T12:58:27.105+0000] {spark_submit.py:571} INFO - (spark.app.name,arrow-spark)
[2025-05-06T12:58:27.105+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-06T12:58:27.105+0000] {spark_submit.py:571} INFO - (spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,/home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T12:58:27.105+0000] {spark_submit.py:571} INFO - (spark.files,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T12:58:27.105+0000] {spark_submit.py:571} INFO - (spark.submit.deployMode,client)
[2025-05-06T12:58:27.105+0000] {spark_submit.py:571} INFO - (spark.master,spark://spark-master:7077)
[2025-05-06T12:58:27.105+0000] {spark_submit.py:571} INFO - (spark.executor.memory,1g)
[2025-05-06T12:58:27.106+0000] {spark_submit.py:571} INFO - (spark.executor.cores,1)
[2025-05-06T12:58:27.106+0000] {spark_submit.py:571} INFO - (spark.repl.local.jars,file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T12:58:27.106+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-06T12:58:27.106+0000] {spark_submit.py:571} INFO - Classpath elements:
[2025-05-06T12:58:27.106+0000] {spark_submit.py:571} INFO - file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-06T12:58:27.106+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar
[2025-05-06T12:58:27.106+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-06T12:58:27.106+0000] {spark_submit.py:571} INFO - 
[2025-05-06T12:58:27.106+0000] {spark_submit.py:571} INFO - 
[2025-05-06T12:58:27.714+0000] {spark_submit.py:571} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2025-05-06T12:58:27.720+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO SparkContext: Running Spark version 3.2.4
[2025-05-06T12:58:27.735+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO ResourceUtils: ==============================================================
[2025-05-06T12:58:27.735+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-06T12:58:27.735+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO ResourceUtils: ==============================================================
[2025-05-06T12:58:27.735+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO SparkContext: Submitted application: FinBestGraphAnalysis
[2025-05-06T12:58:27.751+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-06T12:58:27.759+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-05-06T12:58:27.760+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-06T12:58:27.801+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO SecurityManager: Changing view acls to: airflow
[2025-05-06T12:58:27.802+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO SecurityManager: Changing modify acls to: airflow
[2025-05-06T12:58:27.802+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO SecurityManager: Changing view acls groups to:
[2025-05-06T12:58:27.802+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO SecurityManager: Changing modify acls groups to:
[2025-05-06T12:58:27.802+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(airflow); groups with view permissions: Set(); users  with modify permissions: Set(airflow); groups with modify permissions: Set()
[2025-05-06T12:58:28.011+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO Utils: Successfully started service 'sparkDriver' on port 35795.
[2025-05-06T12:58:28.033+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkEnv: Registering MapOutputTracker
[2025-05-06T12:58:28.061+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-06T12:58:28.075+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-06T12:58:28.076+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-06T12:58:28.079+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-06T12:58:28.101+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0856d411-a436-4a6b-a2c7-4282539e23fb
[2025-05-06T12:58:28.118+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-06T12:58:28.132+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-06T12:58:28.273+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-06T12:58:28.308+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://016737cbcc7e:4040
[2025-05-06T12:58:28.318+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkContext: Added JAR file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar at spark://016737cbcc7e:35795/jars/graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746536307713
[2025-05-06T12:58:28.318+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://016737cbcc7e:35795/jars/org.postgresql_postgresql-42.6.0.jar with timestamp 1746536307713
[2025-05-06T12:58:28.318+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://016737cbcc7e:35795/jars/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746536307713
[2025-05-06T12:58:28.320+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://016737cbcc7e:35795/files/org.postgresql_postgresql-42.6.0.jar with timestamp 1746536307713
[2025-05-06T12:58:28.321+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO Utils: Copying /home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar to /tmp/spark-135fc717-f328-4c63-a9e8-c3c37a6b87e6/userFiles-ec4e7544-4708-46a7-b0da-ec19a3f6b0c5/org.postgresql_postgresql-42.6.0.jar
[2025-05-06T12:58:28.330+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://016737cbcc7e:35795/files/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746536307713
[2025-05-06T12:58:28.331+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO Utils: Copying /home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar to /tmp/spark-135fc717-f328-4c63-a9e8-c3c37a6b87e6/userFiles-ec4e7544-4708-46a7-b0da-ec19a3f6b0c5/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-06T12:58:28.467+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-05-06T12:58:28.500+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:28 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.2:7077 after 22 ms (0 ms spent in bootstraps)
[2025-05-06T12:58:29.133+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250506125829-0000
[2025-05-06T12:58:29.140+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41421.
[2025-05-06T12:58:29.141+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO NettyBlockTransferService: Server created on 016737cbcc7e:41421
[2025-05-06T12:58:29.143+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-06T12:58:29.150+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 016737cbcc7e, 41421, None)
[2025-05-06T12:58:29.154+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO BlockManagerMasterEndpoint: Registering block manager 016737cbcc7e:41421 with 434.4 MiB RAM, BlockManagerId(driver, 016737cbcc7e, 41421, None)
[2025-05-06T12:58:29.157+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 016737cbcc7e, 41421, None)
[2025-05-06T12:58:29.158+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 016737cbcc7e, 41421, None)
[2025-05-06T12:58:29.159+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250506125829-0000/0 on worker-20250506113546-172.18.0.4-40121 (172.18.0.4:40121) with 1 core(s)
[2025-05-06T12:58:29.161+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250506125829-0000/0 on hostPort 172.18.0.4:40121 with 1 core(s), 1024.0 MiB RAM
[2025-05-06T12:58:29.267+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250506125829-0000/0 is now RUNNING
[2025-05-06T12:58:29.317+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-05-06T12:58:29.505+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-06T12:58:29.508+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:29 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-05-06T12:58:30.425+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:30,425 [INFO] SparkSession создана
[2025-05-06T12:58:30.425+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:30,425 [INFO] Загружаем транзакции из raw.masked_transactions
[2025-05-06T12:58:35.549+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.4:47760) with ID 0,  ResourceProfileId 0
[2025-05-06T12:58:35.848+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.4:46559 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.4, 46559, None)
[2025-05-06T12:58:36.062+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO CodeGenerator: Code generated in 95.602811 ms
[2025-05-06T12:58:36.103+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-05-06T12:58:36.106+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:36.106+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:36.106+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:36.107+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:36.109+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:36.207+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-06T12:58:36.233+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-06T12:58:36.236+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:36.240+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:36.255+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:36.256+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-06T12:58:36.281+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:36.456+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:37.276+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1000 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:37.277+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-06T12:58:37.282+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.165 s
[2025-05-06T12:58:37.282+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:37.282+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:37.282+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:37.282+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:37.309+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO CodeGenerator: Code generated in 8.060203 ms
[2025-05-06T12:58:37.334+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T12:58:37.337+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:37.337+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:37.337+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-06T12:58:37.338+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:37.339+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:37.348+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-06T12:58:37.355+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-06T12:58:37.356+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 016737cbcc7e:41421 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:37.356+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:37.358+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:37.358+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-06T12:58:37.363+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:37.377+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:37.397+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:37.405+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.4:46559 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:37.528+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.4:47760
[2025-05-06T12:58:37.619+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 257 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:37.619+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-06T12:58:37.620+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.275 s
[2025-05-06T12:58:37.622+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:37.622+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-06T12:58:37.623+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.288541 s
[2025-05-06T12:58:37.630+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:37,629 [INFO] Загружено 4652 транзакций
[2025-05-06T12:58:37.630+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:37,630 [INFO] Схема данных транзакций:
[2025-05-06T12:58:37.636+0000] {spark_submit.py:571} INFO - root
[2025-05-06T12:58:37.636+0000] {spark_submit.py:571} INFO - |-- transaction_id: string (nullable = true)
[2025-05-06T12:58:37.636+0000] {spark_submit.py:571} INFO - |-- client_id: string (nullable = true)
[2025-05-06T12:58:37.636+0000] {spark_submit.py:571} INFO - |-- datetime: timestamp (nullable = true)
[2025-05-06T12:58:37.636+0000] {spark_submit.py:571} INFO - |-- amount: double (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- currency: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- merchant: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- transaction_type: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- category: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- country_code: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- region: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- device_type: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- session_id: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- channel: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- transaction_purpose: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- ip_network: string (nullable = true)
[2025-05-06T12:58:37.637+0000] {spark_submit.py:571} INFO - |-- recipient_id_hash: string (nullable = true)
[2025-05-06T12:58:37.638+0000] {spark_submit.py:571} INFO - 
[2025-05-06T12:58:37.655+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:37,655 [INFO] Создаем вершины графа
[2025-05-06T12:58:37.733+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:37.757+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO CodeGenerator: Code generated in 18.074252 ms
[2025-05-06T12:58:37.771+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Registering RDD 8 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-05-06T12:58:37.772+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:37.772+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:37.772+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:37.772+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:37.772+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:37.776+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 19.7 KiB, free 434.4 MiB)
[2025-05-06T12:58:37.787+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 434.4 MiB)
[2025-05-06T12:58:37.788+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 016737cbcc7e:41421 (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T12:58:37.789+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 016737cbcc7e:41421 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:37.789+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:37.791+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:37.791+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-05-06T12:58:37.793+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:37.797+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.4:46559 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:37.822+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.4:46559 (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.155+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 363 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:38.156+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-06T12:58:38.157+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.383 s
[2025-05-06T12:58:38.157+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:38.158+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:38.158+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:38.158+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:38.172+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:38.192+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:38.215+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO CodeGenerator: Code generated in 19.19178 ms
[2025-05-06T12:58:38.238+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Registering RDD 11 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-05-06T12:58:38.238+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:38.239+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:38.239+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-06T12:58:38.239+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:38.239+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:38.245+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 33.9 KiB, free 434.3 MiB)
[2025-05-06T12:58:38.254+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
[2025-05-06T12:58:38.255+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 016737cbcc7e:41421 (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.257+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 016737cbcc7e:41421 in memory (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.257+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:38.259+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:38.260+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-06T12:58:38.261+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:38.262+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.4:46559 in memory (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.284+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.4:46559 (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.320+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.4:47760
[2025-05-06T12:58:38.380+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 115 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:38.381+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-06T12:58:38.381+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.138 s
[2025-05-06T12:58:38.382+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:38.382+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:38.383+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:38.383+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:38.418+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO CodeGenerator: Code generated in 15.632796 ms
[2025-05-06T12:58:38.435+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T12:58:38.436+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:38.437+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:38.437+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-06T12:58:38.437+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:38.439+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:38.441+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-06T12:58:38.452+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.3 MiB)
[2025-05-06T12:58:38.453+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 016737cbcc7e:41421 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.456+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:38.456+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:38.456+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-06T12:58:38.459+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 016737cbcc7e:41421 in memory (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.460+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:38.463+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.4:46559 in memory (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.490+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.4:46559 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.514+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.4:47760
[2025-05-06T12:58:38.554+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 95 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:38.554+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-06T12:58:38.555+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.116 s
[2025-05-06T12:58:38.556+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:38.556+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-06T12:58:38.558+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.120906 s
[2025-05-06T12:58:38.561+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:38,560 [INFO] Создано 1139 вершин
[2025-05-06T12:58:38.697+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2025-05-06T12:58:38.698+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:38.698+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:38.698+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:38.698+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:38.698+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:38.700+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.0 KiB, free 434.4 MiB)
[2025-05-06T12:58:38.707+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 434.4 MiB)
[2025-05-06T12:58:38.708+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 016737cbcc7e:41421 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:38.712+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:38.712+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-05-06T12:58:38.713+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 016737cbcc7e:41421 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.714+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:38.715+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.4:46559 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.736+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.4:46559 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.769+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 56 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:38.770+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-05-06T12:58:38.770+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.072 s
[2025-05-06T12:58:38.770+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:38.770+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:38.770+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:38.770+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:38.795+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T12:58:38.796+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:38.796+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:38.796+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-05-06T12:58:38.796+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:38.798+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:38.801+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-06T12:58:38.812+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-06T12:58:38.812+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 016737cbcc7e:41421 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.814+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:38.815+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 016737cbcc7e:41421 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.815+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:38.815+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-05-06T12:58:38.817+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 6) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:38.821+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.4:46559 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.848+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.4:46559 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:38.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.4:47760
[2025-05-06T12:58:38.877+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 6) in 61 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:38.878+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-05-06T12:58:38.879+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.080 s
[2025-05-06T12:58:38.879+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:38.880+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2025-05-06T12:58:38.880+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.084385 s
[2025-05-06T12:58:38.881+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:38,880 [INFO] Найдено 1774 P2P транзакций (transaction_type='p2p')
[2025-05-06T12:58:38.881+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:38,881 [INFO] Найден столбец recipient_id_hash для P2P транзакций
[2025-05-06T12:58:38.881+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:38,881 [INFO] Создаем ребра на основе P2P транзакций
[2025-05-06T12:58:38.983+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2025-05-06T12:58:38.983+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:38.983+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:38.983+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:38.983+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:38.984+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:38.988+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.0 KiB, free 434.4 MiB)
[2025-05-06T12:58:38.999+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:38 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 434.4 MiB)
[2025-05-06T12:58:39.002+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 016737cbcc7e:41421 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.004+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:39.005+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:39.005+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-05-06T12:58:39.008+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 016737cbcc7e:41421 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.011+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 7) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:39.017+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.4:46559 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.033+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.4:46559 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.069+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 7) in 60 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:39.069+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-05-06T12:58:39.070+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.085 s
[2025-05-06T12:58:39.070+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:39.071+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:39.071+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:39.071+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:39.098+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T12:58:39.099+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:39.099+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:39.099+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2025-05-06T12:58:39.100+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:39.101+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:39.103+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-06T12:58:39.113+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-06T12:58:39.114+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 016737cbcc7e:41421 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.117+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:39.118+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:39.118+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-05-06T12:58:39.118+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 016737cbcc7e:41421 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.120+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 8) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:39.120+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.4:46559 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.153+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.4:46559 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.163+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.4:47760
[2025-05-06T12:58:39.180+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 8) in 61 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:39.180+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-05-06T12:58:39.181+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.078 s
[2025-05-06T12:58:39.181+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:39.182+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2025-05-06T12:58:39.182+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.083158 s
[2025-05-06T12:58:39.185+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:39,184 [INFO] Создано 1774 P2P ребер
[2025-05-06T12:58:39.185+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:39,184 [INFO] Создаем ребра на основе общих мерчантов
[2025-05-06T12:58:39.467+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO CodeGenerator: Code generated in 9.294952 ms
[2025-05-06T12:58:39.472+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2025-05-06T12:58:39.472+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Got map stage job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:39.472+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:39.473+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:39.473+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:39.473+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:39.476+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.8 KiB, free 434.4 MiB)
[2025-05-06T12:58:39.487+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-06T12:58:39.492+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.493+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:39.493+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:39.493+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-05-06T12:58:39.493+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 9) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:39.502+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 016737cbcc7e:41421 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.507+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.4:46559 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.539+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.598+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 9) in 106 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:39.600+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-06T12:58:39.601+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.126 s
[2025-05-06T12:58:39.602+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:39.602+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:39.602+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:39.602+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:39.625+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:39.651+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:39.652+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Got job 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:39.652+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Final stage: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:39.652+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
[2025-05-06T12:58:39.652+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:39.653+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[32] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:39.656+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-06T12:58:39.667+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-06T12:58:39.669+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.673+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.674+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:39.674+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[32] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:39.675+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2025-05-06T12:58:39.675+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.679+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 10) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:39.717+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.721+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.4:47760
[2025-05-06T12:58:39.746+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 10) in 71 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:39.748+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2025-05-06T12:58:39.748+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.093 s
[2025-05-06T12:58:39.749+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:39.749+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2025-05-06T12:58:39.749+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Job 10 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.097849 s
[2025-05-06T12:58:39.780+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO CodeGenerator: Code generated in 8.057839 ms
[2025-05-06T12:58:39.789+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.792+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.810+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T12:58:39.825+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 432.3 MiB)
[2025-05-06T12:58:39.827+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 016737cbcc7e:41421 (size: 24.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.828+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:39.834+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:39.870+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO CodeGenerator: Code generated in 12.140621 ms
[2025-05-06T12:58:39.874+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2025-05-06T12:58:39.875+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Got map stage job 11 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:39.875+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:39.875+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
[2025-05-06T12:58:39.875+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:39.876+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:39.879+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 14.8 KiB, free 432.3 MiB)
[2025-05-06T12:58:39.889+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 432.3 MiB)
[2025-05-06T12:58:39.890+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 016737cbcc7e:41421 (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.890+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:39.891+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:39.891+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
[2025-05-06T12:58:39.893+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 11) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:39.910+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.4:46559 (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T12:58:39.963+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.4:46559 (size: 24.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.028+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 11) in 136 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:40.029+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-05-06T12:58:40.031+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0) finished in 0.154 s
[2025-05-06T12:58:40.032+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:40.033+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:40.033+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:40.033+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:40.051+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO CodeGenerator: Code generated in 10.168937 ms
[2025-05-06T12:58:40.064+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T12:58:40.065+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Got job 12 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:40.065+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Final stage: ResultStage 22 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:40.065+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2025-05-06T12:58:40.065+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:40.066+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:40.068+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 11.0 KiB, free 432.3 MiB)
[2025-05-06T12:58:40.069+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 432.3 MiB)
[2025-05-06T12:58:40.070+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 016737cbcc7e:41421 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.070+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:40.071+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:40.071+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-05-06T12:58:40.072+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 12) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:40.083+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.4:46559 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.087+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.18.0.4:47760
[2025-05-06T12:58:40.107+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 12) in 36 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:40.108+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-05-06T12:58:40.108+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: ResultStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0.042 s
[2025-05-06T12:58:40.109+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:40.110+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
[2025-05-06T12:58:40.110+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Job 12 finished: count at NativeMethodAccessorImpl.java:0, took 0.045584 s
[2025-05-06T12:58:40.111+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:40,111 [INFO] Создано 270444 ребер по общим мерчантам
[2025-05-06T12:58:40.111+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:40,111 [INFO] Создаем ребра на основе общих IP-адресов
[2025-05-06T12:58:40.191+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Registering RDD 42 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2025-05-06T12:58:40.191+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Got map stage job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:40.191+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Final stage: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:40.191+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:40.191+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:40.191+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[42] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:40.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 12.8 KiB, free 432.3 MiB)
[2025-05-06T12:58:40.205+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.3 MiB)
[2025-05-06T12:58:40.206+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.208+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:40.209+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[42] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:40.209+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
[2025-05-06T12:58:40.210+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 13) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:40.216+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.4:46559 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.218+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 016737cbcc7e:41421 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.222+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 016737cbcc7e:41421 in memory (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.226+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.4:46559 in memory (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.226+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.241+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 016737cbcc7e:41421 in memory (size: 24.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.245+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.4:46559 in memory (size: 24.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.261+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 13) in 52 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:40.262+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool
[2025-05-06T12:58:40.263+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0) finished in 0.070 s
[2025-05-06T12:58:40.263+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:40.263+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:40.263+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:40.263+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:40.267+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:40.281+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:40.282+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:40.283+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Final stage: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:40.283+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
[2025-05-06T12:58:40.283+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:40.283+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[44] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:40.284+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-06T12:58:40.285+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-06T12:58:40.285+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.286+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:40.286+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[44] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:40.287+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-05-06T12:58:40.287+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 14) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:40.297+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.301+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.4:47760
[2025-05-06T12:58:40.311+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 14) in 24 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:40.311+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.028 s
[2025-05-06T12:58:40.311+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:40.312+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-05-06T12:58:40.312+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
[2025-05-06T12:58:40.313+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.031983 s
[2025-05-06T12:58:40.327+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.330+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.333+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T12:58:40.340+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.342+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 432.2 MiB)
[2025-05-06T12:58:40.343+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.344+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 016737cbcc7e:41421 (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.344+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 16 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:40.350+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:40.370+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Registering RDD 47 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2025-05-06T12:58:40.370+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Got map stage job 15 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:40.371+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:40.371+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2025-05-06T12:58:40.371+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:40.372+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:40.378+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 14.8 KiB, free 432.2 MiB)
[2025-05-06T12:58:40.378+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 432.2 MiB)
[2025-05-06T12:58:40.379+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 016737cbcc7e:41421 (size: 7.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.379+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:40.380+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:40.380+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2025-05-06T12:58:40.381+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 15) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:40.391+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.4:46559 (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.402+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.4:46559 (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.461+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 15) in 80 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:40.461+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-05-06T12:58:40.461+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0.088 s
[2025-05-06T12:58:40.461+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:40.462+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:40.462+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:40.462+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:40.479+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T12:58:40.479+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Got job 16 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:40.480+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:40.480+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
[2025-05-06T12:58:40.480+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:40.480+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:40.482+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 11.0 KiB, free 432.2 MiB)
[2025-05-06T12:58:40.491+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 432.2 MiB)
[2025-05-06T12:58:40.493+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 016737cbcc7e:41421 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.495+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:40.495+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 016737cbcc7e:41421 in memory (size: 7.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.497+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:40.497+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
[2025-05-06T12:58:40.498+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 16) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:40.502+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.4:46559 in memory (size: 7.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.517+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.4:46559 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.536+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.18.0.4:47760
[2025-05-06T12:58:40.549+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 16) in 49 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:40.550+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2025-05-06T12:58:40.550+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0.067 s
[2025-05-06T12:58:40.551+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:40.551+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
[2025-05-06T12:58:40.551+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Job 16 finished: count at NativeMethodAccessorImpl.java:0, took 0.070309 s
[2025-05-06T12:58:40.551+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:40,550 [INFO] Создано 1069538 ребер по общим IP-адресам
[2025-05-06T12:58:40.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Registering RDD 57 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2025-05-06T12:58:40.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Got map stage job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:40.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:40.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:40.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:40.712+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:40.717+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 12.8 KiB, free 432.2 MiB)
[2025-05-06T12:58:40.718+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.2 MiB)
[2025-05-06T12:58:40.718+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.719+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:40.719+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:40.719+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
[2025-05-06T12:58:40.720+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 17) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:40.723+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO CodeGenerator: Code generated in 9.926752 ms
[2025-05-06T12:58:40.727+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2025-05-06T12:58:40.728+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Got map stage job 18 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:40.728+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:40.728+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:40.728+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:40.728+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:40.733+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 12.8 KiB, free 432.2 MiB)
[2025-05-06T12:58:40.742+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.2 MiB)
[2025-05-06T12:58:40.743+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.743+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.745+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:40.745+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:40.745+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-05-06T12:58:40.751+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 016737cbcc7e:41421 in memory (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.753+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.4:46559 in memory (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T12:58:40.761+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 016737cbcc7e:41421 in memory (size: 58.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.764+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.4:46559 in memory (size: 58.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.784+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 18) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:40.784+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 17) in 64 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:40.784+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-05-06T12:58:40.784+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0.071 s
[2025-05-06T12:58:40.785+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:40.785+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: running: Set(ShuffleMapStage 32)
[2025-05-06T12:58:40.785+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:40.785+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:40.804+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:40.805+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.830+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:40.831+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Got job 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:40.831+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Final stage: ResultStage 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:40.831+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
[2025-05-06T12:58:40.831+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:40.835+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[62] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:40.838+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-06T12:58:40.843+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-06T12:58:40.846+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.846+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:40.853+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[62] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:40.853+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
[2025-05-06T12:58:40.862+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 19) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:40.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 18) in 80 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:40.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-05-06T12:58:40.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0) finished in 0.134 s
[2025-05-06T12:58:40.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:40.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: running: Set(ResultStage 34)
[2025-05-06T12:58:40.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:40.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:40.880+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:40.898+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.906+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:40.909+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Got job 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:40.910+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Final stage: ResultStage 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:40.910+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-05-06T12:58:40.911+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:40.911+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.18.0.4:47760
[2025-05-06T12:58:40.916+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:40.917+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.2 KiB, free 434.3 MiB)
[2025-05-06T12:58:40.921+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.3 MiB)
[2025-05-06T12:58:40.922+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.922+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:40.923+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:40.924+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-05-06T12:58:40.937+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 20) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:40.938+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 19) in 77 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:40.938+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool
[2025-05-06T12:58:40.941+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: ResultStage 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.104 s
[2025-05-06T12:58:40.941+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:40.944+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
[2025-05-06T12:58:40.945+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO DAGScheduler: Job 19 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.111338 s
[2025-05-06T12:58:40.953+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T12:58:40.957+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 432.3 MiB)
[2025-05-06T12:58:40.959+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 016737cbcc7e:41421 (size: 24.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.965+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO SparkContext: Created broadcast 23 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:40.969+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:40.976+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.18.0.4:47760
[2025-05-06T12:58:40.999+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:41.000+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:40 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:41.012+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 20) in 75 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:41.014+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-05-06T12:58:41.015+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: ResultStage 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.098 s
[2025-05-06T12:58:41.015+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:41.017+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-05-06T12:58:41.018+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:41.019+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: Job 20 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.111744 s
[2025-05-06T12:58:41.020+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:41.041+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:41.042+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:41.043+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T12:58:41.050+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 430.1 MiB)
[2025-05-06T12:58:41.051+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 016737cbcc7e:41421 (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:41.052+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO SparkContext: Created broadcast 24 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:41.078+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:41.098+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO CodeGenerator: Code generated in 16.268943 ms
[2025-05-06T12:58:41.112+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO CodeGenerator: Code generated in 8.477617 ms
[2025-05-06T12:58:41.130+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO CodeGenerator: Code generated in 11.994699 ms
[2025-05-06T12:58:41.150+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO CodeGenerator: Code generated in 10.882547 ms
[2025-05-06T12:58:41.181+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: Registering RDD 77 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 11
[2025-05-06T12:58:41.182+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: Got map stage job 21 (count at NativeMethodAccessorImpl.java:0) with 21 output partitions
[2025-05-06T12:58:41.182+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:41.182+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37, ShuffleMapStage 38)
[2025-05-06T12:58:41.182+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:41.184+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:41.191+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 52.5 KiB, free 430.1 MiB)
[2025-05-06T12:58:41.193+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 430.0 MiB)
[2025-05-06T12:58:41.193+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 016737cbcc7e:41421 (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T12:58:41.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:41.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO DAGScheduler: Submitting 21 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-06T12:58:41.195+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSchedulerImpl: Adding task set 39.0 with 21 tasks resource profile 0
[2025-05-06T12:58:41.197+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 21) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.214+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.4:46559 (size: 21.6 KiB, free: 434.4 MiB)
[2025-05-06T12:58:41.263+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.18.0.4:47760
[2025-05-06T12:58:41.279+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.4:46559 (size: 24.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:41.350+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 22) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.351+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 21) in 155 ms on 172.18.0.4 (executor 0) (1/21)
[2025-05-06T12:58:41.395+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 23) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.395+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 22) in 45 ms on 172.18.0.4 (executor 0) (2/21)
[2025-05-06T12:58:41.459+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 4.0 in stage 39.0 (TID 24) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.460+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 23) in 64 ms on 172.18.0.4 (executor 0) (3/21)
[2025-05-06T12:58:41.486+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 5.0 in stage 39.0 (TID 25) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.489+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 4.0 in stage 39.0 (TID 24) in 30 ms on 172.18.0.4 (executor 0) (4/21)
[2025-05-06T12:58:41.510+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 6.0 in stage 39.0 (TID 26) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.513+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 5.0 in stage 39.0 (TID 25) in 27 ms on 172.18.0.4 (executor 0) (5/21)
[2025-05-06T12:58:41.544+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 7.0 in stage 39.0 (TID 27) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.545+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 6.0 in stage 39.0 (TID 26) in 35 ms on 172.18.0.4 (executor 0) (6/21)
[2025-05-06T12:58:41.703+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 8.0 in stage 39.0 (TID 28) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.704+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 7.0 in stage 39.0 (TID 27) in 163 ms on 172.18.0.4 (executor 0) (7/21)
[2025-05-06T12:58:41.787+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 9.0 in stage 39.0 (TID 29) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.789+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 8.0 in stage 39.0 (TID 28) in 86 ms on 172.18.0.4 (executor 0) (8/21)
[2025-05-06T12:58:41.852+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 10.0 in stage 39.0 (TID 30) (172.18.0.4, executor 0, partition 10, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.853+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 9.0 in stage 39.0 (TID 29) in 65 ms on 172.18.0.4 (executor 0) (9/21)
[2025-05-06T12:58:41.938+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Starting task 11.0 in stage 39.0 (TID 31) (172.18.0.4, executor 0, partition 11, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:41.939+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO TaskSetManager: Finished task 10.0 in stage 39.0 (TID 30) in 86 ms on 172.18.0.4 (executor 0) (10/21)
[2025-05-06T12:58:41.967+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:41 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.4:46559 (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:42.019+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 12.0 in stage 39.0 (TID 32) (172.18.0.4, executor 0, partition 12, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.019+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 11.0 in stage 39.0 (TID 31) in 82 ms on 172.18.0.4 (executor 0) (11/21)
[2025-05-06T12:58:42.045+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 13.0 in stage 39.0 (TID 33) (172.18.0.4, executor 0, partition 13, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.046+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 12.0 in stage 39.0 (TID 32) in 27 ms on 172.18.0.4 (executor 0) (12/21)
[2025-05-06T12:58:42.068+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 14.0 in stage 39.0 (TID 34) (172.18.0.4, executor 0, partition 14, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.068+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 13.0 in stage 39.0 (TID 33) in 23 ms on 172.18.0.4 (executor 0) (13/21)
[2025-05-06T12:58:42.090+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 15.0 in stage 39.0 (TID 35) (172.18.0.4, executor 0, partition 15, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.091+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 14.0 in stage 39.0 (TID 34) in 23 ms on 172.18.0.4 (executor 0) (14/21)
[2025-05-06T12:58:42.119+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 16.0 in stage 39.0 (TID 36) (172.18.0.4, executor 0, partition 16, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.120+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 15.0 in stage 39.0 (TID 35) in 31 ms on 172.18.0.4 (executor 0) (15/21)
[2025-05-06T12:58:42.140+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 17.0 in stage 39.0 (TID 37) (172.18.0.4, executor 0, partition 17, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.140+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 16.0 in stage 39.0 (TID 36) in 21 ms on 172.18.0.4 (executor 0) (16/21)
[2025-05-06T12:58:42.157+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 18.0 in stage 39.0 (TID 38) (172.18.0.4, executor 0, partition 18, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.158+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 17.0 in stage 39.0 (TID 37) in 18 ms on 172.18.0.4 (executor 0) (17/21)
[2025-05-06T12:58:42.369+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 19.0 in stage 39.0 (TID 39) (172.18.0.4, executor 0, partition 19, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.369+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 18.0 in stage 39.0 (TID 38) in 212 ms on 172.18.0.4 (executor 0) (18/21)
[2025-05-06T12:58:42.387+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 20.0 in stage 39.0 (TID 40) (172.18.0.4, executor 0, partition 20, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.387+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 19.0 in stage 39.0 (TID 39) in 18 ms on 172.18.0.4 (executor 0) (19/21)
[2025-05-06T12:58:42.644+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.644+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 20.0 in stage 39.0 (TID 40) in 258 ms on 172.18.0.4 (executor 0) (20/21)
[2025-05-06T12:58:42.677+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 34 ms on 172.18.0.4 (executor 0) (21/21)
[2025-05-06T12:58:42.677+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-05-06T12:58:42.677+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 1.490 s
[2025-05-06T12:58:42.678+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:42.678+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:42.678+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:42.678+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:42.681+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 2502111, minimum partition size: 1048576
[2025-05-06T12:58:42.688+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:42.701+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO CodeGenerator: Code generated in 11.102056 ms
[2025-05-06T12:58:42.706+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: Registering RDD 80 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 12
[2025-05-06T12:58:42.706+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-05-06T12:58:42.706+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:42.706+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
[2025-05-06T12:58:42.706+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:42.707+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[80] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:42.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 49.4 KiB, free 430.0 MiB)
[2025-05-06T12:58:42.712+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 430.0 MiB)
[2025-05-06T12:58:42.712+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 016737cbcc7e:41421 (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:42.713+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:42.713+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[80] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-06T12:58:42.713+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks resource profile 0
[2025-05-06T12:58:42.714+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 42) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.724+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.4:46559 (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:42.729+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.18.0.4:47760
[2025-05-06T12:58:42.895+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 43) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:42.896+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:42 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 42) in 181 ms on 172.18.0.4 (executor 0) (1/2)
[2025-05-06T12:58:43.011+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 43) in 116 ms on 172.18.0.4 (executor 0) (2/2)
[2025-05-06T12:58:43.011+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-05-06T12:58:43.012+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0) finished in 0.303 s
[2025-05-06T12:58:43.012+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:43.012+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:43.012+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:43.012+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:43.028+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO CodeGenerator: Code generated in 7.384587 ms
[2025-05-06T12:58:43.036+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T12:58:43.037+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T12:58:43.037+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Final stage: ResultStage 48 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T12:58:43.037+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-05-06T12:58:43.037+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:43.037+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[83] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T12:58:43.039+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 11.0 KiB, free 430.0 MiB)
[2025-05-06T12:58:43.047+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 430.0 MiB)
[2025-05-06T12:58:43.048+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 016737cbcc7e:41421 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.049+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 016737cbcc7e:41421 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.049+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:43.050+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[83] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:43.050+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-05-06T12:58:43.051+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 44) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:43.054+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.18.0.4:46559 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.063+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 016737cbcc7e:41421 in memory (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.064+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.4:46559 in memory (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.065+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.18.0.4:46559 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.069+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.071+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.18.0.4:47760
[2025-05-06T12:58:43.071+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.097+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 44) in 46 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:43.098+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-05-06T12:58:43.100+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: ResultStage 48 (count at NativeMethodAccessorImpl.java:0) finished in 0.059 s
[2025-05-06T12:58:43.100+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:43.101+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-05-06T12:58:43.101+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0.065045 s
[2025-05-06T12:58:43.103+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:43,102 [INFO] Всего создано 410196 уникальных ребер
[2025-05-06T12:58:43.103+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:43,103 [INFO] Создаем граф
[2025-05-06T12:58:43.426+0000] {spark_submit.py:571} INFO - 2025-05-06 12:58:43,426 [INFO] Запускаем алгоритм обнаружения сообществ
[2025-05-06T12:58:43.669+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:43.674+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Registering RDD 87 (rdd at GraphFrame.scala:187) as input to shuffle 13
[2025-05-06T12:58:43.674+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Got map stage job 24 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-06T12:58:43.674+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Final stage: ShuffleMapStage 49 (rdd at GraphFrame.scala:187)
[2025-05-06T12:58:43.674+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:43.674+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:43.675+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[87] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-06T12:58:43.677+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 19.9 KiB, free 430.1 MiB)
[2025-05-06T12:58:43.678+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 430.1 MiB)
[2025-05-06T12:58:43.678+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 016737cbcc7e:41421 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.679+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:43.679+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[87] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:43.680+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
[2025-05-06T12:58:43.681+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 45) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:43.688+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.4:46559 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.710+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 45) in 30 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:43.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool
[2025-05-06T12:58:43.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: ShuffleMapStage 49 (rdd at GraphFrame.scala:187) finished in 0.036 s
[2025-05-06T12:58:43.712+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:43.712+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:43.712+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:43.712+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:43.718+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:43.722+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:43.740+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO CodeGenerator: Code generated in 14.09819 ms
[2025-05-06T12:58:43.754+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:43.756+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Got job 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:43.757+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Final stage: ResultStage 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:43.757+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
[2025-05-06T12:58:43.757+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:43.757+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[90] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:43.760+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 32.6 KiB, free 430.1 MiB)
[2025-05-06T12:58:43.764+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 430.0 MiB)
[2025-05-06T12:58:43.765+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 016737cbcc7e:41421 (size: 15.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.765+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:43.765+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[90] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:43.765+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
[2025-05-06T12:58:43.765+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 46) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:43.774+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.4:46559 (size: 15.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.781+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.18.0.4:47760
[2025-05-06T12:58:43.802+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 46) in 38 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:43.802+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool
[2025-05-06T12:58:43.802+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: ResultStage 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.044 s
[2025-05-06T12:58:43.802+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:43.802+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
[2025-05-06T12:58:43.803+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DAGScheduler: Job 25 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.048447 s
[2025-05-06T12:58:43.811+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO CodeGenerator: Code generated in 5.825437 ms
[2025-05-06T12:58:43.817+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 2.1 MiB, free 428.0 MiB)
[2025-05-06T12:58:43.826+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 016737cbcc7e:41421 in memory (size: 24.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.827+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 430.0 MiB)
[2025-05-06T12:58:43.827+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 016737cbcc7e:41421 (size: 27.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.828+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO SparkContext: Created broadcast 30 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:43.830+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.4:46559 in memory (size: 24.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.836+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 016737cbcc7e:41421 in memory (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.837+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.18.0.4:46559 in memory (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.842+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 016737cbcc7e:41421 in memory (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:43.846+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.4:46559 in memory (size: 58.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:43.855+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 016737cbcc7e:41421 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T12:58:43.855+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.18.0.4:46559 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T12:58:43.872+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 016737cbcc7e:41421 in memory (size: 15.3 KiB, free: 434.4 MiB)
[2025-05-06T12:58:43.873+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO CodeGenerator: Code generated in 20.479853 ms
[2025-05-06T12:58:43.876+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.18.0.4:46559 in memory (size: 15.3 KiB, free: 434.4 MiB)
[2025-05-06T12:58:43.887+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:43.888+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:43.888+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:43.925+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO CodeGenerator: Code generated in 27.840236 ms
[2025-05-06T12:58:43.926+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:43.960+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:43 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#305 - id.nullCount#304) > 0)
[2025-05-06T12:58:44.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Registering RDD 111 (collect at GraphFrame.scala:574) as input to shuffle 15
[2025-05-06T12:58:44.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Got map stage job 26 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-06T12:58:44.195+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Final stage: ShuffleMapStage 52 (collect at GraphFrame.scala:574)
[2025-05-06T12:58:44.195+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:44.195+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:44.196+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[111] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T12:58:44.198+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 12.8 KiB, free 432.3 MiB)
[2025-05-06T12:58:44.199+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.3 MiB)
[2025-05-06T12:58:44.200+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.200+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:44.200+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[111] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:44.200+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
[2025-05-06T12:58:44.201+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Registering RDD 113 (collect at GraphFrame.scala:574) as input to shuffle 16
[2025-05-06T12:58:44.201+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 47) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.202+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Got map stage job 27 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-06T12:58:44.202+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Final stage: ShuffleMapStage 53 (collect at GraphFrame.scala:574)
[2025-05-06T12:58:44.202+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:44.202+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:44.202+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[113] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T12:58:44.205+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 12.8 KiB, free 432.3 MiB)
[2025-05-06T12:58:44.206+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.3 MiB)
[2025-05-06T12:58:44.206+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.207+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:44.207+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[113] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:44.207+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-05-06T12:58:44.211+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.229+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 48) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.230+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 47) in 28 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:44.230+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool
[2025-05-06T12:58:44.230+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: ShuffleMapStage 52 (collect at GraphFrame.scala:574) finished in 0.033 s
[2025-05-06T12:58:44.231+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:44.231+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: running: Set(ShuffleMapStage 53)
[2025-05-06T12:58:44.231+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:44.231+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:44.238+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.243+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:44.266+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:44.268+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:44.268+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:44.269+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
[2025-05-06T12:58:44.269+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:44.269+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[116] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:44.271+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.2 KiB, free 432.3 MiB)
[2025-05-06T12:58:44.271+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 48) in 42 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:44.271+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-05-06T12:58:44.282+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.3 MiB)
[2025-05-06T12:58:44.283+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.284+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:44.284+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[116] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:44.284+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-05-06T12:58:44.284+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: ShuffleMapStage 53 (collect at GraphFrame.scala:574) finished in 0.082 s
[2025-05-06T12:58:44.285+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:44.285+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: running: Set(ResultStage 55)
[2025-05-06T12:58:44.285+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:44.285+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:44.292+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.292+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 49) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.293+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.305+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:44.335+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.341+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:44.342+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:44.342+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Final stage: ResultStage 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:44.342+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-05-06T12:58:44.342+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:44.344+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[119] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:44.345+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.4:47760
[2025-05-06T12:58:44.348+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.2 KiB, free 432.3 MiB)
[2025-05-06T12:58:44.350+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.3 MiB)
[2025-05-06T12:58:44.351+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.353+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:44.354+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[119] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:44.354+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-05-06T12:58:44.357+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 50) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.358+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 49) in 70 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:44.358+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-05-06T12:58:44.358+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.089 s
[2025-05-06T12:58:44.358+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:44.358+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-05-06T12:58:44.359+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.092123 s
[2025-05-06T12:58:44.366+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T12:58:44.369+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 430.2 MiB)
[2025-05-06T12:58:44.370+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 016737cbcc7e:41421 (size: 24.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:44.370+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:44.374+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.381+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.18.0.4:47760
[2025-05-06T12:58:44.389+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 50) in 32 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:44.390+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-05-06T12:58:44.390+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: ResultStage 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.044 s
[2025-05-06T12:58:44.390+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:44.390+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-05-06T12:58:44.390+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.049087 s
[2025-05-06T12:58:44.398+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 2.1 MiB, free 428.1 MiB)
[2025-05-06T12:58:44.409+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:44.410+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 428.0 MiB)
[2025-05-06T12:58:44.410+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 016737cbcc7e:41421 (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:44.411+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO SparkContext: Created broadcast 36 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:44.416+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.424+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:44.427+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.434+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:44.436+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.453+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:44.485+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Registering RDD 130 (collect at GraphFrame.scala:574) as input to shuffle 17
[2025-05-06T12:58:44.486+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Got map stage job 30 (collect at GraphFrame.scala:574) with 21 output partitions
[2025-05-06T12:58:44.486+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (collect at GraphFrame.scala:574)
[2025-05-06T12:58:44.486+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58, ShuffleMapStage 59)
[2025-05-06T12:58:44.486+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:44.489+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[130] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T12:58:44.493+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 52.5 KiB, free 428.0 MiB)
[2025-05-06T12:58:44.494+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 428.0 MiB)
[2025-05-06T12:58:44.494+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 016737cbcc7e:41421 (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T12:58:44.495+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:44.496+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO DAGScheduler: Submitting 21 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[130] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-06T12:58:44.496+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSchedulerImpl: Adding task set 60.0 with 21 tasks resource profile 0
[2025-05-06T12:58:44.498+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 51) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.510+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.18.0.4:46559 (size: 21.6 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.516+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.4:47760
[2025-05-06T12:58:44.527+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.4:46559 (size: 24.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:44.562+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 52) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.564+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 51) in 65 ms on 172.18.0.4 (executor 0) (1/21)
[2025-05-06T12:58:44.599+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 53) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.599+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 52) in 39 ms on 172.18.0.4 (executor 0) (2/21)
[2025-05-06T12:58:44.640+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 54) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.640+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 53) in 42 ms on 172.18.0.4 (executor 0) (3/21)
[2025-05-06T12:58:44.669+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 5.0 in stage 60.0 (TID 55) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.670+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 54) in 30 ms on 172.18.0.4 (executor 0) (4/21)
[2025-05-06T12:58:44.690+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 6.0 in stage 60.0 (TID 56) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.690+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 5.0 in stage 60.0 (TID 55) in 22 ms on 172.18.0.4 (executor 0) (5/21)
[2025-05-06T12:58:44.718+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 7.0 in stage 60.0 (TID 57) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.718+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 6.0 in stage 60.0 (TID 56) in 27 ms on 172.18.0.4 (executor 0) (6/21)
[2025-05-06T12:58:44.775+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 8.0 in stage 60.0 (TID 58) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.776+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 7.0 in stage 60.0 (TID 57) in 60 ms on 172.18.0.4 (executor 0) (7/21)
[2025-05-06T12:58:44.820+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 9.0 in stage 60.0 (TID 59) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.821+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 8.0 in stage 60.0 (TID 58) in 45 ms on 172.18.0.4 (executor 0) (8/21)
[2025-05-06T12:58:44.860+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 10.0 in stage 60.0 (TID 60) (172.18.0.4, executor 0, partition 10, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.861+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 9.0 in stage 60.0 (TID 59) in 41 ms on 172.18.0.4 (executor 0) (9/21)
[2025-05-06T12:58:44.915+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 11.0 in stage 60.0 (TID 61) (172.18.0.4, executor 0, partition 11, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.916+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 10.0 in stage 60.0 (TID 60) in 56 ms on 172.18.0.4 (executor 0) (10/21)
[2025-05-06T12:58:44.932+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.4:46559 (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:44.977+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 12.0 in stage 60.0 (TID 62) (172.18.0.4, executor 0, partition 12, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.977+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 11.0 in stage 60.0 (TID 61) in 62 ms on 172.18.0.4 (executor 0) (11/21)
[2025-05-06T12:58:44.994+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Starting task 13.0 in stage 60.0 (TID 63) (172.18.0.4, executor 0, partition 13, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:44.994+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:44 INFO TaskSetManager: Finished task 12.0 in stage 60.0 (TID 62) in 18 ms on 172.18.0.4 (executor 0) (12/21)
[2025-05-06T12:58:45.009+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 14.0 in stage 60.0 (TID 64) (172.18.0.4, executor 0, partition 14, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.009+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 13.0 in stage 60.0 (TID 63) in 16 ms on 172.18.0.4 (executor 0) (13/21)
[2025-05-06T12:58:45.024+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 15.0 in stage 60.0 (TID 65) (172.18.0.4, executor 0, partition 15, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.024+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 14.0 in stage 60.0 (TID 64) in 15 ms on 172.18.0.4 (executor 0) (14/21)
[2025-05-06T12:58:45.039+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 16.0 in stage 60.0 (TID 66) (172.18.0.4, executor 0, partition 16, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.039+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 15.0 in stage 60.0 (TID 65) in 16 ms on 172.18.0.4 (executor 0) (15/21)
[2025-05-06T12:58:45.050+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 17.0 in stage 60.0 (TID 67) (172.18.0.4, executor 0, partition 17, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.051+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 16.0 in stage 60.0 (TID 66) in 13 ms on 172.18.0.4 (executor 0) (16/21)
[2025-05-06T12:58:45.064+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 18.0 in stage 60.0 (TID 68) (172.18.0.4, executor 0, partition 18, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.065+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 17.0 in stage 60.0 (TID 67) in 14 ms on 172.18.0.4 (executor 0) (17/21)
[2025-05-06T12:58:45.245+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 19.0 in stage 60.0 (TID 69) (172.18.0.4, executor 0, partition 19, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.245+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 18.0 in stage 60.0 (TID 68) in 182 ms on 172.18.0.4 (executor 0) (18/21)
[2025-05-06T12:58:45.260+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 20.0 in stage 60.0 (TID 70) (172.18.0.4, executor 0, partition 20, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.261+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 19.0 in stage 60.0 (TID 69) in 16 ms on 172.18.0.4 (executor 0) (19/21)
[2025-05-06T12:58:45.504+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 71) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.504+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 20.0 in stage 60.0 (TID 70) in 244 ms on 172.18.0.4 (executor 0) (20/21)
[2025-05-06T12:58:45.528+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 71) in 24 ms on 172.18.0.4 (executor 0) (21/21)
[2025-05-06T12:58:45.529+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-06T12:58:45.529+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: ShuffleMapStage 60 (collect at GraphFrame.scala:574) finished in 1.038 s
[2025-05-06T12:58:45.529+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:45.530+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:45.530+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:45.530+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:45.534+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 2502111, minimum partition size: 1048576
[2025-05-06T12:58:45.548+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:45.597+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO CodeGenerator: Code generated in 39.004035 ms
[2025-05-06T12:58:45.611+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: Registering RDD 133 (collect at GraphFrame.scala:574) as input to shuffle 18
[2025-05-06T12:58:45.611+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: Got map stage job 31 (collect at GraphFrame.scala:574) with 2 output partitions
[2025-05-06T12:58:45.611+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: Final stage: ShuffleMapStage 64 (collect at GraphFrame.scala:574)
[2025-05-06T12:58:45.611+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
[2025-05-06T12:58:45.611+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:45.611+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[133] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T12:58:45.615+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 59.5 KiB, free 427.9 MiB)
[2025-05-06T12:58:45.616+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 427.9 MiB)
[2025-05-06T12:58:45.616+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 016737cbcc7e:41421 (size: 24.8 KiB, free: 434.2 MiB)
[2025-05-06T12:58:45.617+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:45.617+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[133] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-06T12:58:45.617+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks resource profile 0
[2025-05-06T12:58:45.618+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 72) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.626+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.18.0.4:46559 (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:45.641+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.18.0.4:47760
[2025-05-06T12:58:45.951+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 73) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:45.952+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:45 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 72) in 334 ms on 172.18.0.4 (executor 0) (1/2)
[2025-05-06T12:58:46.125+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 73) in 174 ms on 172.18.0.4 (executor 0) (2/2)
[2025-05-06T12:58:46.126+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-05-06T12:58:46.126+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: ShuffleMapStage 64 (collect at GraphFrame.scala:574) finished in 0.514 s
[2025-05-06T12:58:46.126+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:46.126+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:46.126+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:46.126+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:46.128+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:46.137+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:46.151+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO CodeGenerator: Code generated in 8.99753 ms
[2025-05-06T12:58:46.165+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Starting job: collect at GraphFrame.scala:574
[2025-05-06T12:58:46.166+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Got job 32 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-06T12:58:46.167+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Final stage: ResultStage 69 (collect at GraphFrame.scala:574)
[2025-05-06T12:58:46.167+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
[2025-05-06T12:58:46.167+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:46.167+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[136] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T12:58:46.170+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 54.8 KiB, free 427.8 MiB)
[2025-05-06T12:58:46.179+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 427.8 MiB)
[2025-05-06T12:58:46.180+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 016737cbcc7e:41421 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.180+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 016737cbcc7e:41421 (size: 23.8 KiB, free: 434.2 MiB)
[2025-05-06T12:58:46.182+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:46.182+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[136] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:46.183+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
[2025-05-06T12:58:46.183+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.18.0.4:46559 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.184+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 74) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:46.187+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 016737cbcc7e:41421 in memory (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.188+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.18.0.4:46559 in memory (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.193+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.18.0.4:46559 (size: 23.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.219+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.18.0.4:47760
[2025-05-06T12:58:46.249+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 74) in 66 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:46.250+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-06T12:58:46.250+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: ResultStage 69 (collect at GraphFrame.scala:574) finished in 0.082 s
[2025-05-06T12:58:46.251+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:46.251+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
[2025-05-06T12:58:46.251+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Job 32 finished: collect at GraphFrame.scala:574, took 0.085360 s
[2025-05-06T12:58:46.435+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Registering RDD 145 (rdd at GraphFrame.scala:188) as input to shuffle 19
[2025-05-06T12:58:46.436+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Got map stage job 33 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-06T12:58:46.436+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (rdd at GraphFrame.scala:188)
[2025-05-06T12:58:46.436+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:46.436+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:46.436+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T12:58:46.438+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 12.8 KiB, free 428.0 MiB)
[2025-05-06T12:58:46.439+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:46.439+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 427.9 MiB)
[2025-05-06T12:58:46.440+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.440+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:46.441+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:46.441+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
[2025-05-06T12:58:46.442+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Registering RDD 147 (rdd at GraphFrame.scala:188) as input to shuffle 20
[2025-05-06T12:58:46.442+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Got map stage job 34 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-06T12:58:46.443+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Final stage: ShuffleMapStage 71 (rdd at GraphFrame.scala:188)
[2025-05-06T12:58:46.443+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:46.443+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 75) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:46.443+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:46.443+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[147] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T12:58:46.449+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.8 KiB, free 427.9 MiB)
[2025-05-06T12:58:46.450+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 427.9 MiB)
[2025-05-06T12:58:46.451+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.451+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:46.453+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[147] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:46.454+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0
[2025-05-06T12:58:46.457+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO CodeGenerator: Code generated in 16.288505 ms
[2025-05-06T12:58:46.461+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.464+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Registering RDD 149 (rdd at GraphFrame.scala:188) as input to shuffle 21
[2025-05-06T12:58:46.466+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Got map stage job 35 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-06T12:58:46.468+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Final stage: ShuffleMapStage 72 (rdd at GraphFrame.scala:188)
[2025-05-06T12:58:46.468+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T12:58:46.468+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:46.469+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T12:58:46.469+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 19.9 KiB, free 427.9 MiB)
[2025-05-06T12:58:46.484+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 427.9 MiB)
[2025-05-06T12:58:46.484+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 016737cbcc7e:41421 (size: 9.7 KiB, free: 434.2 MiB)
[2025-05-06T12:58:46.485+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:46.485+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:46.485+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
[2025-05-06T12:58:46.488+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 016737cbcc7e:41421 in memory (size: 24.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.491+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.18.0.4:46559 in memory (size: 24.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.496+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 016737cbcc7e:41421 in memory (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.505+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.18.0.4:46559 in memory (size: 58.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.519+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 016737cbcc7e:41421 in memory (size: 23.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.527+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.18.0.4:46559 in memory (size: 23.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.527+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 76) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:46.527+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 75) in 85 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:46.527+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-05-06T12:58:46.529+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: ShuffleMapStage 70 (rdd at GraphFrame.scala:188) finished in 0.092 s
[2025-05-06T12:58:46.529+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:46.530+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: running: Set(ShuffleMapStage 71, ShuffleMapStage 72)
[2025-05-06T12:58:46.530+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:46.531+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:46.554+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.568+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:46.585+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:46.587+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Got job 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:46.587+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Final stage: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:46.587+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
[2025-05-06T12:58:46.587+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:46.587+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:46.587+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 77) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:46.588+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 76) in 65 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:46.588+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-05-06T12:58:46.588+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.2 KiB, free 432.2 MiB)
[2025-05-06T12:58:46.588+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.2 MiB)
[2025-05-06T12:58:46.589+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.590+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:46.591+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:46.592+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
[2025-05-06T12:58:46.595+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: ShuffleMapStage 71 (rdd at GraphFrame.scala:188) finished in 0.147 s
[2025-05-06T12:58:46.595+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:46.595+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: running: Set(ResultStage 74, ShuffleMapStage 72)
[2025-05-06T12:58:46.595+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:46.595+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:46.616+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.18.0.4:46559 (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.628+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:46.639+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:46.644+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Got job 37 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:46.644+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Final stage: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:46.645+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
[2025-05-06T12:58:46.645+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:46.646+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[155] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:46.646+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 7.2 KiB, free 432.2 MiB)
[2025-05-06T12:58:46.646+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.2 MiB)
[2025-05-06T12:58:46.647+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.647+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:46.648+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[155] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:46.648+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
[2025-05-06T12:58:46.668+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 78) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:46.668+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 77) in 82 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:46.669+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-05-06T12:58:46.669+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: ShuffleMapStage 72 (rdd at GraphFrame.scala:188) finished in 0.207 s
[2025-05-06T12:58:46.669+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:46.670+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: running: Set(ResultStage 74, ResultStage 76)
[2025-05-06T12:58:46.670+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:46.670+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:46.680+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.684+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.18.0.4:47760
[2025-05-06T12:58:46.700+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 016737cbcc7e:41421 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.703+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.18.0.4:46559 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.706+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:46.706+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 79) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:46.707+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 78) in 40 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:46.708+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool
[2025-05-06T12:58:46.708+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.122 s
[2025-05-06T12:58:46.708+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T12:58:46.709+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:46.709+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
[2025-05-06T12:58:46.711+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.716+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Job 36 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.129243 s
[2025-05-06T12:58:46.720+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.722+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.726+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T12:58:46.726+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T12:58:46.727+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.18.0.4:47760
[2025-05-06T12:58:46.727+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 430.2 MiB)
[2025-05-06T12:58:46.729+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 016737cbcc7e:41421 (size: 24.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.730+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.731+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 45 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:46.732+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.742+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 79) in 37 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:46.742+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-05-06T12:58:46.744+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.100 s
[2025-05-06T12:58:46.744+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:46.744+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
[2025-05-06T12:58:46.744+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Job 37 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.105223 s
[2025-05-06T12:58:46.754+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 2.1 MiB, free 428.1 MiB)
[2025-05-06T12:58:46.756+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO CodeGenerator: Code generated in 28.865314 ms
[2025-05-06T12:58:46.769+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 428.0 MiB)
[2025-05-06T12:58:46.770+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 016737cbcc7e:41421 (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.771+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 46 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:46.786+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:46.787+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Got job 38 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T12:58:46.788+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Final stage: ResultStage 78 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T12:58:46.789+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
[2025-05-06T12:58:46.789+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:46.789+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[160] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T12:58:46.793+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 30.8 KiB, free 428.0 MiB)
[2025-05-06T12:58:46.804+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 14.4 KiB, free 428.0 MiB)
[2025-05-06T12:58:46.806+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 016737cbcc7e:41421 (size: 14.4 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.807+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:46.808+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[160] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:46.808+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
[2025-05-06T12:58:46.808+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.812+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.814+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 80) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:46.818+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.819+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.831+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO CodeGenerator: Code generated in 8.641977 ms
[2025-05-06T12:58:46.843+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.860+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.18.0.4:47760
[2025-05-06T12:58:46.871+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO CodeGenerator: Code generated in 28.05033 ms
[2025-05-06T12:58:46.889+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO CodeGenerator: Code generated in 10.688192 ms
[2025-05-06T12:58:46.892+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 80) in 79 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:46.892+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-05-06T12:58:46.893+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: ResultStage 78 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.101 s
[2025-05-06T12:58:46.893+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T12:58:46.893+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
[2025-05-06T12:58:46.893+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Job 38 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.107776 s
[2025-05-06T12:58:46.894+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Registering RDD 169 (rdd at GraphFrame.scala:188) as input to shuffle 22
[2025-05-06T12:58:46.894+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Got map stage job 39 (rdd at GraphFrame.scala:188) with 21 output partitions
[2025-05-06T12:58:46.894+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Final stage: ShuffleMapStage 81 (rdd at GraphFrame.scala:188)
[2025-05-06T12:58:46.894+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-06T12:58:46.894+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:46.894+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[169] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T12:58:46.898+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 2.1 MiB, free 425.9 MiB)
[2025-05-06T12:58:46.900+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 425.9 MiB)
[2025-05-06T12:58:46.900+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 016737cbcc7e:41421 (size: 18.9 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.901+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 48 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T12:58:46.924+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 49.4 KiB, free 425.9 MiB)
[2025-05-06T12:58:46.933+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 20.9 KiB, free 425.8 MiB)
[2025-05-06T12:58:46.934+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 016737cbcc7e:41421 (size: 20.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:46.934+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 016737cbcc7e:41421 in memory (size: 14.4 KiB, free: 434.3 MiB)
[2025-05-06T12:58:46.934+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:46.940+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.18.0.4:46559 in memory (size: 14.4 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.940+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO DAGScheduler: Submitting 21 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[169] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-06T12:58:46.942+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSchedulerImpl: Adding task set 81.0 with 21 tasks resource profile 0
[2025-05-06T12:58:46.942+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 81) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:46.955+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.18.0.4:46559 (size: 20.9 KiB, free: 434.4 MiB)
[2025-05-06T12:58:46.985+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.18.0.4:47760
[2025-05-06T12:58:47.006+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.18.0.4:46559 (size: 24.1 KiB, free: 434.4 MiB)
[2025-05-06T12:58:47.177+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 82) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.177+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 81) in 237 ms on 172.18.0.4 (executor 0) (1/21)
[2025-05-06T12:58:47.266+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 83) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.266+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 82) in 90 ms on 172.18.0.4 (executor 0) (2/21)
[2025-05-06T12:58:47.352+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 84) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.352+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 83) in 87 ms on 172.18.0.4 (executor 0) (3/21)
[2025-05-06T12:58:47.359+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 85) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.360+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 84) in 9 ms on 172.18.0.4 (executor 0) (4/21)
[2025-05-06T12:58:47.367+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 6.0 in stage 81.0 (TID 86) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.368+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 85) in 9 ms on 172.18.0.4 (executor 0) (5/21)
[2025-05-06T12:58:47.389+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 7.0 in stage 81.0 (TID 87) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.389+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 6.0 in stage 81.0 (TID 86) in 22 ms on 172.18.0.4 (executor 0) (6/21)
[2025-05-06T12:58:47.527+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 8.0 in stage 81.0 (TID 88) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.528+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 7.0 in stage 81.0 (TID 87) in 138 ms on 172.18.0.4 (executor 0) (7/21)
[2025-05-06T12:58:47.633+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 9.0 in stage 81.0 (TID 89) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.633+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 8.0 in stage 81.0 (TID 88) in 107 ms on 172.18.0.4 (executor 0) (8/21)
[2025-05-06T12:58:47.733+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 10.0 in stage 81.0 (TID 90) (172.18.0.4, executor 0, partition 10, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.733+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 9.0 in stage 81.0 (TID 89) in 100 ms on 172.18.0.4 (executor 0) (9/21)
[2025-05-06T12:58:47.920+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Starting task 11.0 in stage 81.0 (TID 91) (172.18.0.4, executor 0, partition 11, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:47.921+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO TaskSetManager: Finished task 10.0 in stage 81.0 (TID 90) in 189 ms on 172.18.0.4 (executor 0) (10/21)
[2025-05-06T12:58:47.930+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.18.0.4:47760
[2025-05-06T12:58:47.941+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:47 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.18.0.4:46559 (size: 58.1 KiB, free: 434.3 MiB)
[2025-05-06T12:58:48.024+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Starting task 12.0 in stage 81.0 (TID 92) (172.18.0.4, executor 0, partition 12, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:48.025+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Finished task 11.0 in stage 81.0 (TID 91) in 105 ms on 172.18.0.4 (executor 0) (11/21)
[2025-05-06T12:58:48.046+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Starting task 13.0 in stage 81.0 (TID 93) (172.18.0.4, executor 0, partition 13, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:48.046+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Finished task 12.0 in stage 81.0 (TID 92) in 22 ms on 172.18.0.4 (executor 0) (12/21)
[2025-05-06T12:58:48.066+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Starting task 14.0 in stage 81.0 (TID 94) (172.18.0.4, executor 0, partition 14, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:48.067+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Finished task 13.0 in stage 81.0 (TID 93) in 21 ms on 172.18.0.4 (executor 0) (13/21)
[2025-05-06T12:58:48.083+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Starting task 15.0 in stage 81.0 (TID 95) (172.18.0.4, executor 0, partition 15, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:48.084+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Finished task 14.0 in stage 81.0 (TID 94) in 17 ms on 172.18.0.4 (executor 0) (14/21)
[2025-05-06T12:58:48.105+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Starting task 16.0 in stage 81.0 (TID 96) (172.18.0.4, executor 0, partition 16, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:48.106+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Finished task 15.0 in stage 81.0 (TID 95) in 23 ms on 172.18.0.4 (executor 0) (15/21)
[2025-05-06T12:58:48.121+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Starting task 17.0 in stage 81.0 (TID 97) (172.18.0.4, executor 0, partition 17, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:48.121+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Finished task 16.0 in stage 81.0 (TID 96) in 16 ms on 172.18.0.4 (executor 0) (16/21)
[2025-05-06T12:58:48.145+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Starting task 18.0 in stage 81.0 (TID 98) (172.18.0.4, executor 0, partition 18, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:48.145+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Finished task 17.0 in stage 81.0 (TID 97) in 25 ms on 172.18.0.4 (executor 0) (17/21)
[2025-05-06T12:58:48.755+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Starting task 19.0 in stage 81.0 (TID 99) (172.18.0.4, executor 0, partition 19, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:48.756+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Finished task 18.0 in stage 81.0 (TID 98) in 611 ms on 172.18.0.4 (executor 0) (18/21)
[2025-05-06T12:58:48.771+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Starting task 20.0 in stage 81.0 (TID 100) (172.18.0.4, executor 0, partition 20, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:48.772+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:48 INFO TaskSetManager: Finished task 19.0 in stage 81.0 (TID 99) in 18 ms on 172.18.0.4 (executor 0) (19/21)
[2025-05-06T12:58:49.569+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 101) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:49.569+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO TaskSetManager: Finished task 20.0 in stage 81.0 (TID 100) in 798 ms on 172.18.0.4 (executor 0) (20/21)
[2025-05-06T12:58:49.609+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 101) in 41 ms on 172.18.0.4 (executor 0) (21/21)
[2025-05-06T12:58:49.609+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-05-06T12:58:49.609+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: ShuffleMapStage 81 (rdd at GraphFrame.scala:188) finished in 2.713 s
[2025-05-06T12:58:49.609+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:49.609+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:49.610+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:49.610+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:49.615+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 3162157, minimum partition size: 1048576
[2025-05-06T12:58:49.628+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO CodeGenerator: Code generated in 5.582372 ms
[2025-05-06T12:58:49.632+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: Registering RDD 173 (rdd at GraphFrame.scala:188) as input to shuffle 23
[2025-05-06T12:58:49.632+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: Got map stage job 40 (rdd at GraphFrame.scala:188) with 2 output partitions
[2025-05-06T12:58:49.632+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: Final stage: ShuffleMapStage 85 (rdd at GraphFrame.scala:188)
[2025-05-06T12:58:49.632+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
[2025-05-06T12:58:49.632+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: Missing parents: List()
[2025-05-06T12:58:49.632+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[173] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T12:58:49.642+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 50.0 KiB, free 425.8 MiB)
[2025-05-06T12:58:49.643+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 425.8 MiB)
[2025-05-06T12:58:49.643+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 016737cbcc7e:41421 (size: 21.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:49.644+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:49.644+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[173] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-06T12:58:49.644+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks resource profile 0
[2025-05-06T12:58:49.644+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 102) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:49.652+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.18.0.4:46559 (size: 21.9 KiB, free: 434.3 MiB)
[2025-05-06T12:58:49.657+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.18.0.4:47760
[2025-05-06T12:58:50.359+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 103) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:50.359+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 102) in 715 ms on 172.18.0.4 (executor 0) (1/2)
[2025-05-06T12:58:50.863+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 103) in 504 ms on 172.18.0.4 (executor 0) (2/2)
[2025-05-06T12:58:50.863+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool
[2025-05-06T12:58:50.863+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: ShuffleMapStage 85 (rdd at GraphFrame.scala:188) finished in 1.230 s
[2025-05-06T12:58:50.863+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:50.863+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:50.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:50.864+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:50.894+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO CodeGenerator: Code generated in 12.941357 ms
[2025-05-06T12:58:50.902+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO CodeGenerator: Code generated in 6.701083 ms
[2025-05-06T12:58:50.925+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO CodeGenerator: Code generated in 10.744085 ms
[2025-05-06T12:58:50.926+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#519 - id.nullCount#518) > 0)
[2025-05-06T12:58:50.952+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: Registering RDD 92 (rdd at GraphFrame.scala:187) as input to shuffle 14
[2025-05-06T12:58:50.953+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: Registering RDD 182 (rdd at GraphFrame.scala:188) as input to shuffle 24
[2025-05-06T12:58:50.953+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: Got map stage job 41 (rdd at GraphFrame.scala:188) with 10 output partitions
[2025-05-06T12:58:50.953+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: Final stage: ShuffleMapStage 91 (rdd at GraphFrame.scala:188)
[2025-05-06T12:58:50.953+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89, ShuffleMapStage 90)
[2025-05-06T12:58:50.955+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 89)
[2025-05-06T12:58:50.956+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[92] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-06T12:58:50.957+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 19.7 KiB, free 425.8 MiB)
[2025-05-06T12:58:50.968+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 425.8 MiB)
[2025-05-06T12:58:50.969+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 016737cbcc7e:41421 (size: 9.6 KiB, free: 434.2 MiB)
[2025-05-06T12:58:50.970+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 016737cbcc7e:41421 in memory (size: 20.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:50.970+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:50.970+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[92] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-06T12:58:50.970+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
[2025-05-06T12:58:50.971+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.18.0.4:46559 in memory (size: 20.9 KiB, free: 434.3 MiB)
[2025-05-06T12:58:50.972+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 104) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:50.975+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 016737cbcc7e:41421 in memory (size: 21.9 KiB, free: 434.3 MiB)
[2025-05-06T12:58:50.977+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.18.0.4:46559 in memory (size: 21.9 KiB, free: 434.3 MiB)
[2025-05-06T12:58:50.981+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:50 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.18.0.4:46559 (size: 9.6 KiB, free: 434.3 MiB)
[2025-05-06T12:58:51.019+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 104) in 47 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T12:58:51.021+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool
[2025-05-06T12:58:51.023+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO DAGScheduler: ShuffleMapStage 89 (rdd at GraphFrame.scala:187) finished in 0.064 s
[2025-05-06T12:58:51.027+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:51.028+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:51.028+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 91)
[2025-05-06T12:58:51.029+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:51.029+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[182] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T12:58:51.029+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 101.2 KiB, free 425.8 MiB)
[2025-05-06T12:58:51.030+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 40.3 KiB, free 425.8 MiB)
[2025-05-06T12:58:51.030+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 016737cbcc7e:41421 (size: 40.3 KiB, free: 434.2 MiB)
[2025-05-06T12:58:51.031+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:51.031+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[182] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T12:58:51.031+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSchedulerImpl: Adding task set 91.0 with 10 tasks resource profile 0
[2025-05-06T12:58:51.034+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 105) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:51.042+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.18.0.4:46559 (size: 40.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:51.103+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.18.0.4:47760
[2025-05-06T12:58:51.127+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.18.0.4:47760
[2025-05-06T12:58:51.141+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 016737cbcc7e:41421 in memory (size: 9.6 KiB, free: 434.2 MiB)
[2025-05-06T12:58:51.142+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.18.0.4:46559 in memory (size: 9.6 KiB, free: 434.3 MiB)
[2025-05-06T12:58:51.211+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added rdd_96_0 in memory on 172.18.0.4:46559 (size: 1992.0 B, free: 434.3 MiB)
[2025-05-06T12:58:51.270+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.4:46559 (size: 18.9 KiB, free: 434.3 MiB)
[2025-05-06T12:58:51.401+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 106) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:51.401+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 105) in 369 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T12:58:51.422+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added rdd_96_1 in memory on 172.18.0.4:46559 (size: 2.4 KiB, free: 434.3 MiB)
[2025-05-06T12:58:51.504+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 107) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:51.505+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 106) in 105 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T12:58:51.524+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added rdd_96_2 in memory on 172.18.0.4:46559 (size: 2.2 KiB, free: 434.3 MiB)
[2025-05-06T12:58:51.609+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 108) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:51.609+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 107) in 105 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T12:58:51.632+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added rdd_96_3 in memory on 172.18.0.4:46559 (size: 2.2 KiB, free: 434.3 MiB)
[2025-05-06T12:58:51.703+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 109) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:51.703+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 108) in 95 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T12:58:51.717+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added rdd_96_4 in memory on 172.18.0.4:46559 (size: 2024.0 B, free: 434.3 MiB)
[2025-05-06T12:58:51.771+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 110) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:51.772+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 109) in 69 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T12:58:51.784+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added rdd_96_5 in memory on 172.18.0.4:46559 (size: 2040.0 B, free: 434.2 MiB)
[2025-05-06T12:58:51.823+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 111) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:51.823+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 110) in 52 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T12:58:51.835+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added rdd_96_6 in memory on 172.18.0.4:46559 (size: 2.1 KiB, free: 434.2 MiB)
[2025-05-06T12:58:51.882+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 112) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:51.883+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 111) in 59 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T12:58:51.896+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added rdd_96_7 in memory on 172.18.0.4:46559 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T12:58:51.937+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Starting task 8.0 in stage 91.0 (TID 113) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:51.937+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 112) in 55 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T12:58:51.949+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:51 INFO BlockManagerInfo: Added rdd_96_8 in memory on 172.18.0.4:46559 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T12:58:52.002+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO TaskSetManager: Starting task 9.0 in stage 91.0 (TID 114) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:52.003+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO TaskSetManager: Finished task 8.0 in stage 91.0 (TID 113) in 66 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T12:58:52.015+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO BlockManagerInfo: Added rdd_96_9 in memory on 172.18.0.4:46559 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T12:58:52.059+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO TaskSetManager: Finished task 9.0 in stage 91.0 (TID 114) in 57 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T12:58:52.060+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-05-06T12:58:52.060+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: ShuffleMapStage 91 (rdd at GraphFrame.scala:188) finished in 1.038 s
[2025-05-06T12:58:52.060+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:52.060+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:52.060+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: waiting: Set()
[2025-05-06T12:58:52.060+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:52.076+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO CodeGenerator: Code generated in 7.379817 ms
[2025-05-06T12:58:52.082+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO CodeGenerator: Code generated in 5.153705 ms
[2025-05-06T12:58:52.095+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO CodeGenerator: Code generated in 6.27689 ms
[2025-05-06T12:58:52.096+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#529 - id.nullCount#528) > 0)
[2025-05-06T12:58:52.192+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T12:58:52.193+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Registering RDD 199 (mapPartitions at VertexRDD.scala:356) as input to shuffle 29
[2025-05-06T12:58:52.193+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Registering RDD 104 (map at GraphFrame.scala:187) as input to shuffle 26
[2025-05-06T12:58:52.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Registering RDD 221 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 25
[2025-05-06T12:58:52.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Registering RDD 225 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 27
[2025-05-06T12:58:52.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Registering RDD 229 (mapPartitions at GraphImpl.scala:208) as input to shuffle 28
[2025-05-06T12:58:52.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Got job 42 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T12:58:52.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Final stage: ResultStage 103 (fold at VertexRDDImpl.scala:90)
[2025-05-06T12:58:52.194+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 99, ShuffleMapStage 98)
[2025-05-06T12:58:52.195+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 102, ShuffleMapStage 99, ShuffleMapStage 98)
[2025-05-06T12:58:52.196+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Submitting ShuffleMapStage 98 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[199] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-06T12:58:52.217+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 114.9 KiB, free 425.7 MiB)
[2025-05-06T12:58:52.218+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 45.9 KiB, free 425.7 MiB)
[2025-05-06T12:58:52.218+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 016737cbcc7e:41421 (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:52.219+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:52.219+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 98 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[199] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T12:58:52.219+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO TaskSchedulerImpl: Adding task set 98.0 with 10 tasks resource profile 0
[2025-05-06T12:58:52.220+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[104] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-06T12:58:52.220+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 115) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:52.228+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 67.6 KiB, free 425.6 MiB)
[2025-05-06T12:58:52.235+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 425.6 MiB)
[2025-05-06T12:58:52.236+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 016737cbcc7e:41421 (size: 27.6 KiB, free: 434.2 MiB)
[2025-05-06T12:58:52.237+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:52.237+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 016737cbcc7e:41421 in memory (size: 40.3 KiB, free: 434.2 MiB)
[2025-05-06T12:58:52.238+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[104] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T12:58:52.238+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO TaskSchedulerImpl: Adding task set 99.0 with 10 tasks resource profile 0
[2025-05-06T12:58:52.241+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.18.0.4:46559 in memory (size: 40.3 KiB, free: 434.3 MiB)
[2025-05-06T12:58:52.243+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.18.0.4:46559 (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:52.360+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.18.0.4:47760
[2025-05-06T12:58:53.631+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:53 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 116) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:53.632+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:53 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 115) in 1413 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T12:58:53.939+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:53 INFO TaskSetManager: Starting task 2.0 in stage 98.0 (TID 117) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:53.940+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:53 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 116) in 308 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T12:58:54.128+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Starting task 3.0 in stage 98.0 (TID 118) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:54.128+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Finished task 2.0 in stage 98.0 (TID 117) in 189 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T12:58:54.269+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Starting task 4.0 in stage 98.0 (TID 119) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:54.270+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Finished task 3.0 in stage 98.0 (TID 118) in 143 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T12:58:54.370+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Starting task 5.0 in stage 98.0 (TID 120) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:54.370+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Finished task 4.0 in stage 98.0 (TID 119) in 101 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T12:58:54.490+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Starting task 6.0 in stage 98.0 (TID 121) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:54.491+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Finished task 5.0 in stage 98.0 (TID 120) in 121 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T12:58:54.603+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Starting task 7.0 in stage 98.0 (TID 122) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:54.603+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Finished task 6.0 in stage 98.0 (TID 121) in 113 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T12:58:54.727+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Starting task 8.0 in stage 98.0 (TID 123) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:54.727+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Finished task 7.0 in stage 98.0 (TID 122) in 125 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T12:58:54.830+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Starting task 9.0 in stage 98.0 (TID 124) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:54.830+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Finished task 8.0 in stage 98.0 (TID 123) in 103 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T12:58:54.965+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 125) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:54.965+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSetManager: Finished task 9.0 in stage 98.0 (TID 124) in 136 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T12:58:54.965+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool
[2025-05-06T12:58:54.966+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO DAGScheduler: ShuffleMapStage 98 (mapPartitions at VertexRDD.scala:356) finished in 2.768 s
[2025-05-06T12:58:54.966+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:54.966+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO DAGScheduler: running: Set(ShuffleMapStage 99)
[2025-05-06T12:58:54.967+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103, ShuffleMapStage 100, ShuffleMapStage 101)
[2025-05-06T12:58:54.967+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:54.972+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.18.0.4:46559 (size: 27.6 KiB, free: 434.2 MiB)
[2025-05-06T12:58:54.988+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:54 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.18.0.4:46559 (size: 27.1 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.002+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 126) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.003+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 125) in 37 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T12:58:55.013+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 127) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.014+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 126) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T12:58:55.025+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 3.0 in stage 99.0 (TID 128) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.025+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 127) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T12:58:55.036+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 4.0 in stage 99.0 (TID 129) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.037+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 3.0 in stage 99.0 (TID 128) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T12:58:55.047+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 5.0 in stage 99.0 (TID 130) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.048+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 4.0 in stage 99.0 (TID 129) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T12:58:55.059+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 6.0 in stage 99.0 (TID 131) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.059+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 5.0 in stage 99.0 (TID 130) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T12:58:55.070+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 7.0 in stage 99.0 (TID 132) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.070+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 6.0 in stage 99.0 (TID 131) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T12:58:55.080+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 8.0 in stage 99.0 (TID 133) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.080+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 7.0 in stage 99.0 (TID 132) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T12:58:55.092+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 9.0 in stage 99.0 (TID 134) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.093+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 8.0 in stage 99.0 (TID 133) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T12:58:55.106+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 9.0 in stage 99.0 (TID 134) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T12:58:55.107+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool
[2025-05-06T12:58:55.107+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: ShuffleMapStage 99 (map at GraphFrame.scala:187) finished in 2.886 s
[2025-05-06T12:58:55.107+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:55.107+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:55.107+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103, ShuffleMapStage 100, ShuffleMapStage 101)
[2025-05-06T12:58:55.107+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:55.108+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: Submitting ShuffleMapStage 100 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[221] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T12:58:55.115+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 10.3 KiB, free 425.7 MiB)
[2025-05-06T12:58:55.129+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 016737cbcc7e:41421 in memory (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.129+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 425.9 MiB)
[2025-05-06T12:58:55.129+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 016737cbcc7e:41421 (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.130+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:55.130+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 100 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[221] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T12:58:55.131+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSchedulerImpl: Adding task set 100.0 with 10 tasks resource profile 0
[2025-05-06T12:58:55.131+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: Submitting ShuffleMapStage 101 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[225] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T12:58:55.132+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 135) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.133+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.18.0.4:46559 in memory (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.133+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 9.9 KiB, free 425.8 MiB)
[2025-05-06T12:58:55.134+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 425.8 MiB)
[2025-05-06T12:58:55.135+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 016737cbcc7e:41421 (size: 4.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.135+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:55.136+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 101 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[225] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T12:58:55.136+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSchedulerImpl: Adding task set 101.0 with 10 tasks resource profile 0
[2025-05-06T12:58:55.145+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.18.0.4:46559 (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.204+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.18.0.4:47760
[2025-05-06T12:58:55.215+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 016737cbcc7e:41421 in memory (size: 27.6 KiB, free: 434.3 MiB)
[2025-05-06T12:58:55.217+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.18.0.4:46559 in memory (size: 27.6 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.221+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.18.0.4:47760
[2025-05-06T12:58:55.262+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_0 in memory on 172.18.0.4:46559 (size: 27.8 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.269+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_0 in memory on 172.18.0.4:46559 (size: 13.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.271+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.275+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.289+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 136) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.290+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 135) in 158 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T12:58:55.305+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_1 in memory on 172.18.0.4:46559 (size: 27.4 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.307+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_1 in memory on 172.18.0.4:46559 (size: 13.8 KiB, free: 434.1 MiB)
[2025-05-06T12:58:55.309+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 434.1 MiB)
[2025-05-06T12:58:55.311+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 434.1 MiB)
[2025-05-06T12:58:55.316+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 2.0 in stage 100.0 (TID 137) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.316+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 136) in 27 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T12:58:55.331+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_2 in memory on 172.18.0.4:46559 (size: 26.8 KiB, free: 434.1 MiB)
[2025-05-06T12:58:55.334+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_2 in memory on 172.18.0.4:46559 (size: 13.6 KiB, free: 434.1 MiB)
[2025-05-06T12:58:55.337+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 434.1 MiB)
[2025-05-06T12:58:55.340+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 434.0 MiB)
[2025-05-06T12:58:55.345+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 3.0 in stage 100.0 (TID 138) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.345+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 2.0 in stage 100.0 (TID 137) in 30 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T12:58:55.360+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_3 in memory on 172.18.0.4:46559 (size: 26.7 KiB, free: 434.0 MiB)
[2025-05-06T12:58:55.362+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_3 in memory on 172.18.0.4:46559 (size: 13.6 KiB, free: 434.0 MiB)
[2025-05-06T12:58:55.364+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 434.0 MiB)
[2025-05-06T12:58:55.368+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 434.0 MiB)
[2025-05-06T12:58:55.372+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 4.0 in stage 100.0 (TID 139) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.373+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 3.0 in stage 100.0 (TID 138) in 29 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T12:58:55.388+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_4 in memory on 172.18.0.4:46559 (size: 26.9 KiB, free: 433.9 MiB)
[2025-05-06T12:58:55.390+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_4 in memory on 172.18.0.4:46559 (size: 13.7 KiB, free: 433.9 MiB)
[2025-05-06T12:58:55.393+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 433.9 MiB)
[2025-05-06T12:58:55.396+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 433.9 MiB)
[2025-05-06T12:58:55.401+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 5.0 in stage 100.0 (TID 140) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.401+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 4.0 in stage 100.0 (TID 139) in 29 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T12:58:55.416+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_5 in memory on 172.18.0.4:46559 (size: 26.9 KiB, free: 433.9 MiB)
[2025-05-06T12:58:55.419+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_5 in memory on 172.18.0.4:46559 (size: 13.7 KiB, free: 433.9 MiB)
[2025-05-06T12:58:55.421+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 433.9 MiB)
[2025-05-06T12:58:55.424+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 433.8 MiB)
[2025-05-06T12:58:55.430+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 6.0 in stage 100.0 (TID 141) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.430+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 5.0 in stage 100.0 (TID 140) in 30 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T12:58:55.447+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_6 in memory on 172.18.0.4:46559 (size: 26.8 KiB, free: 433.8 MiB)
[2025-05-06T12:58:55.449+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_6 in memory on 172.18.0.4:46559 (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-06T12:58:55.451+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 433.8 MiB)
[2025-05-06T12:58:55.455+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 433.8 MiB)
[2025-05-06T12:58:55.462+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 7.0 in stage 100.0 (TID 142) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.462+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 6.0 in stage 100.0 (TID 141) in 32 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T12:58:55.480+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_7 in memory on 172.18.0.4:46559 (size: 26.7 KiB, free: 433.7 MiB)
[2025-05-06T12:58:55.483+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_7 in memory on 172.18.0.4:46559 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-06T12:58:55.486+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 433.7 MiB)
[2025-05-06T12:58:55.494+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 433.7 MiB)
[2025-05-06T12:58:55.502+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 8.0 in stage 100.0 (TID 143) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.502+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 7.0 in stage 100.0 (TID 142) in 40 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T12:58:55.520+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_8 in memory on 172.18.0.4:46559 (size: 26.4 KiB, free: 433.7 MiB)
[2025-05-06T12:58:55.523+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_8 in memory on 172.18.0.4:46559 (size: 13.3 KiB, free: 433.7 MiB)
[2025-05-06T12:58:55.526+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 433.7 MiB)
[2025-05-06T12:58:55.530+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 433.6 MiB)
[2025-05-06T12:58:55.535+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 9.0 in stage 100.0 (TID 144) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.535+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 8.0 in stage 100.0 (TID 143) in 34 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T12:58:55.551+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_202_9 in memory on 172.18.0.4:46559 (size: 25.7 KiB, free: 433.6 MiB)
[2025-05-06T12:58:55.553+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_207_9 in memory on 172.18.0.4:46559 (size: 13.0 KiB, free: 433.6 MiB)
[2025-05-06T12:58:55.555+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_213_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 433.6 MiB)
[2025-05-06T12:58:55.558+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_217_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 433.6 MiB)
[2025-05-06T12:58:55.563+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 145) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.563+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 9.0 in stage 100.0 (TID 144) in 28 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T12:58:55.564+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-05-06T12:58:55.565+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: ShuffleMapStage 100 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.454 s
[2025-05-06T12:58:55.565+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:55.566+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: running: Set(ShuffleMapStage 101)
[2025-05-06T12:58:55.566+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103)
[2025-05-06T12:58:55.566+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:55.570+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.4:46559 (size: 4.9 KiB, free: 433.6 MiB)
[2025-05-06T12:58:55.585+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 146) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.586+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 145) in 24 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T12:58:55.596+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 147) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.596+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 146) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T12:58:55.607+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 148) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.607+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 147) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T12:58:55.616+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 4.0 in stage 101.0 (TID 149) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.616+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 148) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T12:58:55.625+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 5.0 in stage 101.0 (TID 150) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.626+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 4.0 in stage 101.0 (TID 149) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T12:58:55.634+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 6.0 in stage 101.0 (TID 151) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.634+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 5.0 in stage 101.0 (TID 150) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T12:58:55.643+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 7.0 in stage 101.0 (TID 152) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.643+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 6.0 in stage 101.0 (TID 151) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T12:58:55.652+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 8.0 in stage 101.0 (TID 153) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.652+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 7.0 in stage 101.0 (TID 152) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T12:58:55.660+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 9.0 in stage 101.0 (TID 154) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.661+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 8.0 in stage 101.0 (TID 153) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T12:58:55.671+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Finished task 9.0 in stage 101.0 (TID 154) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T12:58:55.672+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool
[2025-05-06T12:58:55.672+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: ShuffleMapStage 101 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.540 s
[2025-05-06T12:58:55.672+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T12:58:55.672+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: running: Set()
[2025-05-06T12:58:55.673+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103)
[2025-05-06T12:58:55.673+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: failed: Set()
[2025-05-06T12:58:55.673+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: Submitting ShuffleMapStage 102 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[229] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T12:58:55.680+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 119.3 KiB, free 425.8 MiB)
[2025-05-06T12:58:55.681+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 425.8 MiB)
[2025-05-06T12:58:55.682+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 016737cbcc7e:41421 (size: 47.3 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.682+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1474
[2025-05-06T12:58:55.682+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 102 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[229] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T12:58:55.683+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSchedulerImpl: Adding task set 102.0 with 10 tasks resource profile 0
[2025-05-06T12:58:55.684+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 155) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T12:58:55.692+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.18.0.4:46559 (size: 47.3 KiB, free: 433.5 MiB)
[2025-05-06T12:58:55.724+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.18.0.4:47760
[2025-05-06T12:58:55.863+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_205_0 in memory on 172.18.0.4:46559 (size: 10.7 MiB, free: 422.8 MiB)
[2025-05-06T12:58:55.868+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_209_0 in memory on 172.18.0.4:46559 (size: 10.7 MiB, free: 412.1 MiB)
[2025-05-06T12:58:55.876+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_215_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 411.6 MiB)
[2025-05-06T12:58:55.877+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.18.0.4:47760
[2025-05-06T12:58:55.882+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Added rdd_223_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 411.1 MiB)
[2025-05-06T12:58:55.884+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.18.0.4:47760
[2025-05-06T12:58:55.900+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 016737cbcc7e:41421 in memory (size: 4.9 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.903+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.4:46559 in memory (size: 4.9 KiB, free: 411.1 MiB)
[2025-05-06T12:58:55.912+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 016737cbcc7e:41421 in memory (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T12:58:55.915+0000] {spark_submit.py:571} INFO - 25/05/06 12:58:55 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.18.0.4:46559 in memory (size: 5.0 KiB, free: 411.1 MiB)
[2025-05-06T12:59:04.689+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:04 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 156) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T12:59:04.690+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:04 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 155) in 9006 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T12:59:04.787+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:04 INFO BlockManagerInfo: Added rdd_205_1 in memory on 172.18.0.4:46559 (size: 13.9 MiB, free: 397.2 MiB)
[2025-05-06T12:59:04.790+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:04 INFO BlockManagerInfo: Added rdd_209_1 in memory on 172.18.0.4:46559 (size: 13.9 MiB, free: 383.3 MiB)
[2025-05-06T12:59:04.795+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:04 INFO BlockManagerInfo: Added rdd_215_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 382.7 MiB)
[2025-05-06T12:59:04.798+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:04 INFO BlockManagerInfo: Added rdd_223_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 382.1 MiB)
[2025-05-06T12:59:16.688+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:16 INFO TaskSetManager: Starting task 2.0 in stage 102.0 (TID 157) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T12:59:16.688+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:16 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 156) in 11999 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T12:59:16.787+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:16 INFO BlockManagerInfo: Added rdd_205_2 in memory on 172.18.0.4:46559 (size: 12.5 MiB, free: 369.6 MiB)
[2025-05-06T12:59:16.790+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:16 INFO BlockManagerInfo: Added rdd_209_2 in memory on 172.18.0.4:46559 (size: 12.5 MiB, free: 357.2 MiB)
[2025-05-06T12:59:16.793+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:16 INFO BlockManagerInfo: Added rdd_215_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 356.6 MiB)
[2025-05-06T12:59:16.795+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:16 INFO BlockManagerInfo: Added rdd_223_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 356.1 MiB)
[2025-05-06T12:59:27.192+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:27 INFO TaskSetManager: Starting task 3.0 in stage 102.0 (TID 158) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T12:59:27.193+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:27 INFO TaskSetManager: Finished task 2.0 in stage 102.0 (TID 157) in 10505 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T12:59:27.297+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:27 INFO BlockManagerInfo: Added rdd_205_3 in memory on 172.18.0.4:46559 (size: 11.7 MiB, free: 344.3 MiB)
[2025-05-06T12:59:27.299+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:27 INFO BlockManagerInfo: Added rdd_209_3 in memory on 172.18.0.4:46559 (size: 11.7 MiB, free: 332.6 MiB)
[2025-05-06T12:59:27.307+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:27 INFO BlockManagerInfo: Added rdd_215_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 332.0 MiB)
[2025-05-06T12:59:27.311+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:27 INFO BlockManagerInfo: Added rdd_223_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 331.5 MiB)
[2025-05-06T12:59:35.943+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:35 INFO TaskSetManager: Starting task 4.0 in stage 102.0 (TID 159) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T12:59:35.944+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:35 INFO TaskSetManager: Finished task 3.0 in stage 102.0 (TID 158) in 8751 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T12:59:36.010+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:36 INFO BlockManagerInfo: Added rdd_205_4 in memory on 172.18.0.4:46559 (size: 9.6 MiB, free: 321.9 MiB)
[2025-05-06T12:59:36.012+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:36 INFO BlockManagerInfo: Added rdd_209_4 in memory on 172.18.0.4:46559 (size: 9.6 MiB, free: 312.3 MiB)
[2025-05-06T12:59:36.015+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:36 INFO BlockManagerInfo: Added rdd_215_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 311.8 MiB)
[2025-05-06T12:59:36.020+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:36 INFO BlockManagerInfo: Added rdd_223_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 311.4 MiB)
[2025-05-06T12:59:42.820+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:42 INFO TaskSetManager: Starting task 5.0 in stage 102.0 (TID 160) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T12:59:42.821+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:42 INFO TaskSetManager: Finished task 4.0 in stage 102.0 (TID 159) in 6877 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T12:59:42.892+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:42 INFO BlockManagerInfo: Added rdd_205_5 in memory on 172.18.0.4:46559 (size: 11.5 MiB, free: 299.8 MiB)
[2025-05-06T12:59:42.894+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:42 INFO BlockManagerInfo: Added rdd_209_5 in memory on 172.18.0.4:46559 (size: 11.5 MiB, free: 288.3 MiB)
[2025-05-06T12:59:42.896+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:42 INFO BlockManagerInfo: Added rdd_215_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 287.8 MiB)
[2025-05-06T12:59:42.900+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:42 INFO BlockManagerInfo: Added rdd_223_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 287.3 MiB)
[2025-05-06T12:59:51.736+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:51 INFO TaskSetManager: Starting task 6.0 in stage 102.0 (TID 161) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T12:59:51.737+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:51 INFO TaskSetManager: Finished task 5.0 in stage 102.0 (TID 160) in 8916 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T12:59:51.816+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:51 INFO BlockManagerInfo: Added rdd_205_6 in memory on 172.18.0.4:46559 (size: 11.6 MiB, free: 275.6 MiB)
[2025-05-06T12:59:51.818+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:51 INFO BlockManagerInfo: Added rdd_209_6 in memory on 172.18.0.4:46559 (size: 11.6 MiB, free: 264.0 MiB)
[2025-05-06T12:59:51.820+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:51 INFO BlockManagerInfo: Added rdd_215_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 263.5 MiB)
[2025-05-06T12:59:51.823+0000] {spark_submit.py:571} INFO - 25/05/06 12:59:51 INFO BlockManagerInfo: Added rdd_223_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 263.0 MiB)
[2025-05-06T13:00:00.589+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:00 INFO TaskSetManager: Starting task 7.0 in stage 102.0 (TID 162) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:00.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:00 INFO TaskSetManager: Finished task 6.0 in stage 102.0 (TID 161) in 8853 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:00.684+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:00 INFO BlockManagerInfo: Added rdd_205_7 in memory on 172.18.0.4:46559 (size: 13.2 MiB, free: 249.8 MiB)
[2025-05-06T13:00:00.686+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:00 INFO BlockManagerInfo: Added rdd_209_7 in memory on 172.18.0.4:46559 (size: 13.2 MiB, free: 236.5 MiB)
[2025-05-06T13:00:00.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:00 INFO BlockManagerInfo: Added rdd_215_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 236.0 MiB)
[2025-05-06T13:00:00.691+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:00 INFO BlockManagerInfo: Added rdd_223_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 235.4 MiB)
[2025-05-06T13:00:11.213+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:11 INFO TaskSetManager: Starting task 8.0 in stage 102.0 (TID 163) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:11.213+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:11 INFO TaskSetManager: Finished task 7.0 in stage 102.0 (TID 162) in 10624 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:11.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:11 INFO BlockManagerInfo: Added rdd_205_8 in memory on 172.18.0.4:46559 (size: 12.1 MiB, free: 223.3 MiB)
[2025-05-06T13:00:11.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:11 INFO BlockManagerInfo: Added rdd_209_8 in memory on 172.18.0.4:46559 (size: 12.1 MiB, free: 211.2 MiB)
[2025-05-06T13:00:11.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:11 INFO BlockManagerInfo: Added rdd_215_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 210.6 MiB)
[2025-05-06T13:00:11.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:11 INFO BlockManagerInfo: Added rdd_223_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 210.1 MiB)
[2025-05-06T13:00:20.605+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:20 INFO TaskSetManager: Starting task 9.0 in stage 102.0 (TID 164) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:20.605+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:20 INFO TaskSetManager: Finished task 8.0 in stage 102.0 (TID 163) in 9393 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:20.697+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:20 INFO BlockManagerInfo: Added rdd_205_9 in memory on 172.18.0.4:46559 (size: 13.7 MiB, free: 196.4 MiB)
[2025-05-06T13:00:20.700+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:20 INFO BlockManagerInfo: Added rdd_209_9 in memory on 172.18.0.4:46559 (size: 13.7 MiB, free: 182.7 MiB)
[2025-05-06T13:00:20.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:20 INFO BlockManagerInfo: Added rdd_215_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 182.1 MiB)
[2025-05-06T13:00:20.706+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:20 INFO BlockManagerInfo: Added rdd_223_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 181.5 MiB)
[2025-05-06T13:00:31.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO TaskSetManager: Finished task 9.0 in stage 102.0 (TID 164) in 11186 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:31.791+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool
[2025-05-06T13:00:31.791+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO DAGScheduler: ShuffleMapStage 102 (mapPartitions at GraphImpl.scala:208) finished in 96.116 s
[2025-05-06T13:00:31.791+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:31.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:31.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO DAGScheduler: waiting: Set(ResultStage 103)
[2025-05-06T13:00:31.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:31.793+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[233] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:31.795+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 11.2 KiB, free 425.8 MiB)
[2025-05-06T13:00:31.796+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 425.8 MiB)
[2025-05-06T13:00:31.796+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 016737cbcc7e:41421 (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:31.797+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:31.797+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 103 (MapPartitionsRDD[233] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:31.797+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO TaskSchedulerImpl: Adding task set 103.0 with 10 tasks resource profile 0
[2025-05-06T13:00:31.798+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 165) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:31.806+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.18.0.4:46559 (size: 5.3 KiB, free: 181.5 MiB)
[2025-05-06T13:00:31.811+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.18.0.4:47760
[2025-05-06T13:00:32.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:32 INFO BlockManagerInfo: Added rdd_231_0 in memory on 172.18.0.4:46559 (size: 3.6 MiB, free: 177.9 MiB)
[2025-05-06T13:00:32.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:32 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 166) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:32.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:32 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 165) in 495 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:32.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:32 INFO BlockManagerInfo: Added rdd_231_1 in memory on 172.18.0.4:46559 (size: 3.7 MiB, free: 174.2 MiB)
[2025-05-06T13:00:32.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:32 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 167) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:32.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:32 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 166) in 401 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:33.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:33 INFO BlockManagerInfo: Added rdd_231_2 in memory on 172.18.0.4:46559 (size: 3.4 MiB, free: 170.7 MiB)
[2025-05-06T13:00:33.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:33 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 168) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:33.072+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:33 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 167) in 377 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:33.442+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:33 INFO BlockManagerInfo: Added rdd_231_3 in memory on 172.18.0.4:46559 (size: 3.4 MiB, free: 167.3 MiB)
[2025-05-06T13:00:33.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:33 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 169) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:33.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:33 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 168) in 373 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:33.811+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:33 INFO BlockManagerInfo: Added rdd_231_4 in memory on 172.18.0.4:46559 (size: 3.5 MiB, free: 163.8 MiB)
[2025-05-06T13:00:33.813+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:33 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 170) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:33.813+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:33 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 169) in 370 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:34.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:34 INFO BlockManagerInfo: Added rdd_231_5 in memory on 172.18.0.4:46559 (size: 3.6 MiB, free: 160.2 MiB)
[2025-05-06T13:00:34.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:34 INFO TaskSetManager: Starting task 6.0 in stage 103.0 (TID 171) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:34.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:34 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 170) in 381 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:34.546+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:34 INFO BlockManagerInfo: Added rdd_231_6 in memory on 172.18.0.4:46559 (size: 3.4 MiB, free: 156.8 MiB)
[2025-05-06T13:00:34.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:34 INFO TaskSetManager: Starting task 7.0 in stage 103.0 (TID 172) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:34.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:34 INFO TaskSetManager: Finished task 6.0 in stage 103.0 (TID 171) in 356 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:34.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:34 INFO BlockManagerInfo: Added rdd_231_7 in memory on 172.18.0.4:46559 (size: 3.6 MiB, free: 153.2 MiB)
[2025-05-06T13:00:34.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:34 INFO TaskSetManager: Starting task 8.0 in stage 103.0 (TID 173) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:34.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:34 INFO TaskSetManager: Finished task 7.0 in stage 103.0 (TID 172) in 402 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:35.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_231_8 in memory on 172.18.0.4:46559 (size: 3.5 MiB, free: 149.7 MiB)
[2025-05-06T13:00:35.318+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 9.0 in stage 103.0 (TID 174) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.318+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 8.0 in stage 103.0 (TID 173) in 369 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:35.665+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_231_9 in memory on 172.18.0.4:46559 (size: 3.3 MiB, free: 146.3 MiB)
[2025-05-06T13:00:35.666+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 9.0 in stage 103.0 (TID 174) in 349 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:35.667+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-05-06T13:00:35.667+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: ResultStage 103 (fold at VertexRDDImpl.scala:90) finished in 3.873 s
[2025-05-06T13:00:35.667+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:35.667+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
[2025-05-06T13:00:35.667+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Job 42 finished: fold at VertexRDDImpl.scala:90, took 103.475170 s
[2025-05-06T13:00:35.680+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:35.681+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Registering RDD 242 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 31
[2025-05-06T13:00:35.681+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Registering RDD 238 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 30
[2025-05-06T13:00:35.681+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Registering RDD 246 (mapPartitions at GraphImpl.scala:208) as input to shuffle 32
[2025-05-06T13:00:35.681+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Got job 43 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:35.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Final stage: ResultStage 118 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:35.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 114, ShuffleMapStage 111, ShuffleMapStage 110)
[2025-05-06T13:00:35.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 117)
[2025-05-06T13:00:35.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Submitting ShuffleMapStage 115 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[242] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:35.684+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 10.5 KiB, free 425.8 MiB)
[2025-05-06T13:00:35.689+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:35.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 016737cbcc7e:41421 (size: 5.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:35.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 016737cbcc7e:41421 in memory (size: 47.3 KiB, free: 434.3 MiB)
[2025-05-06T13:00:35.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:35.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 115 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[242] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:35.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSchedulerImpl: Adding task set 115.0 with 10 tasks resource profile 0
[2025-05-06T13:00:35.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Submitting ShuffleMapStage 116 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[238] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:35.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 175) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 11.7 KiB, free 425.9 MiB)
[2025-05-06T13:00:35.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.18.0.4:46559 in memory (size: 47.3 KiB, free: 146.4 MiB)
[2025-05-06T13:00:35.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 425.9 MiB)
[2025-05-06T13:00:35.696+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 016737cbcc7e:41421 (size: 5.4 KiB, free: 434.3 MiB)
[2025-05-06T13:00:35.696+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:35.696+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 116 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[238] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:35.697+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSchedulerImpl: Adding task set 116.0 with 10 tasks resource profile 0
[2025-05-06T13:00:35.697+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 016737cbcc7e:41421 in memory (size: 5.3 KiB, free: 434.3 MiB)
[2025-05-06T13:00:35.698+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.18.0.4:46559 in memory (size: 5.3 KiB, free: 146.4 MiB)
[2025-05-06T13:00:35.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.18.0.4:46559 (size: 5.1 KiB, free: 146.4 MiB)
[2025-05-06T13:00:35.714+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 176) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.714+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 175) in 23 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:35.740+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 2.0 in stage 115.0 (TID 177) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.741+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 176) in 27 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:35.762+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 3.0 in stage 115.0 (TID 178) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 2.0 in stage 115.0 (TID 177) in 22 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:35.783+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 4.0 in stage 115.0 (TID 179) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.783+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 3.0 in stage 115.0 (TID 178) in 21 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:35.797+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 5.0 in stage 115.0 (TID 180) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.797+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 4.0 in stage 115.0 (TID 179) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:35.810+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 6.0 in stage 115.0 (TID 181) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.811+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 5.0 in stage 115.0 (TID 180) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:35.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 7.0 in stage 115.0 (TID 182) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 6.0 in stage 115.0 (TID 181) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:35.835+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 8.0 in stage 115.0 (TID 183) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.835+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 7.0 in stage 115.0 (TID 182) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:35.849+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 9.0 in stage 115.0 (TID 184) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.850+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 8.0 in stage 115.0 (TID 183) in 15 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:35.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 185) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 9.0 in stage 115.0 (TID 184) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:35.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool
[2025-05-06T13:00:35.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: ShuffleMapStage 115 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.179 s
[2025-05-06T13:00:35.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:35.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: running: Set(ShuffleMapStage 116)
[2025-05-06T13:00:35.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 117, ResultStage 118)
[2025-05-06T13:00:35.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:35.867+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.18.0.4:46559 (size: 5.4 KiB, free: 146.4 MiB)
[2025-05-06T13:00:35.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 146.4 MiB)
[2025-05-06T13:00:35.888+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 1.0 in stage 116.0 (TID 186) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.888+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 185) in 27 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:35.894+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 146.4 MiB)
[2025-05-06T13:00:35.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 2.0 in stage 116.0 (TID 187) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 1.0 in stage 116.0 (TID 186) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:35.904+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 146.3 MiB)
[2025-05-06T13:00:35.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 3.0 in stage 116.0 (TID 188) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 2.0 in stage 116.0 (TID 187) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:35.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 146.3 MiB)
[2025-05-06T13:00:35.920+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 4.0 in stage 116.0 (TID 189) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.921+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 3.0 in stage 116.0 (TID 188) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:35.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 146.3 MiB)
[2025-05-06T13:00:35.930+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 5.0 in stage 116.0 (TID 190) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.930+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 4.0 in stage 116.0 (TID 189) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:35.937+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 146.3 MiB)
[2025-05-06T13:00:35.943+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 6.0 in stage 116.0 (TID 191) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 5.0 in stage 116.0 (TID 190) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:35.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 146.3 MiB)
[2025-05-06T13:00:35.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 7.0 in stage 116.0 (TID 192) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.956+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 6.0 in stage 116.0 (TID 191) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:35.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 146.3 MiB)
[2025-05-06T13:00:35.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 8.0 in stage 116.0 (TID 193) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 7.0 in stage 116.0 (TID 192) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:35.971+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 146.3 MiB)
[2025-05-06T13:00:35.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 9.0 in stage 116.0 (TID 194) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 8.0 in stage 116.0 (TID 193) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:35.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added rdd_234_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 146.2 MiB)
[2025-05-06T13:00:35.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Finished task 9.0 in stage 116.0 (TID 194) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:35.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool
[2025-05-06T13:00:35.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: ShuffleMapStage 116 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.292 s
[2025-05-06T13:00:35.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:35.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:35.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 117, ResultStage 118)
[2025-05-06T13:00:35.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:35.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Submitting ShuffleMapStage 117 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[246] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:35.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 120.4 KiB, free 425.8 MiB)
[2025-05-06T13:00:35.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 47.8 KiB, free 425.8 MiB)
[2025-05-06T13:00:35.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 016737cbcc7e:41421 in memory (size: 5.1 KiB, free: 434.3 MiB)
[2025-05-06T13:00:35.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 016737cbcc7e:41421 (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:35.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:35.994+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 117 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[246] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:35.994+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSchedulerImpl: Adding task set 117.0 with 10 tasks resource profile 0
[2025-05-06T13:00:35.994+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.18.0.4:46559 in memory (size: 5.1 KiB, free: 146.2 MiB)
[2025-05-06T13:00:35.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 195) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:35.999+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:35 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.18.0.4:46559 (size: 47.8 KiB, free: 146.2 MiB)
[2025-05-06T13:00:36.006+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.18.0.4:47760
[2025-05-06T13:00:36.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.18.0.4:47760
[2025-05-06T13:00:36.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO BlockManagerInfo: Added rdd_240_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 145.7 MiB)
[2025-05-06T13:00:36.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.18.0.4:47760
[2025-05-06T13:00:36.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 196) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:36.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 195) in 289 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:36.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO BlockManagerInfo: Added rdd_240_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 145.1 MiB)
[2025-05-06T13:00:36.606+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO TaskSetManager: Starting task 2.0 in stage 117.0 (TID 197) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:36.606+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 196) in 324 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:36.615+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO BlockManagerInfo: Added rdd_240_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 144.6 MiB)
[2025-05-06T13:00:36.894+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO TaskSetManager: Starting task 3.0 in stage 117.0 (TID 198) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:36.894+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO TaskSetManager: Finished task 2.0 in stage 117.0 (TID 197) in 289 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:36.902+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:36 INFO BlockManagerInfo: Added rdd_240_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 144.0 MiB)
[2025-05-06T13:00:37.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO TaskSetManager: Starting task 4.0 in stage 117.0 (TID 199) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:37.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO TaskSetManager: Finished task 3.0 in stage 117.0 (TID 198) in 278 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:37.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO BlockManagerInfo: Added rdd_240_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 143.6 MiB)
[2025-05-06T13:00:37.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO TaskSetManager: Starting task 5.0 in stage 117.0 (TID 200) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:37.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO TaskSetManager: Finished task 4.0 in stage 117.0 (TID 199) in 214 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:37.393+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO BlockManagerInfo: Added rdd_240_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 143.1 MiB)
[2025-05-06T13:00:37.658+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO TaskSetManager: Starting task 6.0 in stage 117.0 (TID 201) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:37.658+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO TaskSetManager: Finished task 5.0 in stage 117.0 (TID 200) in 274 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:37.666+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO BlockManagerInfo: Added rdd_240_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 142.5 MiB)
[2025-05-06T13:00:37.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO TaskSetManager: Starting task 7.0 in stage 117.0 (TID 202) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:37.932+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO TaskSetManager: Finished task 6.0 in stage 117.0 (TID 201) in 275 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:37.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:37 INFO BlockManagerInfo: Added rdd_240_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 142.0 MiB)
[2025-05-06T13:00:38.231+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 8.0 in stage 117.0 (TID 203) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.231+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 7.0 in stage 117.0 (TID 202) in 300 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:38.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_240_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 141.4 MiB)
[2025-05-06T13:00:38.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 9.0 in stage 117.0 (TID 204) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 8.0 in stage 117.0 (TID 203) in 282 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:38.522+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_240_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 140.8 MiB)
[2025-05-06T13:00:38.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 9.0 in stage 117.0 (TID 204) in 322 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:38.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-05-06T13:00:38.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO DAGScheduler: ShuffleMapStage 117 (mapPartitions at GraphImpl.scala:208) finished in 2.848 s
[2025-05-06T13:00:38.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:38.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:38.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO DAGScheduler: waiting: Set(ResultStage 118)
[2025-05-06T13:00:38.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:38.834+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[250] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:38.834+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 12.3 KiB, free 425.8 MiB)
[2025-05-06T13:00:38.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 425.8 MiB)
[2025-05-06T13:00:38.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 016737cbcc7e:41421 (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:38.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 016737cbcc7e:41421 in memory (size: 5.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:38.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:38.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 118 (MapPartitionsRDD[250] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:38.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSchedulerImpl: Adding task set 118.0 with 10 tasks resource profile 0
[2025-05-06T13:00:38.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 205) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.18.0.4:46559 in memory (size: 5.4 KiB, free: 140.8 MiB)
[2025-05-06T13:00:38.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.18.0.4:46559 (size: 5.6 KiB, free: 140.8 MiB)
[2025-05-06T13:00:38.848+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.18.0.4:47760
[2025-05-06T13:00:38.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_248_0 in memory on 172.18.0.4:46559 (size: 90.8 KiB, free: 140.7 MiB)
[2025-05-06T13:00:38.873+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 206) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.873+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 205) in 32 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:38.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_248_1 in memory on 172.18.0.4:46559 (size: 89.4 KiB, free: 140.6 MiB)
[2025-05-06T13:00:38.891+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 207) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.891+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 206) in 18 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:38.906+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_248_2 in memory on 172.18.0.4:46559 (size: 86.5 KiB, free: 140.6 MiB)
[2025-05-06T13:00:38.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 208) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 207) in 17 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:38.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_248_3 in memory on 172.18.0.4:46559 (size: 85.4 KiB, free: 140.5 MiB)
[2025-05-06T13:00:38.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 209) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 208) in 17 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:38.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_248_4 in memory on 172.18.0.4:46559 (size: 87.3 KiB, free: 140.4 MiB)
[2025-05-06T13:00:38.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 210) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 209) in 17 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:38.958+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_248_5 in memory on 172.18.0.4:46559 (size: 87.0 KiB, free: 140.3 MiB)
[2025-05-06T13:00:38.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 211) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 210) in 19 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:38.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_248_6 in memory on 172.18.0.4:46559 (size: 85.5 KiB, free: 140.2 MiB)
[2025-05-06T13:00:38.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 212) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 211) in 17 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:38.991+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO BlockManagerInfo: Added rdd_248_7 in memory on 172.18.0.4:46559 (size: 86.6 KiB, free: 140.1 MiB)
[2025-05-06T13:00:38.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Starting task 8.0 in stage 118.0 (TID 213) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:38.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:38 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 212) in 16 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:39.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_248_8 in memory on 172.18.0.4:46559 (size: 84.8 KiB, free: 140.1 MiB)
[2025-05-06T13:00:39.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 9.0 in stage 118.0 (TID 214) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 8.0 in stage 118.0 (TID 213) in 17 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:39.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_248_9 in memory on 172.18.0.4:46559 (size: 82.6 KiB, free: 140.0 MiB)
[2025-05-06T13:00:39.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 9.0 in stage 118.0 (TID 214) in 18 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:39.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-05-06T13:00:39.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: ResultStage 118 (fold at VertexRDDImpl.scala:90) finished in 0.193 s
[2025-05-06T13:00:39.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:39.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 118: Stage finished
[2025-05-06T13:00:39.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Job 43 finished: fold at VertexRDDImpl.scala:90, took 3.348044 s
[2025-05-06T13:00:39.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO Pregel: Pregel finished iteration 0
[2025-05-06T13:00:39.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO ZippedPartitionsRDD2: Removing RDD 231 from persistence list
[2025-05-06T13:00:39.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManager: Removing RDD 231
[2025-05-06T13:00:39.033+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO MapPartitionsRDD: Removing RDD 217 from persistence list
[2025-05-06T13:00:39.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManager: Removing RDD 217
[2025-05-06T13:00:39.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO ZippedPartitionsRDD2: Removing RDD 223 from persistence list
[2025-05-06T13:00:39.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManager: Removing RDD 223
[2025-05-06T13:00:39.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:39.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Registering RDD 255 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 33
[2025-05-06T13:00:39.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Registering RDD 259 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 34
[2025-05-06T13:00:39.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Registering RDD 263 (mapPartitions at GraphImpl.scala:208) as input to shuffle 35
[2025-05-06T13:00:39.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Got job 44 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:39.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Final stage: ResultStage 136 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:39.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135, ShuffleMapStage 132, ShuffleMapStage 129, ShuffleMapStage 125, ShuffleMapStage 126)
[2025-05-06T13:00:39.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 135)
[2025-05-06T13:00:39.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 133 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[255] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:39.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 12.3 KiB, free 425.8 MiB)
[2025-05-06T13:00:39.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 425.8 MiB)
[2025-05-06T13:00:39.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 016737cbcc7e:41421 (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:39.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 016737cbcc7e:41421 in memory (size: 47.8 KiB, free: 434.3 MiB)
[2025-05-06T13:00:39.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:39.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 133 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[255] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:39.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSchedulerImpl: Adding task set 133.0 with 10 tasks resource profile 0
[2025-05-06T13:00:39.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.18.0.4:46559 in memory (size: 47.8 KiB, free: 180.7 MiB)
[2025-05-06T13:00:39.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 134 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[259] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:39.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 215) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 11.6 KiB, free 425.9 MiB)
[2025-05-06T13:00:39.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 425.9 MiB)
[2025-05-06T13:00:39.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 016737cbcc7e:41421 (size: 5.4 KiB, free: 434.3 MiB)
[2025-05-06T13:00:39.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:39.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 134 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[259] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:39.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSchedulerImpl: Adding task set 134.0 with 10 tasks resource profile 0
[2025-05-06T13:00:39.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 016737cbcc7e:41421 in memory (size: 5.6 KiB, free: 434.3 MiB)
[2025-05-06T13:00:39.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.18.0.4:46559 in memory (size: 5.6 KiB, free: 180.7 MiB)
[2025-05-06T13:00:39.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.18.0.4:46559 (size: 5.6 KiB, free: 180.7 MiB)
[2025-05-06T13:00:39.072+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 180.7 MiB)
[2025-05-06T13:00:39.076+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 1.0 in stage 133.0 (TID 216) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 215) in 20 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:39.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 180.7 MiB)
[2025-05-06T13:00:39.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 2.0 in stage 133.0 (TID 217) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 1.0 in stage 133.0 (TID 216) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:39.102+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 180.6 MiB)
[2025-05-06T13:00:39.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 3.0 in stage 133.0 (TID 218) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 2.0 in stage 133.0 (TID 217) in 21 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:39.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 180.6 MiB)
[2025-05-06T13:00:39.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 4.0 in stage 133.0 (TID 219) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 3.0 in stage 133.0 (TID 218) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:39.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 180.6 MiB)
[2025-05-06T13:00:39.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 5.0 in stage 133.0 (TID 220) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 4.0 in stage 133.0 (TID 219) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:39.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 180.6 MiB)
[2025-05-06T13:00:39.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 6.0 in stage 133.0 (TID 221) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 5.0 in stage 133.0 (TID 220) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:39.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 180.6 MiB)
[2025-05-06T13:00:39.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 7.0 in stage 133.0 (TID 222) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 6.0 in stage 133.0 (TID 221) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:39.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 180.6 MiB)
[2025-05-06T13:00:39.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 8.0 in stage 133.0 (TID 223) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 7.0 in stage 133.0 (TID 222) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:39.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 180.6 MiB)
[2025-05-06T13:00:39.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 9.0 in stage 133.0 (TID 224) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 8.0 in stage 133.0 (TID 223) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:39.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_251_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 180.5 MiB)
[2025-05-06T13:00:39.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 225) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 9.0 in stage 133.0 (TID 224) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:39.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool
[2025-05-06T13:00:39.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: ShuffleMapStage 133 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.123 s
[2025-05-06T13:00:39.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:39.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: running: Set(ShuffleMapStage 134)
[2025-05-06T13:00:39.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 135, ResultStage 136)
[2025-05-06T13:00:39.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:39.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.18.0.4:46559 (size: 5.4 KiB, free: 180.5 MiB)
[2025-05-06T13:00:39.188+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 226) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.188+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 225) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:39.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 227) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 226) in 16 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:39.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 228) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 227) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:39.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 4.0 in stage 134.0 (TID 229) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.231+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 228) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:39.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 5.0 in stage 134.0 (TID 230) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 4.0 in stage 134.0 (TID 229) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:39.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 6.0 in stage 134.0 (TID 231) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 5.0 in stage 134.0 (TID 230) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:39.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 7.0 in stage 134.0 (TID 232) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 6.0 in stage 134.0 (TID 231) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:39.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 8.0 in stage 134.0 (TID 233) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 7.0 in stage 134.0 (TID 232) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:39.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 9.0 in stage 134.0 (TID 234) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 8.0 in stage 134.0 (TID 233) in 18 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:39.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 9.0 in stage 134.0 (TID 234) in 17 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:39.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool
[2025-05-06T13:00:39.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: ShuffleMapStage 134 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.259 s
[2025-05-06T13:00:39.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:39.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:39.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 135, ResultStage 136)
[2025-05-06T13:00:39.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:39.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[263] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:39.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 120.7 KiB, free 425.8 MiB)
[2025-05-06T13:00:39.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.8 MiB)
[2025-05-06T13:00:39.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 016737cbcc7e:41421 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:39.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 016737cbcc7e:41421 in memory (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:39.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:39.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[263] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:39.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSchedulerImpl: Adding task set 135.0 with 10 tasks resource profile 0
[2025-05-06T13:00:39.329+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 235) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.329+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.18.0.4:46559 in memory (size: 5.6 KiB, free: 180.5 MiB)
[2025-05-06T13:00:39.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.18.0.4:46559 (size: 47.9 KiB, free: 180.5 MiB)
[2025-05-06T13:00:39.344+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.18.0.4:47760
[2025-05-06T13:00:39.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 180.0 MiB)
[2025-05-06T13:00:39.350+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.18.0.4:47760
[2025-05-06T13:00:39.416+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 236) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.416+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 235) in 87 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:39.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 179.4 MiB)
[2025-05-06T13:00:39.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 237) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 236) in 72 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:39.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 178.8 MiB)
[2025-05-06T13:00:39.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 238) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 237) in 66 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:39.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 178.3 MiB)
[2025-05-06T13:00:39.617+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 4.0 in stage 135.0 (TID 239) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 238) in 65 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:39.624+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 177.9 MiB)
[2025-05-06T13:00:39.669+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 5.0 in stage 135.0 (TID 240) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.670+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 4.0 in stage 135.0 (TID 239) in 53 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:39.680+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 177.4 MiB)
[2025-05-06T13:00:39.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 6.0 in stage 135.0 (TID 241) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 5.0 in stage 135.0 (TID 240) in 64 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:39.740+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 176.8 MiB)
[2025-05-06T13:00:39.798+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 7.0 in stage 135.0 (TID 242) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.798+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 6.0 in stage 135.0 (TID 241) in 65 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:39.805+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 176.3 MiB)
[2025-05-06T13:00:39.868+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 8.0 in stage 135.0 (TID 243) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.868+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 7.0 in stage 135.0 (TID 242) in 69 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:39.875+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 175.7 MiB)
[2025-05-06T13:00:39.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Starting task 9.0 in stage 135.0 (TID 244) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:39.935+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO TaskSetManager: Finished task 8.0 in stage 135.0 (TID 243) in 67 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:39.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:39 INFO BlockManagerInfo: Added rdd_257_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 175.1 MiB)
[2025-05-06T13:00:40.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 9.0 in stage 135.0 (TID 244) in 76 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:40.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool
[2025-05-06T13:00:40.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: ShuffleMapStage 135 (mapPartitions at GraphImpl.scala:208) finished in 0.693 s
[2025-05-06T13:00:40.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:40.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:40.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: waiting: Set(ResultStage 136)
[2025-05-06T13:00:40.011+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:40.011+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[267] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:40.012+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 12.9 KiB, free 425.8 MiB)
[2025-05-06T13:00:40.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 425.8 MiB)
[2025-05-06T13:00:40.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 016737cbcc7e:41421 (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:40.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 016737cbcc7e:41421 in memory (size: 5.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:40.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:40.018+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 136 (MapPartitionsRDD[267] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:40.018+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSchedulerImpl: Adding task set 136.0 with 10 tasks resource profile 0
[2025-05-06T13:00:40.018+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.18.0.4:46559 in memory (size: 5.4 KiB, free: 175.1 MiB)
[2025-05-06T13:00:40.019+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 245) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.023+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.18.0.4:46559 (size: 5.8 KiB, free: 175.1 MiB)
[2025-05-06T13:00:40.026+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.18.0.4:47760
[2025-05-06T13:00:40.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_0 in memory on 172.18.0.4:46559 (size: 37.2 KiB, free: 175.1 MiB)
[2025-05-06T13:00:40.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 246) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 245) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:40.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_1 in memory on 172.18.0.4:46559 (size: 36.8 KiB, free: 175.0 MiB)
[2025-05-06T13:00:40.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 2.0 in stage 136.0 (TID 247) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 246) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:40.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_2 in memory on 172.18.0.4:46559 (size: 35.9 KiB, free: 175.0 MiB)
[2025-05-06T13:00:40.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 3.0 in stage 136.0 (TID 248) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 2.0 in stage 136.0 (TID 247) in 17 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:40.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_3 in memory on 172.18.0.4:46559 (size: 35.9 KiB, free: 175.0 MiB)
[2025-05-06T13:00:40.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 4.0 in stage 136.0 (TID 249) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 3.0 in stage 136.0 (TID 248) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:40.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_4 in memory on 172.18.0.4:46559 (size: 36.2 KiB, free: 174.9 MiB)
[2025-05-06T13:00:40.102+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 5.0 in stage 136.0 (TID 250) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.103+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 4.0 in stage 136.0 (TID 249) in 31 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:40.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_5 in memory on 172.18.0.4:46559 (size: 35.9 KiB, free: 174.9 MiB)
[2025-05-06T13:00:40.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 6.0 in stage 136.0 (TID 251) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 5.0 in stage 136.0 (TID 250) in 19 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:40.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_6 in memory on 172.18.0.4:46559 (size: 35.7 KiB, free: 174.9 MiB)
[2025-05-06T13:00:40.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 7.0 in stage 136.0 (TID 252) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 6.0 in stage 136.0 (TID 251) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:40.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_7 in memory on 172.18.0.4:46559 (size: 35.7 KiB, free: 174.8 MiB)
[2025-05-06T13:00:40.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 8.0 in stage 136.0 (TID 253) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 7.0 in stage 136.0 (TID 252) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:40.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_8 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 174.8 MiB)
[2025-05-06T13:00:40.149+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 9.0 in stage 136.0 (TID 254) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.149+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 8.0 in stage 136.0 (TID 253) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:40.159+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_265_9 in memory on 172.18.0.4:46559 (size: 34.2 KiB, free: 174.8 MiB)
[2025-05-06T13:00:40.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 9.0 in stage 136.0 (TID 254) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:40.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-05-06T13:00:40.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: ResultStage 136 (fold at VertexRDDImpl.scala:90) finished in 0.150 s
[2025-05-06T13:00:40.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:40.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished
[2025-05-06T13:00:40.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Job 44 finished: fold at VertexRDDImpl.scala:90, took 1.115818 s
[2025-05-06T13:00:40.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO Pregel: Pregel finished iteration 1
[2025-05-06T13:00:40.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO ZippedPartitionsRDD2: Removing RDD 248 from persistence list
[2025-05-06T13:00:40.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO ZippedPartitionsRDD2: Removing RDD 234 from persistence list
[2025-05-06T13:00:40.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManager: Removing RDD 248
[2025-05-06T13:00:40.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO ZippedPartitionsRDD2: Removing RDD 240 from persistence list
[2025-05-06T13:00:40.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManager: Removing RDD 234
[2025-05-06T13:00:40.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManager: Removing RDD 240
[2025-05-06T13:00:40.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MapPartitionsRDD: Removing RDD 217 from persistence list
[2025-05-06T13:00:40.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO ZippedPartitionsRDD2: Removing RDD 227 from persistence list
[2025-05-06T13:00:40.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManager: Removing RDD 217
[2025-05-06T13:00:40.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManager: Removing RDD 227
[2025-05-06T13:00:40.174+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO ZippedPartitionsRDD2: Removing RDD 231 from persistence list
[2025-05-06T13:00:40.175+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManager: Removing RDD 231
[2025-05-06T13:00:40.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:40.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Registering RDD 272 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 36
[2025-05-06T13:00:40.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Registering RDD 276 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 37
[2025-05-06T13:00:40.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Registering RDD 280 (mapPartitions at GraphImpl.scala:208) as input to shuffle 38
[2025-05-06T13:00:40.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Got job 45 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:40.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Final stage: ResultStage 157 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:40.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143, ShuffleMapStage 153, ShuffleMapStage 150, ShuffleMapStage 147, ShuffleMapStage 144, ShuffleMapStage 156)
[2025-05-06T13:00:40.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 156)
[2025-05-06T13:00:40.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 154 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[272] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:40.182+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 12.9 KiB, free 425.8 MiB)
[2025-05-06T13:00:40.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 425.8 MiB)
[2025-05-06T13:00:40.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 016737cbcc7e:41421 (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:40.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 016737cbcc7e:41421 in memory (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:40.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.18.0.4:46559 in memory (size: 5.8 KiB, free: 181.1 MiB)
[2025-05-06T13:00:40.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:40.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 154 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[272] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:40.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSchedulerImpl: Adding task set 154.0 with 10 tasks resource profile 0
[2025-05-06T13:00:40.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 155 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[276] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:40.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 255) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 12.2 KiB, free 425.8 MiB)
[2025-05-06T13:00:40.197+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 425.8 MiB)
[2025-05-06T13:00:40.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 016737cbcc7e:41421 (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:40.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:40.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 155 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[276] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:40.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSchedulerImpl: Adding task set 155.0 with 10 tasks resource profile 0
[2025-05-06T13:00:40.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 016737cbcc7e:41421 in memory (size: 47.9 KiB, free: 434.3 MiB)
[2025-05-06T13:00:40.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.18.0.4:46559 in memory (size: 47.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:40.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.18.0.4:46559 (size: 5.7 KiB, free: 181.2 MiB)
[2025-05-06T13:00:40.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:40.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 256) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 255) in 37 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:40.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 181.1 MiB)
[2025-05-06T13:00:40.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 257) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 256) in 22 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:40.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:00:40.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 258) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.253+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 257) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:40.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:40.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 259) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 258) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:40.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:40.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 5.0 in stage 154.0 (TID 260) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.267+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 259) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:40.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:40.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 6.0 in stage 154.0 (TID 261) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 5.0 in stage 154.0 (TID 260) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:40.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:40.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 7.0 in stage 154.0 (TID 262) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 6.0 in stage 154.0 (TID 261) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:40.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:00:40.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 8.0 in stage 154.0 (TID 263) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 7.0 in stage 154.0 (TID 262) in 6 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:40.290+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 181.0 MiB)
[2025-05-06T13:00:40.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 9.0 in stage 154.0 (TID 264) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 8.0 in stage 154.0 (TID 263) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:40.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_268_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:40.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 265) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 9.0 in stage 154.0 (TID 264) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:40.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool
[2025-05-06T13:00:40.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: ShuffleMapStage 154 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.120 s
[2025-05-06T13:00:40.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:40.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: running: Set(ShuffleMapStage 155)
[2025-05-06T13:00:40.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: waiting: Set(ResultStage 157, ShuffleMapStage 156)
[2025-05-06T13:00:40.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:40.304+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.18.0.4:46559 (size: 5.6 KiB, free: 181.0 MiB)
[2025-05-06T13:00:40.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 266) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 265) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:40.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 267) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 266) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:40.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 268) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.338+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 267) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:40.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 4.0 in stage 155.0 (TID 269) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 268) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:40.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 5.0 in stage 155.0 (TID 270) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 4.0 in stage 155.0 (TID 269) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:40.368+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 6.0 in stage 155.0 (TID 271) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.369+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 5.0 in stage 155.0 (TID 270) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:40.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 7.0 in stage 155.0 (TID 272) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 6.0 in stage 155.0 (TID 271) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:40.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 8.0 in stage 155.0 (TID 273) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 7.0 in stage 155.0 (TID 272) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:40.399+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 9.0 in stage 155.0 (TID 274) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.399+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 8.0 in stage 155.0 (TID 273) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 9.0 in stage 155.0 (TID 274) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool
[2025-05-06T13:00:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: ShuffleMapStage 155 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.215 s
[2025-05-06T13:00:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: waiting: Set(ResultStage 157, ShuffleMapStage 156)
[2025-05-06T13:00:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 156 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[280] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:40.413+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 121.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:40.419+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.8 MiB)
[2025-05-06T13:00:40.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 016737cbcc7e:41421 in memory (size: 5.7 KiB, free: 434.3 MiB)
[2025-05-06T13:00:40.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 016737cbcc7e:41421 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:40.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:40.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 156 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[280] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:40.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSchedulerImpl: Adding task set 156.0 with 10 tasks resource profile 0
[2025-05-06T13:00:40.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 275) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.18.0.4:46559 in memory (size: 5.7 KiB, free: 181.0 MiB)
[2025-05-06T13:00:40.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.18.0.4:46559 (size: 47.9 KiB, free: 181.0 MiB)
[2025-05-06T13:00:40.430+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.18.0.4:47760
[2025-05-06T13:00:40.433+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_274_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:00:40.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.18.0.4:47760
[2025-05-06T13:00:40.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 276) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 275) in 71 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:40.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_274_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:00:40.561+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 277) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.561+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 276) in 70 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:40.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_274_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 179.3 MiB)
[2025-05-06T13:00:40.626+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 278) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.626+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 277) in 66 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:40.632+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_274_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:00:40.686+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 4.0 in stage 156.0 (TID 279) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.686+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 278) in 61 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:40.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_274_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:00:40.761+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 5.0 in stage 156.0 (TID 280) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.761+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 4.0 in stage 156.0 (TID 279) in 76 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:40.768+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_274_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:00:40.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 6.0 in stage 156.0 (TID 281) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 5.0 in stage 156.0 (TID 280) in 62 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:40.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_274_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:00:40.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 7.0 in stage 156.0 (TID 282) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 6.0 in stage 156.0 (TID 281) in 61 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:40.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_274_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:00:40.957+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Starting task 8.0 in stage 156.0 (TID 283) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:40.957+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO TaskSetManager: Finished task 7.0 in stage 156.0 (TID 282) in 75 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:40.965+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:40 INFO BlockManagerInfo: Added rdd_274_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:00:41.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 9.0 in stage 156.0 (TID 284) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 8.0 in stage 156.0 (TID 283) in 90 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:41.053+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_274_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:00:41.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 9.0 in stage 156.0 (TID 284) in 74 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:41.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool
[2025-05-06T13:00:41.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: ShuffleMapStage 156 (mapPartitions at GraphImpl.scala:208) finished in 0.708 s
[2025-05-06T13:00:41.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:41.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:41.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: waiting: Set(ResultStage 157)
[2025-05-06T13:00:41.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:41.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[284] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:41.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 13.5 KiB, free 425.8 MiB)
[2025-05-06T13:00:41.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T13:00:41.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 016737cbcc7e:41421 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:41.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 016737cbcc7e:41421 in memory (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:41.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:41.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 157 (MapPartitionsRDD[284] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:41.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSchedulerImpl: Adding task set 157.0 with 10 tasks resource profile 0
[2025-05-06T13:00:41.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.18.0.4:46559 in memory (size: 5.6 KiB, free: 175.6 MiB)
[2025-05-06T13:00:41.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 285) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.18.0.4:46559 (size: 5.9 KiB, free: 175.6 MiB)
[2025-05-06T13:00:41.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.18.0.4:47760
[2025-05-06T13:00:41.149+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_0 in memory on 172.18.0.4:46559 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:41.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 286) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 285) in 20 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:41.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_1 in memory on 172.18.0.4:46559 (size: 35.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:41.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 2.0 in stage 157.0 (TID 287) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 286) in 18 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:41.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_2 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:41.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 3.0 in stage 157.0 (TID 288) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 2.0 in stage 157.0 (TID 287) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:41.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_3 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:41.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 4.0 in stage 157.0 (TID 289) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 3.0 in stage 157.0 (TID 288) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:41.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_4 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:41.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 5.0 in stage 157.0 (TID 290) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 4.0 in stage 157.0 (TID 289) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:41.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_5 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:41.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 6.0 in stage 157.0 (TID 291) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 5.0 in stage 157.0 (TID 290) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:41.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_6 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:00:41.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 7.0 in stage 157.0 (TID 292) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 6.0 in stage 157.0 (TID 291) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:41.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_7 in memory on 172.18.0.4:46559 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:00:41.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 8.0 in stage 157.0 (TID 293) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 7.0 in stage 157.0 (TID 292) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:41.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_8 in memory on 172.18.0.4:46559 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:00:41.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 9.0 in stage 157.0 (TID 294) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 8.0 in stage 157.0 (TID 293) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:41.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_282_9 in memory on 172.18.0.4:46559 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:00:41.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 9.0 in stage 157.0 (TID 294) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:41.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool
[2025-05-06T13:00:41.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: ResultStage 157 (fold at VertexRDDImpl.scala:90) finished in 0.130 s
[2025-05-06T13:00:41.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:41.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 157: Stage finished
[2025-05-06T13:00:41.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Job 45 finished: fold at VertexRDDImpl.scala:90, took 1.072297 s
[2025-05-06T13:00:41.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO Pregel: Pregel finished iteration 2
[2025-05-06T13:00:41.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO ZippedPartitionsRDD2: Removing RDD 265 from persistence list
[2025-05-06T13:00:41.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO ZippedPartitionsRDD2: Removing RDD 251 from persistence list
[2025-05-06T13:00:41.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManager: Removing RDD 265
[2025-05-06T13:00:41.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO ZippedPartitionsRDD2: Removing RDD 257 from persistence list
[2025-05-06T13:00:41.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManager: Removing RDD 251
[2025-05-06T13:00:41.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManager: Removing RDD 257
[2025-05-06T13:00:41.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO ZippedPartitionsRDD2: Removing RDD 234 from persistence list
[2025-05-06T13:00:41.259+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO ZippedPartitionsRDD2: Removing RDD 240 from persistence list
[2025-05-06T13:00:41.259+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManager: Removing RDD 234
[2025-05-06T13:00:41.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManager: Removing RDD 240
[2025-05-06T13:00:41.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO ZippedPartitionsRDD2: Removing RDD 248 from persistence list
[2025-05-06T13:00:41.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManager: Removing RDD 248
[2025-05-06T13:00:41.267+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:41.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Registering RDD 289 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 39
[2025-05-06T13:00:41.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Registering RDD 293 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 40
[2025-05-06T13:00:41.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Registering RDD 297 (mapPartitions at GraphImpl.scala:208) as input to shuffle 41
[2025-05-06T13:00:41.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Got job 46 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:41.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Final stage: ResultStage 181 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:41.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 171, ShuffleMapStage 168, ShuffleMapStage 165, ShuffleMapStage 180, ShuffleMapStage 159, ShuffleMapStage 174, ShuffleMapStage 177)
[2025-05-06T13:00:41.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 180)
[2025-05-06T13:00:41.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Submitting ShuffleMapStage 178 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[289] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:41.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 13.6 KiB, free 425.8 MiB)
[2025-05-06T13:00:41.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T13:00:41.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 016737cbcc7e:41421 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:41.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 016737cbcc7e:41421 in memory (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:41.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:41.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 178 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[289] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:41.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSchedulerImpl: Adding task set 178.0 with 10 tasks resource profile 0
[2025-05-06T13:00:41.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Submitting ShuffleMapStage 179 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[293] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:41.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.18.0.4:46559 in memory (size: 5.9 KiB, free: 181.1 MiB)
[2025-05-06T13:00:41.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 12.9 KiB, free 425.8 MiB)
[2025-05-06T13:00:41.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 295) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 425.8 MiB)
[2025-05-06T13:00:41.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 016737cbcc7e:41421 (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:41.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:41.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 179 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[293] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:41.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSchedulerImpl: Adding task set 179.0 with 10 tasks resource profile 0
[2025-05-06T13:00:41.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 016737cbcc7e:41421 in memory (size: 47.9 KiB, free: 434.3 MiB)
[2025-05-06T13:00:41.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.18.0.4:46559 in memory (size: 47.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:41.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.18.0.4:46559 (size: 5.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:41.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:41.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 1.0 in stage 178.0 (TID 296) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 295) in 19 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:41.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:00:41.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 2.0 in stage 178.0 (TID 297) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.318+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 1.0 in stage 178.0 (TID 296) in 16 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:41.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:00:41.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 3.0 in stage 178.0 (TID 298) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 2.0 in stage 178.0 (TID 297) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:41.333+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:41.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 4.0 in stage 178.0 (TID 299) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 3.0 in stage 178.0 (TID 298) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:41.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:41.343+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 5.0 in stage 178.0 (TID 300) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.344+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 4.0 in stage 178.0 (TID 299) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:41.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:41.351+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 6.0 in stage 178.0 (TID 301) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.351+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 5.0 in stage 178.0 (TID 300) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:41.354+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:41.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 7.0 in stage 178.0 (TID 302) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.358+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 6.0 in stage 178.0 (TID 301) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:41.363+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:00:41.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 8.0 in stage 178.0 (TID 303) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 7.0 in stage 178.0 (TID 302) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:41.370+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:00:41.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 9.0 in stage 178.0 (TID 304) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 8.0 in stage 178.0 (TID 303) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:41.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_285_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:41.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 305) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.382+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 9.0 in stage 178.0 (TID 304) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:41.382+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool
[2025-05-06T13:00:41.382+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: ShuffleMapStage 178 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.111 s
[2025-05-06T13:00:41.382+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:41.382+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: running: Set(ShuffleMapStage 179)
[2025-05-06T13:00:41.382+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 180, ResultStage 181)
[2025-05-06T13:00:41.382+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:41.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.18.0.4:46559 (size: 5.7 KiB, free: 181.0 MiB)
[2025-05-06T13:00:41.395+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 1.0 in stage 179.0 (TID 306) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.396+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 305) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:41.406+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 2.0 in stage 179.0 (TID 307) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 1.0 in stage 179.0 (TID 306) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:41.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 3.0 in stage 179.0 (TID 308) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 2.0 in stage 179.0 (TID 307) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:41.428+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 4.0 in stage 179.0 (TID 309) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.429+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 3.0 in stage 179.0 (TID 308) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:41.440+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 5.0 in stage 179.0 (TID 310) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.441+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 4.0 in stage 179.0 (TID 309) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:41.451+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 6.0 in stage 179.0 (TID 311) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.451+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 5.0 in stage 179.0 (TID 310) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:41.463+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 7.0 in stage 179.0 (TID 312) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.463+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 6.0 in stage 179.0 (TID 311) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:41.474+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 8.0 in stage 179.0 (TID 313) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.474+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 7.0 in stage 179.0 (TID 312) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:41.485+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 9.0 in stage 179.0 (TID 314) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.485+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 8.0 in stage 179.0 (TID 313) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:41.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 9.0 in stage 179.0 (TID 314) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:41.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool
[2025-05-06T13:00:41.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: ShuffleMapStage 179 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.217 s
[2025-05-06T13:00:41.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:41.500+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:41.500+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 180, ResultStage 181)
[2025-05-06T13:00:41.500+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:41.500+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Submitting ShuffleMapStage 180 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[297] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:41.502+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 121.3 KiB, free 425.8 MiB)
[2025-05-06T13:00:41.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:41.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 016737cbcc7e:41421 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:41.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 016737cbcc7e:41421 in memory (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:41.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:41.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 180 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[297] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:41.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSchedulerImpl: Adding task set 180.0 with 10 tasks resource profile 0
[2025-05-06T13:00:41.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.18.0.4:46559 in memory (size: 5.9 KiB, free: 181.0 MiB)
[2025-05-06T13:00:41.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 315) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.519+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.18.0.4:46559 (size: 48.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:41.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.18.0.4:47760
[2025-05-06T13:00:41.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_291_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:00:41.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.18.0.4:47760
[2025-05-06T13:00:41.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 1.0 in stage 180.0 (TID 316) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 315) in 98 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:41.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_291_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:00:41.687+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 2.0 in stage 180.0 (TID 317) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 1.0 in stage 180.0 (TID 316) in 75 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:41.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_291_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:00:41.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 3.0 in stage 180.0 (TID 318) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 2.0 in stage 180.0 (TID 317) in 63 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:41.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_291_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:00:41.808+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 4.0 in stage 180.0 (TID 319) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.809+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 3.0 in stage 180.0 (TID 318) in 58 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:41.815+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_291_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:00:41.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 5.0 in stage 180.0 (TID 320) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 4.0 in stage 180.0 (TID 319) in 51 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:41.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_291_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:00:41.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 6.0 in stage 180.0 (TID 321) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.916+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 5.0 in stage 180.0 (TID 320) in 56 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:41.922+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_291_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:00:41.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Starting task 7.0 in stage 180.0 (TID 322) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:41.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO TaskSetManager: Finished task 6.0 in stage 180.0 (TID 321) in 65 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:41.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:41 INFO BlockManagerInfo: Added rdd_291_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:00:42.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 8.0 in stage 180.0 (TID 323) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 7.0 in stage 180.0 (TID 322) in 68 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:42.054+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_291_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:00:42.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 9.0 in stage 180.0 (TID 324) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 8.0 in stage 180.0 (TID 323) in 65 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:42.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_291_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:00:42.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 9.0 in stage 180.0 (TID 324) in 72 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:42.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool
[2025-05-06T13:00:42.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: ShuffleMapStage 180 (mapPartitions at GraphImpl.scala:208) finished in 0.683 s
[2025-05-06T13:00:42.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:42.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:42.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: waiting: Set(ResultStage 181)
[2025-05-06T13:00:42.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:42.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[301] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:42.185+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 14.2 KiB, free 425.8 MiB)
[2025-05-06T13:00:42.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:42.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 016737cbcc7e:41421 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:42.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 016737cbcc7e:41421 in memory (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:42.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:42.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 181 (MapPartitionsRDD[301] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:42.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSchedulerImpl: Adding task set 181.0 with 10 tasks resource profile 0
[2025-05-06T13:00:42.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.18.0.4:46559 in memory (size: 5.7 KiB, free: 175.6 MiB)
[2025-05-06T13:00:42.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 325) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.18.0.4:46559 (size: 6.0 KiB, free: 175.6 MiB)
[2025-05-06T13:00:42.197+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.18.0.4:47760
[2025-05-06T13:00:42.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_0 in memory on 172.18.0.4:46559 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:42.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 1.0 in stage 181.0 (TID 326) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 325) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:42.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_1 in memory on 172.18.0.4:46559 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:00:42.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 2.0 in stage 181.0 (TID 327) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 1.0 in stage 181.0 (TID 326) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:42.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_2 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:42.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 3.0 in stage 181.0 (TID 328) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 2.0 in stage 181.0 (TID 327) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:42.237+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_3 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:42.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 4.0 in stage 181.0 (TID 329) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 3.0 in stage 181.0 (TID 328) in 17 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:42.246+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_4 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.5 MiB)
[2025-05-06T13:00:42.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 5.0 in stage 181.0 (TID 330) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 4.0 in stage 181.0 (TID 329) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:42.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_5 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:42.257+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 6.0 in stage 181.0 (TID 331) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.257+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 5.0 in stage 181.0 (TID 330) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:42.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_6 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:00:42.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 7.0 in stage 181.0 (TID 332) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 6.0 in stage 181.0 (TID 331) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:42.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_7 in memory on 172.18.0.4:46559 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:00:42.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 8.0 in stage 181.0 (TID 333) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 7.0 in stage 181.0 (TID 332) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:42.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_8 in memory on 172.18.0.4:46559 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:00:42.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 9.0 in stage 181.0 (TID 334) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 8.0 in stage 181.0 (TID 333) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:42.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_299_9 in memory on 172.18.0.4:46559 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:00:42.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 9.0 in stage 181.0 (TID 334) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:42.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool
[2025-05-06T13:00:42.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: ResultStage 181 (fold at VertexRDDImpl.scala:90) finished in 0.107 s
[2025-05-06T13:00:42.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:42.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished
[2025-05-06T13:00:42.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Job 46 finished: fold at VertexRDDImpl.scala:90, took 1.023790 s
[2025-05-06T13:00:42.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO Pregel: Pregel finished iteration 3
[2025-05-06T13:00:42.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO ZippedPartitionsRDD2: Removing RDD 282 from persistence list
[2025-05-06T13:00:42.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO ZippedPartitionsRDD2: Removing RDD 268 from persistence list
[2025-05-06T13:00:42.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManager: Removing RDD 282
[2025-05-06T13:00:42.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManager: Removing RDD 268
[2025-05-06T13:00:42.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO ZippedPartitionsRDD2: Removing RDD 274 from persistence list
[2025-05-06T13:00:42.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManager: Removing RDD 274
[2025-05-06T13:00:42.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO ZippedPartitionsRDD2: Removing RDD 251 from persistence list
[2025-05-06T13:00:42.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManager: Removing RDD 251
[2025-05-06T13:00:42.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO ZippedPartitionsRDD2: Removing RDD 257 from persistence list
[2025-05-06T13:00:42.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManager: Removing RDD 257
[2025-05-06T13:00:42.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO ZippedPartitionsRDD2: Removing RDD 265 from persistence list
[2025-05-06T13:00:42.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManager: Removing RDD 265
[2025-05-06T13:00:42.305+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:42.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Registering RDD 306 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 42
[2025-05-06T13:00:42.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Registering RDD 310 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 43
[2025-05-06T13:00:42.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Registering RDD 314 (mapPartitions at GraphImpl.scala:208) as input to shuffle 44
[2025-05-06T13:00:42.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Got job 47 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:42.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Final stage: ResultStage 208 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:42.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 204, ShuffleMapStage 183, ShuffleMapStage 198, ShuffleMapStage 201, ShuffleMapStage 195, ShuffleMapStage 192, ShuffleMapStage 189, ShuffleMapStage 207)
[2025-05-06T13:00:42.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 207)
[2025-05-06T13:00:42.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Submitting ShuffleMapStage 205 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[306] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:42.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 14.2 KiB, free 425.8 MiB)
[2025-05-06T13:00:42.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:42.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 016737cbcc7e:41421 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:42.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 016737cbcc7e:41421 in memory (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:42.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:42.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 205 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[306] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:42.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSchedulerImpl: Adding task set 205.0 with 10 tasks resource profile 0
[2025-05-06T13:00:42.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.18.0.4:46559 in memory (size: 6.0 KiB, free: 181.1 MiB)
[2025-05-06T13:00:42.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Submitting ShuffleMapStage 206 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[310] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:42.318+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 335) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 13.5 KiB, free 425.8 MiB)
[2025-05-06T13:00:42.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 425.8 MiB)
[2025-05-06T13:00:42.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 016737cbcc7e:41421 (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:42.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:42.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 206 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[310] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:42.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSchedulerImpl: Adding task set 206.0 with 10 tasks resource profile 0
[2025-05-06T13:00:42.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 016737cbcc7e:41421 in memory (size: 48.0 KiB, free: 434.3 MiB)
[2025-05-06T13:00:42.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.18.0.4:46559 in memory (size: 48.0 KiB, free: 181.2 MiB)
[2025-05-06T13:00:42.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.18.0.4:46559 (size: 6.0 KiB, free: 181.2 MiB)
[2025-05-06T13:00:42.329+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:42.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 1.0 in stage 205.0 (TID 336) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 335) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:42.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:00:42.343+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 2.0 in stage 205.0 (TID 337) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.343+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 1.0 in stage 205.0 (TID 336) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:42.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:00:42.360+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 3.0 in stage 205.0 (TID 338) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.361+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 2.0 in stage 205.0 (TID 337) in 18 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:42.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:42.370+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 4.0 in stage 205.0 (TID 339) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.370+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 3.0 in stage 205.0 (TID 338) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:42.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:42.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 5.0 in stage 205.0 (TID 340) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 4.0 in stage 205.0 (TID 339) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:42.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:42.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 6.0 in stage 205.0 (TID 341) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 5.0 in stage 205.0 (TID 340) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:42.387+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:42.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 7.0 in stage 205.0 (TID 342) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 6.0 in stage 205.0 (TID 341) in 6 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:42.394+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:00:42.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 8.0 in stage 205.0 (TID 343) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 7.0 in stage 205.0 (TID 342) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:42.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:00:42.404+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 9.0 in stage 205.0 (TID 344) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.404+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 8.0 in stage 205.0 (TID 343) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:42.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_302_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:42.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 345) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 9.0 in stage 205.0 (TID 344) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:42.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool
[2025-05-06T13:00:42.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: ShuffleMapStage 205 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.102 s
[2025-05-06T13:00:42.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:42.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: running: Set(ShuffleMapStage 206)
[2025-05-06T13:00:42.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: waiting: Set(ResultStage 208, ShuffleMapStage 207)
[2025-05-06T13:00:42.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:42.414+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.18.0.4:46559 (size: 5.8 KiB, free: 181.0 MiB)
[2025-05-06T13:00:42.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 1.0 in stage 206.0 (TID 346) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.424+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 345) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:42.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 2.0 in stage 206.0 (TID 347) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 1.0 in stage 206.0 (TID 346) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:42.446+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 3.0 in stage 206.0 (TID 348) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.446+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 2.0 in stage 206.0 (TID 347) in 13 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:42.454+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 4.0 in stage 206.0 (TID 349) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 3.0 in stage 206.0 (TID 348) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:42.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 5.0 in stage 206.0 (TID 350) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 4.0 in stage 206.0 (TID 349) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:42.473+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 6.0 in stage 206.0 (TID 351) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.473+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 5.0 in stage 206.0 (TID 350) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:42.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 7.0 in stage 206.0 (TID 352) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 6.0 in stage 206.0 (TID 351) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:42.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 8.0 in stage 206.0 (TID 353) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 7.0 in stage 206.0 (TID 352) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:42.502+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 9.0 in stage 206.0 (TID 354) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.503+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 8.0 in stage 206.0 (TID 353) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:42.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 9.0 in stage 206.0 (TID 354) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:42.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool
[2025-05-06T13:00:42.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: ShuffleMapStage 206 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.197 s
[2025-05-06T13:00:42.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:42.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:42.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: waiting: Set(ResultStage 208, ShuffleMapStage 207)
[2025-05-06T13:00:42.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:42.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Submitting ShuffleMapStage 207 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[314] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:42.517+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 121.5 KiB, free 425.8 MiB)
[2025-05-06T13:00:42.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 016737cbcc7e:41421 in memory (size: 6.0 KiB, free: 434.3 MiB)
[2025-05-06T13:00:42.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:42.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 016737cbcc7e:41421 (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:42.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:42.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 207 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[314] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:42.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSchedulerImpl: Adding task set 207.0 with 10 tasks resource profile 0
[2025-05-06T13:00:42.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.18.0.4:46559 in memory (size: 6.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:42.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 355) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.529+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.18.0.4:46559 (size: 48.1 KiB, free: 181.0 MiB)
[2025-05-06T13:00:42.535+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.18.0.4:47760
[2025-05-06T13:00:42.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_308_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:00:42.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.18.0.4:47760
[2025-05-06T13:00:42.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 1.0 in stage 207.0 (TID 356) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 355) in 68 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:42.600+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_308_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:00:42.661+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 2.0 in stage 207.0 (TID 357) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.661+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 1.0 in stage 207.0 (TID 356) in 68 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:42.667+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_308_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:00:42.722+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 3.0 in stage 207.0 (TID 358) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.722+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 2.0 in stage 207.0 (TID 357) in 62 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:42.728+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_308_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:00:42.781+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 4.0 in stage 207.0 (TID 359) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.781+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 3.0 in stage 207.0 (TID 358) in 59 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:42.787+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_308_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:00:42.832+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 5.0 in stage 207.0 (TID 360) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 4.0 in stage 207.0 (TID 359) in 51 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:42.838+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_308_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:00:42.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 6.0 in stage 207.0 (TID 361) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.894+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 5.0 in stage 207.0 (TID 360) in 61 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:42.902+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_308_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:00:42.956+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Starting task 7.0 in stage 207.0 (TID 362) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:42.956+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO TaskSetManager: Finished task 6.0 in stage 207.0 (TID 361) in 63 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:42.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:42 INFO BlockManagerInfo: Added rdd_308_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:00:43.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 8.0 in stage 207.0 (TID 363) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.021+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 7.0 in stage 207.0 (TID 362) in 65 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:43.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_308_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:00:43.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 9.0 in stage 207.0 (TID 364) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 8.0 in stage 207.0 (TID 363) in 60 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:43.086+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_308_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:00:43.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 9.0 in stage 207.0 (TID 364) in 63 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:43.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool
[2025-05-06T13:00:43.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: ShuffleMapStage 207 (mapPartitions at GraphImpl.scala:208) finished in 0.629 s
[2025-05-06T13:00:43.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:43.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:43.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: waiting: Set(ResultStage 208)
[2025-05-06T13:00:43.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:43.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Submitting ResultStage 208 (MapPartitionsRDD[318] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:43.145+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 14.8 KiB, free 425.8 MiB)
[2025-05-06T13:00:43.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 016737cbcc7e:41421 in memory (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:43.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:43.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 016737cbcc7e:41421 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:43.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:43.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 208 (MapPartitionsRDD[318] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:43.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSchedulerImpl: Adding task set 208.0 with 10 tasks resource profile 0
[2025-05-06T13:00:43.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.18.0.4:46559 in memory (size: 5.8 KiB, free: 175.6 MiB)
[2025-05-06T13:00:43.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 365) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.18.0.4:46559 (size: 6.1 KiB, free: 175.6 MiB)
[2025-05-06T13:00:43.158+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.18.0.4:47760
[2025-05-06T13:00:43.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_0 in memory on 172.18.0.4:46559 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:43.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 1.0 in stage 208.0 (TID 366) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 365) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:43.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_1 in memory on 172.18.0.4:46559 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:00:43.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 2.0 in stage 208.0 (TID 367) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 1.0 in stage 208.0 (TID 366) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:43.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_2 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:43.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 3.0 in stage 208.0 (TID 368) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.197+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 2.0 in stage 208.0 (TID 367) in 18 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:43.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_3 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:43.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 4.0 in stage 208.0 (TID 369) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 3.0 in stage 208.0 (TID 368) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:43.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_4 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.5 MiB)
[2025-05-06T13:00:43.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 5.0 in stage 208.0 (TID 370) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 4.0 in stage 208.0 (TID 369) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:43.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_5 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:43.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 6.0 in stage 208.0 (TID 371) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 5.0 in stage 208.0 (TID 370) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:43.233+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_6 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:00:43.234+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 7.0 in stage 208.0 (TID 372) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 6.0 in stage 208.0 (TID 371) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:43.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_7 in memory on 172.18.0.4:46559 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:00:43.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 8.0 in stage 208.0 (TID 373) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.244+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 7.0 in stage 208.0 (TID 372) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:43.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_8 in memory on 172.18.0.4:46559 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:00:43.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 9.0 in stage 208.0 (TID 374) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 8.0 in stage 208.0 (TID 373) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:43.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_316_9 in memory on 172.18.0.4:46559 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:00:43.267+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 9.0 in stage 208.0 (TID 374) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:43.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool
[2025-05-06T13:00:43.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: ResultStage 208 (fold at VertexRDDImpl.scala:90) finished in 0.123 s
[2025-05-06T13:00:43.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:43.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 208: Stage finished
[2025-05-06T13:00:43.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Job 47 finished: fold at VertexRDDImpl.scala:90, took 0.963588 s
[2025-05-06T13:00:43.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO Pregel: Pregel finished iteration 4
[2025-05-06T13:00:43.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO ZippedPartitionsRDD2: Removing RDD 299 from persistence list
[2025-05-06T13:00:43.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManager: Removing RDD 299
[2025-05-06T13:00:43.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO ZippedPartitionsRDD2: Removing RDD 285 from persistence list
[2025-05-06T13:00:43.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManager: Removing RDD 285
[2025-05-06T13:00:43.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO ZippedPartitionsRDD2: Removing RDD 291 from persistence list
[2025-05-06T13:00:43.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManager: Removing RDD 291
[2025-05-06T13:00:43.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO ZippedPartitionsRDD2: Removing RDD 268 from persistence list
[2025-05-06T13:00:43.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManager: Removing RDD 268
[2025-05-06T13:00:43.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO ZippedPartitionsRDD2: Removing RDD 274 from persistence list
[2025-05-06T13:00:43.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManager: Removing RDD 274
[2025-05-06T13:00:43.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO ZippedPartitionsRDD2: Removing RDD 282 from persistence list
[2025-05-06T13:00:43.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManager: Removing RDD 282
[2025-05-06T13:00:43.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:43.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Registering RDD 327 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 46
[2025-05-06T13:00:43.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Registering RDD 323 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 45
[2025-05-06T13:00:43.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Registering RDD 331 (mapPartitions at GraphImpl.scala:208) as input to shuffle 47
[2025-05-06T13:00:43.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Got job 48 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:43.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Final stage: ResultStage 238 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:43.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 222, ShuffleMapStage 219, ShuffleMapStage 216, ShuffleMapStage 237, ShuffleMapStage 234, ShuffleMapStage 231, ShuffleMapStage 210, ShuffleMapStage 225, ShuffleMapStage 228)
[2025-05-06T13:00:43.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 237)
[2025-05-06T13:00:43.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Submitting ShuffleMapStage 235 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[327] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:43.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 14.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:43.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T13:00:43.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 016737cbcc7e:41421 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:43.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 016737cbcc7e:41421 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:43.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:43.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 235 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[327] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:43.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSchedulerImpl: Adding task set 235.0 with 10 tasks resource profile 0
[2025-05-06T13:00:43.305+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Submitting ShuffleMapStage 236 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[323] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:43.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 14.8 KiB, free 425.8 MiB)
[2025-05-06T13:00:43.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 375) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.18.0.4:46559 in memory (size: 6.1 KiB, free: 181.1 MiB)
[2025-05-06T13:00:43.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:43.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 016737cbcc7e:41421 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:43.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:43.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 236 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[323] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:43.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSchedulerImpl: Adding task set 236.0 with 10 tasks resource profile 0
[2025-05-06T13:00:43.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 016737cbcc7e:41421 in memory (size: 48.1 KiB, free: 434.3 MiB)
[2025-05-06T13:00:43.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.18.0.4:46559 in memory (size: 48.1 KiB, free: 181.2 MiB)
[2025-05-06T13:00:43.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.18.0.4:46559 (size: 5.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:43.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 1.0 in stage 235.0 (TID 376) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 375) in 30 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:43.354+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 2.0 in stage 235.0 (TID 377) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.354+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 1.0 in stage 235.0 (TID 376) in 20 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:43.367+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 3.0 in stage 235.0 (TID 378) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.368+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 2.0 in stage 235.0 (TID 377) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:43.380+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 4.0 in stage 235.0 (TID 379) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.380+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 3.0 in stage 235.0 (TID 378) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:43.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 5.0 in stage 235.0 (TID 380) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.391+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 4.0 in stage 235.0 (TID 379) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:43.400+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 6.0 in stage 235.0 (TID 381) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 5.0 in stage 235.0 (TID 380) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:43.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 7.0 in stage 235.0 (TID 382) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 6.0 in stage 235.0 (TID 381) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:43.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 8.0 in stage 235.0 (TID 383) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 7.0 in stage 235.0 (TID 382) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:43.433+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 9.0 in stage 235.0 (TID 384) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.433+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 8.0 in stage 235.0 (TID 383) in 14 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:43.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 385) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 9.0 in stage 235.0 (TID 384) in 16 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:43.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool
[2025-05-06T13:00:43.449+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: ShuffleMapStage 235 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.158 s
[2025-05-06T13:00:43.449+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:43.449+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: running: Set(ShuffleMapStage 236)
[2025-05-06T13:00:43.449+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 237, ResultStage 238)
[2025-05-06T13:00:43.449+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:43.451+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.18.0.4:46559 (size: 6.0 KiB, free: 181.2 MiB)
[2025-05-06T13:00:43.454+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:43.458+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 1.0 in stage 236.0 (TID 386) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.459+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 385) in 10 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:43.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:00:43.465+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 2.0 in stage 236.0 (TID 387) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.466+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 1.0 in stage 236.0 (TID 386) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:43.468+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:00:43.471+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 3.0 in stage 236.0 (TID 388) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.471+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 2.0 in stage 236.0 (TID 387) in 6 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:43.476+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:43.479+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 4.0 in stage 236.0 (TID 389) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.480+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 3.0 in stage 236.0 (TID 388) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:43.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:43.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 5.0 in stage 236.0 (TID 390) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 4.0 in stage 236.0 (TID 389) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:43.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:43.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 6.0 in stage 236.0 (TID 391) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 5.0 in stage 236.0 (TID 390) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:43.498+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:43.501+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 7.0 in stage 236.0 (TID 392) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.502+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 6.0 in stage 236.0 (TID 391) in 6 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:43.504+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:00:43.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 8.0 in stage 236.0 (TID 393) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.510+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 7.0 in stage 236.0 (TID 392) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:43.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:00:43.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 9.0 in stage 236.0 (TID 394) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 8.0 in stage 236.0 (TID 393) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:43.519+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_319_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:43.522+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 9.0 in stage 236.0 (TID 394) in 6 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:43.522+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool
[2025-05-06T13:00:43.523+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: ShuffleMapStage 236 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.220 s
[2025-05-06T13:00:43.523+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:43.523+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:43.523+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 237, ResultStage 238)
[2025-05-06T13:00:43.523+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:43.523+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Submitting ShuffleMapStage 237 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[331] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:43.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 121.8 KiB, free 425.8 MiB)
[2025-05-06T13:00:43.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 016737cbcc7e:41421 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-05-06T13:00:43.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:43.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 016737cbcc7e:41421 (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:43.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:43.535+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 237 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[331] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:43.535+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSchedulerImpl: Adding task set 237.0 with 10 tasks resource profile 0
[2025-05-06T13:00:43.535+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.18.0.4:46559 in memory (size: 5.9 KiB, free: 181.0 MiB)
[2025-05-06T13:00:43.535+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 0.0 in stage 237.0 (TID 395) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.18.0.4:46559 (size: 48.1 KiB, free: 181.0 MiB)
[2025-05-06T13:00:43.546+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.18.0.4:47760
[2025-05-06T13:00:43.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_325_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:00:43.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.18.0.4:47760
[2025-05-06T13:00:43.607+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 1.0 in stage 237.0 (TID 396) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.607+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 0.0 in stage 237.0 (TID 395) in 72 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:43.613+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_325_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:00:43.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 2.0 in stage 237.0 (TID 397) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 1.0 in stage 237.0 (TID 396) in 65 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:43.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_325_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:00:43.730+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 3.0 in stage 237.0 (TID 398) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.730+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 2.0 in stage 237.0 (TID 397) in 58 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:43.739+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_325_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:00:43.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 4.0 in stage 237.0 (TID 399) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 3.0 in stage 237.0 (TID 398) in 73 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:43.809+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_325_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:00:43.854+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 5.0 in stage 237.0 (TID 400) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.854+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 4.0 in stage 237.0 (TID 399) in 51 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:43.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_325_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:00:43.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 6.0 in stage 237.0 (TID 401) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 5.0 in stage 237.0 (TID 400) in 56 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:43.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_325_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:00:43.969+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Starting task 7.0 in stage 237.0 (TID 402) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:43.969+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO TaskSetManager: Finished task 6.0 in stage 237.0 (TID 401) in 60 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:43.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:43 INFO BlockManagerInfo: Added rdd_325_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:00:44.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 8.0 in stage 237.0 (TID 403) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 7.0 in stage 237.0 (TID 402) in 68 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:44.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_325_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:00:44.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 9.0 in stage 237.0 (TID 404) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 8.0 in stage 237.0 (TID 403) in 63 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:44.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_325_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:00:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 9.0 in stage 237.0 (TID 404) in 68 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSchedulerImpl: Removed TaskSet 237.0, whose tasks have all completed, from pool
[2025-05-06T13:00:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: ShuffleMapStage 237 (mapPartitions at GraphImpl.scala:208) finished in 0.642 s
[2025-05-06T13:00:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: waiting: Set(ResultStage 238)
[2025-05-06T13:00:44.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:44.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Submitting ResultStage 238 (MapPartitionsRDD[335] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:44.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 15.4 KiB, free 425.8 MiB)
[2025-05-06T13:00:44.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 425.8 MiB)
[2025-05-06T13:00:44.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 016737cbcc7e:41421 in memory (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:44.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 016737cbcc7e:41421 (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T13:00:44.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:44.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 238 (MapPartitionsRDD[335] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:44.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSchedulerImpl: Adding task set 238.0 with 10 tasks resource profile 0
[2025-05-06T13:00:44.174+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.18.0.4:46559 in memory (size: 6.0 KiB, free: 175.6 MiB)
[2025-05-06T13:00:44.174+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 0.0 in stage 238.0 (TID 405) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.18.0.4:46559 (size: 6.2 KiB, free: 175.6 MiB)
[2025-05-06T13:00:44.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.18.0.4:47760
[2025-05-06T13:00:44.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_0 in memory on 172.18.0.4:46559 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:44.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 1.0 in stage 238.0 (TID 406) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 0.0 in stage 238.0 (TID 405) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:44.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_1 in memory on 172.18.0.4:46559 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:00:44.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 2.0 in stage 238.0 (TID 407) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 1.0 in stage 238.0 (TID 406) in 16 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:44.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_2 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:44.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 3.0 in stage 238.0 (TID 408) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.213+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 2.0 in stage 238.0 (TID 407) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:44.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_3 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:44.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 4.0 in stage 238.0 (TID 409) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 3.0 in stage 238.0 (TID 408) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:44.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_4 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.5 MiB)
[2025-05-06T13:00:44.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 5.0 in stage 238.0 (TID 410) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 4.0 in stage 238.0 (TID 409) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:44.237+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_5 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:44.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 6.0 in stage 238.0 (TID 411) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 5.0 in stage 238.0 (TID 410) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:44.246+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_6 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:00:44.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 7.0 in stage 238.0 (TID 412) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 6.0 in stage 238.0 (TID 411) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:44.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_7 in memory on 172.18.0.4:46559 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:00:44.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 8.0 in stage 238.0 (TID 413) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 7.0 in stage 238.0 (TID 412) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:44.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_8 in memory on 172.18.0.4:46559 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:00:44.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 9.0 in stage 238.0 (TID 414) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 8.0 in stage 238.0 (TID 413) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:44.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_333_9 in memory on 172.18.0.4:46559 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:00:44.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 9.0 in stage 238.0 (TID 414) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:44.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool
[2025-05-06T13:00:44.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: ResultStage 238 (fold at VertexRDDImpl.scala:90) finished in 0.107 s
[2025-05-06T13:00:44.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:44.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 238: Stage finished
[2025-05-06T13:00:44.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Job 48 finished: fold at VertexRDDImpl.scala:90, took 0.990886 s
[2025-05-06T13:00:44.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO Pregel: Pregel finished iteration 5
[2025-05-06T13:00:44.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO ZippedPartitionsRDD2: Removing RDD 316 from persistence list
[2025-05-06T13:00:44.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManager: Removing RDD 316
[2025-05-06T13:00:44.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO ZippedPartitionsRDD2: Removing RDD 302 from persistence list
[2025-05-06T13:00:44.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManager: Removing RDD 302
[2025-05-06T13:00:44.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO ZippedPartitionsRDD2: Removing RDD 308 from persistence list
[2025-05-06T13:00:44.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManager: Removing RDD 308
[2025-05-06T13:00:44.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO ZippedPartitionsRDD2: Removing RDD 285 from persistence list
[2025-05-06T13:00:44.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManager: Removing RDD 285
[2025-05-06T13:00:44.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO ZippedPartitionsRDD2: Removing RDD 291 from persistence list
[2025-05-06T13:00:44.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManager: Removing RDD 291
[2025-05-06T13:00:44.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO ZippedPartitionsRDD2: Removing RDD 299 from persistence list
[2025-05-06T13:00:44.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManager: Removing RDD 299
[2025-05-06T13:00:44.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:44.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Registering RDD 344 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 49
[2025-05-06T13:00:44.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Registering RDD 340 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 48
[2025-05-06T13:00:44.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Registering RDD 348 (mapPartitions at GraphImpl.scala:208) as input to shuffle 50
[2025-05-06T13:00:44.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Got job 49 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:44.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Final stage: ResultStage 271 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:44.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 255, ShuffleMapStage 270, ShuffleMapStage 249, ShuffleMapStage 252, ShuffleMapStage 267, ShuffleMapStage 246, ShuffleMapStage 261, ShuffleMapStage 264, ShuffleMapStage 240, ShuffleMapStage 258)
[2025-05-06T13:00:44.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 270)
[2025-05-06T13:00:44.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Submitting ShuffleMapStage 268 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[344] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:44.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 14.8 KiB, free 425.8 MiB)
[2025-05-06T13:00:44.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:44.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 016737cbcc7e:41421 in memory (size: 48.1 KiB, free: 434.3 MiB)
[2025-05-06T13:00:44.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 016737cbcc7e:41421 (size: 6.0 KiB, free: 434.3 MiB)
[2025-05-06T13:00:44.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:44.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 268 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[344] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:44.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSchedulerImpl: Adding task set 268.0 with 10 tasks resource profile 0
[2025-05-06T13:00:44.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Submitting ShuffleMapStage 269 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[340] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:44.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 0.0 in stage 268.0 (TID 415) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.18.0.4:46559 in memory (size: 48.1 KiB, free: 181.2 MiB)
[2025-05-06T13:00:44.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 15.5 KiB, free 425.9 MiB)
[2025-05-06T13:00:44.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 425.9 MiB)
[2025-05-06T13:00:44.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 016737cbcc7e:41421 (size: 6.2 KiB, free: 434.3 MiB)
[2025-05-06T13:00:44.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:44.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 269 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[340] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:44.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSchedulerImpl: Adding task set 269.0 with 10 tasks resource profile 0
[2025-05-06T13:00:44.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 016737cbcc7e:41421 in memory (size: 6.2 KiB, free: 434.3 MiB)
[2025-05-06T13:00:44.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.18.0.4:46559 in memory (size: 6.2 KiB, free: 181.2 MiB)
[2025-05-06T13:00:44.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.18.0.4:46559 (size: 6.0 KiB, free: 181.2 MiB)
[2025-05-06T13:00:44.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 1.0 in stage 268.0 (TID 416) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.341+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 0.0 in stage 268.0 (TID 415) in 31 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:44.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 2.0 in stage 268.0 (TID 417) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 1.0 in stage 268.0 (TID 416) in 18 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:44.369+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 3.0 in stage 268.0 (TID 418) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.369+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 2.0 in stage 268.0 (TID 417) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:44.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 4.0 in stage 268.0 (TID 419) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 3.0 in stage 268.0 (TID 418) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:44.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 5.0 in stage 268.0 (TID 420) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.391+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 4.0 in stage 268.0 (TID 419) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:44.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 6.0 in stage 268.0 (TID 421) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 5.0 in stage 268.0 (TID 420) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:44.412+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 7.0 in stage 268.0 (TID 422) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.412+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 6.0 in stage 268.0 (TID 421) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:44.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 8.0 in stage 268.0 (TID 423) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 7.0 in stage 268.0 (TID 422) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:44.436+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 9.0 in stage 268.0 (TID 424) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.436+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 8.0 in stage 268.0 (TID 423) in 15 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:44.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 0.0 in stage 269.0 (TID 425) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 9.0 in stage 268.0 (TID 424) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:44.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool
[2025-05-06T13:00:44.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: ShuffleMapStage 268 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.150 s
[2025-05-06T13:00:44.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:44.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: running: Set(ShuffleMapStage 269)
[2025-05-06T13:00:44.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 270, ResultStage 271)
[2025-05-06T13:00:44.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:44.451+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.18.0.4:46559 (size: 6.2 KiB, free: 181.2 MiB)
[2025-05-06T13:00:44.454+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:44.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 1.0 in stage 269.0 (TID 426) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 0.0 in stage 269.0 (TID 425) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:44.465+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:00:44.469+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 2.0 in stage 269.0 (TID 427) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.469+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 1.0 in stage 269.0 (TID 426) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:44.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:00:44.476+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 3.0 in stage 269.0 (TID 428) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.477+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 2.0 in stage 269.0 (TID 427) in 8 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:44.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:44.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 4.0 in stage 269.0 (TID 429) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.485+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 3.0 in stage 269.0 (TID 428) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:44.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:44.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 5.0 in stage 269.0 (TID 430) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 4.0 in stage 269.0 (TID 429) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:44.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:44.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 6.0 in stage 269.0 (TID 431) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 5.0 in stage 269.0 (TID 430) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:44.502+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:44.505+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 7.0 in stage 269.0 (TID 432) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.505+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 6.0 in stage 269.0 (TID 431) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:44.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:00:44.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 8.0 in stage 269.0 (TID 433) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 7.0 in stage 269.0 (TID 432) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:44.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:00:44.519+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 9.0 in stage 269.0 (TID 434) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.519+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 8.0 in stage 269.0 (TID 433) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:44.522+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_336_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:44.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 9.0 in stage 269.0 (TID 434) in 6 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:44.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool
[2025-05-06T13:00:44.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: ShuffleMapStage 269 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.215 s
[2025-05-06T13:00:44.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:44.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:44.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 270, ResultStage 271)
[2025-05-06T13:00:44.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:44.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Submitting ShuffleMapStage 270 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[348] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:44.528+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 122.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:44.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 016737cbcc7e:41421 in memory (size: 6.0 KiB, free: 434.3 MiB)
[2025-05-06T13:00:44.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 425.8 MiB)
[2025-05-06T13:00:44.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 016737cbcc7e:41421 (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T13:00:44.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:44.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 270 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[348] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:44.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSchedulerImpl: Adding task set 270.0 with 10 tasks resource profile 0
[2025-05-06T13:00:44.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.18.0.4:46559 in memory (size: 6.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:44.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 0.0 in stage 270.0 (TID 435) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.18.0.4:46559 (size: 48.2 KiB, free: 181.0 MiB)
[2025-05-06T13:00:44.546+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.18.0.4:47760
[2025-05-06T13:00:44.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_342_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:00:44.550+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.18.0.4:47760
[2025-05-06T13:00:44.604+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 1.0 in stage 270.0 (TID 436) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.604+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 0.0 in stage 270.0 (TID 435) in 67 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:44.610+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_342_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:00:44.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 2.0 in stage 270.0 (TID 437) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.673+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 1.0 in stage 270.0 (TID 436) in 69 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:44.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_342_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:00:44.735+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 3.0 in stage 270.0 (TID 438) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.735+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 2.0 in stage 270.0 (TID 437) in 63 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:44.740+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_342_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:00:44.794+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 4.0 in stage 270.0 (TID 439) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.794+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 3.0 in stage 270.0 (TID 438) in 60 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:44.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_342_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:00:44.844+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 5.0 in stage 270.0 (TID 440) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.844+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 4.0 in stage 270.0 (TID 439) in 50 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:44.850+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_342_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:00:44.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 6.0 in stage 270.0 (TID 441) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 5.0 in stage 270.0 (TID 440) in 55 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:44.904+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_342_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:00:44.957+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Starting task 7.0 in stage 270.0 (TID 442) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:44.958+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO TaskSetManager: Finished task 6.0 in stage 270.0 (TID 441) in 59 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:44.963+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:44 INFO BlockManagerInfo: Added rdd_342_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:00:45.021+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 8.0 in stage 270.0 (TID 443) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 7.0 in stage 270.0 (TID 442) in 64 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:45.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_342_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:00:45.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 9.0 in stage 270.0 (TID 444) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 8.0 in stage 270.0 (TID 443) in 60 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:45.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_342_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:00:45.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 9.0 in stage 270.0 (TID 444) in 70 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:45.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool
[2025-05-06T13:00:45.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: ShuffleMapStage 270 (mapPartitions at GraphImpl.scala:208) finished in 0.625 s
[2025-05-06T13:00:45.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:45.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:45.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: waiting: Set(ResultStage 271)
[2025-05-06T13:00:45.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:45.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[352] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:45.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 16.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:45.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.8 MiB)
[2025-05-06T13:00:45.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 016737cbcc7e:41421 in memory (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T13:00:45.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 016737cbcc7e:41421 (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:45.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:45.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 271 (MapPartitionsRDD[352] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:45.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSchedulerImpl: Adding task set 271.0 with 10 tasks resource profile 0
[2025-05-06T13:00:45.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.18.0.4:46559 in memory (size: 6.2 KiB, free: 175.6 MiB)
[2025-05-06T13:00:45.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 0.0 in stage 271.0 (TID 445) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.18.0.4:46559 (size: 6.3 KiB, free: 175.6 MiB)
[2025-05-06T13:00:45.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.18.0.4:47760
[2025-05-06T13:00:45.174+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_0 in memory on 172.18.0.4:46559 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:45.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 1.0 in stage 271.0 (TID 446) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 0.0 in stage 271.0 (TID 445) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:45.184+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_1 in memory on 172.18.0.4:46559 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:00:45.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 2.0 in stage 271.0 (TID 447) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 1.0 in stage 271.0 (TID 446) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:45.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_2 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:45.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 3.0 in stage 271.0 (TID 448) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 2.0 in stage 271.0 (TID 447) in 18 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:45.213+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_3 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:45.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 4.0 in stage 271.0 (TID 449) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 3.0 in stage 271.0 (TID 448) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:45.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_4 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:45.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 5.0 in stage 271.0 (TID 450) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.227+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 4.0 in stage 271.0 (TID 449) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:45.233+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_5 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:45.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 6.0 in stage 271.0 (TID 451) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 5.0 in stage 271.0 (TID 450) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:45.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_6 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:00:45.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 7.0 in stage 271.0 (TID 452) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.244+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 6.0 in stage 271.0 (TID 451) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:45.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_7 in memory on 172.18.0.4:46559 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:00:45.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 8.0 in stage 271.0 (TID 453) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 7.0 in stage 271.0 (TID 452) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:45.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_8 in memory on 172.18.0.4:46559 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:00:45.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 9.0 in stage 271.0 (TID 454) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 8.0 in stage 271.0 (TID 453) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:45.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_350_9 in memory on 172.18.0.4:46559 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:00:45.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 9.0 in stage 271.0 (TID 454) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:45.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool
[2025-05-06T13:00:45.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: ResultStage 271 (fold at VertexRDDImpl.scala:90) finished in 0.123 s
[2025-05-06T13:00:45.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:45.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 271: Stage finished
[2025-05-06T13:00:45.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Job 49 finished: fold at VertexRDDImpl.scala:90, took 0.982522 s
[2025-05-06T13:00:45.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO Pregel: Pregel finished iteration 6
[2025-05-06T13:00:45.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO ZippedPartitionsRDD2: Removing RDD 333 from persistence list
[2025-05-06T13:00:45.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManager: Removing RDD 333
[2025-05-06T13:00:45.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO ZippedPartitionsRDD2: Removing RDD 319 from persistence list
[2025-05-06T13:00:45.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManager: Removing RDD 319
[2025-05-06T13:00:45.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO ZippedPartitionsRDD2: Removing RDD 325 from persistence list
[2025-05-06T13:00:45.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManager: Removing RDD 325
[2025-05-06T13:00:45.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO ZippedPartitionsRDD2: Removing RDD 302 from persistence list
[2025-05-06T13:00:45.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManager: Removing RDD 302
[2025-05-06T13:00:45.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO ZippedPartitionsRDD2: Removing RDD 308 from persistence list
[2025-05-06T13:00:45.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManager: Removing RDD 308
[2025-05-06T13:00:45.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO ZippedPartitionsRDD2: Removing RDD 316 from persistence list
[2025-05-06T13:00:45.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManager: Removing RDD 316
[2025-05-06T13:00:45.290+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:45.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Registering RDD 361 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 52
[2025-05-06T13:00:45.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Registering RDD 357 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 51
[2025-05-06T13:00:45.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Registering RDD 365 (mapPartitions at GraphImpl.scala:208) as input to shuffle 53
[2025-05-06T13:00:45.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Got job 50 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:45.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Final stage: ResultStage 307 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:45.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 273, ShuffleMapStage 288, ShuffleMapStage 303, ShuffleMapStage 285, ShuffleMapStage 300, ShuffleMapStage 306, ShuffleMapStage 291, ShuffleMapStage 282, ShuffleMapStage 279, ShuffleMapStage 294, ShuffleMapStage 297)
[2025-05-06T13:00:45.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 306)
[2025-05-06T13:00:45.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Submitting ShuffleMapStage 304 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[361] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:45.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 15.4 KiB, free 425.8 MiB)
[2025-05-06T13:00:45.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:45.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 016737cbcc7e:41421 in memory (size: 48.2 KiB, free: 434.3 MiB)
[2025-05-06T13:00:45.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 016737cbcc7e:41421 (size: 6.1 KiB, free: 434.3 MiB)
[2025-05-06T13:00:45.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:45.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 304 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[361] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:45.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSchedulerImpl: Adding task set 304.0 with 10 tasks resource profile 0
[2025-05-06T13:00:45.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Submitting ShuffleMapStage 305 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[357] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:45.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 455) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.305+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.18.0.4:46559 in memory (size: 48.2 KiB, free: 181.2 MiB)
[2025-05-06T13:00:45.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 16.1 KiB, free 425.9 MiB)
[2025-05-06T13:00:45.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.9 MiB)
[2025-05-06T13:00:45.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 016737cbcc7e:41421 (size: 6.3 KiB, free: 434.3 MiB)
[2025-05-06T13:00:45.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:45.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 305 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[357] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:45.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSchedulerImpl: Adding task set 305.0 with 10 tasks resource profile 0
[2025-05-06T13:00:45.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 016737cbcc7e:41421 in memory (size: 6.3 KiB, free: 434.3 MiB)
[2025-05-06T13:00:45.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.18.0.4:46559 (size: 6.1 KiB, free: 181.2 MiB)
[2025-05-06T13:00:45.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.18.0.4:46559 in memory (size: 6.3 KiB, free: 181.2 MiB)
[2025-05-06T13:00:45.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 1.0 in stage 304.0 (TID 456) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 455) in 21 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:45.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 2.0 in stage 304.0 (TID 457) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 1.0 in stage 304.0 (TID 456) in 22 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:45.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 3.0 in stage 304.0 (TID 458) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 2.0 in stage 304.0 (TID 457) in 19 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:45.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 4.0 in stage 304.0 (TID 459) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 3.0 in stage 304.0 (TID 458) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:45.383+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 5.0 in stage 304.0 (TID 460) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 4.0 in stage 304.0 (TID 459) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:45.393+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 6.0 in stage 304.0 (TID 461) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.393+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 5.0 in stage 304.0 (TID 460) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:45.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 7.0 in stage 304.0 (TID 462) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.403+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 6.0 in stage 304.0 (TID 461) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:45.412+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 8.0 in stage 304.0 (TID 463) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.412+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 7.0 in stage 304.0 (TID 462) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:45.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 9.0 in stage 304.0 (TID 464) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 8.0 in stage 304.0 (TID 463) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:45.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 0.0 in stage 305.0 (TID 465) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 9.0 in stage 304.0 (TID 464) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:45.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool
[2025-05-06T13:00:45.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: ShuffleMapStage 304 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.144 s
[2025-05-06T13:00:45.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:45.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: running: Set(ShuffleMapStage 305)
[2025-05-06T13:00:45.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 306, ResultStage 307)
[2025-05-06T13:00:45.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:45.441+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.18.0.4:46559 (size: 6.3 KiB, free: 181.2 MiB)
[2025-05-06T13:00:45.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:45.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 1.0 in stage 305.0 (TID 466) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 0.0 in stage 305.0 (TID 465) in 10 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:45.451+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:00:45.454+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 2.0 in stage 305.0 (TID 467) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.454+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 1.0 in stage 305.0 (TID 466) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:45.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:00:45.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 3.0 in stage 305.0 (TID 468) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 2.0 in stage 305.0 (TID 467) in 6 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:45.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:45.467+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 4.0 in stage 305.0 (TID 469) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.467+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 3.0 in stage 305.0 (TID 468) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:45.470+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:45.473+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 5.0 in stage 305.0 (TID 470) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.474+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 4.0 in stage 305.0 (TID 469) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:45.478+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:45.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 6.0 in stage 305.0 (TID 471) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 5.0 in stage 305.0 (TID 470) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:45.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:45.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 7.0 in stage 305.0 (TID 472) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 6.0 in stage 305.0 (TID 471) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:45.493+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:00:45.497+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 8.0 in stage 305.0 (TID 473) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.497+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 7.0 in stage 305.0 (TID 472) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:45.501+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:00:45.504+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 9.0 in stage 305.0 (TID 474) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.505+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 8.0 in stage 305.0 (TID 473) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:45.508+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_353_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:45.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 9.0 in stage 305.0 (TID 474) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:45.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSchedulerImpl: Removed TaskSet 305.0, whose tasks have all completed, from pool
[2025-05-06T13:00:45.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: ShuffleMapStage 305 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.209 s
[2025-05-06T13:00:45.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:45.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:45.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 306, ResultStage 307)
[2025-05-06T13:00:45.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:45.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Submitting ShuffleMapStage 306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[365] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:45.517+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 122.4 KiB, free 425.8 MiB)
[2025-05-06T13:00:45.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 48.5 KiB, free 425.8 MiB)
[2025-05-06T13:00:45.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 016737cbcc7e:41421 (size: 48.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:45.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:45.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 016737cbcc7e:41421 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:45.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[365] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:45.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSchedulerImpl: Adding task set 306.0 with 10 tasks resource profile 0
[2025-05-06T13:00:45.530+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.18.0.4:46559 in memory (size: 6.1 KiB, free: 181.0 MiB)
[2025-05-06T13:00:45.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 0.0 in stage 306.0 (TID 475) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.535+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.18.0.4:46559 (size: 48.5 KiB, free: 181.0 MiB)
[2025-05-06T13:00:45.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.18.0.4:47760
[2025-05-06T13:00:45.546+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_359_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:00:45.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.18.0.4:47760
[2025-05-06T13:00:45.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 1.0 in stage 306.0 (TID 476) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 0.0 in stage 306.0 (TID 475) in 88 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:45.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_359_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:00:45.701+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 2.0 in stage 306.0 (TID 477) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 1.0 in stage 306.0 (TID 476) in 84 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:45.708+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_359_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:00:45.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 3.0 in stage 306.0 (TID 478) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 2.0 in stage 306.0 (TID 477) in 62 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:45.769+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_359_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:00:45.824+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 4.0 in stage 306.0 (TID 479) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.824+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 3.0 in stage 306.0 (TID 478) in 61 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:45.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_359_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:00:45.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 5.0 in stage 306.0 (TID 480) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 4.0 in stage 306.0 (TID 479) in 52 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:45.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_359_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:00:45.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Starting task 6.0 in stage 306.0 (TID 481) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:45.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO TaskSetManager: Finished task 5.0 in stage 306.0 (TID 480) in 63 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:45.946+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:45 INFO BlockManagerInfo: Added rdd_359_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:00:46.001+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 7.0 in stage 306.0 (TID 482) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 6.0 in stage 306.0 (TID 481) in 63 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:46.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_359_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:00:46.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 8.0 in stage 306.0 (TID 483) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.072+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 7.0 in stage 306.0 (TID 482) in 71 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:46.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_359_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:00:46.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 9.0 in stage 306.0 (TID 484) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 8.0 in stage 306.0 (TID 483) in 65 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:46.141+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_359_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:00:46.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 9.0 in stage 306.0 (TID 484) in 66 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:46.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool
[2025-05-06T13:00:46.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: ShuffleMapStage 306 (mapPartitions at GraphImpl.scala:208) finished in 0.688 s
[2025-05-06T13:00:46.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:46.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:46.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: waiting: Set(ResultStage 307)
[2025-05-06T13:00:46.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:46.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Submitting ResultStage 307 (MapPartitionsRDD[369] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:46.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 16.7 KiB, free 425.8 MiB)
[2025-05-06T13:00:46.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 425.8 MiB)
[2025-05-06T13:00:46.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 016737cbcc7e:41421 in memory (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:46.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 016737cbcc7e:41421 (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:46.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:46.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 307 (MapPartitionsRDD[369] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:46.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSchedulerImpl: Adding task set 307.0 with 10 tasks resource profile 0
[2025-05-06T13:00:46.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 0.0 in stage 307.0 (TID 485) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.18.0.4:46559 in memory (size: 6.3 KiB, free: 175.6 MiB)
[2025-05-06T13:00:46.213+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.18.0.4:46559 (size: 6.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:46.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.18.0.4:47760
[2025-05-06T13:00:46.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_0 in memory on 172.18.0.4:46559 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:46.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 1.0 in stage 307.0 (TID 486) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 0.0 in stage 307.0 (TID 485) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:46.245+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_1 in memory on 172.18.0.4:46559 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:00:46.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 2.0 in stage 307.0 (TID 487) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 1.0 in stage 307.0 (TID 486) in 21 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:46.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_2 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:46.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 3.0 in stage 307.0 (TID 488) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 2.0 in stage 307.0 (TID 487) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:46.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_3 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:46.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 4.0 in stage 307.0 (TID 489) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 3.0 in stage 307.0 (TID 488) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:46.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_4 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:46.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 5.0 in stage 307.0 (TID 490) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 4.0 in stage 307.0 (TID 489) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:46.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_5 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:46.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 6.0 in stage 307.0 (TID 491) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 5.0 in stage 307.0 (TID 490) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:46.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_6 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:00:46.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 7.0 in stage 307.0 (TID 492) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 6.0 in stage 307.0 (TID 491) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:46.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_7 in memory on 172.18.0.4:46559 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:00:46.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 8.0 in stage 307.0 (TID 493) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 7.0 in stage 307.0 (TID 492) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:46.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_8 in memory on 172.18.0.4:46559 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:00:46.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 9.0 in stage 307.0 (TID 494) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 8.0 in stage 307.0 (TID 493) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:46.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_367_9 in memory on 172.18.0.4:46559 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:00:46.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 9.0 in stage 307.0 (TID 494) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:46.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSchedulerImpl: Removed TaskSet 307.0, whose tasks have all completed, from pool
[2025-05-06T13:00:46.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: ResultStage 307 (fold at VertexRDDImpl.scala:90) finished in 0.117 s
[2025-05-06T13:00:46.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:46.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 307: Stage finished
[2025-05-06T13:00:46.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Job 50 finished: fold at VertexRDDImpl.scala:90, took 1.029216 s
[2025-05-06T13:00:46.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO Pregel: Pregel finished iteration 7
[2025-05-06T13:00:46.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO ZippedPartitionsRDD2: Removing RDD 350 from persistence list
[2025-05-06T13:00:46.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManager: Removing RDD 350
[2025-05-06T13:00:46.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO ZippedPartitionsRDD2: Removing RDD 336 from persistence list
[2025-05-06T13:00:46.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManager: Removing RDD 336
[2025-05-06T13:00:46.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO ZippedPartitionsRDD2: Removing RDD 342 from persistence list
[2025-05-06T13:00:46.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManager: Removing RDD 342
[2025-05-06T13:00:46.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO ZippedPartitionsRDD2: Removing RDD 319 from persistence list
[2025-05-06T13:00:46.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManager: Removing RDD 319
[2025-05-06T13:00:46.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO ZippedPartitionsRDD2: Removing RDD 325 from persistence list
[2025-05-06T13:00:46.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManager: Removing RDD 325
[2025-05-06T13:00:46.330+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO ZippedPartitionsRDD2: Removing RDD 333 from persistence list
[2025-05-06T13:00:46.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManager: Removing RDD 333
[2025-05-06T13:00:46.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:46.338+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Registering RDD 378 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 55
[2025-05-06T13:00:46.338+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Registering RDD 374 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 54
[2025-05-06T13:00:46.338+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Registering RDD 382 (mapPartitions at GraphImpl.scala:208) as input to shuffle 56
[2025-05-06T13:00:46.338+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Got job 51 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:46.338+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Final stage: ResultStage 346 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:46.338+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 324, ShuffleMapStage 339, ShuffleMapStage 318, ShuffleMapStage 321, ShuffleMapStage 336, ShuffleMapStage 342, ShuffleMapStage 315, ShuffleMapStage 330, ShuffleMapStage 345, ShuffleMapStage 333, ShuffleMapStage 309, ShuffleMapStage 327)
[2025-05-06T13:00:46.338+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 345)
[2025-05-06T13:00:46.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Submitting ShuffleMapStage 343 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[378] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:46.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 16.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:46.346+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 425.8 MiB)
[2025-05-06T13:00:46.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 016737cbcc7e:41421 (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T13:00:46.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 016737cbcc7e:41421 in memory (size: 48.5 KiB, free: 434.3 MiB)
[2025-05-06T13:00:46.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.18.0.4:46559 in memory (size: 48.5 KiB, free: 181.2 MiB)
[2025-05-06T13:00:46.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:46.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 343 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[378] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:46.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSchedulerImpl: Adding task set 343.0 with 10 tasks resource profile 0
[2025-05-06T13:00:46.351+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Submitting ShuffleMapStage 344 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[374] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:46.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 0.0 in stage 343.0 (TID 495) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 16.7 KiB, free 425.9 MiB)
[2025-05-06T13:00:46.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 425.9 MiB)
[2025-05-06T13:00:46.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 016737cbcc7e:41421 (size: 6.4 KiB, free: 434.3 MiB)
[2025-05-06T13:00:46.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 016737cbcc7e:41421 in memory (size: 6.4 KiB, free: 434.3 MiB)
[2025-05-06T13:00:46.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:46.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 344 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[374] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:46.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSchedulerImpl: Adding task set 344.0 with 10 tasks resource profile 0
[2025-05-06T13:00:46.354+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.18.0.4:46559 in memory (size: 6.4 KiB, free: 181.2 MiB)
[2025-05-06T13:00:46.355+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.18.0.4:46559 (size: 6.2 KiB, free: 181.2 MiB)
[2025-05-06T13:00:46.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 1.0 in stage 343.0 (TID 496) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 0.0 in stage 343.0 (TID 495) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:46.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 2.0 in stage 343.0 (TID 497) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 1.0 in stage 343.0 (TID 496) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:46.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 3.0 in stage 343.0 (TID 498) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 2.0 in stage 343.0 (TID 497) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:46.398+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 4.0 in stage 343.0 (TID 499) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.399+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 3.0 in stage 343.0 (TID 498) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:46.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 5.0 in stage 343.0 (TID 500) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 4.0 in stage 343.0 (TID 499) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:46.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 6.0 in stage 343.0 (TID 501) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 5.0 in stage 343.0 (TID 500) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:46.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 7.0 in stage 343.0 (TID 502) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 6.0 in stage 343.0 (TID 501) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:46.436+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 8.0 in stage 343.0 (TID 503) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.436+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 7.0 in stage 343.0 (TID 502) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:46.445+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 9.0 in stage 343.0 (TID 504) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.445+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 8.0 in stage 343.0 (TID 503) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:46.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 0.0 in stage 344.0 (TID 505) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 9.0 in stage 343.0 (TID 504) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:46.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSchedulerImpl: Removed TaskSet 343.0, whose tasks have all completed, from pool
[2025-05-06T13:00:46.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: ShuffleMapStage 343 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.117 s
[2025-05-06T13:00:46.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:46.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: running: Set(ShuffleMapStage 344)
[2025-05-06T13:00:46.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 345, ResultStage 346)
[2025-05-06T13:00:46.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:46.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.18.0.4:46559 (size: 6.4 KiB, free: 181.2 MiB)
[2025-05-06T13:00:46.463+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:46.468+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 1.0 in stage 344.0 (TID 506) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.468+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 0.0 in stage 344.0 (TID 505) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:46.471+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:00:46.475+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 2.0 in stage 344.0 (TID 507) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.475+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 1.0 in stage 344.0 (TID 506) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:46.479+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:00:46.485+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 3.0 in stage 344.0 (TID 508) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.485+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 2.0 in stage 344.0 (TID 507) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:46.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:46.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 4.0 in stage 344.0 (TID 509) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 3.0 in stage 344.0 (TID 508) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:46.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:46.498+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 5.0 in stage 344.0 (TID 510) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 4.0 in stage 344.0 (TID 509) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:46.502+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:46.507+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 6.0 in stage 344.0 (TID 511) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.508+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 5.0 in stage 344.0 (TID 510) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:46.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:46.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 7.0 in stage 344.0 (TID 512) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.517+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 6.0 in stage 344.0 (TID 511) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:46.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:00:46.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 8.0 in stage 344.0 (TID 513) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.528+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 7.0 in stage 344.0 (TID 512) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:46.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:00:46.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 9.0 in stage 344.0 (TID 514) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 8.0 in stage 344.0 (TID 513) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:46.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_370_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:46.546+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 9.0 in stage 344.0 (TID 514) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:46.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool
[2025-05-06T13:00:46.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: ShuffleMapStage 344 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.197 s
[2025-05-06T13:00:46.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:46.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:46.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 345, ResultStage 346)
[2025-05-06T13:00:46.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:46.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Submitting ShuffleMapStage 345 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[382] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:46.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 122.7 KiB, free 425.8 MiB)
[2025-05-06T13:00:46.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 016737cbcc7e:41421 in memory (size: 6.2 KiB, free: 434.3 MiB)
[2025-05-06T13:00:46.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 48.4 KiB, free 425.8 MiB)
[2025-05-06T13:00:46.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 016737cbcc7e:41421 (size: 48.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:46.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:46.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 345 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[382] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:46.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSchedulerImpl: Adding task set 345.0 with 10 tasks resource profile 0
[2025-05-06T13:00:46.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.18.0.4:46559 in memory (size: 6.2 KiB, free: 181.0 MiB)
[2025-05-06T13:00:46.559+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 0.0 in stage 345.0 (TID 515) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.18.0.4:46559 (size: 48.4 KiB, free: 181.0 MiB)
[2025-05-06T13:00:46.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.18.0.4:47760
[2025-05-06T13:00:46.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_376_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:00:46.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.18.0.4:47760
[2025-05-06T13:00:46.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 1.0 in stage 345.0 (TID 516) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 0.0 in stage 345.0 (TID 515) in 69 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:46.633+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_376_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:00:46.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 2.0 in stage 345.0 (TID 517) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 1.0 in stage 345.0 (TID 516) in 66 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:46.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_376_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:00:46.751+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 3.0 in stage 345.0 (TID 518) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.751+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 2.0 in stage 345.0 (TID 517) in 58 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:46.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_376_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:00:46.817+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 4.0 in stage 345.0 (TID 519) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.818+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 3.0 in stage 345.0 (TID 518) in 66 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:46.824+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_376_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:00:46.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 5.0 in stage 345.0 (TID 520) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.872+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 4.0 in stage 345.0 (TID 519) in 54 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:46.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_376_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:00:46.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 6.0 in stage 345.0 (TID 521) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 5.0 in stage 345.0 (TID 520) in 62 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:46.941+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO BlockManagerInfo: Added rdd_376_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:00:46.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Starting task 7.0 in stage 345.0 (TID 522) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:46.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:46 INFO TaskSetManager: Finished task 6.0 in stage 345.0 (TID 521) in 63 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:47.003+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_376_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:00:47.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 8.0 in stage 345.0 (TID 523) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 7.0 in stage 345.0 (TID 522) in 67 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:47.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_376_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:00:47.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 9.0 in stage 345.0 (TID 524) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 8.0 in stage 345.0 (TID 523) in 67 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:47.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_376_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:00:47.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 9.0 in stage 345.0 (TID 524) in 77 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:47.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSchedulerImpl: Removed TaskSet 345.0, whose tasks have all completed, from pool
[2025-05-06T13:00:47.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: ShuffleMapStage 345 (mapPartitions at GraphImpl.scala:208) finished in 0.659 s
[2025-05-06T13:00:47.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:47.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:47.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: waiting: Set(ResultStage 346)
[2025-05-06T13:00:47.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:47.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Submitting ResultStage 346 (MapPartitionsRDD[386] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:47.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 17.3 KiB, free 425.8 MiB)
[2025-05-06T13:00:47.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 425.8 MiB)
[2025-05-06T13:00:47.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 016737cbcc7e:41421 in memory (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:47.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 016737cbcc7e:41421 (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:47.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:47.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 346 (MapPartitionsRDD[386] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:47.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSchedulerImpl: Adding task set 346.0 with 10 tasks resource profile 0
[2025-05-06T13:00:47.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.18.0.4:46559 in memory (size: 6.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:47.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 0.0 in stage 346.0 (TID 525) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.18.0.4:46559 (size: 6.5 KiB, free: 175.6 MiB)
[2025-05-06T13:00:47.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.18.0.4:47760
[2025-05-06T13:00:47.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_0 in memory on 172.18.0.4:46559 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:47.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 1.0 in stage 346.0 (TID 526) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 0.0 in stage 346.0 (TID 525) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:47.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_1 in memory on 172.18.0.4:46559 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:00:47.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 2.0 in stage 346.0 (TID 527) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 1.0 in stage 346.0 (TID 526) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:47.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_2 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:47.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 3.0 in stage 346.0 (TID 528) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 2.0 in stage 346.0 (TID 527) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:47.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_3 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:47.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 4.0 in stage 346.0 (TID 529) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 3.0 in stage 346.0 (TID 528) in 16 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:47.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_4 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:47.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 5.0 in stage 346.0 (TID 530) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 4.0 in stage 346.0 (TID 529) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:47.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_5 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:47.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 6.0 in stage 346.0 (TID 531) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 5.0 in stage 346.0 (TID 530) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:47.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_6 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:00:47.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 7.0 in stage 346.0 (TID 532) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 6.0 in stage 346.0 (TID 531) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:47.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_7 in memory on 172.18.0.4:46559 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:00:47.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 8.0 in stage 346.0 (TID 533) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 7.0 in stage 346.0 (TID 532) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:47.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_8 in memory on 172.18.0.4:46559 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:00:47.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 9.0 in stage 346.0 (TID 534) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 8.0 in stage 346.0 (TID 533) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:47.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_384_9 in memory on 172.18.0.4:46559 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:00:47.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 9.0 in stage 346.0 (TID 534) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:47.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool
[2025-05-06T13:00:47.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: ResultStage 346 (fold at VertexRDDImpl.scala:90) finished in 0.112 s
[2025-05-06T13:00:47.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:47.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 346: Stage finished
[2025-05-06T13:00:47.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Job 51 finished: fold at VertexRDDImpl.scala:90, took 0.985656 s
[2025-05-06T13:00:47.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO Pregel: Pregel finished iteration 8
[2025-05-06T13:00:47.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO ZippedPartitionsRDD2: Removing RDD 367 from persistence list
[2025-05-06T13:00:47.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManager: Removing RDD 367
[2025-05-06T13:00:47.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO ZippedPartitionsRDD2: Removing RDD 353 from persistence list
[2025-05-06T13:00:47.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManager: Removing RDD 353
[2025-05-06T13:00:47.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO ZippedPartitionsRDD2: Removing RDD 359 from persistence list
[2025-05-06T13:00:47.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManager: Removing RDD 359
[2025-05-06T13:00:47.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO ZippedPartitionsRDD2: Removing RDD 336 from persistence list
[2025-05-06T13:00:47.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManager: Removing RDD 336
[2025-05-06T13:00:47.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO ZippedPartitionsRDD2: Removing RDD 342 from persistence list
[2025-05-06T13:00:47.329+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManager: Removing RDD 342
[2025-05-06T13:00:47.332+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO ZippedPartitionsRDD2: Removing RDD 350 from persistence list
[2025-05-06T13:00:47.332+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManager: Removing RDD 350
[2025-05-06T13:00:47.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:47.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Registering RDD 391 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 57
[2025-05-06T13:00:47.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Registering RDD 395 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 58
[2025-05-06T13:00:47.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Registering RDD 399 (mapPartitions at GraphImpl.scala:208) as input to shuffle 59
[2025-05-06T13:00:47.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Got job 52 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:47.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Final stage: ResultStage 388 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:47.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 357, ShuffleMapStage 354, ShuffleMapStage 369, ShuffleMapStage 387, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 384, ShuffleMapStage 363, ShuffleMapStage 378, ShuffleMapStage 360, ShuffleMapStage 381, ShuffleMapStage 348, ShuffleMapStage 366)
[2025-05-06T13:00:47.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 387)
[2025-05-06T13:00:47.341+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Submitting ShuffleMapStage 385 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[391] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:47.342+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 17.4 KiB, free 425.8 MiB)
[2025-05-06T13:00:47.349+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 425.7 MiB)
[2025-05-06T13:00:47.350+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 016737cbcc7e:41421 (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:47.350+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 016737cbcc7e:41421 in memory (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:47.351+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:47.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 385 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[391] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:47.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSchedulerImpl: Adding task set 385.0 with 10 tasks resource profile 0
[2025-05-06T13:00:47.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.18.0.4:46559 in memory (size: 6.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:47.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Submitting ShuffleMapStage 386 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[395] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:00:47.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 0.0 in stage 385.0 (TID 535) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.354+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 16.7 KiB, free 425.8 MiB)
[2025-05-06T13:00:47.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 016737cbcc7e:41421 in memory (size: 48.4 KiB, free: 434.3 MiB)
[2025-05-06T13:00:47.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.8 MiB)
[2025-05-06T13:00:47.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 016737cbcc7e:41421 (size: 6.3 KiB, free: 434.3 MiB)
[2025-05-06T13:00:47.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.18.0.4:46559 in memory (size: 48.4 KiB, free: 181.2 MiB)
[2025-05-06T13:00:47.358+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:47.358+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 386 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[395] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:47.358+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSchedulerImpl: Adding task set 386.0 with 10 tasks resource profile 0
[2025-05-06T13:00:47.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.18.0.4:46559 (size: 6.5 KiB, free: 181.2 MiB)
[2025-05-06T13:00:47.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:00:47.371+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 1.0 in stage 385.0 (TID 536) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.371+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 0.0 in stage 385.0 (TID 535) in 19 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:47.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:00:47.380+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 2.0 in stage 385.0 (TID 537) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 1.0 in stage 385.0 (TID 536) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:47.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:00:47.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 3.0 in stage 385.0 (TID 538) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.398+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 2.0 in stage 385.0 (TID 537) in 17 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:47.403+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:47.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 4.0 in stage 385.0 (TID 539) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.408+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 3.0 in stage 385.0 (TID 538) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:47.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:47.416+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 5.0 in stage 385.0 (TID 540) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 4.0 in stage 385.0 (TID 539) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:47.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:00:47.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 6.0 in stage 385.0 (TID 541) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.424+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 5.0 in stage 385.0 (TID 540) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:47.427+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:00:47.430+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 7.0 in stage 385.0 (TID 542) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.431+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 6.0 in stage 385.0 (TID 541) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:47.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:00:47.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 8.0 in stage 385.0 (TID 543) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 7.0 in stage 385.0 (TID 542) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:47.442+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:00:47.446+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 9.0 in stage 385.0 (TID 544) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.446+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 8.0 in stage 385.0 (TID 543) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:47.449+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_387_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:00:47.452+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 0.0 in stage 386.0 (TID 545) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 9.0 in stage 385.0 (TID 544) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:47.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSchedulerImpl: Removed TaskSet 385.0, whose tasks have all completed, from pool
[2025-05-06T13:00:47.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: ShuffleMapStage 385 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.112 s
[2025-05-06T13:00:47.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:47.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: running: Set(ShuffleMapStage 386)
[2025-05-06T13:00:47.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 387, ResultStage 388)
[2025-05-06T13:00:47.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:47.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.18.0.4:46559 (size: 6.3 KiB, free: 181.0 MiB)
[2025-05-06T13:00:47.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 1.0 in stage 386.0 (TID 546) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 0.0 in stage 386.0 (TID 545) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:47.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 2.0 in stage 386.0 (TID 547) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 1.0 in stage 386.0 (TID 546) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:47.480+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 3.0 in stage 386.0 (TID 548) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 2.0 in stage 386.0 (TID 547) in 8 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:47.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 4.0 in stage 386.0 (TID 549) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 3.0 in stage 386.0 (TID 548) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:47.501+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 5.0 in stage 386.0 (TID 550) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.501+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 4.0 in stage 386.0 (TID 549) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:47.511+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 6.0 in stage 386.0 (TID 551) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.511+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 5.0 in stage 386.0 (TID 550) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:47.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 7.0 in stage 386.0 (TID 552) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 6.0 in stage 386.0 (TID 551) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:47.528+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 8.0 in stage 386.0 (TID 553) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.529+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 7.0 in stage 386.0 (TID 552) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:47.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 9.0 in stage 386.0 (TID 554) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 8.0 in stage 386.0 (TID 553) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:47.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 9.0 in stage 386.0 (TID 554) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:47.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool
[2025-05-06T13:00:47.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: ShuffleMapStage 386 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.191 s
[2025-05-06T13:00:47.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:47.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:47.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 387, ResultStage 388)
[2025-05-06T13:00:47.545+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:47.545+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Submitting ShuffleMapStage 387 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[399] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:47.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 123.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:47.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 016737cbcc7e:41421 in memory (size: 6.5 KiB, free: 434.3 MiB)
[2025-05-06T13:00:47.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 48.6 KiB, free 425.8 MiB)
[2025-05-06T13:00:47.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 016737cbcc7e:41421 (size: 48.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:47.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:47.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 387 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[399] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:47.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSchedulerImpl: Adding task set 387.0 with 10 tasks resource profile 0
[2025-05-06T13:00:47.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.18.0.4:46559 in memory (size: 6.5 KiB, free: 181.0 MiB)
[2025-05-06T13:00:47.555+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 0.0 in stage 387.0 (TID 555) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.18.0.4:46559 (size: 48.6 KiB, free: 181.0 MiB)
[2025-05-06T13:00:47.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 172.18.0.4:47760
[2025-05-06T13:00:47.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_393_0 in memory on 172.18.0.4:46559 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:00:47.566+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.18.0.4:47760
[2025-05-06T13:00:47.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 1.0 in stage 387.0 (TID 556) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 0.0 in stage 387.0 (TID 555) in 73 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:47.634+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_393_1 in memory on 172.18.0.4:46559 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:00:47.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 2.0 in stage 387.0 (TID 557) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 1.0 in stage 387.0 (TID 556) in 75 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:47.708+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_393_2 in memory on 172.18.0.4:46559 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:00:47.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 3.0 in stage 387.0 (TID 558) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.767+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 2.0 in stage 387.0 (TID 557) in 65 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:47.774+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_393_3 in memory on 172.18.0.4:46559 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:00:47.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 4.0 in stage 387.0 (TID 559) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 3.0 in stage 387.0 (TID 558) in 60 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:47.834+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_393_4 in memory on 172.18.0.4:46559 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:00:47.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 5.0 in stage 387.0 (TID 560) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.878+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 4.0 in stage 387.0 (TID 559) in 51 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:47.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_393_5 in memory on 172.18.0.4:46559 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:00:47.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 6.0 in stage 387.0 (TID 561) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 5.0 in stage 387.0 (TID 560) in 54 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:47.941+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_393_6 in memory on 172.18.0.4:46559 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:00:47.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Starting task 7.0 in stage 387.0 (TID 562) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:47.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO TaskSetManager: Finished task 6.0 in stage 387.0 (TID 561) in 61 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:47.999+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:47 INFO BlockManagerInfo: Added rdd_393_7 in memory on 172.18.0.4:46559 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:00:48.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 8.0 in stage 387.0 (TID 563) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.078+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 7.0 in stage 387.0 (TID 562) in 85 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:48.084+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_393_8 in memory on 172.18.0.4:46559 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:00:48.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 9.0 in stage 387.0 (TID 564) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 8.0 in stage 387.0 (TID 563) in 63 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:48.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_393_9 in memory on 172.18.0.4:46559 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:00:48.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 9.0 in stage 387.0 (TID 564) in 70 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:48.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Removed TaskSet 387.0, whose tasks have all completed, from pool
[2025-05-06T13:00:48.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: ShuffleMapStage 387 (mapPartitions at GraphImpl.scala:208) finished in 0.664 s
[2025-05-06T13:00:48.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:48.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:48.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: waiting: Set(ResultStage 388)
[2025-05-06T13:00:48.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:48.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Submitting ResultStage 388 (MapPartitionsRDD[403] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:48.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 18.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:48.217+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 425.7 MiB)
[2025-05-06T13:00:48.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 016737cbcc7e:41421 in memory (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:48.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 016737cbcc7e:41421 (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:48.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:48.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 388 (MapPartitionsRDD[403] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:48.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Adding task set 388.0 with 10 tasks resource profile 0
[2025-05-06T13:00:48.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.18.0.4:46559 in memory (size: 6.3 KiB, free: 175.6 MiB)
[2025-05-06T13:00:48.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 0.0 in stage 388.0 (TID 565) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.18.0.4:46559 (size: 6.7 KiB, free: 175.6 MiB)
[2025-05-06T13:00:48.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.18.0.4:47760
[2025-05-06T13:00:48.234+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_0 in memory on 172.18.0.4:46559 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:00:48.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 1.0 in stage 388.0 (TID 566) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.236+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 0.0 in stage 388.0 (TID 565) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:48.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_1 in memory on 172.18.0.4:46559 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:00:48.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 2.0 in stage 388.0 (TID 567) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 1.0 in stage 388.0 (TID 566) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:48.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_2 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:48.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 3.0 in stage 388.0 (TID 568) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 2.0 in stage 388.0 (TID 567) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:48.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_3 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:00:48.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 4.0 in stage 388.0 (TID 569) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 3.0 in stage 388.0 (TID 568) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:48.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_4 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:48.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 5.0 in stage 388.0 (TID 570) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 4.0 in stage 388.0 (TID 569) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:48.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_5 in memory on 172.18.0.4:46559 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:00:48.290+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 6.0 in stage 388.0 (TID 571) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.290+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 5.0 in stage 388.0 (TID 570) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:48.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_6 in memory on 172.18.0.4:46559 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:00:48.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 7.0 in stage 388.0 (TID 572) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 6.0 in stage 388.0 (TID 571) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:48.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_7 in memory on 172.18.0.4:46559 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:00:48.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 8.0 in stage 388.0 (TID 573) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 7.0 in stage 388.0 (TID 572) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:48.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_8 in memory on 172.18.0.4:46559 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:00:48.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 9.0 in stage 388.0 (TID 574) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 8.0 in stage 388.0 (TID 573) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:48.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_401_9 in memory on 172.18.0.4:46559 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:00:48.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 9.0 in stage 388.0 (TID 574) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:48.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Removed TaskSet 388.0, whose tasks have all completed, from pool
[2025-05-06T13:00:48.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: ResultStage 388 (fold at VertexRDDImpl.scala:90) finished in 0.112 s
[2025-05-06T13:00:48.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:48.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 388: Stage finished
[2025-05-06T13:00:48.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Job 52 finished: fold at VertexRDDImpl.scala:90, took 0.987451 s
[2025-05-06T13:00:48.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO Pregel: Pregel finished iteration 9
[2025-05-06T13:00:48.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO ZippedPartitionsRDD2: Removing RDD 384 from persistence list
[2025-05-06T13:00:48.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManager: Removing RDD 384
[2025-05-06T13:00:48.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO ZippedPartitionsRDD2: Removing RDD 370 from persistence list
[2025-05-06T13:00:48.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManager: Removing RDD 370
[2025-05-06T13:00:48.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO ZippedPartitionsRDD2: Removing RDD 376 from persistence list
[2025-05-06T13:00:48.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManager: Removing RDD 376
[2025-05-06T13:00:48.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO ZippedPartitionsRDD2: Removing RDD 367 from persistence list
[2025-05-06T13:00:48.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManager: Removing RDD 367
[2025-05-06T13:00:48.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO ZippedPartitionsRDD2: Removing RDD 384 from persistence list
[2025-05-06T13:00:48.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManager: Removing RDD 384
[2025-05-06T13:00:48.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO ZippedPartitionsRDD2: Removing RDD 401 from persistence list
[2025-05-06T13:00:48.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManager: Removing RDD 401
[2025-05-06T13:00:48.490+0000] {spark_submit.py:571} INFO - 2025-05-06 13:00:48,490 [INFO] Вычисляем PageRank для определения влиятельности клиентов
[2025-05-06T13:00:48.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:48.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Registering RDD 406 (mapPartitions at GraphImpl.scala:208) as input to shuffle 61
[2025-05-06T13:00:48.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Registering RDD 424 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 62
[2025-05-06T13:00:48.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Registering RDD 414 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 60
[2025-05-06T13:00:48.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Registering RDD 428 (mapPartitions at GraphImpl.scala:208) as input to shuffle 64
[2025-05-06T13:00:48.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Registering RDD 436 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 63
[2025-05-06T13:00:48.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Got job 53 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:48.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Final stage: ResultStage 402 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:48.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 401, ShuffleMapStage 394, ShuffleMapStage 398, ShuffleMapStage 392, ShuffleMapStage 399)
[2025-05-06T13:00:48.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 401, ShuffleMapStage 398, ShuffleMapStage 399)
[2025-05-06T13:00:48.529+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Submitting ShuffleMapStage 396 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[406] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:48.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 117.8 KiB, free 425.7 MiB)
[2025-05-06T13:00:48.540+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 425.6 MiB)
[2025-05-06T13:00:48.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 016737cbcc7e:41421 (size: 46.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:48.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:48.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 396 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[406] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:48.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Adding task set 396.0 with 10 tasks resource profile 0
[2025-05-06T13:00:48.542+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 0.0 in stage 396.0 (TID 575) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 016737cbcc7e:41421 in memory (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:48.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.18.0.4:46559 in memory (size: 6.7 KiB, free: 181.5 MiB)
[2025-05-06T13:00:48.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.18.0.4:46559 (size: 46.9 KiB, free: 181.4 MiB)
[2025-05-06T13:00:48.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 016737cbcc7e:41421 in memory (size: 48.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:48.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.18.0.4:46559 in memory (size: 48.6 KiB, free: 181.5 MiB)
[2025-05-06T13:00:48.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManager: Removing RDD 401
[2025-05-06T13:00:48.589+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 1.0 in stage 396.0 (TID 576) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.589+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 0.0 in stage 396.0 (TID 575) in 47 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:48.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 2.0 in stage 396.0 (TID 577) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 1.0 in stage 396.0 (TID 576) in 23 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:48.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 3.0 in stage 396.0 (TID 578) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 2.0 in stage 396.0 (TID 577) in 20 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:48.647+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 4.0 in stage 396.0 (TID 579) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.648+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 3.0 in stage 396.0 (TID 578) in 17 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:48.664+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 5.0 in stage 396.0 (TID 580) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.665+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 4.0 in stage 396.0 (TID 579) in 17 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:48.676+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 6.0 in stage 396.0 (TID 581) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.676+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 5.0 in stage 396.0 (TID 580) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:48.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 7.0 in stage 396.0 (TID 582) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 6.0 in stage 396.0 (TID 581) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:48.701+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 8.0 in stage 396.0 (TID 583) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.701+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 7.0 in stage 396.0 (TID 582) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:48.716+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 9.0 in stage 396.0 (TID 584) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.716+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 8.0 in stage 396.0 (TID 583) in 15 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:48.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 9.0 in stage 396.0 (TID 584) in 15 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:48.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Removed TaskSet 396.0, whose tasks have all completed, from pool
[2025-05-06T13:00:48.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: ShuffleMapStage 396 (mapPartitions at GraphImpl.scala:208) finished in 0.202 s
[2025-05-06T13:00:48.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:48.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:48.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ShuffleMapStage 398, ResultStage 402, ShuffleMapStage 399, ShuffleMapStage 400)
[2025-05-06T13:00:48.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:48.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Submitting ShuffleMapStage 398 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[424] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:48.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 10.7 KiB, free 425.8 MiB)
[2025-05-06T13:00:48.743+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 425.8 MiB)
[2025-05-06T13:00:48.743+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 016737cbcc7e:41421 (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:48.744+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManager: Removing RDD 393
[2025-05-06T13:00:48.744+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:48.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 398 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[424] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:48.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Adding task set 398.0 with 10 tasks resource profile 0
[2025-05-06T13:00:48.746+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Submitting ShuffleMapStage 399 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[414] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:48.747+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 0.0 in stage 398.0 (TID 585) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.747+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 10.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:48.748+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:48.749+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 016737cbcc7e:41421 (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:48.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:48.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 399 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[414] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:48.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Adding task set 399.0 with 10 tasks resource profile 0
[2025-05-06T13:00:48.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.18.0.4:46559 (size: 5.3 KiB, free: 186.9 MiB)
[2025-05-06T13:00:48.776+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.18.0.4:47760
[2025-05-06T13:00:48.793+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_0 in memory on 172.18.0.4:46559 (size: 13.9 KiB, free: 186.8 MiB)
[2025-05-06T13:00:48.795+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 186.8 MiB)
[2025-05-06T13:00:48.806+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 1.0 in stage 398.0 (TID 586) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.806+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 0.0 in stage 398.0 (TID 585) in 60 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:48.815+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_1 in memory on 172.18.0.4:46559 (size: 13.8 KiB, free: 186.8 MiB)
[2025-05-06T13:00:48.818+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 186.8 MiB)
[2025-05-06T13:00:48.821+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 2.0 in stage 398.0 (TID 587) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.822+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 1.0 in stage 398.0 (TID 586) in 15 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:48.828+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_2 in memory on 172.18.0.4:46559 (size: 13.6 KiB, free: 186.8 MiB)
[2025-05-06T13:00:48.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 186.8 MiB)
[2025-05-06T13:00:48.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 3.0 in stage 398.0 (TID 588) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 2.0 in stage 398.0 (TID 587) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:48.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_3 in memory on 172.18.0.4:46559 (size: 13.5 KiB, free: 186.8 MiB)
[2025-05-06T13:00:48.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 186.7 MiB)
[2025-05-06T13:00:48.844+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 4.0 in stage 398.0 (TID 589) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.845+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 3.0 in stage 398.0 (TID 588) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:48.851+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_4 in memory on 172.18.0.4:46559 (size: 13.7 KiB, free: 186.7 MiB)
[2025-05-06T13:00:48.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 186.7 MiB)
[2025-05-06T13:00:48.856+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 5.0 in stage 398.0 (TID 590) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.856+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 4.0 in stage 398.0 (TID 589) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:48.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_5 in memory on 172.18.0.4:46559 (size: 13.7 KiB, free: 186.7 MiB)
[2025-05-06T13:00:48.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 186.7 MiB)
[2025-05-06T13:00:48.868+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 6.0 in stage 398.0 (TID 591) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.869+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 5.0 in stage 398.0 (TID 590) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:48.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_6 in memory on 172.18.0.4:46559 (size: 13.5 KiB, free: 186.7 MiB)
[2025-05-06T13:00:48.878+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 186.7 MiB)
[2025-05-06T13:00:48.882+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 7.0 in stage 398.0 (TID 592) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 6.0 in stage 398.0 (TID 591) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:48.892+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_7 in memory on 172.18.0.4:46559 (size: 13.4 KiB, free: 186.6 MiB)
[2025-05-06T13:00:48.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 186.6 MiB)
[2025-05-06T13:00:48.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 8.0 in stage 398.0 (TID 593) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 7.0 in stage 398.0 (TID 592) in 15 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:48.905+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_8 in memory on 172.18.0.4:46559 (size: 13.3 KiB, free: 186.6 MiB)
[2025-05-06T13:00:48.906+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 186.6 MiB)
[2025-05-06T13:00:48.911+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 9.0 in stage 398.0 (TID 594) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.911+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 8.0 in stage 398.0 (TID 593) in 14 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:48.917+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_410_9 in memory on 172.18.0.4:46559 (size: 13.0 KiB, free: 186.6 MiB)
[2025-05-06T13:00:48.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added rdd_420_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 186.6 MiB)
[2025-05-06T13:00:48.922+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 0.0 in stage 399.0 (TID 595) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 9.0 in stage 398.0 (TID 594) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:48.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Removed TaskSet 398.0, whose tasks have all completed, from pool
[2025-05-06T13:00:48.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: ShuffleMapStage 398 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.190 s
[2025-05-06T13:00:48.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:48.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: running: Set(ShuffleMapStage 399)
[2025-05-06T13:00:48.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ResultStage 402, ShuffleMapStage 400)
[2025-05-06T13:00:48.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:48.927+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.18.0.4:46559 (size: 5.0 KiB, free: 186.6 MiB)
[2025-05-06T13:00:48.937+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 1.0 in stage 399.0 (TID 596) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.938+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 0.0 in stage 399.0 (TID 595) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:48.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 2.0 in stage 399.0 (TID 597) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 1.0 in stage 399.0 (TID 596) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:48.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 3.0 in stage 399.0 (TID 598) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 2.0 in stage 399.0 (TID 597) in 6 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:48.958+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 4.0 in stage 399.0 (TID 599) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.958+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 3.0 in stage 399.0 (TID 598) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:48.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 5.0 in stage 399.0 (TID 600) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 4.0 in stage 399.0 (TID 599) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:48.971+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 6.0 in stage 399.0 (TID 601) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.971+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 5.0 in stage 399.0 (TID 600) in 5 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:48.976+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 7.0 in stage 399.0 (TID 602) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 6.0 in stage 399.0 (TID 601) in 5 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:48.983+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 8.0 in stage 399.0 (TID 603) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.983+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 7.0 in stage 399.0 (TID 602) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:48.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Starting task 9.0 in stage 399.0 (TID 604) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:48.988+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 8.0 in stage 399.0 (TID 603) in 5 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:48.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSetManager: Finished task 9.0 in stage 399.0 (TID 604) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:48.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool
[2025-05-06T13:00:48.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: ShuffleMapStage 399 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.249 s
[2025-05-06T13:00:48.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:48.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:48.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ResultStage 402, ShuffleMapStage 400)
[2025-05-06T13:00:48.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:48.997+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:48 INFO DAGScheduler: Submitting ShuffleMapStage 400 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[428] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:49.000+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 120.2 KiB, free 425.7 MiB)
[2025-05-06T13:00:49.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 47.5 KiB, free 425.7 MiB)
[2025-05-06T13:00:49.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 016737cbcc7e:41421 in memory (size: 46.9 KiB, free: 434.3 MiB)
[2025-05-06T13:00:49.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 016737cbcc7e:41421 (size: 47.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.015+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:49.015+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 400 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[428] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:49.016+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Adding task set 400.0 with 10 tasks resource profile 0
[2025-05-06T13:00:49.016+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 0.0 in stage 400.0 (TID 605) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.18.0.4:46559 in memory (size: 46.9 KiB, free: 186.6 MiB)
[2025-05-06T13:00:49.019+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 016737cbcc7e:41421 in memory (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.18.0.4:46559 in memory (size: 5.3 KiB, free: 186.6 MiB)
[2025-05-06T13:00:49.024+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.18.0.4:46559 (size: 47.5 KiB, free: 186.6 MiB)
[2025-05-06T13:00:49.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_0 in memory on 172.18.0.4:46559 (size: 494.4 KiB, free: 186.1 MiB)
[2025-05-06T13:00:49.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 172.18.0.4:47760
[2025-05-06T13:00:49.054+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 185.5 MiB)
[2025-05-06T13:00:49.072+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.18.0.4:47760
[2025-05-06T13:00:49.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 1.0 in stage 400.0 (TID 606) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 0.0 in stage 400.0 (TID 605) in 80 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:49.104+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_1 in memory on 172.18.0.4:46559 (size: 618.0 KiB, free: 184.9 MiB)
[2025-05-06T13:00:49.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 184.1 MiB)
[2025-05-06T13:00:49.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 2.0 in stage 400.0 (TID 607) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 1.0 in stage 400.0 (TID 606) in 30 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:49.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_2 in memory on 172.18.0.4:46559 (size: 559.2 KiB, free: 183.5 MiB)
[2025-05-06T13:00:49.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 182.8 MiB)
[2025-05-06T13:00:49.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 3.0 in stage 400.0 (TID 608) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.158+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 2.0 in stage 400.0 (TID 607) in 33 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:49.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_3 in memory on 172.18.0.4:46559 (size: 535.8 KiB, free: 182.3 MiB)
[2025-05-06T13:00:49.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 181.6 MiB)
[2025-05-06T13:00:49.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 4.0 in stage 400.0 (TID 609) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 3.0 in stage 400.0 (TID 608) in 30 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:49.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_4 in memory on 172.18.0.4:46559 (size: 448.0 KiB, free: 181.2 MiB)
[2025-05-06T13:00:49.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 180.6 MiB)
[2025-05-06T13:00:49.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 5.0 in stage 400.0 (TID 610) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 4.0 in stage 400.0 (TID 609) in 24 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:49.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_5 in memory on 172.18.0.4:46559 (size: 522.5 KiB, free: 180.1 MiB)
[2025-05-06T13:00:49.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 179.4 MiB)
[2025-05-06T13:00:49.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 6.0 in stage 400.0 (TID 611) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 5.0 in stage 400.0 (TID 610) in 19 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:49.237+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_6 in memory on 172.18.0.4:46559 (size: 529.8 KiB, free: 178.9 MiB)
[2025-05-06T13:00:49.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 178.3 MiB)
[2025-05-06T13:00:49.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 7.0 in stage 400.0 (TID 612) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 6.0 in stage 400.0 (TID 611) in 22 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:49.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_7 in memory on 172.18.0.4:46559 (size: 596.6 KiB, free: 177.7 MiB)
[2025-05-06T13:00:49.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 176.9 MiB)
[2025-05-06T13:00:49.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 8.0 in stage 400.0 (TID 613) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 7.0 in stage 400.0 (TID 612) in 22 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:49.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_8 in memory on 172.18.0.4:46559 (size: 544.3 KiB, free: 176.4 MiB)
[2025-05-06T13:00:49.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 175.7 MiB)
[2025-05-06T13:00:49.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 9.0 in stage 400.0 (TID 614) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 8.0 in stage 400.0 (TID 613) in 20 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:49.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_412_9 in memory on 172.18.0.4:46559 (size: 610.2 KiB, free: 175.1 MiB)
[2025-05-06T13:00:49.304+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_422_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 9.0 in stage 400.0 (TID 614) in 23 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:49.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Removed TaskSet 400.0, whose tasks have all completed, from pool
[2025-05-06T13:00:49.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: ShuffleMapStage 400 (mapPartitions at GraphImpl.scala:208) finished in 0.317 s
[2025-05-06T13:00:49.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:49.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:49.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ResultStage 402)
[2025-05-06T13:00:49.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:49.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Submitting ShuffleMapStage 401 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[436] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:49.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 12.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:49.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 425.8 MiB)
[2025-05-06T13:00:49.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 016737cbcc7e:41421 in memory (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 016737cbcc7e:41421 (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:49.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 401 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[436] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:49.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Adding task set 401.0 with 10 tasks resource profile 0
[2025-05-06T13:00:49.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 0.0 in stage 401.0 (TID 615) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.18.0.4:46559 in memory (size: 5.0 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.18.0.4:46559 (size: 5.7 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.18.0.4:47760
[2025-05-06T13:00:49.350+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 1.0 in stage 401.0 (TID 616) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 0.0 in stage 401.0 (TID 615) in 31 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:49.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 2.0 in stage 401.0 (TID 617) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 1.0 in stage 401.0 (TID 616) in 30 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:49.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.405+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 3.0 in stage 401.0 (TID 618) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.406+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 2.0 in stage 401.0 (TID 617) in 20 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:49.414+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 4.0 in stage 401.0 (TID 619) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 3.0 in stage 401.0 (TID 618) in 16 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:49.428+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.433+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 5.0 in stage 401.0 (TID 620) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 4.0 in stage 401.0 (TID 619) in 15 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:49.441+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.446+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 6.0 in stage 401.0 (TID 621) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 5.0 in stage 401.0 (TID 620) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:49.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 7.0 in stage 401.0 (TID 622) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 6.0 in stage 401.0 (TID 621) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:49.469+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.474+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 8.0 in stage 401.0 (TID 623) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.475+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 7.0 in stage 401.0 (TID 622) in 15 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:49.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 9.0 in stage 401.0 (TID 624) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 8.0 in stage 401.0 (TID 623) in 17 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:49.501+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_432_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.508+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 9.0 in stage 401.0 (TID 624) in 17 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:49.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Removed TaskSet 401.0, whose tasks have all completed, from pool
[2025-05-06T13:00:49.511+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: ShuffleMapStage 401 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.196 s
[2025-05-06T13:00:49.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:49.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:49.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: waiting: Set(ResultStage 402)
[2025-05-06T13:00:49.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:49.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Submitting ResultStage 402 (EdgeRDDImpl[439] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:49.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 120.0 KiB, free 425.7 MiB)
[2025-05-06T13:00:49.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 47.4 KiB, free 425.6 MiB)
[2025-05-06T13:00:49.533+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 016737cbcc7e:41421 (size: 47.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.533+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:49.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 402 (EdgeRDDImpl[439] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:49.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Adding task set 402.0 with 10 tasks resource profile 0
[2025-05-06T13:00:49.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 0.0 in stage 402.0 (TID 625) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 016737cbcc7e:41421 in memory (size: 47.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.18.0.4:46559 in memory (size: 47.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.18.0.4:46559 (size: 47.4 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.18.0.4:47760
[2025-05-06T13:00:49.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 63 to 172.18.0.4:47760
[2025-05-06T13:00:49.566+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:49.584+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 1.0 in stage 402.0 (TID 626) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.586+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 0.0 in stage 402.0 (TID 625) in 54 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:49.596+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:00:49.598+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 2.0 in stage 402.0 (TID 627) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.599+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 1.0 in stage 402.0 (TID 626) in 15 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:49.609+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:49.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 3.0 in stage 402.0 (TID 628) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 2.0 in stage 402.0 (TID 627) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:49.622+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:00:49.624+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 4.0 in stage 402.0 (TID 629) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.624+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 3.0 in stage 402.0 (TID 628) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:49.635+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:49.637+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 5.0 in stage 402.0 (TID 630) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 4.0 in stage 402.0 (TID 629) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:49.649+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:49.651+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 6.0 in stage 402.0 (TID 631) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.651+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 5.0 in stage 402.0 (TID 630) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:49.658+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:00:49.660+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 7.0 in stage 402.0 (TID 632) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.660+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 6.0 in stage 402.0 (TID 631) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:49.668+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:49.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 8.0 in stage 402.0 (TID 633) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 7.0 in stage 402.0 (TID 632) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:49.680+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:49.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 9.0 in stage 402.0 (TID 634) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 8.0 in stage 402.0 (TID 633) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:49.691+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_438_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:49.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 9.0 in stage 402.0 (TID 634) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:49.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool
[2025-05-06T13:00:49.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: ResultStage 402 (foreachPartition at PageRank.scala:199) finished in 0.181 s
[2025-05-06T13:00:49.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:49.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 402: Stage finished
[2025-05-06T13:00:49.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Job 53 finished: foreachPartition at PageRank.scala:199, took 1.168281 s
[2025-05-06T13:00:49.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO PageRank: PageRank finished iteration 0.
[2025-05-06T13:00:49.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MapPartitionsRDD: Removing RDD 420 from persistence list
[2025-05-06T13:00:49.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManager: Removing RDD 420
[2025-05-06T13:00:49.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MapPartitionsRDD: Removing RDD 422 from persistence list
[2025-05-06T13:00:49.696+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManager: Removing RDD 422
[2025-05-06T13:00:49.707+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:49.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Registering RDD 440 (mapPartitions at GraphImpl.scala:208) as input to shuffle 66
[2025-05-06T13:00:49.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Registering RDD 448 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 65
[2025-05-06T13:00:49.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Got job 54 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:49.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Final stage: ResultStage 418 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:49.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 408, ShuffleMapStage 412, ShuffleMapStage 413, ShuffleMapStage 417, ShuffleMapStage 403, ShuffleMapStage 415)
[2025-05-06T13:00:49.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 417)
[2025-05-06T13:00:49.710+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Submitting ShuffleMapStage 416 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[440] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:49.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 120.5 KiB, free 425.7 MiB)
[2025-05-06T13:00:49.723+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.6 MiB)
[2025-05-06T13:00:49.724+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 016737cbcc7e:41421 in memory (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.724+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 016737cbcc7e:41421 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.724+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:49.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 416 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[440] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:49.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Adding task set 416.0 with 10 tasks resource profile 0
[2025-05-06T13:00:49.726+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 0.0 in stage 416.0 (TID 635) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.726+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.18.0.4:46559 in memory (size: 5.7 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.729+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 016737cbcc7e:41421 in memory (size: 47.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.730+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.18.0.4:46559 in memory (size: 47.4 KiB, free: 174.4 MiB)
[2025-05-06T13:00:49.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.18.0.4:46559 (size: 47.7 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 1.0 in stage 416.0 (TID 636) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 0.0 in stage 416.0 (TID 635) in 29 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:49.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 2.0 in stage 416.0 (TID 637) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.778+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 1.0 in stage 416.0 (TID 636) in 23 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:49.789+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 3.0 in stage 416.0 (TID 638) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 2.0 in stage 416.0 (TID 637) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:49.806+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 4.0 in stage 416.0 (TID 639) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.808+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 3.0 in stage 416.0 (TID 638) in 18 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:49.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 5.0 in stage 416.0 (TID 640) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 4.0 in stage 416.0 (TID 639) in 17 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:49.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 6.0 in stage 416.0 (TID 641) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 5.0 in stage 416.0 (TID 640) in 17 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:49.851+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 7.0 in stage 416.0 (TID 642) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 6.0 in stage 416.0 (TID 641) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:49.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 8.0 in stage 416.0 (TID 643) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 7.0 in stage 416.0 (TID 642) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:49.878+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 9.0 in stage 416.0 (TID 644) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 8.0 in stage 416.0 (TID 643) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:49.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 9.0 in stage 416.0 (TID 644) in 17 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:49.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Removed TaskSet 416.0, whose tasks have all completed, from pool
[2025-05-06T13:00:49.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: ShuffleMapStage 416 (mapPartitions at GraphImpl.scala:208) finished in 0.186 s
[2025-05-06T13:00:49.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:49.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:49.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 417, ResultStage 418)
[2025-05-06T13:00:49.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:49.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Submitting ShuffleMapStage 417 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[448] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:49.899+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 12.8 KiB, free 425.8 MiB)
[2025-05-06T13:00:49.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T13:00:49.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 016737cbcc7e:41421 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:49.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:49.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 417 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[448] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:49.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSchedulerImpl: Adding task set 417.0 with 10 tasks resource profile 0
[2025-05-06T13:00:49.910+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 0.0 in stage 417.0 (TID 645) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.916+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.18.0.4:46559 (size: 5.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.920+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 66 to 172.18.0.4:47760
[2025-05-06T13:00:49.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_444_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.932+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 1.0 in stage 417.0 (TID 646) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 0.0 in stage 417.0 (TID 645) in 22 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:49.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_444_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 2.0 in stage 417.0 (TID 647) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.943+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 1.0 in stage 417.0 (TID 646) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:49.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_444_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 3.0 in stage 417.0 (TID 648) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 2.0 in stage 417.0 (TID 647) in 18 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:49.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_444_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:00:49.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 4.0 in stage 417.0 (TID 649) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 3.0 in stage 417.0 (TID 648) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:49.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_444_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.982+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 5.0 in stage 417.0 (TID 650) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.983+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 4.0 in stage 417.0 (TID 649) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:49.991+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO BlockManagerInfo: Added rdd_444_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:49.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Starting task 6.0 in stage 417.0 (TID 651) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:49.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:49 INFO TaskSetManager: Finished task 5.0 in stage 417.0 (TID 650) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:50.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_444_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.006+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 7.0 in stage 417.0 (TID 652) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.006+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 6.0 in stage 417.0 (TID 651) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:50.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_444_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 8.0 in stage 417.0 (TID 653) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 7.0 in stage 417.0 (TID 652) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:50.023+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_444_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 9.0 in stage 417.0 (TID 654) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 8.0 in stage 417.0 (TID 653) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:50.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_444_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 9.0 in stage 417.0 (TID 654) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:50.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Removed TaskSet 417.0, whose tasks have all completed, from pool
[2025-05-06T13:00:50.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: ShuffleMapStage 417 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.138 s
[2025-05-06T13:00:50.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:50.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:50.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: waiting: Set(ResultStage 418)
[2025-05-06T13:00:50.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:50.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting ResultStage 418 (EdgeRDDImpl[451] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:50.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 120.3 KiB, free 425.7 MiB)
[2025-05-06T13:00:50.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 016737cbcc7e:41421 in memory (size: 47.7 KiB, free: 434.3 MiB)
[2025-05-06T13:00:50.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 47.6 KiB, free 425.8 MiB)
[2025-05-06T13:00:50.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 016737cbcc7e:41421 (size: 47.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:50.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 418 (EdgeRDDImpl[451] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:50.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Adding task set 418.0 with 10 tasks resource profile 0
[2025-05-06T13:00:50.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 0.0 in stage 418.0 (TID 655) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 172.18.0.4:46559 in memory (size: 47.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.052+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.18.0.4:46559 (size: 47.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 65 to 172.18.0.4:47760
[2025-05-06T13:00:50.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:50.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 1.0 in stage 418.0 (TID 656) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 0.0 in stage 418.0 (TID 655) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:50.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:00:50.072+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 2.0 in stage 418.0 (TID 657) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 1.0 in stage 418.0 (TID 656) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:50.083+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:50.098+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 3.0 in stage 418.0 (TID 658) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.098+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 2.0 in stage 418.0 (TID 657) in 25 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:50.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:00:50.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 4.0 in stage 418.0 (TID 659) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 3.0 in stage 418.0 (TID 658) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:50.118+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:50.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 5.0 in stage 418.0 (TID 660) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 4.0 in stage 418.0 (TID 659) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:50.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:50.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 6.0 in stage 418.0 (TID 661) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 5.0 in stage 418.0 (TID 660) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:50.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:00:50.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 7.0 in stage 418.0 (TID 662) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 6.0 in stage 418.0 (TID 661) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:50.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:50.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 8.0 in stage 418.0 (TID 663) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.145+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 7.0 in stage 418.0 (TID 662) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:50.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:50.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 9.0 in stage 418.0 (TID 664) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 8.0 in stage 418.0 (TID 663) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:50.158+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_450_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:50.159+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 9.0 in stage 418.0 (TID 664) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:50.159+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Removed TaskSet 418.0, whose tasks have all completed, from pool
[2025-05-06T13:00:50.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: ResultStage 418 (foreachPartition at PageRank.scala:199) finished in 0.123 s
[2025-05-06T13:00:50.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:50.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 418: Stage finished
[2025-05-06T13:00:50.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Job 54 finished: foreachPartition at PageRank.scala:199, took 0.453518 s
[2025-05-06T13:00:50.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO PageRank: PageRank finished iteration 1.
[2025-05-06T13:00:50.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO ZippedPartitionsRDD2: Removing RDD 432 from persistence list
[2025-05-06T13:00:50.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManager: Removing RDD 432
[2025-05-06T13:00:50.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO ZippedPartitionsRDD2: Removing RDD 438 from persistence list
[2025-05-06T13:00:50.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManager: Removing RDD 438
[2025-05-06T13:00:50.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:50.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Registering RDD 452 (mapPartitions at GraphImpl.scala:208) as input to shuffle 68
[2025-05-06T13:00:50.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Registering RDD 460 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 67
[2025-05-06T13:00:50.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Got job 55 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:50.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Final stage: ResultStage 436 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:50.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 419, ShuffleMapStage 424, ShuffleMapStage 431, ShuffleMapStage 428, ShuffleMapStage 435, ShuffleMapStage 429, ShuffleMapStage 433)
[2025-05-06T13:00:50.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 435)
[2025-05-06T13:00:50.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting ShuffleMapStage 434 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[452] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:50.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 120.8 KiB, free 425.7 MiB)
[2025-05-06T13:00:50.184+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 47.8 KiB, free 425.6 MiB)
[2025-05-06T13:00:50.185+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 016737cbcc7e:41421 (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.185+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:50.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 434 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[452] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:50.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Adding task set 434.0 with 10 tasks resource profile 0
[2025-05-06T13:00:50.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 0.0 in stage 434.0 (TID 665) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 172.18.0.4:46559 in memory (size: 47.6 KiB, free: 174.4 MiB)
[2025-05-06T13:00:50.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 016737cbcc7e:41421 in memory (size: 47.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 016737cbcc7e:41421 in memory (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.18.0.4:46559 in memory (size: 5.9 KiB, free: 174.4 MiB)
[2025-05-06T13:00:50.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.18.0.4:46559 (size: 47.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:50.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 1.0 in stage 434.0 (TID 666) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 0.0 in stage 434.0 (TID 665) in 26 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:50.236+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 2.0 in stage 434.0 (TID 667) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.236+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 1.0 in stage 434.0 (TID 666) in 24 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:50.257+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 3.0 in stage 434.0 (TID 668) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 2.0 in stage 434.0 (TID 667) in 23 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:50.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 4.0 in stage 434.0 (TID 669) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 3.0 in stage 434.0 (TID 668) in 23 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:50.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 5.0 in stage 434.0 (TID 670) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 4.0 in stage 434.0 (TID 669) in 16 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:50.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 6.0 in stage 434.0 (TID 671) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 5.0 in stage 434.0 (TID 670) in 15 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:50.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 7.0 in stage 434.0 (TID 672) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 6.0 in stage 434.0 (TID 671) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:50.342+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 8.0 in stage 434.0 (TID 673) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.342+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 7.0 in stage 434.0 (TID 672) in 18 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:50.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 9.0 in stage 434.0 (TID 674) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.354+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 8.0 in stage 434.0 (TID 673) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:50.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 9.0 in stage 434.0 (TID 674) in 21 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:50.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Removed TaskSet 434.0, whose tasks have all completed, from pool
[2025-05-06T13:00:50.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: ShuffleMapStage 434 (mapPartitions at GraphImpl.scala:208) finished in 0.201 s
[2025-05-06T13:00:50.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:50.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:50.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 435, ResultStage 436)
[2025-05-06T13:00:50.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:50.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting ShuffleMapStage 435 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[460] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:50.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 13.5 KiB, free 425.8 MiB)
[2025-05-06T13:00:50.388+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T13:00:50.388+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 016737cbcc7e:41421 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.388+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:50.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 435 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[460] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:50.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Adding task set 435.0 with 10 tasks resource profile 0
[2025-05-06T13:00:50.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 0.0 in stage 435.0 (TID 675) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.396+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.18.0.4:46559 (size: 6.1 KiB, free: 174.3 MiB)
[2025-05-06T13:00:50.400+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 68 to 172.18.0.4:47760
[2025-05-06T13:00:50.404+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:50.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 1.0 in stage 435.0 (TID 676) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 0.0 in stage 435.0 (TID 675) in 21 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:50.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:50.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 2.0 in stage 435.0 (TID 677) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.422+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 1.0 in stage 435.0 (TID 676) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:50.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:50.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 3.0 in stage 435.0 (TID 678) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 2.0 in stage 435.0 (TID 677) in 26 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:50.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:00:50.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 4.0 in stage 435.0 (TID 679) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.458+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 3.0 in stage 435.0 (TID 678) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:50.463+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.466+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 5.0 in stage 435.0 (TID 680) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.466+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 4.0 in stage 435.0 (TID 679) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:50.471+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.474+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 6.0 in stage 435.0 (TID 681) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.474+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 5.0 in stage 435.0 (TID 680) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:50.479+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 7.0 in stage 435.0 (TID 682) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 6.0 in stage 435.0 (TID 681) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:50.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 8.0 in stage 435.0 (TID 683) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 7.0 in stage 435.0 (TID 682) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:50.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.503+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 9.0 in stage 435.0 (TID 684) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.504+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 8.0 in stage 435.0 (TID 683) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:50.511+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_456_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 9.0 in stage 435.0 (TID 684) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:50.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Removed TaskSet 435.0, whose tasks have all completed, from pool
[2025-05-06T13:00:50.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: ShuffleMapStage 435 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.138 s
[2025-05-06T13:00:50.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:50.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:50.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: waiting: Set(ResultStage 436)
[2025-05-06T13:00:50.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:50.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting ResultStage 436 (EdgeRDDImpl[463] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:50.519+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 120.6 KiB, free 425.7 MiB)
[2025-05-06T13:00:50.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 016737cbcc7e:41421 in memory (size: 47.8 KiB, free: 434.3 MiB)
[2025-05-06T13:00:50.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 47.6 KiB, free 425.7 MiB)
[2025-05-06T13:00:50.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 016737cbcc7e:41421 (size: 47.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:50.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 436 (EdgeRDDImpl[463] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:50.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Adding task set 436.0 with 10 tasks resource profile 0
[2025-05-06T13:00:50.533+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.18.0.4:46559 in memory (size: 47.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 0.0 in stage 436.0 (TID 685) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.18.0.4:46559 (size: 47.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.546+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 67 to 172.18.0.4:47760
[2025-05-06T13:00:50.550+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:50.552+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 1.0 in stage 436.0 (TID 686) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 0.0 in stage 436.0 (TID 685) in 18 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:50.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:00:50.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 2.0 in stage 436.0 (TID 687) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.584+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 1.0 in stage 436.0 (TID 686) in 32 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:50.587+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:50.588+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 3.0 in stage 436.0 (TID 688) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.589+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 2.0 in stage 436.0 (TID 687) in 21 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:50.597+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:00:50.599+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 4.0 in stage 436.0 (TID 689) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.600+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 3.0 in stage 436.0 (TID 688) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:50.606+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:50.608+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 5.0 in stage 436.0 (TID 690) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.608+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 4.0 in stage 436.0 (TID 689) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:50.614+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:50.616+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 6.0 in stage 436.0 (TID 691) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.616+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 5.0 in stage 436.0 (TID 690) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:50.621+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:00:50.623+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 7.0 in stage 436.0 (TID 692) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.623+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 6.0 in stage 436.0 (TID 691) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:50.634+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:50.635+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 8.0 in stage 436.0 (TID 693) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.636+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 7.0 in stage 436.0 (TID 692) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:50.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:50.643+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 9.0 in stage 436.0 (TID 694) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.643+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 8.0 in stage 436.0 (TID 693) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:50.650+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_462_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:50.652+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 9.0 in stage 436.0 (TID 694) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:50.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Removed TaskSet 436.0, whose tasks have all completed, from pool
[2025-05-06T13:00:50.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: ResultStage 436 (foreachPartition at PageRank.scala:199) finished in 0.136 s
[2025-05-06T13:00:50.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:50.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 436: Stage finished
[2025-05-06T13:00:50.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Job 55 finished: foreachPartition at PageRank.scala:199, took 0.481197 s
[2025-05-06T13:00:50.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO PageRank: PageRank finished iteration 2.
[2025-05-06T13:00:50.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO ZippedPartitionsRDD2: Removing RDD 444 from persistence list
[2025-05-06T13:00:50.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManager: Removing RDD 444
[2025-05-06T13:00:50.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO ZippedPartitionsRDD2: Removing RDD 450 from persistence list
[2025-05-06T13:00:50.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManager: Removing RDD 450
[2025-05-06T13:00:50.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:50.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Registering RDD 464 (mapPartitions at GraphImpl.scala:208) as input to shuffle 70
[2025-05-06T13:00:50.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Registering RDD 472 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 69
[2025-05-06T13:00:50.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Got job 56 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:50.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Final stage: ResultStage 456 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:50.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 455, ShuffleMapStage 437, ShuffleMapStage 442, ShuffleMapStage 449, ShuffleMapStage 446, ShuffleMapStage 453, ShuffleMapStage 447, ShuffleMapStage 451)
[2025-05-06T13:00:50.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 455)
[2025-05-06T13:00:50.673+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting ShuffleMapStage 454 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[464] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:50.676+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 121.1 KiB, free 425.7 MiB)
[2025-05-06T13:00:50.677+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 47.8 KiB, free 425.6 MiB)
[2025-05-06T13:00:50.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 016737cbcc7e:41421 (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:50.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 454 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[464] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:50.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Adding task set 454.0 with 10 tasks resource profile 0
[2025-05-06T13:00:50.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 0.0 in stage 454.0 (TID 695) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.18.0.4:46559 (size: 47.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:50.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 1.0 in stage 454.0 (TID 696) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.696+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 0.0 in stage 454.0 (TID 695) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:50.708+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 2.0 in stage 454.0 (TID 697) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 1.0 in stage 454.0 (TID 696) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:50.720+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 3.0 in stage 454.0 (TID 698) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.721+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 2.0 in stage 454.0 (TID 697) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:50.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 4.0 in stage 454.0 (TID 699) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 3.0 in stage 454.0 (TID 698) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:50.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 5.0 in stage 454.0 (TID 700) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 4.0 in stage 454.0 (TID 699) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:50.756+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 6.0 in stage 454.0 (TID 701) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 5.0 in stage 454.0 (TID 700) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:50.770+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 7.0 in stage 454.0 (TID 702) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.770+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 6.0 in stage 454.0 (TID 701) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:50.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 8.0 in stage 454.0 (TID 703) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 7.0 in stage 454.0 (TID 702) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:50.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 9.0 in stage 454.0 (TID 704) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 8.0 in stage 454.0 (TID 703) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:50.802+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 9.0 in stage 454.0 (TID 704) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:50.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Removed TaskSet 454.0, whose tasks have all completed, from pool
[2025-05-06T13:00:50.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: ShuffleMapStage 454 (mapPartitions at GraphImpl.scala:208) finished in 0.129 s
[2025-05-06T13:00:50.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:50.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:50.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 455, ResultStage 456)
[2025-05-06T13:00:50.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:50.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting ShuffleMapStage 455 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[472] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:50.804+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 14.2 KiB, free 425.6 MiB)
[2025-05-06T13:00:50.805+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.6 MiB)
[2025-05-06T13:00:50.805+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 016737cbcc7e:41421 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.805+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:50.805+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 455 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[472] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:50.805+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Adding task set 455.0 with 10 tasks resource profile 0
[2025-05-06T13:00:50.805+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 0.0 in stage 455.0 (TID 705) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.809+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.18.0.4:46559 (size: 6.1 KiB, free: 174.3 MiB)
[2025-05-06T13:00:50.811+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 70 to 172.18.0.4:47760
[2025-05-06T13:00:50.814+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.817+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 1.0 in stage 455.0 (TID 706) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.817+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 0.0 in stage 455.0 (TID 705) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:50.822+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.825+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 2.0 in stage 455.0 (TID 707) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.825+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 1.0 in stage 455.0 (TID 706) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:50.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.832+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 3.0 in stage 455.0 (TID 708) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.832+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 2.0 in stage 455.0 (TID 707) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:50.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 4.0 in stage 455.0 (TID 709) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 3.0 in stage 455.0 (TID 708) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:50.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 5.0 in stage 455.0 (TID 710) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.847+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 4.0 in stage 455.0 (TID 709) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:50.851+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.854+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 6.0 in stage 455.0 (TID 711) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.854+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 5.0 in stage 455.0 (TID 710) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:50.858+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 7.0 in stage 455.0 (TID 712) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 6.0 in stage 455.0 (TID 711) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:50.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.1 MiB)
[2025-05-06T13:00:50.869+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 8.0 in stage 455.0 (TID 713) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.869+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 7.0 in stage 455.0 (TID 712) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:50.874+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.1 MiB)
[2025-05-06T13:00:50.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 9.0 in stage 455.0 (TID 714) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 8.0 in stage 455.0 (TID 713) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:50.881+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_468_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.1 MiB)
[2025-05-06T13:00:50.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 9.0 in stage 455.0 (TID 714) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:50.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Removed TaskSet 455.0, whose tasks have all completed, from pool
[2025-05-06T13:00:50.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: ShuffleMapStage 455 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.081 s
[2025-05-06T13:00:50.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:50.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:50.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: waiting: Set(ResultStage 456)
[2025-05-06T13:00:50.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:50.885+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting ResultStage 456 (EdgeRDDImpl[475] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:50.887+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 120.9 KiB, free 425.5 MiB)
[2025-05-06T13:00:50.892+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 016737cbcc7e:41421 in memory (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.5 MiB)
[2025-05-06T13:00:50.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 016737cbcc7e:41421 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:50.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 456 (EdgeRDDImpl[475] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:50.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Adding task set 456.0 with 10 tasks resource profile 0
[2025-05-06T13:00:50.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.18.0.4:46559 in memory (size: 47.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.894+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 0.0 in stage 456.0 (TID 715) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 016737cbcc7e:41421 in memory (size: 47.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.18.0.4:46559 in memory (size: 47.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 016737cbcc7e:41421 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:50.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.18.0.4:46559 in memory (size: 6.1 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.899+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.18.0.4:46559 (size: 47.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:50.903+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 69 to 172.18.0.4:47760
[2025-05-06T13:00:50.906+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:50.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 1.0 in stage 456.0 (TID 716) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 0.0 in stage 456.0 (TID 715) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:50.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:00:50.917+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 2.0 in stage 456.0 (TID 717) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.917+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 1.0 in stage 456.0 (TID 716) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:50.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:50.936+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 3.0 in stage 456.0 (TID 718) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.937+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 2.0 in stage 456.0 (TID 717) in 19 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:50.943+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:00:50.945+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 4.0 in stage 456.0 (TID 719) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.946+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 3.0 in stage 456.0 (TID 718) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:50.952+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:50.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 5.0 in stage 456.0 (TID 720) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 4.0 in stage 456.0 (TID 719) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:50.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:50.963+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 6.0 in stage 456.0 (TID 721) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.964+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 5.0 in stage 456.0 (TID 720) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:50.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:00:50.971+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 7.0 in stage 456.0 (TID 722) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 6.0 in stage 456.0 (TID 721) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:50.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:50.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 8.0 in stage 456.0 (TID 723) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.981+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 7.0 in stage 456.0 (TID 722) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:50.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:50.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Starting task 9.0 in stage 456.0 (TID 724) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:50.988+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 8.0 in stage 456.0 (TID 723) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:50.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManagerInfo: Added rdd_474_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:50.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSetManager: Finished task 9.0 in stage 456.0 (TID 724) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:50.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Removed TaskSet 456.0, whose tasks have all completed, from pool
[2025-05-06T13:00:50.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: ResultStage 456 (foreachPartition at PageRank.scala:199) finished in 0.110 s
[2025-05-06T13:00:50.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:50.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 456: Stage finished
[2025-05-06T13:00:50.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO DAGScheduler: Job 56 finished: foreachPartition at PageRank.scala:199, took 0.324640 s
[2025-05-06T13:00:50.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO PageRank: PageRank finished iteration 3.
[2025-05-06T13:00:50.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO ZippedPartitionsRDD2: Removing RDD 456 from persistence list
[2025-05-06T13:00:50.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManager: Removing RDD 456
[2025-05-06T13:00:50.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO ZippedPartitionsRDD2: Removing RDD 462 from persistence list
[2025-05-06T13:00:50.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:50 INFO BlockManager: Removing RDD 462
[2025-05-06T13:00:51.004+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:51.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Registering RDD 476 (mapPartitions at GraphImpl.scala:208) as input to shuffle 72
[2025-05-06T13:00:51.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Registering RDD 484 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 71
[2025-05-06T13:00:51.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Got job 57 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:51.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Final stage: ResultStage 478 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:51.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 466, ShuffleMapStage 473, ShuffleMapStage 462, ShuffleMapStage 477, ShuffleMapStage 475, ShuffleMapStage 467, ShuffleMapStage 471, ShuffleMapStage 457, ShuffleMapStage 469)
[2025-05-06T13:00:51.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 477)
[2025-05-06T13:00:51.006+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting ShuffleMapStage 476 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[476] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:51.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 121.4 KiB, free 425.7 MiB)
[2025-05-06T13:00:51.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.6 MiB)
[2025-05-06T13:00:51.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 016737cbcc7e:41421 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:51.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 476 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[476] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:51.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Adding task set 476.0 with 10 tasks resource profile 0
[2025-05-06T13:00:51.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 0.0 in stage 476.0 (TID 725) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.18.0.4:46559 (size: 47.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:51.024+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 1.0 in stage 476.0 (TID 726) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.024+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 0.0 in stage 476.0 (TID 725) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:51.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 2.0 in stage 476.0 (TID 727) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 1.0 in stage 476.0 (TID 726) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:51.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 3.0 in stage 476.0 (TID 728) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 2.0 in stage 476.0 (TID 727) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:51.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 4.0 in stage 476.0 (TID 729) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 3.0 in stage 476.0 (TID 728) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:51.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 5.0 in stage 476.0 (TID 730) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 4.0 in stage 476.0 (TID 729) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:51.078+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 6.0 in stage 476.0 (TID 731) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.078+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 5.0 in stage 476.0 (TID 730) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:51.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 7.0 in stage 476.0 (TID 732) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 6.0 in stage 476.0 (TID 731) in 15 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:51.104+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 8.0 in stage 476.0 (TID 733) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.104+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 7.0 in stage 476.0 (TID 732) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:51.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 9.0 in stage 476.0 (TID 734) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 8.0 in stage 476.0 (TID 733) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:51.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 9.0 in stage 476.0 (TID 734) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:51.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Removed TaskSet 476.0, whose tasks have all completed, from pool
[2025-05-06T13:00:51.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: ShuffleMapStage 476 (mapPartitions at GraphImpl.scala:208) finished in 0.119 s
[2025-05-06T13:00:51.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:51.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:51.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 477, ResultStage 478)
[2025-05-06T13:00:51.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:51.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting ShuffleMapStage 477 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[484] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:51.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 14.9 KiB, free 425.6 MiB)
[2025-05-06T13:00:51.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.6 MiB)
[2025-05-06T13:00:51.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 016737cbcc7e:41421 (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:51.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 477 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[484] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:51.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Adding task set 477.0 with 10 tasks resource profile 0
[2025-05-06T13:00:51.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 0.0 in stage 477.0 (TID 735) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.18.0.4:46559 (size: 6.3 KiB, free: 174.3 MiB)
[2025-05-06T13:00:51.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.18.0.4:47760
[2025-05-06T13:00:51.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 1.0 in stage 477.0 (TID 736) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 0.0 in stage 477.0 (TID 735) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:51.145+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 2.0 in stage 477.0 (TID 737) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 1.0 in stage 477.0 (TID 736) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:51.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 3.0 in stage 477.0 (TID 738) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 2.0 in stage 477.0 (TID 737) in 8 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:51.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 4.0 in stage 477.0 (TID 739) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 3.0 in stage 477.0 (TID 738) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:51.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 5.0 in stage 477.0 (TID 740) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 4.0 in stage 477.0 (TID 739) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:51.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 6.0 in stage 477.0 (TID 741) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 5.0 in stage 477.0 (TID 740) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:51.184+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 7.0 in stage 477.0 (TID 742) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 6.0 in stage 477.0 (TID 741) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:51.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 8.0 in stage 477.0 (TID 743) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 7.0 in stage 477.0 (TID 742) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:51.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 9.0 in stage 477.0 (TID 744) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 8.0 in stage 477.0 (TID 743) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:51.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_480_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 9.0 in stage 477.0 (TID 744) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:51.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Removed TaskSet 477.0, whose tasks have all completed, from pool
[2025-05-06T13:00:51.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: ShuffleMapStage 477 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.084 s
[2025-05-06T13:00:51.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:51.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:51.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: waiting: Set(ResultStage 478)
[2025-05-06T13:00:51.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:51.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting ResultStage 478 (EdgeRDDImpl[487] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:51.213+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 121.2 KiB, free 425.5 MiB)
[2025-05-06T13:00:51.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 016737cbcc7e:41421 in memory (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 47.8 KiB, free 425.5 MiB)
[2025-05-06T13:00:51.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 016737cbcc7e:41421 (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:51.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 478 (EdgeRDDImpl[487] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:51.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Adding task set 478.0 with 10 tasks resource profile 0
[2025-05-06T13:00:51.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.18.0.4:46559 in memory (size: 47.9 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 0.0 in stage 478.0 (TID 745) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 016737cbcc7e:41421 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.227+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 172.18.0.4:46559 in memory (size: 6.1 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.228+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.18.0.4:46559 (size: 47.8 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 016737cbcc7e:41421 in memory (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.18.0.4:46559 in memory (size: 47.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.18.0.4:47760
[2025-05-06T13:00:51.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:51.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 1.0 in stage 478.0 (TID 746) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 0.0 in stage 478.0 (TID 745) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:51.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:00:51.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 2.0 in stage 478.0 (TID 747) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 1.0 in stage 478.0 (TID 746) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:51.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:51.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 3.0 in stage 478.0 (TID 748) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 2.0 in stage 478.0 (TID 747) in 16 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:51.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:00:51.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 4.0 in stage 478.0 (TID 749) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 3.0 in stage 478.0 (TID 748) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:51.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:51.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 5.0 in stage 478.0 (TID 750) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 4.0 in stage 478.0 (TID 749) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:51.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:51.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 6.0 in stage 478.0 (TID 751) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 5.0 in stage 478.0 (TID 750) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:51.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:00:51.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 7.0 in stage 478.0 (TID 752) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 6.0 in stage 478.0 (TID 751) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:51.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:51.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 8.0 in stage 478.0 (TID 753) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 7.0 in stage 478.0 (TID 752) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:51.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:51.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 9.0 in stage 478.0 (TID 754) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 8.0 in stage 478.0 (TID 753) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:51.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_486_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:51.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 9.0 in stage 478.0 (TID 754) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:51.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Removed TaskSet 478.0, whose tasks have all completed, from pool
[2025-05-06T13:00:51.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: ResultStage 478 (foreachPartition at PageRank.scala:199) finished in 0.110 s
[2025-05-06T13:00:51.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:51.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 478: Stage finished
[2025-05-06T13:00:51.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Job 57 finished: foreachPartition at PageRank.scala:199, took 0.317850 s
[2025-05-06T13:00:51.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO PageRank: PageRank finished iteration 4.
[2025-05-06T13:00:51.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO ZippedPartitionsRDD2: Removing RDD 468 from persistence list
[2025-05-06T13:00:51.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManager: Removing RDD 468
[2025-05-06T13:00:51.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO ZippedPartitionsRDD2: Removing RDD 474 from persistence list
[2025-05-06T13:00:51.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManager: Removing RDD 474
[2025-05-06T13:00:51.330+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:51.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Registering RDD 488 (mapPartitions at GraphImpl.scala:208) as input to shuffle 74
[2025-05-06T13:00:51.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Registering RDD 496 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 73
[2025-05-06T13:00:51.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Got job 58 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:51.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Final stage: ResultStage 502 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:51.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 484, ShuffleMapStage 491, ShuffleMapStage 488, ShuffleMapStage 495, ShuffleMapStage 489, ShuffleMapStage 499, ShuffleMapStage 493, ShuffleMapStage 497, ShuffleMapStage 479, ShuffleMapStage 501)
[2025-05-06T13:00:51.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 501)
[2025-05-06T13:00:51.332+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting ShuffleMapStage 500 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[488] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:51.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 121.7 KiB, free 425.7 MiB)
[2025-05-06T13:00:51.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.6 MiB)
[2025-05-06T13:00:51.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 016737cbcc7e:41421 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:51.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 500 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[488] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:51.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Adding task set 500.0 with 10 tasks resource profile 0
[2025-05-06T13:00:51.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 0.0 in stage 500.0 (TID 755) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.341+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.18.0.4:46559 (size: 47.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:51.359+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 1.0 in stage 500.0 (TID 756) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.360+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 0.0 in stage 500.0 (TID 755) in 23 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:51.378+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 2.0 in stage 500.0 (TID 757) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.378+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 1.0 in stage 500.0 (TID 756) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:51.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 3.0 in stage 500.0 (TID 758) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 2.0 in stage 500.0 (TID 757) in 20 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:51.408+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 4.0 in stage 500.0 (TID 759) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.409+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 3.0 in stage 500.0 (TID 758) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:51.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 5.0 in stage 500.0 (TID 760) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 4.0 in stage 500.0 (TID 759) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:51.436+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 6.0 in stage 500.0 (TID 761) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 5.0 in stage 500.0 (TID 760) in 17 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:51.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 7.0 in stage 500.0 (TID 762) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 6.0 in stage 500.0 (TID 761) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:51.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 8.0 in stage 500.0 (TID 763) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 7.0 in stage 500.0 (TID 762) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:51.471+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 9.0 in stage 500.0 (TID 764) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 8.0 in stage 500.0 (TID 763) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:51.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 9.0 in stage 500.0 (TID 764) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:51.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Removed TaskSet 500.0, whose tasks have all completed, from pool
[2025-05-06T13:00:51.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: ShuffleMapStage 500 (mapPartitions at GraphImpl.scala:208) finished in 0.151 s
[2025-05-06T13:00:51.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:51.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:51.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: waiting: Set(ResultStage 502, ShuffleMapStage 501)
[2025-05-06T13:00:51.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:51.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting ShuffleMapStage 501 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[496] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:51.485+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 15.6 KiB, free 425.6 MiB)
[2025-05-06T13:00:51.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 425.6 MiB)
[2025-05-06T13:00:51.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 016737cbcc7e:41421 (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:51.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 501 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[496] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:51.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Adding task set 501.0 with 10 tasks resource profile 0
[2025-05-06T13:00:51.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 0.0 in stage 501.0 (TID 765) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.490+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.18.0.4:46559 (size: 6.4 KiB, free: 174.3 MiB)
[2025-05-06T13:00:51.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.18.0.4:47760
[2025-05-06T13:00:51.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 1.0 in stage 501.0 (TID 766) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 0.0 in stage 501.0 (TID 765) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:51.504+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.507+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 2.0 in stage 501.0 (TID 767) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.507+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 1.0 in stage 501.0 (TID 766) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:51.511+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 3.0 in stage 501.0 (TID 768) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 2.0 in stage 501.0 (TID 767) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:51.522+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 4.0 in stage 501.0 (TID 769) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 3.0 in stage 501.0 (TID 768) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:51.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 5.0 in stage 501.0 (TID 770) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 4.0 in stage 501.0 (TID 769) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:51.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.542+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 6.0 in stage 501.0 (TID 771) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.543+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 5.0 in stage 501.0 (TID 770) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:51.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.550+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 7.0 in stage 501.0 (TID 772) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.550+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 6.0 in stage 501.0 (TID 771) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:51.556+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 8.0 in stage 501.0 (TID 773) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 7.0 in stage 501.0 (TID 772) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:51.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 9.0 in stage 501.0 (TID 774) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 8.0 in stage 501.0 (TID 773) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:51.575+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_492_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.580+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 9.0 in stage 501.0 (TID 774) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:51.580+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Removed TaskSet 501.0, whose tasks have all completed, from pool
[2025-05-06T13:00:51.580+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: ShuffleMapStage 501 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.096 s
[2025-05-06T13:00:51.580+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:51.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:51.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: waiting: Set(ResultStage 502)
[2025-05-06T13:00:51.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:51.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting ResultStage 502 (EdgeRDDImpl[499] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:51.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 121.5 KiB, free 425.5 MiB)
[2025-05-06T13:00:51.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.4 MiB)
[2025-05-06T13:00:51.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 016737cbcc7e:41421 (size: 47.9 KiB, free: 434.1 MiB)
[2025-05-06T13:00:51.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:51.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 016737cbcc7e:41421 in memory (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 502 (EdgeRDDImpl[499] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:51.594+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Adding task set 502.0 with 10 tasks resource profile 0
[2025-05-06T13:00:51.594+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 172.18.0.4:46559 in memory (size: 47.9 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.595+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 0.0 in stage 502.0 (TID 775) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.596+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 016737cbcc7e:41421 in memory (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.597+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 172.18.0.4:46559 in memory (size: 47.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.599+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 016737cbcc7e:41421 in memory (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.599+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.18.0.4:46559 in memory (size: 6.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.600+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.18.0.4:46559 (size: 47.9 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.614+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.18.0.4:47760
[2025-05-06T13:00:51.617+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:51.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 1.0 in stage 502.0 (TID 776) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 0.0 in stage 502.0 (TID 775) in 25 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:51.636+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:00:51.637+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 2.0 in stage 502.0 (TID 777) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 1.0 in stage 502.0 (TID 776) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:51.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:51.647+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 3.0 in stage 502.0 (TID 778) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.647+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 2.0 in stage 502.0 (TID 777) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:51.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:00:51.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 4.0 in stage 502.0 (TID 779) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 3.0 in stage 502.0 (TID 778) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:51.662+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:51.663+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 5.0 in stage 502.0 (TID 780) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.664+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 4.0 in stage 502.0 (TID 779) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:51.669+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:51.670+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 6.0 in stage 502.0 (TID 781) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 5.0 in stage 502.0 (TID 780) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:51.677+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:00:51.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 7.0 in stage 502.0 (TID 782) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 6.0 in stage 502.0 (TID 781) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:51.684+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:51.685+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 8.0 in stage 502.0 (TID 783) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.686+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 7.0 in stage 502.0 (TID 782) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:51.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:51.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 9.0 in stage 502.0 (TID 784) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 8.0 in stage 502.0 (TID 783) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:51.700+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_498_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:51.701+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 9.0 in stage 502.0 (TID 784) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:51.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Removed TaskSet 502.0, whose tasks have all completed, from pool
[2025-05-06T13:00:51.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: ResultStage 502 (foreachPartition at PageRank.scala:199) finished in 0.121 s
[2025-05-06T13:00:51.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:51.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 502: Stage finished
[2025-05-06T13:00:51.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Job 58 finished: foreachPartition at PageRank.scala:199, took 0.371687 s
[2025-05-06T13:00:51.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO PageRank: PageRank finished iteration 5.
[2025-05-06T13:00:51.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO ZippedPartitionsRDD2: Removing RDD 480 from persistence list
[2025-05-06T13:00:51.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManager: Removing RDD 480
[2025-05-06T13:00:51.703+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO ZippedPartitionsRDD2: Removing RDD 486 from persistence list
[2025-05-06T13:00:51.703+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManager: Removing RDD 486
[2025-05-06T13:00:51.711+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:51.712+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Registering RDD 500 (mapPartitions at GraphImpl.scala:208) as input to shuffle 76
[2025-05-06T13:00:51.712+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Registering RDD 508 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 75
[2025-05-06T13:00:51.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Got job 59 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:51.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Final stage: ResultStage 528 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:51.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 527, ShuffleMapStage 521, ShuffleMapStage 503, ShuffleMapStage 513, ShuffleMapStage 525, ShuffleMapStage 517, ShuffleMapStage 515, ShuffleMapStage 512, ShuffleMapStage 519, ShuffleMapStage 508, ShuffleMapStage 523)
[2025-05-06T13:00:51.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 527)
[2025-05-06T13:00:51.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting ShuffleMapStage 526 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[500] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:51.716+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 122.0 KiB, free 425.7 MiB)
[2025-05-06T13:00:51.717+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.6 MiB)
[2025-05-06T13:00:51.718+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 016737cbcc7e:41421 (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.718+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:51.718+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 526 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[500] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:51.718+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Adding task set 526.0 with 10 tasks resource profile 0
[2025-05-06T13:00:51.719+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 0.0 in stage 526.0 (TID 785) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.722+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.18.0.4:46559 (size: 48.1 KiB, free: 174.3 MiB)
[2025-05-06T13:00:51.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 1.0 in stage 526.0 (TID 786) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 0.0 in stage 526.0 (TID 785) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:51.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 2.0 in stage 526.0 (TID 787) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.746+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 1.0 in stage 526.0 (TID 786) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:51.756+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 3.0 in stage 526.0 (TID 788) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.756+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 2.0 in stage 526.0 (TID 787) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:51.767+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 4.0 in stage 526.0 (TID 789) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.767+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 3.0 in stage 526.0 (TID 788) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:51.778+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 5.0 in stage 526.0 (TID 790) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.779+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 4.0 in stage 526.0 (TID 789) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:51.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 6.0 in stage 526.0 (TID 791) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.793+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 5.0 in stage 526.0 (TID 790) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:51.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 7.0 in stage 526.0 (TID 792) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.804+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 6.0 in stage 526.0 (TID 791) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:51.814+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 8.0 in stage 526.0 (TID 793) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.815+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 7.0 in stage 526.0 (TID 792) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:51.825+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 9.0 in stage 526.0 (TID 794) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 8.0 in stage 526.0 (TID 793) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:51.837+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 9.0 in stage 526.0 (TID 794) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:51.837+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Removed TaskSet 526.0, whose tasks have all completed, from pool
[2025-05-06T13:00:51.837+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: ShuffleMapStage 526 (mapPartitions at GraphImpl.scala:208) finished in 0.124 s
[2025-05-06T13:00:51.837+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:51.837+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:51.837+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 527, ResultStage 528)
[2025-05-06T13:00:51.837+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:51.837+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting ShuffleMapStage 527 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[508] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:51.838+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 16.4 KiB, free 425.6 MiB)
[2025-05-06T13:00:51.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 425.6 MiB)
[2025-05-06T13:00:51.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 016737cbcc7e:41421 (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:51.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 527 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[508] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:51.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Adding task set 527.0 with 10 tasks resource profile 0
[2025-05-06T13:00:51.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 0.0 in stage 527.0 (TID 795) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.844+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.18.0.4:46559 (size: 6.5 KiB, free: 174.3 MiB)
[2025-05-06T13:00:51.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.18.0.4:47760
[2025-05-06T13:00:51.849+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 1.0 in stage 527.0 (TID 796) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 0.0 in stage 527.0 (TID 795) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:51.856+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 2.0 in stage 527.0 (TID 797) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 1.0 in stage 527.0 (TID 796) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:51.864+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.867+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 3.0 in stage 527.0 (TID 798) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.868+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 2.0 in stage 527.0 (TID 797) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:51.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.875+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 4.0 in stage 527.0 (TID 799) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 3.0 in stage 527.0 (TID 798) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:51.880+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.882+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 5.0 in stage 527.0 (TID 800) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 4.0 in stage 527.0 (TID 799) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:51.886+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 6.0 in stage 527.0 (TID 801) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 5.0 in stage 527.0 (TID 800) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:51.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 7.0 in stage 527.0 (TID 802) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 6.0 in stage 527.0 (TID 801) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:51.902+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.904+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 8.0 in stage 527.0 (TID 803) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.904+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 7.0 in stage 527.0 (TID 802) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:51.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.912+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 9.0 in stage 527.0 (TID 804) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.912+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 8.0 in stage 527.0 (TID 803) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:51.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_504_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.920+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 9.0 in stage 527.0 (TID 804) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:51.920+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Removed TaskSet 527.0, whose tasks have all completed, from pool
[2025-05-06T13:00:51.920+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: ShuffleMapStage 527 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.082 s
[2025-05-06T13:00:51.921+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:51.921+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:51.921+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: waiting: Set(ResultStage 528)
[2025-05-06T13:00:51.921+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:51.921+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting ResultStage 528 (EdgeRDDImpl[511] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:51.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 121.8 KiB, free 425.5 MiB)
[2025-05-06T13:00:51.930+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 016737cbcc7e:41421 in memory (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.4 MiB)
[2025-05-06T13:00:51.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 016737cbcc7e:41421 (size: 48.0 KiB, free: 434.1 MiB)
[2025-05-06T13:00:51.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:51.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 528 (EdgeRDDImpl[511] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:51.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSchedulerImpl: Adding task set 528.0 with 10 tasks resource profile 0
[2025-05-06T13:00:51.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 172.18.0.4:46559 in memory (size: 6.4 KiB, free: 174.1 MiB)
[2025-05-06T13:00:51.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 0.0 in stage 528.0 (TID 805) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 016737cbcc7e:41421 in memory (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 172.18.0.4:46559 in memory (size: 48.1 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.936+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 016737cbcc7e:41421 in memory (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:00:51.937+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.18.0.4:46559 in memory (size: 47.9 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.937+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.18.0.4:46559 (size: 48.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:51.941+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.18.0.4:47760
[2025-05-06T13:00:51.943+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_510_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:51.945+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 1.0 in stage 528.0 (TID 806) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.945+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 0.0 in stage 528.0 (TID 805) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:51.952+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_510_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:00:51.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 2.0 in stage 528.0 (TID 807) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 1.0 in stage 528.0 (TID 806) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:51.968+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_510_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:51.969+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 3.0 in stage 528.0 (TID 808) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 2.0 in stage 528.0 (TID 807) in 16 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:51.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_510_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:00:51.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 4.0 in stage 528.0 (TID 809) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.981+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 3.0 in stage 528.0 (TID 808) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:51.989+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_510_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:51.990+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 5.0 in stage 528.0 (TID 810) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.990+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 4.0 in stage 528.0 (TID 809) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:51.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO BlockManagerInfo: Added rdd_510_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:51.997+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Starting task 6.0 in stage 528.0 (TID 811) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:51.998+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:51 INFO TaskSetManager: Finished task 5.0 in stage 528.0 (TID 810) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:52.003+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_510_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:00:52.004+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 7.0 in stage 528.0 (TID 812) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.004+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 6.0 in stage 528.0 (TID 811) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:52.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_510_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:52.011+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 8.0 in stage 528.0 (TID 813) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.012+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 7.0 in stage 528.0 (TID 812) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:52.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_510_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:52.018+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 9.0 in stage 528.0 (TID 814) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.019+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 8.0 in stage 528.0 (TID 813) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:52.024+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_510_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:52.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 9.0 in stage 528.0 (TID 814) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:52.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Removed TaskSet 528.0, whose tasks have all completed, from pool
[2025-05-06T13:00:52.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: ResultStage 528 (foreachPartition at PageRank.scala:199) finished in 0.104 s
[2025-05-06T13:00:52.026+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:52.026+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 528: Stage finished
[2025-05-06T13:00:52.026+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Job 59 finished: foreachPartition at PageRank.scala:199, took 0.314557 s
[2025-05-06T13:00:52.026+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO PageRank: PageRank finished iteration 6.
[2025-05-06T13:00:52.026+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO ZippedPartitionsRDD2: Removing RDD 492 from persistence list
[2025-05-06T13:00:52.026+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManager: Removing RDD 492
[2025-05-06T13:00:52.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO ZippedPartitionsRDD2: Removing RDD 498 from persistence list
[2025-05-06T13:00:52.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManager: Removing RDD 498
[2025-05-06T13:00:52.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:52.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Registering RDD 512 (mapPartitions at GraphImpl.scala:208) as input to shuffle 78
[2025-05-06T13:00:52.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Registering RDD 520 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 77
[2025-05-06T13:00:52.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Got job 60 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:52.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Final stage: ResultStage 556 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:52.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 538, ShuffleMapStage 553, ShuffleMapStage 545, ShuffleMapStage 539, ShuffleMapStage 543, ShuffleMapStage 547, ShuffleMapStage 529, ShuffleMapStage 551, ShuffleMapStage 555, ShuffleMapStage 534, ShuffleMapStage 549, ShuffleMapStage 541)
[2025-05-06T13:00:52.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 555)
[2025-05-06T13:00:52.037+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting ShuffleMapStage 554 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[512] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:52.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 122.3 KiB, free 425.7 MiB)
[2025-05-06T13:00:52.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 48.3 KiB, free 425.6 MiB)
[2025-05-06T13:00:52.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 016737cbcc7e:41421 (size: 48.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:52.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 554 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[512] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:52.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Adding task set 554.0 with 10 tasks resource profile 0
[2025-05-06T13:00:52.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 0.0 in stage 554.0 (TID 815) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.18.0.4:46559 (size: 48.3 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 1.0 in stage 554.0 (TID 816) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 0.0 in stage 554.0 (TID 815) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:52.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 2.0 in stage 554.0 (TID 817) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 1.0 in stage 554.0 (TID 816) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:52.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 3.0 in stage 554.0 (TID 818) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 2.0 in stage 554.0 (TID 817) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:52.094+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 4.0 in stage 554.0 (TID 819) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.094+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 3.0 in stage 554.0 (TID 818) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:52.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 5.0 in stage 554.0 (TID 820) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 4.0 in stage 554.0 (TID 819) in 15 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:52.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 6.0 in stage 554.0 (TID 821) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 5.0 in stage 554.0 (TID 820) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:52.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 7.0 in stage 554.0 (TID 822) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 6.0 in stage 554.0 (TID 821) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:52.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 8.0 in stage 554.0 (TID 823) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 7.0 in stage 554.0 (TID 822) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:52.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 9.0 in stage 554.0 (TID 824) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 8.0 in stage 554.0 (TID 823) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:52.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 9.0 in stage 554.0 (TID 824) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:52.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Removed TaskSet 554.0, whose tasks have all completed, from pool
[2025-05-06T13:00:52.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: ShuffleMapStage 554 (mapPartitions at GraphImpl.scala:208) finished in 0.130 s
[2025-05-06T13:00:52.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:52.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:52.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: waiting: Set(ResultStage 556, ShuffleMapStage 555)
[2025-05-06T13:00:52.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:52.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting ShuffleMapStage 555 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[520] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:52.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 17.1 KiB, free 425.6 MiB)
[2025-05-06T13:00:52.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 425.6 MiB)
[2025-05-06T13:00:52.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 016737cbcc7e:41421 (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:52.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 555 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[520] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:52.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Adding task set 555.0 with 10 tasks resource profile 0
[2025-05-06T13:00:52.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 0.0 in stage 555.0 (TID 825) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.174+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 172.18.0.4:46559 (size: 6.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.18.0.4:47760
[2025-05-06T13:00:52.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 1.0 in stage 555.0 (TID 826) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.182+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 0.0 in stage 555.0 (TID 825) in 11 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:52.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 2.0 in stage 555.0 (TID 827) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 1.0 in stage 555.0 (TID 826) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:52.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 3.0 in stage 555.0 (TID 828) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 2.0 in stage 555.0 (TID 827) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:52.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 4.0 in stage 555.0 (TID 829) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 3.0 in stage 555.0 (TID 828) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:52.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 5.0 in stage 555.0 (TID 830) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 4.0 in stage 555.0 (TID 829) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:52.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 6.0 in stage 555.0 (TID 831) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 5.0 in stage 555.0 (TID 830) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:52.231+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 7.0 in stage 555.0 (TID 832) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 6.0 in stage 555.0 (TID 831) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:52.244+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.1 MiB)
[2025-05-06T13:00:52.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 8.0 in stage 555.0 (TID 833) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 7.0 in stage 555.0 (TID 832) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:52.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.1 MiB)
[2025-05-06T13:00:52.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 9.0 in stage 555.0 (TID 834) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 8.0 in stage 555.0 (TID 833) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:52.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_516_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.1 MiB)
[2025-05-06T13:00:52.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 9.0 in stage 555.0 (TID 834) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:52.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Removed TaskSet 555.0, whose tasks have all completed, from pool
[2025-05-06T13:00:52.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: ShuffleMapStage 555 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.095 s
[2025-05-06T13:00:52.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:52.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:52.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: waiting: Set(ResultStage 556)
[2025-05-06T13:00:52.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:52.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting ResultStage 556 (EdgeRDDImpl[523] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:52.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 122.1 KiB, free 425.5 MiB)
[2025-05-06T13:00:52.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 016737cbcc7e:41421 in memory (size: 48.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.5 MiB)
[2025-05-06T13:00:52.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 016737cbcc7e:41421 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:52.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 172.18.0.4:46559 in memory (size: 48.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 556 (EdgeRDDImpl[523] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:52.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Adding task set 556.0 with 10 tasks resource profile 0
[2025-05-06T13:00:52.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 0.0 in stage 556.0 (TID 835) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 016737cbcc7e:41421 in memory (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.18.0.4:46559 in memory (size: 6.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 016737cbcc7e:41421 in memory (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 172.18.0.4:46559 in memory (size: 48.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 172.18.0.4:46559 (size: 48.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.18.0.4:47760
[2025-05-06T13:00:52.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:52.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 1.0 in stage 556.0 (TID 836) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 0.0 in stage 556.0 (TID 835) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:52.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:00:52.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 2.0 in stage 556.0 (TID 837) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 1.0 in stage 556.0 (TID 836) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:52.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:52.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 3.0 in stage 556.0 (TID 838) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 2.0 in stage 556.0 (TID 837) in 19 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:52.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:00:52.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 4.0 in stage 556.0 (TID 839) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 3.0 in stage 556.0 (TID 838) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:52.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:52.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 5.0 in stage 556.0 (TID 840) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 4.0 in stage 556.0 (TID 839) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:52.343+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:52.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 6.0 in stage 556.0 (TID 841) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 5.0 in stage 556.0 (TID 840) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:52.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:00:52.354+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 7.0 in stage 556.0 (TID 842) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.354+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 6.0 in stage 556.0 (TID 841) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:52.360+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:52.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 8.0 in stage 556.0 (TID 843) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 7.0 in stage 556.0 (TID 842) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:52.368+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:52.369+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 9.0 in stage 556.0 (TID 844) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.370+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 8.0 in stage 556.0 (TID 843) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:52.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_522_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:52.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 9.0 in stage 556.0 (TID 844) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:52.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Removed TaskSet 556.0, whose tasks have all completed, from pool
[2025-05-06T13:00:52.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: ResultStage 556 (foreachPartition at PageRank.scala:199) finished in 0.113 s
[2025-05-06T13:00:52.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:52.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 556: Stage finished
[2025-05-06T13:00:52.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Job 60 finished: foreachPartition at PageRank.scala:199, took 0.342757 s
[2025-05-06T13:00:52.378+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO PageRank: PageRank finished iteration 7.
[2025-05-06T13:00:52.378+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO ZippedPartitionsRDD2: Removing RDD 504 from persistence list
[2025-05-06T13:00:52.378+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManager: Removing RDD 504
[2025-05-06T13:00:52.378+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO ZippedPartitionsRDD2: Removing RDD 510 from persistence list
[2025-05-06T13:00:52.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManager: Removing RDD 510
[2025-05-06T13:00:52.413+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:52.415+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Registering RDD 524 (mapPartitions at GraphImpl.scala:208) as input to shuffle 80
[2025-05-06T13:00:52.415+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Registering RDD 532 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 79
[2025-05-06T13:00:52.415+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Got job 61 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:52.415+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Final stage: ResultStage 586 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:52.415+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 571, ShuffleMapStage 575, ShuffleMapStage 557, ShuffleMapStage 579, ShuffleMapStage 583, ShuffleMapStage 562, ShuffleMapStage 569, ShuffleMapStage 566, ShuffleMapStage 581, ShuffleMapStage 573, ShuffleMapStage 585, ShuffleMapStage 567, ShuffleMapStage 577)
[2025-05-06T13:00:52.415+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 585)
[2025-05-06T13:00:52.416+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting ShuffleMapStage 584 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[524] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:52.419+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 122.5 KiB, free 425.7 MiB)
[2025-05-06T13:00:52.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 425.6 MiB)
[2025-05-06T13:00:52.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 016737cbcc7e:41421 (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:52.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 584 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[524] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:52.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Adding task set 584.0 with 10 tasks resource profile 0
[2025-05-06T13:00:52.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 0.0 in stage 584.0 (TID 845) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.424+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 172.18.0.4:46559 (size: 48.2 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.435+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 1.0 in stage 584.0 (TID 846) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.435+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 0.0 in stage 584.0 (TID 845) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:52.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 2.0 in stage 584.0 (TID 847) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 1.0 in stage 584.0 (TID 846) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:52.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 3.0 in stage 584.0 (TID 848) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 2.0 in stage 584.0 (TID 847) in 13 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:52.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 4.0 in stage 584.0 (TID 849) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 3.0 in stage 584.0 (TID 848) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:52.487+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 5.0 in stage 584.0 (TID 850) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 4.0 in stage 584.0 (TID 849) in 15 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:52.500+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 6.0 in stage 584.0 (TID 851) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.501+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 5.0 in stage 584.0 (TID 850) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:52.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 7.0 in stage 584.0 (TID 852) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 6.0 in stage 584.0 (TID 851) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:52.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 8.0 in stage 584.0 (TID 853) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 7.0 in stage 584.0 (TID 852) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:52.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 9.0 in stage 584.0 (TID 854) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 8.0 in stage 584.0 (TID 853) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:52.550+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 9.0 in stage 584.0 (TID 854) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:52.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Removed TaskSet 584.0, whose tasks have all completed, from pool
[2025-05-06T13:00:52.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: ShuffleMapStage 584 (mapPartitions at GraphImpl.scala:208) finished in 0.134 s
[2025-05-06T13:00:52.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:52.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:52.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: waiting: Set(ResultStage 586, ShuffleMapStage 585)
[2025-05-06T13:00:52.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:52.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting ShuffleMapStage 585 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[532] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:52.552+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 17.8 KiB, free 425.6 MiB)
[2025-05-06T13:00:52.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 425.6 MiB)
[2025-05-06T13:00:52.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 016737cbcc7e:41421 (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:52.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 585 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[532] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:52.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Adding task set 585.0 with 10 tasks resource profile 0
[2025-05-06T13:00:52.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 0.0 in stage 585.0 (TID 855) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 172.18.0.4:46559 (size: 6.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.18.0.4:47760
[2025-05-06T13:00:52.567+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 016737cbcc7e:41421 in memory (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.568+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 172.18.0.4:46559 in memory (size: 48.0 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 016737cbcc7e:41421 in memory (size: 48.2 KiB, free: 434.3 MiB)
[2025-05-06T13:00:52.570+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 172.18.0.4:46559 in memory (size: 48.2 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 016737cbcc7e:41421 in memory (size: 6.6 KiB, free: 434.3 MiB)
[2025-05-06T13:00:52.573+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 172.18.0.4:46559 in memory (size: 6.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.575+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 1.0 in stage 585.0 (TID 856) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.575+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 0.0 in stage 585.0 (TID 855) in 21 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:52.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.586+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 2.0 in stage 585.0 (TID 857) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.586+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 1.0 in stage 585.0 (TID 856) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:52.592+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.596+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 3.0 in stage 585.0 (TID 858) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.596+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 2.0 in stage 585.0 (TID 857) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:52.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.616+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 4.0 in stage 585.0 (TID 859) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.617+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 3.0 in stage 585.0 (TID 858) in 22 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:52.623+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 5.0 in stage 585.0 (TID 860) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 4.0 in stage 585.0 (TID 859) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:52.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 6.0 in stage 585.0 (TID 861) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 5.0 in stage 585.0 (TID 860) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:52.648+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 7.0 in stage 585.0 (TID 862) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 6.0 in stage 585.0 (TID 861) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:52.660+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.665+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 8.0 in stage 585.0 (TID 863) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.665+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 7.0 in stage 585.0 (TID 862) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:52.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.674+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 9.0 in stage 585.0 (TID 864) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.674+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 8.0 in stage 585.0 (TID 863) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:52.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_528_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 9.0 in stage 585.0 (TID 864) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:52.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Removed TaskSet 585.0, whose tasks have all completed, from pool
[2025-05-06T13:00:52.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: ShuffleMapStage 585 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.131 s
[2025-05-06T13:00:52.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:52.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:52.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: waiting: Set(ResultStage 586)
[2025-05-06T13:00:52.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:52.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting ResultStage 586 (EdgeRDDImpl[535] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:52.687+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 122.3 KiB, free 425.8 MiB)
[2025-05-06T13:00:52.689+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.8 MiB)
[2025-05-06T13:00:52.689+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 016737cbcc7e:41421 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.689+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:52.689+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 586 (EdgeRDDImpl[535] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:52.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Adding task set 586.0 with 10 tasks resource profile 0
[2025-05-06T13:00:52.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 0.0 in stage 586.0 (TID 865) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 172.18.0.4:46559 (size: 48.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:52.701+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.18.0.4:47760
[2025-05-06T13:00:52.703+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:52.705+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 1.0 in stage 586.0 (TID 866) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.705+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 0.0 in stage 586.0 (TID 865) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:52.711+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:00:52.712+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 2.0 in stage 586.0 (TID 867) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 1.0 in stage 586.0 (TID 866) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:52.721+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:52.722+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 3.0 in stage 586.0 (TID 868) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.723+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 2.0 in stage 586.0 (TID 867) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:52.728+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:00:52.730+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 4.0 in stage 586.0 (TID 869) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.730+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 3.0 in stage 586.0 (TID 868) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:52.738+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:52.739+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 5.0 in stage 586.0 (TID 870) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.739+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 4.0 in stage 586.0 (TID 869) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:52.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:52.746+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 6.0 in stage 586.0 (TID 871) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.746+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 5.0 in stage 586.0 (TID 870) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:52.753+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:00:52.754+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 7.0 in stage 586.0 (TID 872) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 6.0 in stage 586.0 (TID 871) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:52.762+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:52.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 8.0 in stage 586.0 (TID 873) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 7.0 in stage 586.0 (TID 872) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:52.771+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:52.773+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 9.0 in stage 586.0 (TID 874) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.774+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 8.0 in stage 586.0 (TID 873) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:52.780+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_534_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:52.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 9.0 in stage 586.0 (TID 874) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:52.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Removed TaskSet 586.0, whose tasks have all completed, from pool
[2025-05-06T13:00:52.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: ResultStage 586 (foreachPartition at PageRank.scala:199) finished in 0.098 s
[2025-05-06T13:00:52.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:52.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 586: Stage finished
[2025-05-06T13:00:52.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Job 61 finished: foreachPartition at PageRank.scala:199, took 0.369068 s
[2025-05-06T13:00:52.783+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO PageRank: PageRank finished iteration 8.
[2025-05-06T13:00:52.783+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO ZippedPartitionsRDD2: Removing RDD 516 from persistence list
[2025-05-06T13:00:52.783+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManager: Removing RDD 516
[2025-05-06T13:00:52.783+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO ZippedPartitionsRDD2: Removing RDD 522 from persistence list
[2025-05-06T13:00:52.784+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManager: Removing RDD 522
[2025-05-06T13:00:52.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:00:52.794+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Registering RDD 536 (mapPartitions at GraphImpl.scala:208) as input to shuffle 82
[2025-05-06T13:00:52.794+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Registering RDD 544 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 81
[2025-05-06T13:00:52.795+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Got job 62 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:00:52.795+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Final stage: ResultStage 618 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:00:52.795+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 596, ShuffleMapStage 611, ShuffleMapStage 597, ShuffleMapStage 613, ShuffleMapStage 605, ShuffleMapStage 599, ShuffleMapStage 592, ShuffleMapStage 607, ShuffleMapStage 615, ShuffleMapStage 609, ShuffleMapStage 601, ShuffleMapStage 587, ShuffleMapStage 617, ShuffleMapStage 603)
[2025-05-06T13:00:52.795+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 617)
[2025-05-06T13:00:52.796+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting ShuffleMapStage 616 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[536] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:00:52.799+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 122.8 KiB, free 425.7 MiB)
[2025-05-06T13:00:52.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 48.4 KiB, free 425.6 MiB)
[2025-05-06T13:00:52.801+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 016737cbcc7e:41421 (size: 48.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.801+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:52.801+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 616 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[536] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:52.801+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Adding task set 616.0 with 10 tasks resource profile 0
[2025-05-06T13:00:52.802+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 0.0 in stage 616.0 (TID 875) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.806+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 172.18.0.4:46559 (size: 48.4 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.818+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 1.0 in stage 616.0 (TID 876) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.818+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 0.0 in stage 616.0 (TID 875) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:52.830+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 2.0 in stage 616.0 (TID 877) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 1.0 in stage 616.0 (TID 876) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:52.844+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 3.0 in stage 616.0 (TID 878) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.845+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 2.0 in stage 616.0 (TID 877) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:52.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 4.0 in stage 616.0 (TID 879) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 3.0 in stage 616.0 (TID 878) in 18 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:52.875+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 5.0 in stage 616.0 (TID 880) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.875+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 4.0 in stage 616.0 (TID 879) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:52.887+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 6.0 in stage 616.0 (TID 881) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.888+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 5.0 in stage 616.0 (TID 880) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:52.900+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 7.0 in stage 616.0 (TID 882) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.901+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 6.0 in stage 616.0 (TID 881) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:52.913+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 8.0 in stage 616.0 (TID 883) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.913+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 7.0 in stage 616.0 (TID 882) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:52.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 9.0 in stage 616.0 (TID 884) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.927+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 8.0 in stage 616.0 (TID 883) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:52.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 9.0 in stage 616.0 (TID 884) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:52.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Removed TaskSet 616.0, whose tasks have all completed, from pool
[2025-05-06T13:00:52.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: ShuffleMapStage 616 (mapPartitions at GraphImpl.scala:208) finished in 0.143 s
[2025-05-06T13:00:52.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:52.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:52.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 617, ResultStage 618)
[2025-05-06T13:00:52.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:52.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting ShuffleMapStage 617 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[544] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:00:52.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 18.5 KiB, free 425.6 MiB)
[2025-05-06T13:00:52.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 425.6 MiB)
[2025-05-06T13:00:52.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 016737cbcc7e:41421 in memory (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:52.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 617 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[544] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:52.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSchedulerImpl: Adding task set 617.0 with 10 tasks resource profile 0
[2025-05-06T13:00:52.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 0.0 in stage 617.0 (TID 885) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 172.18.0.4:46559 in memory (size: 48.0 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 016737cbcc7e:41421 in memory (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:52.952+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 172.18.0.4:46559 in memory (size: 6.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.957+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.18.0.4:47760
[2025-05-06T13:00:52.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_540_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.964+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 1.0 in stage 617.0 (TID 886) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.965+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 0.0 in stage 617.0 (TID 885) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:52.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_540_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 2.0 in stage 617.0 (TID 887) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 1.0 in stage 617.0 (TID 886) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:52.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_540_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.989+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 3.0 in stage 617.0 (TID 888) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:52.990+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 2.0 in stage 617.0 (TID 887) in 17 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:52.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO BlockManagerInfo: Added rdd_540_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:00:52.999+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Starting task 4.0 in stage 617.0 (TID 889) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.000+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:52 INFO TaskSetManager: Finished task 3.0 in stage 617.0 (TID 888) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:53.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_540_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:53.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 5.0 in stage 617.0 (TID 890) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 4.0 in stage 617.0 (TID 889) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:53.018+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_540_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:53.021+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 6.0 in stage 617.0 (TID 891) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.021+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 5.0 in stage 617.0 (TID 890) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:53.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_540_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:53.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 7.0 in stage 617.0 (TID 892) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 6.0 in stage 617.0 (TID 891) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:53.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_540_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:00:53.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 8.0 in stage 617.0 (TID 893) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 7.0 in stage 617.0 (TID 892) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:53.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_540_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:53.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 9.0 in stage 617.0 (TID 894) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 8.0 in stage 617.0 (TID 893) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:53.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_540_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:53.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 9.0 in stage 617.0 (TID 894) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:53.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Removed TaskSet 617.0, whose tasks have all completed, from pool
[2025-05-06T13:00:53.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: ShuffleMapStage 617 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.110 s
[2025-05-06T13:00:53.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:53.050+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:53.050+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: waiting: Set(ResultStage 618)
[2025-05-06T13:00:53.050+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:53.050+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting ResultStage 618 (EdgeRDDImpl[547] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:00:53.052+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 122.6 KiB, free 425.7 MiB)
[2025-05-06T13:00:53.053+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 425.6 MiB)
[2025-05-06T13:00:53.053+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 016737cbcc7e:41421 (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.054+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:53.054+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 618 (EdgeRDDImpl[547] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:53.054+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Adding task set 618.0 with 10 tasks resource profile 0
[2025-05-06T13:00:53.054+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 0.0 in stage 618.0 (TID 895) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 172.18.0.4:46559 (size: 48.2 KiB, free: 174.1 MiB)
[2025-05-06T13:00:53.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.18.0.4:47760
[2025-05-06T13:00:53.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_0 in memory on 172.18.0.4:46559 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:00:53.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 1.0 in stage 618.0 (TID 896) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 0.0 in stage 618.0 (TID 895) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:53.073+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_1 in memory on 172.18.0.4:46559 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T13:00:53.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 2.0 in stage 618.0 (TID 897) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 1.0 in stage 618.0 (TID 896) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:53.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_2 in memory on 172.18.0.4:46559 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:00:53.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 3.0 in stage 618.0 (TID 898) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 2.0 in stage 618.0 (TID 897) in 8 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:53.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_3 in memory on 172.18.0.4:46559 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T13:00:53.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 4.0 in stage 618.0 (TID 899) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 3.0 in stage 618.0 (TID 898) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:53.095+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_4 in memory on 172.18.0.4:46559 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:00:53.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 5.0 in stage 618.0 (TID 900) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 4.0 in stage 618.0 (TID 899) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:53.102+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_5 in memory on 172.18.0.4:46559 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:00:53.103+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 6.0 in stage 618.0 (TID 901) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.103+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 5.0 in stage 618.0 (TID 900) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:53.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_6 in memory on 172.18.0.4:46559 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T13:00:53.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 7.0 in stage 618.0 (TID 902) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 6.0 in stage 618.0 (TID 901) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:53.116+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_7 in memory on 172.18.0.4:46559 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:00:53.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 8.0 in stage 618.0 (TID 903) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.118+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 7.0 in stage 618.0 (TID 902) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:53.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_8 in memory on 172.18.0.4:46559 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:00:53.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 9.0 in stage 618.0 (TID 904) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 8.0 in stage 618.0 (TID 903) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:53.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added rdd_546_9 in memory on 172.18.0.4:46559 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:00:53.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 9.0 in stage 618.0 (TID 904) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:53.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Removed TaskSet 618.0, whose tasks have all completed, from pool
[2025-05-06T13:00:53.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: ResultStage 618 (foreachPartition at PageRank.scala:199) finished in 0.087 s
[2025-05-06T13:00:53.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:53.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 618: Stage finished
[2025-05-06T13:00:53.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Job 62 finished: foreachPartition at PageRank.scala:199, took 0.344499 s
[2025-05-06T13:00:53.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO PageRank: PageRank finished iteration 9.
[2025-05-06T13:00:53.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO ZippedPartitionsRDD2: Removing RDD 528 from persistence list
[2025-05-06T13:00:53.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManager: Removing RDD 528
[2025-05-06T13:00:53.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO ZippedPartitionsRDD2: Removing RDD 534 from persistence list
[2025-05-06T13:00:53.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManager: Removing RDD 534
[2025-05-06T13:00:53.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Starting job: sum at PageRank.scala:503
[2025-05-06T13:00:53.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Got job 63 (sum at PageRank.scala:503) with 10 output partitions
[2025-05-06T13:00:53.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Final stage: ResultStage 649 (sum at PageRank.scala:503)
[2025-05-06T13:00:53.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 625, ShuffleMapStage 640, ShuffleMapStage 626, ShuffleMapStage 644, ShuffleMapStage 648, ShuffleMapStage 630, ShuffleMapStage 627, ShuffleMapStage 634, ShuffleMapStage 646, ShuffleMapStage 638, ShuffleMapStage 632, ShuffleMapStage 642, ShuffleMapStage 636)
[2025-05-06T13:00:53.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:53.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting ResultStage 649 (MapPartitionsRDD[548] at values at PageRank.scala:503), which has no missing parents
[2025-05-06T13:00:53.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 18.9 KiB, free 425.6 MiB)
[2025-05-06T13:00:53.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 425.6 MiB)
[2025-05-06T13:00:53.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 016737cbcc7e:41421 (size: 7.0 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:53.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 649 (MapPartitionsRDD[548] at values at PageRank.scala:503) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:53.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Adding task set 649.0 with 10 tasks resource profile 0
[2025-05-06T13:00:53.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 0.0 in stage 649.0 (TID 905) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:53.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 016737cbcc7e:41421 in memory (size: 48.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 172.18.0.4:46559 in memory (size: 48.4 KiB, free: 174.3 MiB)
[2025-05-06T13:00:53.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 172.18.0.4:46559 (size: 7.0 KiB, free: 174.3 MiB)
[2025-05-06T13:00:53.171+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 016737cbcc7e:41421 in memory (size: 48.2 KiB, free: 434.3 MiB)
[2025-05-06T13:00:53.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 172.18.0.4:46559 in memory (size: 48.2 KiB, free: 174.4 MiB)
[2025-05-06T13:00:53.198+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 1.0 in stage 649.0 (TID 906) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 0.0 in stage 649.0 (TID 905) in 34 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:53.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 2.0 in stage 649.0 (TID 907) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 1.0 in stage 649.0 (TID 906) in 14 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:53.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 3.0 in stage 649.0 (TID 908) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 2.0 in stage 649.0 (TID 907) in 4 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:53.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 4.0 in stage 649.0 (TID 909) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 3.0 in stage 649.0 (TID 908) in 4 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:53.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 5.0 in stage 649.0 (TID 910) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 4.0 in stage 649.0 (TID 909) in 4 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:53.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 6.0 in stage 649.0 (TID 911) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 5.0 in stage 649.0 (TID 910) in 4 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:53.228+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 7.0 in stage 649.0 (TID 912) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.228+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 6.0 in stage 649.0 (TID 911) in 4 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:53.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 8.0 in stage 649.0 (TID 913) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 7.0 in stage 649.0 (TID 912) in 5 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:53.234+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 9.0 in stage 649.0 (TID 914) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 8.0 in stage 649.0 (TID 913) in 3 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:53.237+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 9.0 in stage 649.0 (TID 914) in 3 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:53.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Removed TaskSet 649.0, whose tasks have all completed, from pool
[2025-05-06T13:00:53.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: ResultStage 649 (sum at PageRank.scala:503) finished in 0.083 s
[2025-05-06T13:00:53.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:53.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 649: Stage finished
[2025-05-06T13:00:53.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Job 63 finished: sum at PageRank.scala:503, took 0.086478 s
[2025-05-06T13:00:53.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:00:53.244+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Got job 64 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:00:53.244+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Final stage: ResultStage 680 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:00:53.244+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 679, ShuffleMapStage 661, ShuffleMapStage 673, ShuffleMapStage 658, ShuffleMapStage 665, ShuffleMapStage 677, ShuffleMapStage 663, ShuffleMapStage 667, ShuffleMapStage 656, ShuffleMapStage 671, ShuffleMapStage 657, ShuffleMapStage 675, ShuffleMapStage 669)
[2025-05-06T13:00:53.244+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:53.245+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting ResultStage 680 (MapPartitionsRDD[549] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:00:53.246+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 18.7 KiB, free 425.9 MiB)
[2025-05-06T13:00:53.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 425.9 MiB)
[2025-05-06T13:00:53.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 016737cbcc7e:41421 (size: 6.9 KiB, free: 434.3 MiB)
[2025-05-06T13:00:53.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:53.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 680 (MapPartitionsRDD[549] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:53.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Adding task set 680.0 with 10 tasks resource profile 0
[2025-05-06T13:00:53.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 0.0 in stage 680.0 (TID 915) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 172.18.0.4:46559 (size: 6.9 KiB, free: 174.4 MiB)
[2025-05-06T13:00:53.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 1.0 in stage 680.0 (TID 916) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 0.0 in stage 680.0 (TID 915) in 7 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:53.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 2.0 in stage 680.0 (TID 917) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 1.0 in stage 680.0 (TID 916) in 4 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:53.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 3.0 in stage 680.0 (TID 918) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 2.0 in stage 680.0 (TID 917) in 4 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:53.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 4.0 in stage 680.0 (TID 919) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 3.0 in stage 680.0 (TID 918) in 4 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:53.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 5.0 in stage 680.0 (TID 920) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 4.0 in stage 680.0 (TID 919) in 4 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:53.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 6.0 in stage 680.0 (TID 921) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 5.0 in stage 680.0 (TID 920) in 4 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:53.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 7.0 in stage 680.0 (TID 922) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 6.0 in stage 680.0 (TID 921) in 4 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:53.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 8.0 in stage 680.0 (TID 923) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 7.0 in stage 680.0 (TID 922) in 4 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:53.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 9.0 in stage 680.0 (TID 924) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 8.0 in stage 680.0 (TID 923) in 3 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:53.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 9.0 in stage 680.0 (TID 924) in 3 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:53.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Removed TaskSet 680.0, whose tasks have all completed, from pool
[2025-05-06T13:00:53.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: ResultStage 680 (fold at VertexRDDImpl.scala:90) finished in 0.040 s
[2025-05-06T13:00:53.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:53.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 680: Stage finished
[2025-05-06T13:00:53.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Job 64 finished: fold at VertexRDDImpl.scala:90, took 0.044545 s
[2025-05-06T13:00:53.444+0000] {spark_submit.py:571} INFO - 2025-05-06 13:00:53,444 [INFO] Объединяем результаты анализа
[2025-05-06T13:00:53.515+0000] {spark_submit.py:571} INFO - 2025-05-06 13:00:53,515 [INFO] Сохраняем результаты в graph.client_communities
[2025-05-06T13:00:53.717+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:00:53.726+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 016737cbcc7e:41421 in memory (size: 7.0 KiB, free: 434.3 MiB)
[2025-05-06T13:00:53.727+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 172.18.0.4:46559 in memory (size: 7.0 KiB, free: 174.4 MiB)
[2025-05-06T13:00:53.728+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Registering RDD 565 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 84
[2025-05-06T13:00:53.729+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Got map stage job 65 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:00:53.729+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Final stage: ShuffleMapStage 681 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:53.729+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:00:53.729+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:53.729+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting ShuffleMapStage 681 (MapPartitionsRDD[565] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:53.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 19.9 KiB, free 425.9 MiB)
[2025-05-06T13:00:53.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO CodeGenerator: Code generated in 13.279079 ms
[2025-05-06T13:00:53.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#994 - id.nullCount#993) > 0)
[2025-05-06T13:00:53.735+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 425.9 MiB)
[2025-05-06T13:00:53.735+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 016737cbcc7e:41421 in memory (size: 6.9 KiB, free: 434.3 MiB)
[2025-05-06T13:00:53.735+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 172.18.0.4:46559 in memory (size: 6.9 KiB, free: 174.4 MiB)
[2025-05-06T13:00:53.736+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 016737cbcc7e:41421 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T13:00:53.738+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:53.738+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 681 (MapPartitionsRDD[565] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:53.738+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Adding task set 681.0 with 1 tasks resource profile 0
[2025-05-06T13:00:53.739+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 0.0 in stage 681.0 (TID 925) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.746+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 172.18.0.4:46559 (size: 9.7 KiB, free: 174.4 MiB)
[2025-05-06T13:00:53.746+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:53.748+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Got job 66 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 10 output partitions
[2025-05-06T13:00:53.749+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Final stage: ResultStage 683 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:00:53.749+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 682)
[2025-05-06T13:00:53.749+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:53.753+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting ResultStage 683 (MapPartitionsRDD[570] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:00:53.754+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 49.9 KiB, free 425.9 MiB)
[2025-05-06T13:00:53.754+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 425.9 MiB)
[2025-05-06T13:00:53.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 016737cbcc7e:41421 (size: 20.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:53.756+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 683 (MapPartitionsRDD[570] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:53.756+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Adding task set 683.0 with 10 tasks resource profile 0
[2025-05-06T13:00:53.760+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO CodeGenerator: Code generated in 12.333995 ms
[2025-05-06T13:00:53.767+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Registering RDD 573 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 85
[2025-05-06T13:00:53.768+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Got map stage job 67 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-06T13:00:53.769+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Final stage: ShuffleMapStage 721 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:53.769+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 711, ShuffleMapStage 708, ShuffleMapStage 684, ShuffleMapStage 699, ShuffleMapStage 714, ShuffleMapStage 696, ShuffleMapStage 717, ShuffleMapStage 702, ShuffleMapStage 693, ShuffleMapStage 690, ShuffleMapStage 705, ShuffleMapStage 720)
[2025-05-06T13:00:53.769+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:53.769+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting ShuffleMapStage 721 (MapPartitionsRDD[573] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:53.774+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 30.4 KiB, free 425.8 MiB)
[2025-05-06T13:00:53.775+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 425.8 MiB)
[2025-05-06T13:00:53.776+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 016737cbcc7e:41421 (size: 11.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:53.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 721 (MapPartitionsRDD[573] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:53.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Adding task set 721.0 with 10 tasks resource profile 0
[2025-05-06T13:00:53.779+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 0.0 in stage 683.0 (TID 926) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.779+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 0.0 in stage 681.0 (TID 925) in 41 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:53.779+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Removed TaskSet 681.0, whose tasks have all completed, from pool
[2025-05-06T13:00:53.780+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: ShuffleMapStage 681 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.051 s
[2025-05-06T13:00:53.781+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:53.781+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: running: Set(ShuffleMapStage 721, ResultStage 683)
[2025-05-06T13:00:53.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:53.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:53.784+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO CodeGenerator: Code generated in 14.249718 ms
[2025-05-06T13:00:53.784+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 172.18.0.4:46559 (size: 20.4 KiB, free: 174.3 MiB)
[2025-05-06T13:00:53.789+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Registering RDD 576 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 86
[2025-05-06T13:00:53.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Got map stage job 68 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-06T13:00:53.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Final stage: ShuffleMapStage 744 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:53.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 727, ShuffleMapStage 731, ShuffleMapStage 743, ShuffleMapStage 684, ShuffleMapStage 735, ShuffleMapStage 729, ShuffleMapStage 739, ShuffleMapStage 733, ShuffleMapStage 725, ShuffleMapStage 722, ShuffleMapStage 737, ShuffleMapStage 690, ShuffleMapStage 741)
[2025-05-06T13:00:53.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:53.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting ShuffleMapStage 744 (MapPartitionsRDD[576] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:53.798+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 31.6 KiB, free 425.8 MiB)
[2025-05-06T13:00:53.809+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 425.8 MiB)
[2025-05-06T13:00:53.812+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 016737cbcc7e:41421 (size: 11.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.813+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 016737cbcc7e:41421 in memory (size: 9.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.813+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:53.814+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 744 (MapPartitionsRDD[576] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:53.814+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Adding task set 744.0 with 10 tasks resource profile 0
[2025-05-06T13:00:53.815+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 172.18.0.4:46559 in memory (size: 9.7 KiB, free: 174.3 MiB)
[2025-05-06T13:00:53.815+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 1.0 in stage 683.0 (TID 927) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.815+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 0.0 in stage 683.0 (TID 926) in 36 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:53.816+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO CodeGenerator: Code generated in 24.923658 ms
[2025-05-06T13:00:53.821+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Registering RDD 579 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 87
[2025-05-06T13:00:53.822+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Got map stage job 69 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-06T13:00:53.825+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Final stage: ShuffleMapStage 745 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:53.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 727, ShuffleMapStage 731, ShuffleMapStage 743, ShuffleMapStage 684, ShuffleMapStage 735, ShuffleMapStage 729, ShuffleMapStage 739, ShuffleMapStage 733, ShuffleMapStage 725, ShuffleMapStage 722, ShuffleMapStage 737, ShuffleMapStage 690, ShuffleMapStage 741)
[2025-05-06T13:00:53.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 2.0 in stage 683.0 (TID 928) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 1.0 in stage 683.0 (TID 927) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:53.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:53.828+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting ShuffleMapStage 745 (MapPartitionsRDD[579] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:53.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 3.0 in stage 683.0 (TID 929) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 26.7 KiB, free 425.8 MiB)
[2025-05-06T13:00:53.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 10.6 KiB, free 425.8 MiB)
[2025-05-06T13:00:53.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 016737cbcc7e:41421 (size: 10.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 2.0 in stage 683.0 (TID 928) in 13 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:53.844+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:53.844+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 745 (MapPartitionsRDD[579] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:00:53.845+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Adding task set 745.0 with 10 tasks resource profile 0
[2025-05-06T13:00:53.845+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 4.0 in stage 683.0 (TID 930) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 3.0 in stage 683.0 (TID 929) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:53.848+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 5.0 in stage 683.0 (TID 931) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.850+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 4.0 in stage 683.0 (TID 930) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:53.854+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 6.0 in stage 683.0 (TID 932) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.854+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 5.0 in stage 683.0 (TID 931) in 6 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:53.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 7.0 in stage 683.0 (TID 933) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 6.0 in stage 683.0 (TID 932) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:53.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 8.0 in stage 683.0 (TID 934) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.867+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 7.0 in stage 683.0 (TID 933) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:53.873+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 9.0 in stage 683.0 (TID 935) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.874+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 8.0 in stage 683.0 (TID 934) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:53.888+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 0.0 in stage 721.0 (TID 936) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 9.0 in stage 683.0 (TID 935) in 16 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:53.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Removed TaskSet 683.0, whose tasks have all completed, from pool
[2025-05-06T13:00:53.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: ResultStage 683 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.138 s
[2025-05-06T13:00:53.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:53.892+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 683: Stage finished
[2025-05-06T13:00:53.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Job 66 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.143375 s
[2025-05-06T13:00:53.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 172.18.0.4:46559 (size: 11.5 KiB, free: 174.3 MiB)
[2025-05-06T13:00:53.899+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO CodeGenerator: Code generated in 6.025973 ms
[2025-05-06T13:00:53.910+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 2.1 MiB, free 423.7 MiB)
[2025-05-06T13:00:53.912+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 26.3 KiB, free 423.7 MiB)
[2025-05-06T13:00:53.913+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 016737cbcc7e:41421 (size: 26.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:53.914+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO SparkContext: Created broadcast 139 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:53.930+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:53.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:53.936+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:53.938+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:53.941+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:00:53.956+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 0.0 in stage 721.0 (TID 936) in 68 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:53.957+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 1.0 in stage 721.0 (TID 937) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.964+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO CodeGenerator: Code generated in 18.463434 ms
[2025-05-06T13:00:53.979+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Starting task 2.0 in stage 721.0 (TID 938) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:53.979+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO TaskSetManager: Finished task 1.0 in stage 721.0 (TID 937) in 22 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:53.982+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Registering RDD 582 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 88
[2025-05-06T13:00:53.983+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Got map stage job 70 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:00:53.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Final stage: ShuffleMapStage 747 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:53.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 746)
[2025-05-06T13:00:53.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:53.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO DAGScheduler: Submitting ShuffleMapStage 747 (MapPartitionsRDD[582] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:53.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:53 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 66.4 KiB, free 423.6 MiB)
[2025-05-06T13:00:54.006+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 423.6 MiB)
[2025-05-06T13:00:54.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 3.0 in stage 721.0 (TID 939) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.011+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 016737cbcc7e:41421 (size: 27.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 172.18.0.4:46559 in memory (size: 20.4 KiB, free: 174.4 MiB)
[2025-05-06T13:00:54.015+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 016737cbcc7e:41421 in memory (size: 20.4 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.015+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 2.0 in stage 721.0 (TID 938) in 32 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:54.016+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.016+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 747 (MapPartitionsRDD[582] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 747.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 4.0 in stage 721.0 (TID 940) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.024+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 3.0 in stage 721.0 (TID 939) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:54.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 5.0 in stage 721.0 (TID 941) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 4.0 in stage 721.0 (TID 940) in 19 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:54.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 6.0 in stage 721.0 (TID 942) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.053+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 5.0 in stage 721.0 (TID 941) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:54.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 7.0 in stage 721.0 (TID 943) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 6.0 in stage 721.0 (TID 942) in 15 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:54.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 8.0 in stage 721.0 (TID 944) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 7.0 in stage 721.0 (TID 943) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:54.094+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 9.0 in stage 721.0 (TID 945) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.094+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 8.0 in stage 721.0 (TID 944) in 24 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:54.103+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 744.0 (TID 946) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 9.0 in stage 721.0 (TID 945) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:54.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ShuffleMapStage 721 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.336 s
[2025-05-06T13:00:54.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:54.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: running: Set(ShuffleMapStage 745, ShuffleMapStage 747, ShuffleMapStage 744)
[2025-05-06T13:00:54.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:54.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:54.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 721.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 172.18.0.4:46559 (size: 11.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:54.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_0 in memory on 172.18.0.4:46559 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:00:54.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(85), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(85), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 1.0 in stage 744.0 (TID 947) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 744.0 (TID 946) in 47 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:54.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got job 71 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:00:54.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ResultStage 779 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:00:54.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 778)
[2025-05-06T13:00:54.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ResultStage 779 (MapPartitionsRDD[584] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:00:54.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 7.2 KiB, free 423.7 MiB)
[2025-05-06T13:00:54.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 423.7 MiB)
[2025-05-06T13:00:54.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 779 (MapPartitionsRDD[584] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 779.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_1 in memory on 172.18.0.4:46559 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:00:54.171+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 2.0 in stage 744.0 (TID 948) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 1.0 in stage 744.0 (TID 947) in 21 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:54.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_2 in memory on 172.18.0.4:46559 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:00:54.185+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 3.0 in stage 744.0 (TID 949) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.185+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 2.0 in stage 744.0 (TID 948) in 13 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:54.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_3 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:00:54.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 4.0 in stage 744.0 (TID 950) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.197+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 3.0 in stage 744.0 (TID 949) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:54.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_4 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:00:54.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 5.0 in stage 744.0 (TID 951) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 4.0 in stage 744.0 (TID 950) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:54.213+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_5 in memory on 172.18.0.4:46559 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:00:54.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 6.0 in stage 744.0 (TID 952) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 5.0 in stage 744.0 (TID 951) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:54.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_6 in memory on 172.18.0.4:46559 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 7.0 in stage 744.0 (TID 953) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 6.0 in stage 744.0 (TID 952) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:54.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_7 in memory on 172.18.0.4:46559 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.234+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 8.0 in stage 744.0 (TID 954) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 7.0 in stage 744.0 (TID 953) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:54.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_8 in memory on 172.18.0.4:46559 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 9.0 in stage 744.0 (TID 955) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 8.0 in stage 744.0 (TID 954) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:54.246+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added rdd_550_9 in memory on 172.18.0.4:46559 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 745.0 (TID 956) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 9.0 in stage 744.0 (TID 955) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:54.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 744.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ShuffleMapStage 744 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.460 s
[2025-05-06T13:00:54.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:54.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: running: Set(ShuffleMapStage 745, ResultStage 779, ShuffleMapStage 747)
[2025-05-06T13:00:54.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:54.253+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:54.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 172.18.0.4:46559 (size: 10.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(86), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got job 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:00:54.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ResultStage 781 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:00:54.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 780)
[2025-05-06T13:00:54.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ResultStage 781 (MapPartitionsRDD[586] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:00:54.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 7.2 KiB, free 423.6 MiB)
[2025-05-06T13:00:54.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 423.6 MiB)
[2025-05-06T13:00:54.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 1.0 in stage 745.0 (TID 957) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 745.0 (TID 956) in 46 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:00:54.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 016737cbcc7e:41421 in memory (size: 11.5 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 781 (MapPartitionsRDD[586] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 781.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 172.18.0.4:46559 in memory (size: 11.5 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 016737cbcc7e:41421 in memory (size: 11.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 172.18.0.4:46559 in memory (size: 11.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 2.0 in stage 745.0 (TID 958) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 1.0 in stage 745.0 (TID 957) in 17 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:00:54.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 3.0 in stage 745.0 (TID 959) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 2.0 in stage 745.0 (TID 958) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:00:54.330+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 4.0 in stage 745.0 (TID 960) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 3.0 in stage 745.0 (TID 959) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:00:54.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 5.0 in stage 745.0 (TID 961) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 4.0 in stage 745.0 (TID 960) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:00:54.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 6.0 in stage 745.0 (TID 962) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.363+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 5.0 in stage 745.0 (TID 961) in 23 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:00:54.372+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 7.0 in stage 745.0 (TID 963) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.372+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 6.0 in stage 745.0 (TID 962) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:00:54.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 8.0 in stage 745.0 (TID 964) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.382+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 7.0 in stage 745.0 (TID 963) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:00:54.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 9.0 in stage 745.0 (TID 965) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.391+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 8.0 in stage 745.0 (TID 964) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:00:54.400+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 747.0 (TID 966) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 9.0 in stage 745.0 (TID 965) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:00:54.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 745.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ShuffleMapStage 745 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.575 s
[2025-05-06T13:00:54.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:54.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: running: Set(ResultStage 781, ResultStage 779, ShuffleMapStage 747)
[2025-05-06T13:00:54.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:54.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:54.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 172.18.0.4:46559 (size: 27.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.413+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(87), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.415+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.18.0.4:47760
[2025-05-06T13:00:54.432+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.433+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got job 73 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:00:54.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ResultStage 783 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:00:54.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 782)
[2025-05-06T13:00:54.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ResultStage 783 (MapPartitionsRDD[588] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:00:54.435+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 7.2 KiB, free 423.7 MiB)
[2025-05-06T13:00:54.436+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 423.7 MiB)
[2025-05-06T13:00:54.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.439+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 783 (MapPartitionsRDD[588] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.439+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 783.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.442+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 172.18.0.4:46559 (size: 26.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 779.0 (TID 967) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.458+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 747.0 (TID 966) in 57 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.458+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 747.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.459+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ShuffleMapStage 747 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.475 s
[2025-05-06T13:00:54.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:54.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: running: Set(ResultStage 781, ResultStage 779, ResultStage 783)
[2025-05-06T13:00:54.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:54.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:54.467+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.471+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.18.0.4:47760
[2025-05-06T13:00:54.485+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 016737cbcc7e:41421 in memory (size: 10.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 172.18.0.4:46559 in memory (size: 10.6 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 016737cbcc7e:41421 in memory (size: 27.3 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 781.0 (TID 968) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.494+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 779.0 (TID 967) in 38 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 779.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.496+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ResultStage 779 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.340 s
[2025-05-06T13:00:54.497+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 172.18.0.4:46559 in memory (size: 27.3 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.498+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:54.498+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 779: Stage finished
[2025-05-06T13:00:54.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 71 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.347964 s
[2025-05-06T13:00:54.504+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.508+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.18.0.4:47760
[2025-05-06T13:00:54.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 783.0 (TID 969) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 781.0 (TID 968) in 25 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.518+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 781.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.519+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ResultStage 781 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.246 s
[2025-05-06T13:00:54.519+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:54.520+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 781: Stage finished
[2025-05-06T13:00:54.520+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 72 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.248716 s
[2025-05-06T13:00:54.520+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO CodeGenerator: Code generated in 14.075202 ms
[2025-05-06T13:00:54.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 1088.0 KiB, free 422.8 MiB)
[2025-05-06T13:00:54.530+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 1088.0 KiB, free 421.7 MiB)
[2025-05-06T13:00:54.533+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 32.1 KiB, free 421.7 MiB)
[2025-05-06T13:00:54.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 016737cbcc7e:41421 (size: 32.1 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 145 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 22.8 KiB, free 421.7 MiB)
[2025-05-06T13:00:54.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 016737cbcc7e:41421 (size: 22.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.566+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.18.0.4:47760
[2025-05-06T13:00:54.567+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 144 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.570+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.585+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 783.0 (TID 969) in 69 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.586+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 783.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.587+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO CodeGenerator: Code generated in 9.076866 ms
[2025-05-06T13:00:54.591+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ResultStage 783 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.153 s
[2025-05-06T13:00:54.592+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:54.592+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 783: Stage finished
[2025-05-06T13:00:54.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 73 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.161083 s
[2025-05-06T13:00:54.596+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Registering RDD 591 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 89
[2025-05-06T13:00:54.597+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got map stage job 74 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:00:54.598+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ShuffleMapStage 786 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:54.598+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 785)
[2025-05-06T13:00:54.599+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.599+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ShuffleMapStage 786 (MapPartitionsRDD[591] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:54.603+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 13.5 KiB, free 421.7 MiB)
[2025-05-06T13:00:54.605+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 421.6 MiB)
[2025-05-06T13:00:54.606+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 016737cbcc7e:41421 (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.609+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.610+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 786 (MapPartitionsRDD[591] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.611+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 786.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.611+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 786.0 (TID 970) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.616+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO CodeGenerator: Code generated in 18.319574 ms
[2025-05-06T13:00:54.622+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 1088.0 KiB, free 420.6 MiB)
[2025-05-06T13:00:54.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 420.6 MiB)
[2025-05-06T13:00:54.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.643+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 016737cbcc7e:41421 (size: 21.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.647+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 172.18.0.4:46559 (size: 6.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.647+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 147 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.648+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.651+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.652+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.18.0.4:47760
[2025-05-06T13:00:54.657+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.658+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.662+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.663+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.663+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO CodeGenerator: Code generated in 14.033885 ms
[2025-05-06T13:00:54.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Registering RDD 594 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 90
[2025-05-06T13:00:54.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got map stage job 75 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:00:54.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ShuffleMapStage 787 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:54.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 785)
[2025-05-06T13:00:54.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ShuffleMapStage 787 (MapPartitionsRDD[594] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:54.676+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 13.4 KiB, free 420.6 MiB)
[2025-05-06T13:00:54.677+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 420.6 MiB)
[2025-05-06T13:00:54.677+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 016737cbcc7e:41421 (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 787 (MapPartitionsRDD[594] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 787.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.685+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO CodeGenerator: Code generated in 11.654682 ms
[2025-05-06T13:00:54.700+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 172.18.0.4:46559 (size: 32.1 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.705+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Registering RDD 597 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 91
[2025-05-06T13:00:54.707+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got map stage job 76 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:00:54.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ShuffleMapStage 788 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:54.710+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 785)
[2025-05-06T13:00:54.710+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.711+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ShuffleMapStage 788 (MapPartitionsRDD[597] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:54.715+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 12.9 KiB, free 420.6 MiB)
[2025-05-06T13:00:54.715+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 420.6 MiB)
[2025-05-06T13:00:54.715+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 016737cbcc7e:41421 (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.716+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.716+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 788 (MapPartitionsRDD[597] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.716+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 788.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 787.0 (TID 971) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 786.0 (TID 970) in 122 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 786.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ShuffleMapStage 786 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.136 s
[2025-05-06T13:00:54.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:54.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: running: Set(ShuffleMapStage 787, ShuffleMapStage 788)
[2025-05-06T13:00:54.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:54.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:54.739+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 172.18.0.4:46559 (size: 6.7 KiB, free: 174.2 MiB)
[2025-05-06T13:00:54.740+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(89), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.751+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.751+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got job 77 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:00:54.751+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ResultStage 790 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:00:54.752+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 789)
[2025-05-06T13:00:54.752+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.752+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ResultStage 790 (MapPartitionsRDD[599] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:00:54.753+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 7.2 KiB, free 420.5 MiB)
[2025-05-06T13:00:54.754+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 420.5 MiB)
[2025-05-06T13:00:54.754+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 172.18.0.4:46559 (size: 22.8 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 790 (MapPartitionsRDD[599] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 790.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.761+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 788.0 (TID 972) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.762+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 787.0 (TID 971) in 30 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.762+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 787.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.762+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ShuffleMapStage 787 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.089 s
[2025-05-06T13:00:54.762+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:54.762+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: running: Set(ResultStage 790, ShuffleMapStage 788)
[2025-05-06T13:00:54.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:54.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:54.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 172.18.0.4:46559 (size: 6.6 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.768+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(90), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.776+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.776+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got job 78 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:00:54.776+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ResultStage 792 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:00:54.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 791)
[2025-05-06T13:00:54.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ResultStage 792 (MapPartitionsRDD[601] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:00:54.778+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 172.18.0.4:46559 (size: 21.7 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.778+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 7.2 KiB, free 420.5 MiB)
[2025-05-06T13:00:54.791+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 016737cbcc7e:41421 in memory (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 420.5 MiB)
[2025-05-06T13:00:54.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 016737cbcc7e:41421 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.793+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 172.18.0.4:46559 in memory (size: 6.8 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.793+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.793+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 792 (MapPartitionsRDD[601] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.793+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 792.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.794+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 016737cbcc7e:41421 in memory (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T13:00:54.797+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 172.18.0.4:46559 in memory (size: 6.7 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 790.0 (TID 973) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 788.0 (TID 972) in 39 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 788.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ShuffleMapStage 788 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.092 s
[2025-05-06T13:00:54.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:54.801+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: running: Set(ResultStage 790, ResultStage 792)
[2025-05-06T13:00:54.801+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:54.801+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:54.805+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.807+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.18.0.4:47760
[2025-05-06T13:00:54.810+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 792.0 (TID 974) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.811+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 790.0 (TID 973) in 12 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.811+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 790.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.811+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ResultStage 790 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.059 s
[2025-05-06T13:00:54.811+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:54.812+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 790: Stage finished
[2025-05-06T13:00:54.812+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 77 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.060591 s
[2025-05-06T13:00:54.816+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 172.18.0.4:46559 (size: 3.8 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.817+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 2.1 MiB, free 418.5 MiB)
[2025-05-06T13:00:54.818+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.18.0.4:47760
[2025-05-06T13:00:54.818+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 30.4 KiB, free 418.5 MiB)
[2025-05-06T13:00:54.819+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 016737cbcc7e:41421 (size: 30.4 KiB, free: 434.1 MiB)
[2025-05-06T13:00:54.819+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 152 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.822+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 792.0 (TID 974) in 12 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 792.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ResultStage 792 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.045 s
[2025-05-06T13:00:54.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:54.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 792: Stage finished
[2025-05-06T13:00:54.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Job 78 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.046884 s
[2025-05-06T13:00:54.825+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(90), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.828+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 2.1 MiB, free 416.4 MiB)
[2025-05-06T13:00:54.830+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 416.4 MiB)
[2025-05-06T13:00:54.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 016737cbcc7e:41421 (size: 19.8 KiB, free: 434.1 MiB)
[2025-05-06T13:00:54.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 153 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:54.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO CodeGenerator: Code generated in 8.525655 ms
[2025-05-06T13:00:54.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Registering RDD 604 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 92
[2025-05-06T13:00:54.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got map stage job 79 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:00:54.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ShuffleMapStage 796 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:54.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 795)
[2025-05-06T13:00:54.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ShuffleMapStage 796 (MapPartitionsRDD[604] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:54.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO ShufflePartitionsUtil: For shuffle(91), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:54.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 14.0 KiB, free 416.4 MiB)
[2025-05-06T13:00:54.878+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 416.4 MiB)
[2025-05-06T13:00:54.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 016737cbcc7e:41421 (size: 7.0 KiB, free: 434.1 MiB)
[2025-05-06T13:00:54.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.880+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 796 (MapPartitionsRDD[604] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.880+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 796.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.880+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 796.0 (TID 975) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 172.18.0.4:46559 (size: 7.0 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.894+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.18.0.4:47760
[2025-05-06T13:00:54.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO CodeGenerator: Code generated in 34.854583 ms
[2025-05-06T13:00:54.924+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 172.18.0.4:46559 (size: 30.4 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Finished task 0.0 in stage 796.0 (TID 975) in 71 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:54.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Removed TaskSet 796.0, whose tasks have all completed, from pool
[2025-05-06T13:00:54.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: ShuffleMapStage 796 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.088 s
[2025-05-06T13:00:54.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:54.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:54.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:54.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:54.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Registering RDD 607 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 93
[2025-05-06T13:00:54.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Got map stage job 80 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:00:54.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Final stage: ShuffleMapStage 800 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:54.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 799)
[2025-05-06T13:00:54.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:54.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting ShuffleMapStage 800 (MapPartitionsRDD[607] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:54.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 116.3 KiB, free 416.3 MiB)
[2025-05-06T13:00:54.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 45.6 KiB, free 416.2 MiB)
[2025-05-06T13:00:54.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 016737cbcc7e:41421 (size: 45.6 KiB, free: 434.1 MiB)
[2025-05-06T13:00:54.971+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.1 MiB)
[2025-05-06T13:00:54.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:54.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 800 (MapPartitionsRDD[607] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:54.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSchedulerImpl: Adding task set 800.0 with 1 tasks resource profile 0
[2025-05-06T13:00:54.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO TaskSetManager: Starting task 0.0 in stage 800.0 (TID 976) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:54.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 016737cbcc7e:41421 in memory (size: 3.8 KiB, free: 434.1 MiB)
[2025-05-06T13:00:54.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 172.18.0.4:46559 in memory (size: 3.8 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 016737cbcc7e:41421 in memory (size: 6.6 KiB, free: 434.1 MiB)
[2025-05-06T13:00:54.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 172.18.0.4:46559 in memory (size: 6.6 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 172.18.0.4:46559 (size: 45.6 KiB, free: 174.0 MiB)
[2025-05-06T13:00:54.979+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 016737cbcc7e:41421 in memory (size: 7.0 KiB, free: 434.1 MiB)
[2025-05-06T13:00:54.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 172.18.0.4:46559 in memory (size: 7.0 KiB, free: 174.1 MiB)
[2025-05-06T13:00:54.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.18.0.4:47760
[2025-05-06T13:00:55.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 172.18.0.4:46559 (size: 19.8 KiB, free: 174.0 MiB)
[2025-05-06T13:00:55.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSetManager: Finished task 0.0 in stage 800.0 (TID 976) in 93 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:55.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSchedulerImpl: Removed TaskSet 800.0, whose tasks have all completed, from pool
[2025-05-06T13:00:55.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: ShuffleMapStage 800 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.115 s
[2025-05-06T13:00:55.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:00:55.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: running: Set()
[2025-05-06T13:00:55.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:00:55.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: failed: Set()
[2025-05-06T13:00:55.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO ShufflePartitionsUtil: For shuffle(93), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:55.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:00:55.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO CodeGenerator: Code generated in 9.155894 ms
[2025-05-06T13:00:55.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:55.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Got job 81 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:00:55.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Final stage: ResultStage 805 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:00:55.116+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 804)
[2025-05-06T13:00:55.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:55.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Submitting ResultStage 805 (MapPartitionsRDD[610] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:00:55.122+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 113.2 KiB, free 416.2 MiB)
[2025-05-06T13:00:55.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 42.7 KiB, free 416.1 MiB)
[2025-05-06T13:00:55.124+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 016737cbcc7e:41421 (size: 42.7 KiB, free: 434.0 MiB)
[2025-05-06T13:00:55.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:55.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 805 (MapPartitionsRDD[610] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:55.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSchedulerImpl: Adding task set 805.0 with 1 tasks resource profile 0
[2025-05-06T13:00:55.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSetManager: Starting task 0.0 in stage 805.0 (TID 977) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:55.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 172.18.0.4:46559 (size: 42.7 KiB, free: 174.0 MiB)
[2025-05-06T13:00:55.145+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.18.0.4:47760
[2025-05-06T13:00:55.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSetManager: Finished task 0.0 in stage 805.0 (TID 977) in 40 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:55.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSchedulerImpl: Removed TaskSet 805.0, whose tasks have all completed, from pool
[2025-05-06T13:00:55.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: ResultStage 805 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.055 s
[2025-05-06T13:00:55.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:55.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 805: Stage finished
[2025-05-06T13:00:55.171+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Job 81 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.059025 s
[2025-05-06T13:00:55.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO CodeGenerator: Code generated in 5.847873 ms
[2025-05-06T13:00:55.184+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 1024.0 KiB, free 415.1 MiB)
[2025-05-06T13:00:55.184+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 209.0 B, free 415.1 MiB)
[2025-05-06T13:00:55.184+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 016737cbcc7e:41421 (size: 209.0 B, free: 434.0 MiB)
[2025-05-06T13:00:55.185+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO SparkContext: Created broadcast 157 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:00:55.188+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO ShufflePartitionsUtil: For shuffle(92), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:00:55.200+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO CodeGenerator: Code generated in 7.675993 ms
[2025-05-06T13:00:55.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-05-06T13:00:55.245+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Got job 82 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:00:55.245+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Final stage: ResultStage 810 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:00:55.245+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 809)
[2025-05-06T13:00:55.245+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:00:55.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Submitting ResultStage 810 (MapPartitionsRDD[615] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:00:55.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 128.8 KiB, free 415.0 MiB)
[2025-05-06T13:00:55.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 48.7 KiB, free 415.0 MiB)
[2025-05-06T13:00:55.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 016737cbcc7e:41421 (size: 48.7 KiB, free: 434.0 MiB)
[2025-05-06T13:00:55.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 016737cbcc7e:41421 in memory (size: 45.6 KiB, free: 434.0 MiB)
[2025-05-06T13:00:55.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:00:55.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 810 (MapPartitionsRDD[615] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:00:55.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSchedulerImpl: Adding task set 810.0 with 1 tasks resource profile 0
[2025-05-06T13:00:55.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSetManager: Starting task 0.0 in stage 810.0 (TID 978) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:00:55.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 172.18.0.4:46559 in memory (size: 45.6 KiB, free: 174.0 MiB)
[2025-05-06T13:00:55.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 016737cbcc7e:41421 in memory (size: 42.7 KiB, free: 434.1 MiB)
[2025-05-06T13:00:55.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 172.18.0.4:46559 in memory (size: 42.7 KiB, free: 174.1 MiB)
[2025-05-06T13:00:55.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 172.18.0.4:46559 (size: 48.7 KiB, free: 174.0 MiB)
[2025-05-06T13:00:55.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.18.0.4:47760
[2025-05-06T13:00:55.392+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 172.18.0.4:46559 (size: 209.0 B, free: 174.0 MiB)
[2025-05-06T13:00:55.463+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSetManager: Finished task 0.0 in stage 810.0 (TID 978) in 142 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:00:55.463+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSchedulerImpl: Removed TaskSet 810.0, whose tasks have all completed, from pool
[2025-05-06T13:00:55.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: ResultStage 810 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.216 s
[2025-05-06T13:00:55.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:00:55.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 810: Stage finished
[2025-05-06T13:00:55.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO DAGScheduler: Job 82 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.220251 s
[2025-05-06T13:00:55.477+0000] {spark_submit.py:571} INFO - 2025-05-06 13:00:55,477 [INFO] Анализ графа успешно завершен
[2025-05-06T13:00:55.489+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO SparkUI: Stopped Spark web UI at http://016737cbcc7e:4040
[2025-05-06T13:00:55.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-05-06T13:00:55.493+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2025-05-06T13:00:55.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-06T13:00:55.542+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO MemoryStore: MemoryStore cleared
[2025-05-06T13:00:55.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManager: BlockManager stopped
[2025-05-06T13:00:55.550+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-06T13:00:55.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-06T13:00:55.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:55 INFO SparkContext: Successfully stopped SparkContext
[2025-05-06T13:00:55.985+0000] {spark_submit.py:571} INFO - 2025-05-06 13:00:55,985 [INFO] SparkSession остановлена
[2025-05-06T13:00:56.011+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:56 INFO ShutdownHookManager: Shutdown hook called
[2025-05-06T13:00:56.011+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-135fc717-f328-4c63-a9e8-c3c37a6b87e6/pyspark-2660dcc9-7a7f-4b34-921b-8bd503ec1b70
[2025-05-06T13:00:56.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-5b7bc95c-f681-4080-a9bd-d744678b427b
[2025-05-06T13:00:56.016+0000] {spark_submit.py:571} INFO - 25/05/06 13:00:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-135fc717-f328-4c63-a9e8-c3c37a6b87e6
[2025-05-06T13:00:56.092+0000] {taskinstance.py:1345} INFO - Marking task as SUCCESS. dag_id=graph_analysis, task_id=build_graph, execution_date=20250506T125814, start_date=20250506T125821, end_date=20250506T130056
[2025-05-06T13:00:56.132+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2025-05-06T13:00:56.157+0000] {taskinstance.py:2653} INFO - 1 downstream tasks scheduled from follow-on schedule check
