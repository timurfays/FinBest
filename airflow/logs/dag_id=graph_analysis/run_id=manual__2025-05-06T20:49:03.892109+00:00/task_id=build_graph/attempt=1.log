[2025-05-06T20:49:10.636+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-06T20:49:03.892109+00:00 [queued]>
[2025-05-06T20:49:10.642+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-06T20:49:03.892109+00:00 [queued]>
[2025-05-06T20:49:10.642+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 2
[2025-05-06T20:49:10.650+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): build_graph> on 2025-05-06 20:49:03.892109+00:00
[2025-05-06T20:49:10.654+0000] {standard_task_runner.py:57} INFO - Started process 345 to run task
[2025-05-06T20:49:10.657+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'graph_analysis', 'build_graph', 'manual__2025-05-06T20:49:03.892109+00:00', '--job-id', '226', '--raw', '--subdir', 'DAGS_FOLDER/graph_analysis.py', '--cfg-path', '/tmp/tmp9d59y2z9']
[2025-05-06T20:49:10.658+0000] {standard_task_runner.py:85} INFO - Job 226: Subtask build_graph
[2025-05-06T20:49:10.669+0000] {logging_mixin.py:150} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-06T20:49:10.696+0000] {task_command.py:410} INFO - Running <TaskInstance: graph_analysis.build_graph manual__2025-05-06T20:49:03.892109+00:00 [running]> on host 837932af135c
[2025-05-06T20:49:10.763+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='finbest' AIRFLOW_CTX_DAG_ID='graph_analysis' AIRFLOW_CTX_TASK_ID='build_graph' AIRFLOW_CTX_EXECUTION_DATE='2025-05-06T20:49:03.892109+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-06T20:49:03.892109+00:00'
[2025-05-06T20:49:10.771+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-05-06T20:49:10.772+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --jars /opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar --packages org.postgresql:postgresql:42.6.0 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******
[2025-05-06T20:49:10.789+0000] {spark_submit.py:571} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-05-06T20:49:11.794+0000] {spark_submit.py:571} INFO - Using properties file: null
[2025-05-06T20:49:11.858+0000] {spark_submit.py:571} INFO - WARNING: An illegal reflective access operation has occurred
[2025-05-06T20:49:11.859+0000] {spark_submit.py:571} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2025-05-06T20:49:11.859+0000] {spark_submit.py:571} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2025-05-06T20:49:11.859+0000] {spark_submit.py:571} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-05-06T20:49:11.859+0000] {spark_submit.py:571} INFO - WARNING: All illegal access operations will be denied in a future release
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - Parsed arguments:
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - master                  spark://spark-master:7077
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - deployMode              null
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - executorMemory          1g
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - executorCores           1
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - totalExecutorCores      null
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - propertiesFile          null
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - driverMemory            1g
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - driverCores             null
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - driverExtraClassPath    null
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - driverExtraLibraryPath  null
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - driverExtraJavaOptions  null
[2025-05-06T20:49:11.897+0000] {spark_submit.py:571} INFO - supervise               false
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - queue                   null
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - numExecutors            null
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - files                   null
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - pyFiles                 null
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - archives                null
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - mainClass               null
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - primaryResource         file:/opt/airflow/spark/build_graph.py
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - name                    arrow-spark
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - childArgs               [--jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ***]
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - jars                    file:/opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - packages                org.postgresql:postgresql:42.6.0
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - packagesExclusions      null
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - repositories            null
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - verbose                 true
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - 
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - Spark properties used, including those specified through
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - --conf and those from the properties file null:
[2025-05-06T20:49:11.898+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-06T20:49:11.899+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-06T20:49:11.899+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-06T20:49:11.899+0000] {spark_submit.py:571} INFO - 
[2025-05-06T20:49:11.899+0000] {spark_submit.py:571} INFO - 
[2025-05-06T20:49:12.000+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-06T20:49:12.072+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-05-06T20:49:12.072+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-05-06T20:49:12.076+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql added as a dependency
[2025-05-06T20:49:12.077+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-c0ff5c9c-67de-4fa1-ad91-cca65ecbd0b1;1.0
[2025-05-06T20:49:12.077+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-06T20:49:14.943+0000] {spark_submit.py:571} INFO - found org.postgresql#postgresql;42.6.0 in central
[2025-05-06T20:49:16.556+0000] {spark_submit.py:571} INFO - found org.checkerframework#checker-qual;3.31.0 in central
[2025-05-06T20:49:16.566+0000] {spark_submit.py:571} INFO - downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.6.0/postgresql-42.6.0.jar ...
[2025-05-06T20:49:22.485+0000] {spark_submit.py:571} INFO - [SUCCESSFUL ] org.postgresql#postgresql;42.6.0!postgresql.jar (5919ms)
[2025-05-06T20:49:22.489+0000] {spark_submit.py:571} INFO - downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.31.0/checker-qual-3.31.0.jar ...
[2025-05-06T20:49:22.877+0000] {spark_submit.py:571} INFO - [SUCCESSFUL ] org.checkerframework#checker-qual;3.31.0!checker-qual.jar (389ms)
[2025-05-06T20:49:22.879+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 4487ms :: artifacts dl 6315ms
[2025-05-06T20:49:22.880+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-05-06T20:49:22.880+0000] {spark_submit.py:571} INFO - org.checkerframework#checker-qual;3.31.0 from central in [default]
[2025-05-06T20:49:22.880+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql;42.6.0 from central in [default]
[2025-05-06T20:49:22.880+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-06T20:49:22.881+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-05-06T20:49:22.881+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-06T20:49:22.881+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-06T20:49:22.881+0000] {spark_submit.py:571} INFO - |      default     |   2   |   2   |   2   |   0   ||   2   |   2   |
[2025-05-06T20:49:22.881+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-06T20:49:22.889+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-c0ff5c9c-67de-4fa1-ad91-cca65ecbd0b1
[2025-05-06T20:49:22.889+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-06T20:49:22.896+0000] {spark_submit.py:571} INFO - 2 artifacts copied, 0 already retrieved (1274kB/7ms)
[2025-05-06T20:49:23.077+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-06T20:49:23.261+0000] {spark_submit.py:571} INFO - Main class:
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - org.apache.spark.deploy.PythonRunner
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - Arguments:
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - file:/opt/airflow/spark/build_graph.py
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - --jdbc
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - jdbc:postgresql://postgres:5432/finbest
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - --user
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - finbest
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - --password
[2025-05-06T20:49:23.262+0000] {spark_submit.py:571} INFO - ***
[2025-05-06T20:49:23.264+0000] {spark_submit.py:571} INFO - Spark config:
[2025-05-06T20:49:23.264+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-06T20:49:23.264+0000] {spark_submit.py:571} INFO - (spark.jars,file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T20:49:23.264+0000] {spark_submit.py:571} INFO - (spark.app.name,arrow-spark)
[2025-05-06T20:49:23.264+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-06T20:49:23.264+0000] {spark_submit.py:571} INFO - (spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,/home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T20:49:23.264+0000] {spark_submit.py:571} INFO - (spark.files,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T20:49:23.264+0000] {spark_submit.py:571} INFO - (spark.submit.deployMode,client)
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - (spark.master,spark://spark-master:7077)
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - (spark.executor.memory,1g)
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - (spark.executor.cores,1)
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - (spark.repl.local.jars,file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - Classpath elements:
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - 
[2025-05-06T20:49:23.265+0000] {spark_submit.py:571} INFO - 
[2025-05-06T20:49:23.897+0000] {spark_submit.py:571} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2025-05-06T20:49:23.906+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:23 INFO SparkContext: Running Spark version 3.2.4
[2025-05-06T20:49:23.925+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:23 INFO ResourceUtils: ==============================================================
[2025-05-06T20:49:23.925+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:23 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-06T20:49:23.925+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:23 INFO ResourceUtils: ==============================================================
[2025-05-06T20:49:23.926+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:23 INFO SparkContext: Submitted application: FinBestGraphAnalysis
[2025-05-06T20:49:23.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-06T20:49:23.953+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:23 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-05-06T20:49:23.954+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:23 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-06T20:49:24.002+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SecurityManager: Changing view acls to: airflow
[2025-05-06T20:49:24.002+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SecurityManager: Changing modify acls to: airflow
[2025-05-06T20:49:24.002+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SecurityManager: Changing view acls groups to:
[2025-05-06T20:49:24.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SecurityManager: Changing modify acls groups to:
[2025-05-06T20:49:24.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(airflow); groups with view permissions: Set(); users  with modify permissions: Set(airflow); groups with modify permissions: Set()
[2025-05-06T20:49:24.271+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO Utils: Successfully started service 'sparkDriver' on port 43389.
[2025-05-06T20:49:24.300+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkEnv: Registering MapOutputTracker
[2025-05-06T20:49:24.336+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-06T20:49:24.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-06T20:49:24.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-06T20:49:24.356+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-06T20:49:24.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7cf7c61b-840f-47ff-af98-8da5aa6eb2fc
[2025-05-06T20:49:24.393+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-06T20:49:24.405+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-06T20:49:24.572+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-06T20:49:24.617+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://837932af135c:4040
[2025-05-06T20:49:24.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkContext: Added JAR file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar at spark://837932af135c:43389/jars/graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746564563895
[2025-05-06T20:49:24.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://837932af135c:43389/jars/org.postgresql_postgresql-42.6.0.jar with timestamp 1746564563895
[2025-05-06T20:49:24.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://837932af135c:43389/jars/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746564563895
[2025-05-06T20:49:24.633+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://837932af135c:43389/files/org.postgresql_postgresql-42.6.0.jar with timestamp 1746564563895
[2025-05-06T20:49:24.634+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar to /tmp/spark-80d42ff9-2753-4b9e-bd65-b57082cccf26/userFiles-5ca6278b-6d24-4ae1-8106-4bded44151e9/org.postgresql_postgresql-42.6.0.jar
[2025-05-06T20:49:24.643+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://837932af135c:43389/files/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746564563895
[2025-05-06T20:49:24.643+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar to /tmp/spark-80d42ff9-2753-4b9e-bd65-b57082cccf26/userFiles-5ca6278b-6d24-4ae1-8106-4bded44151e9/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-06T20:49:24.768+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-05-06T20:49:24.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.2:7077 after 18 ms (0 ms spent in bootstraps)
[2025-05-06T20:49:24.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250506204924-0000
[2025-05-06T20:49:25.002+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42719.
[2025-05-06T20:49:25.002+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO NettyBlockTransferService: Server created on 837932af135c:42719
[2025-05-06T20:49:25.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-06T20:49:25.008+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 837932af135c, 42719, None)
[2025-05-06T20:49:25.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO BlockManagerMasterEndpoint: Registering block manager 837932af135c:42719 with 434.4 MiB RAM, BlockManagerId(driver, 837932af135c, 42719, None)
[2025-05-06T20:49:25.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 837932af135c, 42719, None)
[2025-05-06T20:49:25.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 837932af135c, 42719, None)
[2025-05-06T20:49:25.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250506204924-0000/0 on worker-20250506203414-172.18.0.4-43817 (172.18.0.4:43817) with 1 core(s)
[2025-05-06T20:49:25.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20250506204924-0000/0 on hostPort 172.18.0.4:43817 with 1 core(s), 1024.0 MiB RAM
[2025-05-06T20:49:25.151+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-05-06T20:49:25.291+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-06T20:49:25.292+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-05-06T20:49:25.493+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250506204924-0000/0 is now RUNNING
[2025-05-06T20:49:27.865+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:27,865 [INFO] SparkSession создана
[2025-05-06T20:49:27.866+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:27,865 [INFO] Загружаем транзакции из raw.masked_transactions
[2025-05-06T20:49:29.972+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.4:41314) with ID 0,  ResourceProfileId 0
[2025-05-06T20:49:30.129+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:30 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.4:45323 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.4, 45323, None)
[2025-05-06T20:49:30.933+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:30 INFO CodeGenerator: Code generated in 454.99105 ms
[2025-05-06T20:49:30.970+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:30 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-05-06T20:49:30.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:30 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:30.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:30 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:30.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:30 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:30.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:30 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:30.976+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:31.056+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-06T20:49:31.078+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-06T20:49:31.080+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:31.082+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:31.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:31.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-06T20:49:31.115+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:31.280+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.082+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 974 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:32.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-06T20:49:32.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.100 s
[2025-05-06T20:49:32.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:32.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:32.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:32.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:32.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO CodeGenerator: Code generated in 7.563873 ms
[2025-05-06T20:49:32.141+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T20:49:32.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:32.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:32.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-06T20:49:32.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:32.145+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:32.152+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-06T20:49:32.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-06T20:49:32.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 837932af135c:42719 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.156+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:32.157+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:32.157+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-06T20:49:32.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:32.185+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.4:45323 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.251+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.4:41314
[2025-05-06T20:49:32.288+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.304+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 194 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:32.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-06T20:49:32.354+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.204 s
[2025-05-06T20:49:32.355+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:32.355+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-06T20:49:32.356+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.215127 s
[2025-05-06T20:49:32.363+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:32,363 [INFO] Загружено 4652 транзакций
[2025-05-06T20:49:32.363+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:32,363 [INFO] Схема данных транзакций:
[2025-05-06T20:49:32.367+0000] {spark_submit.py:571} INFO - root
[2025-05-06T20:49:32.367+0000] {spark_submit.py:571} INFO - |-- transaction_id: string (nullable = true)
[2025-05-06T20:49:32.367+0000] {spark_submit.py:571} INFO - |-- client_id: string (nullable = true)
[2025-05-06T20:49:32.367+0000] {spark_submit.py:571} INFO - |-- datetime: timestamp (nullable = true)
[2025-05-06T20:49:32.367+0000] {spark_submit.py:571} INFO - |-- amount: double (nullable = true)
[2025-05-06T20:49:32.367+0000] {spark_submit.py:571} INFO - |-- currency: string (nullable = true)
[2025-05-06T20:49:32.367+0000] {spark_submit.py:571} INFO - |-- merchant: string (nullable = true)
[2025-05-06T20:49:32.367+0000] {spark_submit.py:571} INFO - |-- transaction_type: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - |-- category: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - |-- country_code: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - |-- region: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - |-- device_type: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - |-- session_id: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - |-- channel: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - |-- transaction_purpose: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - |-- ip_network: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - |-- recipient_id_hash: string (nullable = true)
[2025-05-06T20:49:32.368+0000] {spark_submit.py:571} INFO - 
[2025-05-06T20:49:32.380+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:32,380 [INFO] Создаем вершины графа
[2025-05-06T20:49:32.455+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:32.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO CodeGenerator: Code generated in 23.946749 ms
[2025-05-06T20:49:32.506+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Registering RDD 8 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-05-06T20:49:32.507+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:32.507+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:32.507+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:32.507+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:32.508+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:32.512+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 19.7 KiB, free 434.4 MiB)
[2025-05-06T20:49:32.514+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 434.4 MiB)
[2025-05-06T20:49:32.514+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 837932af135c:42719 (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.515+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:32.515+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:32.515+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-05-06T20:49:32.516+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:32.531+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.4:45323 (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 269 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:32.786+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-06T20:49:32.786+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.277 s
[2025-05-06T20:49:32.786+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:32.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:32.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:32.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:32.794+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:32.806+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:32.821+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO CodeGenerator: Code generated in 11.924265 ms
[2025-05-06T20:49:32.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Registering RDD 11 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-05-06T20:49:32.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:32.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:32.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-06T20:49:32.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:32.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:32.841+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 33.9 KiB, free 434.3 MiB)
[2025-05-06T20:49:32.853+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
[2025-05-06T20:49:32.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 837932af135c:42719 in memory (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 837932af135c:42719 (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:32.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:32.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-06T20:49:32.856+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:32.857+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.4:45323 in memory (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.869+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 837932af135c:42719 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.874+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.4:45323 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.883+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.4:45323 (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:32.918+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.4:41314
[2025-05-06T20:49:32.983+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 127 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:32.984+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-06T20:49:32.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.146 s
[2025-05-06T20:49:32.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:32.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:32.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:32.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:32 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:33.008+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO CodeGenerator: Code generated in 10.61043 ms
[2025-05-06T20:49:33.026+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T20:49:33.027+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:33.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:33.032+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-06T20:49:33.033+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:33.033+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:33.035+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-06T20:49:33.048+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.3 MiB)
[2025-05-06T20:49:33.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 837932af135c:42719 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.053+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:33.053+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:33.054+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-06T20:49:33.060+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:33.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 837932af135c:42719 in memory (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.4:45323 in memory (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.104+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.4:45323 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.115+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.4:41314
[2025-05-06T20:49:33.153+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 93 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:33.153+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-06T20:49:33.153+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.122 s
[2025-05-06T20:49:33.154+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:33.154+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-06T20:49:33.154+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.128272 s
[2025-05-06T20:49:33.169+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:33,168 [INFO] Создано 1139 вершин
[2025-05-06T20:49:33.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2025-05-06T20:49:33.358+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:33.358+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:33.358+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:33.358+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:33.358+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:33.359+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.0 KiB, free 434.4 MiB)
[2025-05-06T20:49:33.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 434.4 MiB)
[2025-05-06T20:49:33.367+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 837932af135c:42719 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.370+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:33.370+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:33.371+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-05-06T20:49:33.372+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 837932af135c:42719 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.373+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:33.379+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.4:45323 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.401+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.4:45323 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.426+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 54 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:33.427+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-05-06T20:49:33.429+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.096 s
[2025-05-06T20:49:33.430+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:33.431+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:33.432+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:33.432+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:33.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T20:49:33.454+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:33.455+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:33.455+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-05-06T20:49:33.455+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:33.457+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:33.459+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-06T20:49:33.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-06T20:49:33.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 837932af135c:42719 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.475+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:33.476+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:33.476+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-05-06T20:49:33.477+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 837932af135c:42719 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.480+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 6) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:33.482+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.4:45323 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.518+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.4:45323 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.528+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.4:41314
[2025-05-06T20:49:33.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 6) in 58 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:33.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-05-06T20:49:33.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.081 s
[2025-05-06T20:49:33.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:33.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2025-05-06T20:49:33.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.085444 s
[2025-05-06T20:49:33.540+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:33,540 [INFO] Найдено 1774 P2P транзакций (transaction_type='p2p')
[2025-05-06T20:49:33.540+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:33,540 [INFO] Найден столбец recipient_id_hash для P2P транзакций
[2025-05-06T20:49:33.541+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:33,540 [INFO] Создаем ребра на основе P2P транзакций
[2025-05-06T20:49:33.622+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2025-05-06T20:49:33.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:33.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:33.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:33.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:33.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:33.626+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.0 KiB, free 434.4 MiB)
[2025-05-06T20:49:33.633+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 434.4 MiB)
[2025-05-06T20:49:33.634+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 837932af135c:42719 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:33.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:33.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-05-06T20:49:33.639+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 837932af135c:42719 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.639+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 7) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:33.642+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.4:45323 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.657+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.4:45323 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.685+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 7) in 47 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:33.685+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-05-06T20:49:33.686+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.061 s
[2025-05-06T20:49:33.686+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:33.686+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:33.686+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:33.686+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:33.709+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T20:49:33.710+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:33.710+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:33.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2025-05-06T20:49:33.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:33.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:33.713+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-06T20:49:33.719+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-06T20:49:33.720+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 837932af135c:42719 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.721+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 837932af135c:42719 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.721+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:33.722+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:33.722+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-05-06T20:49:33.724+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 8) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:33.725+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.4:45323 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.751+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.4:45323 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:33.758+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.4:41314
[2025-05-06T20:49:33.767+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 8) in 44 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:33.768+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-05-06T20:49:33.769+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.056 s
[2025-05-06T20:49:33.769+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:33.769+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2025-05-06T20:49:33.770+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.059973 s
[2025-05-06T20:49:33.771+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:33,771 [INFO] Создано 1774 P2P ребер
[2025-05-06T20:49:33.771+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:33,771 [INFO] Создаем ребра на основе общих мерчантов
[2025-05-06T20:49:33.993+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO CodeGenerator: Code generated in 5.737533 ms
[2025-05-06T20:49:33.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2025-05-06T20:49:33.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Got map stage job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:33.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:33.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:33.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:33.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:33 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:34.000+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.8 KiB, free 434.4 MiB)
[2025-05-06T20:49:34.009+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-06T20:49:34.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:34.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:34.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-05-06T20:49:34.015+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 837932af135c:42719 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.016+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 9) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:34.020+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.4:45323 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.037+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 9) in 85 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:34.100+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-06T20:49:34.101+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.104 s
[2025-05-06T20:49:34.102+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:34.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:34.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:34.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:34.123+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:34.148+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:34.149+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Got job 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:34.149+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Final stage: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:34.149+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
[2025-05-06T20:49:34.149+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:34.150+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[32] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:34.153+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-06T20:49:34.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-06T20:49:34.163+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.164+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.164+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:34.164+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[32] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:34.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2025-05-06T20:49:34.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 10) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:34.168+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.186+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.202+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.4:41314
[2025-05-06T20:49:34.218+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 10) in 52 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:34.218+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2025-05-06T20:49:34.219+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.067 s
[2025-05-06T20:49:34.219+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:34.219+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2025-05-06T20:49:34.219+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Job 10 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.070834 s
[2025-05-06T20:49:34.246+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO CodeGenerator: Code generated in 9.250108 ms
[2025-05-06T20:49:34.269+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.269+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T20:49:34.306+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 432.3 MiB)
[2025-05-06T20:49:34.311+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 837932af135c:42719 (size: 23.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.314+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:34.328+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:34.368+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO CodeGenerator: Code generated in 12.962304 ms
[2025-05-06T20:49:34.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2025-05-06T20:49:34.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Got map stage job 11 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:34.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:34.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
[2025-05-06T20:49:34.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:34.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:34.379+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 14.8 KiB, free 432.3 MiB)
[2025-05-06T20:49:34.389+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 432.3 MiB)
[2025-05-06T20:49:34.390+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 837932af135c:42719 (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.390+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:34.391+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:34.391+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
[2025-05-06T20:49:34.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 11) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:34.411+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.4:45323 (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.4:45323 (size: 23.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.611+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 11) in 219 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:34.612+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-05-06T20:49:34.612+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0) finished in 0.235 s
[2025-05-06T20:49:34.612+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:34.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:34.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:34.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:34.633+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO CodeGenerator: Code generated in 8.461287 ms
[2025-05-06T20:49:34.647+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T20:49:34.648+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Got job 12 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:34.648+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Final stage: ResultStage 22 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:34.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2025-05-06T20:49:34.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:34.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:34.651+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 11.0 KiB, free 432.3 MiB)
[2025-05-06T20:49:34.653+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 432.3 MiB)
[2025-05-06T20:49:34.653+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 837932af135c:42719 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.654+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:34.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:34.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-05-06T20:49:34.658+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 12) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:34.673+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.4:45323 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.680+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.18.0.4:41314
[2025-05-06T20:49:34.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 12) in 40 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:34.698+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-05-06T20:49:34.699+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: ResultStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0.048 s
[2025-05-06T20:49:34.700+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:34.700+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
[2025-05-06T20:49:34.701+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Job 12 finished: count at NativeMethodAccessorImpl.java:0, took 0.051764 s
[2025-05-06T20:49:34.701+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:34,700 [INFO] Создано 270444 ребер по общим мерчантам
[2025-05-06T20:49:34.702+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:34,700 [INFO] Создаем ребра на основе общих IP-адресов
[2025-05-06T20:49:34.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Registering RDD 42 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2025-05-06T20:49:34.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Got map stage job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:34.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Final stage: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:34.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:34.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:34.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[42] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:34.788+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 12.8 KiB, free 432.3 MiB)
[2025-05-06T20:49:34.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.3 MiB)
[2025-05-06T20:49:34.800+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.800+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:34.801+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 837932af135c:42719 in memory (size: 23.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.801+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[42] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:34.801+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
[2025-05-06T20:49:34.802+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 13) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:34.806+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.4:45323 in memory (size: 23.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.816+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 837932af135c:42719 in memory (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.821+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.4:45323 in memory (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.823+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.832+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 837932af135c:42719 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.846+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.4:45323 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.877+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 13) in 74 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:34.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool
[2025-05-06T20:49:34.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0) finished in 0.092 s
[2025-05-06T20:49:34.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:34.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:34.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:34.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:34.884+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:34.898+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:34.899+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:34.899+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Final stage: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:34.900+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
[2025-05-06T20:49:34.900+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:34.900+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[44] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:34.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-06T20:49:34.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-06T20:49:34.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:34.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[44] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:34.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-05-06T20:49:34.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 14) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:34.915+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.920+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.4:41314
[2025-05-06T20:49:34.932+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 14) in 29 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:34.932+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-05-06T20:49:34.932+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.032 s
[2025-05-06T20:49:34.933+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:34.933+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
[2025-05-06T20:49:34.933+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.034681 s
[2025-05-06T20:49:34.946+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.948+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.950+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T20:49:34.955+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 432.2 MiB)
[2025-05-06T20:49:34.956+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 837932af135c:42719 (size: 58.2 KiB, free: 434.3 MiB)
[2025-05-06T20:49:34.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:34.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Created broadcast 16 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:34.962+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:34.966+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:34.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Registering RDD 47 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2025-05-06T20:49:34.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Got map stage job 15 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:34.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:34.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2025-05-06T20:49:34.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:34.992+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:34.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 14.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:34.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 432.2 MiB)
[2025-05-06T20:49:34.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 837932af135c:42719 (size: 7.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:34.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:34.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:34.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2025-05-06T20:49:34.999+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:34 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 15) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:35.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.4:45323 (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.021+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.4:45323 (size: 58.2 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.094+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 15) in 95 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:35.094+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-05-06T20:49:35.094+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0.102 s
[2025-05-06T20:49:35.094+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:35.095+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:35.095+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:35.095+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:35.108+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T20:49:35.109+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Got job 16 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:35.109+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:35.109+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
[2025-05-06T20:49:35.109+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:35.109+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:35.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 11.0 KiB, free 432.2 MiB)
[2025-05-06T20:49:35.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 432.2 MiB)
[2025-05-06T20:49:35.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 837932af135c:42719 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.117+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:35.118+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 837932af135c:42719 in memory (size: 7.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.118+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:35.118+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
[2025-05-06T20:49:35.120+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 16) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:35.121+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.4:45323 in memory (size: 7.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.133+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.4:45323 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.138+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.18.0.4:41314
[2025-05-06T20:49:35.156+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 16) in 37 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:35.157+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2025-05-06T20:49:35.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0.047 s
[2025-05-06T20:49:35.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:35.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
[2025-05-06T20:49:35.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Job 16 finished: count at NativeMethodAccessorImpl.java:0, took 0.049773 s
[2025-05-06T20:49:35.161+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:35,160 [INFO] Создано 1069538 ребер по общим IP-адресам
[2025-05-06T20:49:35.314+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Registering RDD 57 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2025-05-06T20:49:35.314+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Got map stage job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:35.315+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:35.315+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:35.315+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:35.315+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:35.317+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 12.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:35.318+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:35.319+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.319+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:35.320+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:35.320+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
[2025-05-06T20:49:35.322+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 17) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:35.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO CodeGenerator: Code generated in 11.382261 ms
[2025-05-06T20:49:35.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2025-05-06T20:49:35.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Got map stage job 18 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:35.332+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:35.332+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:35.332+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:35.332+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:35.336+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 12.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:35.336+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:35.357+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.357+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 837932af135c:42719 in memory (size: 58.2 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.357+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:35.360+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:35.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-05-06T20:49:35.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.4:45323 in memory (size: 58.2 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.401+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 837932af135c:42719 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.406+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.4:45323 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.407+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 18) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:35.409+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 17) in 88 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:35.410+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-05-06T20:49:35.410+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0.094 s
[2025-05-06T20:49:35.410+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:35.410+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: running: Set(ShuffleMapStage 32)
[2025-05-06T20:49:35.410+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:35.410+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:35.429+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.439+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:35.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:35.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Got job 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:35.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Final stage: ResultStage 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:35.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
[2025-05-06T20:49:35.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:35.466+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[62] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:35.469+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-06T20:49:35.470+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-06T20:49:35.470+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.471+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:35.480+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[62] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:35.480+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
[2025-05-06T20:49:35.489+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 19) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:35.490+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 18) in 86 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:35.491+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-05-06T20:49:35.492+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0) finished in 0.158 s
[2025-05-06T20:49:35.493+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:35.493+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: running: Set(ResultStage 34)
[2025-05-06T20:49:35.493+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:35.493+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:35.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:35.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.517+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.18.0.4:41314
[2025-05-06T20:49:35.531+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 19) in 43 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:35.532+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool
[2025-05-06T20:49:35.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:35.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: ResultStage 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.066 s
[2025-05-06T20:49:35.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:35.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
[2025-05-06T20:49:35.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Got job 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:35.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Final stage: ResultStage 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:35.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-05-06T20:49:35.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:35.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Job 19 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.073286 s
[2025-05-06T20:49:35.534+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:35.536+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.2 KiB, free 434.3 MiB)
[2025-05-06T20:49:35.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.3 MiB)
[2025-05-06T20:49:35.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:35.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:35.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-05-06T20:49:35.557+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 20) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:35.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T20:49:35.570+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 432.3 MiB)
[2025-05-06T20:49:35.570+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 837932af135c:42719 (size: 23.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.570+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.570+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Created broadcast 23 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:35.572+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.592+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.603+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.18.0.4:41314
[2025-05-06T20:49:35.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.620+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 20) in 72 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:35.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-05-06T20:49:35.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: ResultStage 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.096 s
[2025-05-06T20:49:35.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:35.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-05-06T20:49:35.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Job 20 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.098955 s
[2025-05-06T20:49:35.642+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T20:49:35.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 430.1 MiB)
[2025-05-06T20:49:35.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 837932af135c:42719 (size: 58.2 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Created broadcast 24 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:35.667+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:35.687+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO CodeGenerator: Code generated in 16.787039 ms
[2025-05-06T20:49:35.699+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO CodeGenerator: Code generated in 8.035646 ms
[2025-05-06T20:49:35.718+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO CodeGenerator: Code generated in 11.257469 ms
[2025-05-06T20:49:35.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO CodeGenerator: Code generated in 10.047908 ms
[2025-05-06T20:49:35.773+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Registering RDD 76 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 11
[2025-05-06T20:49:35.774+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Got map stage job 21 (count at NativeMethodAccessorImpl.java:0) with 21 output partitions
[2025-05-06T20:49:35.774+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:35.774+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37, ShuffleMapStage 38)
[2025-05-06T20:49:35.774+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:35.776+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[76] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:35.782+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 52.5 KiB, free 430.1 MiB)
[2025-05-06T20:49:35.783+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 430.0 MiB)
[2025-05-06T20:49:35.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 837932af135c:42719 (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T20:49:35.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:35.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO DAGScheduler: Submitting 21 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[76] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-06T20:49:35.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSchedulerImpl: Adding task set 39.0 with 21 tasks resource profile 0
[2025-05-06T20:49:35.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 21) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:35.801+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.4:45323 (size: 21.6 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.859+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.18.0.4:41314
[2025-05-06T20:49:35.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.4:45323 (size: 23.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:35.970+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 22) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:35.971+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:35 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 21) in 185 ms on 172.18.0.4 (executor 0) (1/21)
[2025-05-06T20:49:36.002+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 23) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 22) in 32 ms on 172.18.0.4 (executor 0) (2/21)
[2025-05-06T20:49:36.059+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 4.0 in stage 39.0 (TID 24) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.061+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 23) in 58 ms on 172.18.0.4 (executor 0) (3/21)
[2025-05-06T20:49:36.081+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 5.0 in stage 39.0 (TID 25) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.081+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 4.0 in stage 39.0 (TID 24) in 23 ms on 172.18.0.4 (executor 0) (4/21)
[2025-05-06T20:49:36.102+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 6.0 in stage 39.0 (TID 26) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 5.0 in stage 39.0 (TID 25) in 23 ms on 172.18.0.4 (executor 0) (5/21)
[2025-05-06T20:49:36.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 7.0 in stage 39.0 (TID 27) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 6.0 in stage 39.0 (TID 26) in 31 ms on 172.18.0.4 (executor 0) (6/21)
[2025-05-06T20:49:36.230+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 8.0 in stage 39.0 (TID 28) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.230+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 7.0 in stage 39.0 (TID 27) in 99 ms on 172.18.0.4 (executor 0) (7/21)
[2025-05-06T20:49:36.303+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 9.0 in stage 39.0 (TID 29) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.304+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 8.0 in stage 39.0 (TID 28) in 74 ms on 172.18.0.4 (executor 0) (8/21)
[2025-05-06T20:49:36.370+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 10.0 in stage 39.0 (TID 30) (172.18.0.4, executor 0, partition 10, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.370+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 9.0 in stage 39.0 (TID 29) in 67 ms on 172.18.0.4 (executor 0) (9/21)
[2025-05-06T20:49:36.437+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 11.0 in stage 39.0 (TID 31) (172.18.0.4, executor 0, partition 11, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.437+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 10.0 in stage 39.0 (TID 30) in 68 ms on 172.18.0.4 (executor 0) (10/21)
[2025-05-06T20:49:36.459+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.4:45323 (size: 58.2 KiB, free: 434.3 MiB)
[2025-05-06T20:49:36.520+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 12.0 in stage 39.0 (TID 32) (172.18.0.4, executor 0, partition 12, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.522+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 11.0 in stage 39.0 (TID 31) in 85 ms on 172.18.0.4 (executor 0) (11/21)
[2025-05-06T20:49:36.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 13.0 in stage 39.0 (TID 33) (172.18.0.4, executor 0, partition 13, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.549+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 12.0 in stage 39.0 (TID 32) in 28 ms on 172.18.0.4 (executor 0) (12/21)
[2025-05-06T20:49:36.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 14.0 in stage 39.0 (TID 34) (172.18.0.4, executor 0, partition 14, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.579+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 13.0 in stage 39.0 (TID 33) in 31 ms on 172.18.0.4 (executor 0) (13/21)
[2025-05-06T20:49:36.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 15.0 in stage 39.0 (TID 35) (172.18.0.4, executor 0, partition 15, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.616+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 14.0 in stage 39.0 (TID 34) in 38 ms on 172.18.0.4 (executor 0) (14/21)
[2025-05-06T20:49:36.657+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 16.0 in stage 39.0 (TID 36) (172.18.0.4, executor 0, partition 16, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.657+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 15.0 in stage 39.0 (TID 35) in 42 ms on 172.18.0.4 (executor 0) (15/21)
[2025-05-06T20:49:36.681+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 17.0 in stage 39.0 (TID 37) (172.18.0.4, executor 0, partition 17, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.682+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 16.0 in stage 39.0 (TID 36) in 26 ms on 172.18.0.4 (executor 0) (16/21)
[2025-05-06T20:49:36.704+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 18.0 in stage 39.0 (TID 38) (172.18.0.4, executor 0, partition 18, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.704+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 17.0 in stage 39.0 (TID 37) in 23 ms on 172.18.0.4 (executor 0) (17/21)
[2025-05-06T20:49:36.925+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 19.0 in stage 39.0 (TID 39) (172.18.0.4, executor 0, partition 19, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.925+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 18.0 in stage 39.0 (TID 38) in 222 ms on 172.18.0.4 (executor 0) (18/21)
[2025-05-06T20:49:36.941+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Starting task 20.0 in stage 39.0 (TID 40) (172.18.0.4, executor 0, partition 20, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:36.941+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:36 INFO TaskSetManager: Finished task 19.0 in stage 39.0 (TID 39) in 17 ms on 172.18.0.4 (executor 0) (19/21)
[2025-05-06T20:49:37.170+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:37.170+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Finished task 20.0 in stage 39.0 (TID 40) in 229 ms on 172.18.0.4 (executor 0) (20/21)
[2025-05-06T20:49:37.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 28 ms on 172.18.0.4 (executor 0) (21/21)
[2025-05-06T20:49:37.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-05-06T20:49:37.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 1.420 s
[2025-05-06T20:49:37.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:37.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:37.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:37.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:37.200+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 2502967, minimum partition size: 1048576
[2025-05-06T20:49:37.209+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:37.225+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO CodeGenerator: Code generated in 13.331105 ms
[2025-05-06T20:49:37.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Registering RDD 79 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 12
[2025-05-06T20:49:37.232+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-05-06T20:49:37.232+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:37.232+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
[2025-05-06T20:49:37.232+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:37.232+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:37.235+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 49.4 KiB, free 430.0 MiB)
[2025-05-06T20:49:37.241+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 430.0 MiB)
[2025-05-06T20:49:37.242+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 837932af135c:42719 (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.242+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 837932af135c:42719 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.242+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:37.243+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-06T20:49:37.243+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks resource profile 0
[2025-05-06T20:49:37.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 42) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:37.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.18.0.4:45323 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.249+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.252+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.256+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.4:45323 (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.266+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.18.0.4:41314
[2025-05-06T20:49:37.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 43) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:37.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 42) in 217 ms on 172.18.0.4 (executor 0) (1/2)
[2025-05-06T20:49:37.600+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 43) in 139 ms on 172.18.0.4 (executor 0) (2/2)
[2025-05-06T20:49:37.601+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-05-06T20:49:37.601+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0) finished in 0.368 s
[2025-05-06T20:49:37.601+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:37.601+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:37.601+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:37.601+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:37.616+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO CodeGenerator: Code generated in 6.868483 ms
[2025-05-06T20:49:37.624+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T20:49:37.626+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:49:37.626+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Final stage: ResultStage 48 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:49:37.626+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-05-06T20:49:37.626+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:37.626+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:49:37.628+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 11.0 KiB, free 430.1 MiB)
[2025-05-06T20:49:37.629+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 430.0 MiB)
[2025-05-06T20:49:37.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 837932af135c:42719 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:37.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:37.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-05-06T20:49:37.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 44) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:37.638+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.18.0.4:45323 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.641+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.18.0.4:41314
[2025-05-06T20:49:37.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 44) in 21 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:37.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-05-06T20:49:37.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: ResultStage 48 (count at NativeMethodAccessorImpl.java:0) finished in 0.025 s
[2025-05-06T20:49:37.653+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:37.653+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-05-06T20:49:37.653+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0.028369 s
[2025-05-06T20:49:37.654+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:37,654 [INFO] Всего создано 410196 уникальных ребер
[2025-05-06T20:49:37.654+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:37,654 [INFO] Создаем граф
[2025-05-06T20:49:37.679+0000] {spark_submit.py:571} INFO - 2025-05-06 20:49:37,679 [INFO] Запускаем алгоритм обнаружения сообществ
[2025-05-06T20:49:37.829+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:37.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Registering RDD 86 (rdd at GraphFrame.scala:187) as input to shuffle 13
[2025-05-06T20:49:37.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Got map stage job 24 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-06T20:49:37.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Final stage: ShuffleMapStage 49 (rdd at GraphFrame.scala:187)
[2025-05-06T20:49:37.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:37.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:37.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[86] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-06T20:49:37.836+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 19.9 KiB, free 430.0 MiB)
[2025-05-06T20:49:37.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 430.0 MiB)
[2025-05-06T20:49:37.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 837932af135c:42719 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:37.838+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[86] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:37.838+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
[2025-05-06T20:49:37.839+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 45) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:37.846+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.4:45323 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.870+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 45) in 31 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:37.870+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool
[2025-05-06T20:49:37.870+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: ShuffleMapStage 49 (rdd at GraphFrame.scala:187) finished in 0.035 s
[2025-05-06T20:49:37.870+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:37.870+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:37.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:37.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:37.875+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:37.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:37.898+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO CodeGenerator: Code generated in 13.531063 ms
[2025-05-06T20:49:37.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:37.911+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Got job 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:37.911+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Final stage: ResultStage 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:37.911+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
[2025-05-06T20:49:37.912+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:37.912+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[89] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:37.914+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 32.6 KiB, free 430.0 MiB)
[2025-05-06T20:49:37.915+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 430.0 MiB)
[2025-05-06T20:49:37.915+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 837932af135c:42719 (size: 15.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.916+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:37.916+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[89] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:37.916+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
[2025-05-06T20:49:37.917+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 46) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:37.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.4:45323 (size: 15.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.18.0.4:41314
[2025-05-06T20:49:37.939+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 837932af135c:42719 in memory (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.941+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.18.0.4:45323 in memory (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.946+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 837932af135c:42719 in memory (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.948+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.18.0.4:45323 in memory (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.953+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 837932af135c:42719 in memory (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.953+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.4:45323 in memory (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 837932af135c:42719 in memory (size: 23.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.4:45323 in memory (size: 23.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:37.972+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 837932af135c:42719 in memory (size: 58.2 KiB, free: 434.4 MiB)
[2025-05-06T20:49:37.972+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.4:45323 in memory (size: 58.2 KiB, free: 434.4 MiB)
[2025-05-06T20:49:37.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 46) in 57 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:37.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool
[2025-05-06T20:49:37.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: ResultStage 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.061 s
[2025-05-06T20:49:37.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:37.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
[2025-05-06T20:49:37.975+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO DAGScheduler: Job 25 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.063662 s
[2025-05-06T20:49:37.982+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO CodeGenerator: Code generated in 4.458157 ms
[2025-05-06T20:49:37.987+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T20:49:37.988+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 432.3 MiB)
[2025-05-06T20:49:37.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 837932af135c:42719 (size: 27.1 KiB, free: 434.4 MiB)
[2025-05-06T20:49:37.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:37 INFO SparkContext: Created broadcast 30 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:38.008+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO CodeGenerator: Code generated in 8.674687 ms
[2025-05-06T20:49:38.012+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:38.012+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:38.012+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:38.037+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO CodeGenerator: Code generated in 18.475462 ms
[2025-05-06T20:49:38.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:38.056+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#305 - id.nullCount#304) > 0)
[2025-05-06T20:49:38.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Registering RDD 110 (collect at GraphFrame.scala:574) as input to shuffle 15
[2025-05-06T20:49:38.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Got map stage job 26 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-06T20:49:38.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Final stage: ShuffleMapStage 52 (collect at GraphFrame.scala:574)
[2025-05-06T20:49:38.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:38.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:38.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[110] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T20:49:38.255+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 12.8 KiB, free 432.3 MiB)
[2025-05-06T20:49:38.257+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:38.257+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.257+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:38.258+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[110] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:38.258+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
[2025-05-06T20:49:38.259+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Registering RDD 112 (collect at GraphFrame.scala:574) as input to shuffle 16
[2025-05-06T20:49:38.259+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Got map stage job 27 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-06T20:49:38.259+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Final stage: ShuffleMapStage 53 (collect at GraphFrame.scala:574)
[2025-05-06T20:49:38.259+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:38.259+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 47) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.259+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:38.262+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T20:49:38.265+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 12.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:38.266+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:38.267+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.268+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:38.268+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:38.268+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-05-06T20:49:38.272+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.295+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 48) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.296+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 47) in 37 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:38.296+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool
[2025-05-06T20:49:38.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: ShuffleMapStage 52 (collect at GraphFrame.scala:574) finished in 0.042 s
[2025-05-06T20:49:38.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:38.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: running: Set(ShuffleMapStage 53)
[2025-05-06T20:49:38.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:38.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:38.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.311+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:38.337+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:38.337+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:38.338+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:38.338+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
[2025-05-06T20:49:38.339+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:38.339+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[115] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:38.339+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.2 KiB, free 432.2 MiB)
[2025-05-06T20:49:38.356+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:38.357+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.360+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:38.360+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 48) in 64 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:38.360+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[115] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:38.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-05-06T20:49:38.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-05-06T20:49:38.364+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: ShuffleMapStage 53 (collect at GraphFrame.scala:574) finished in 0.099 s
[2025-05-06T20:49:38.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:38.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: running: Set(ResultStage 55)
[2025-05-06T20:49:38.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:38.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:38.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 837932af135c:42719 in memory (size: 15.3 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 49) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.373+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.18.0.4:45323 in memory (size: 15.3 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.380+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.386+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.388+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:38.389+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.403+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.4:41314
[2025-05-06T20:49:38.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 49) in 46 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:38.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-05-06T20:49:38.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.077 s
[2025-05-06T20:49:38.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:38.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-05-06T20:49:38.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.079572 s
[2025-05-06T20:49:38.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T20:49:38.421+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 430.2 MiB)
[2025-05-06T20:49:38.423+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 837932af135c:42719 (size: 23.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.423+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO SparkContext: Created broadcast 34 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:38.428+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:38.429+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:38.429+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Final stage: ResultStage 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:38.430+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-05-06T20:49:38.430+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:38.430+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[118] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:38.431+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.2 KiB, free 430.2 MiB)
[2025-05-06T20:49:38.432+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 430.2 MiB)
[2025-05-06T20:49:38.432+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:38.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[118] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:38.434+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-05-06T20:49:38.434+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 50) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.444+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.451+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.18.0.4:41314
[2025-05-06T20:49:38.457+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 50) in 23 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:38.458+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-05-06T20:49:38.458+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: ResultStage 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.027 s
[2025-05-06T20:49:38.458+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:38.458+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-05-06T20:49:38.459+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.030985 s
[2025-05-06T20:49:38.466+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 2.1 MiB, free 428.1 MiB)
[2025-05-06T20:49:38.476+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.477+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 428.0 MiB)
[2025-05-06T20:49:38.478+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 837932af135c:42719 (size: 58.2 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO SparkContext: Created broadcast 36 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:38.482+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.505+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:38.540+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Registering RDD 128 (collect at GraphFrame.scala:574) as input to shuffle 17
[2025-05-06T20:49:38.540+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Got map stage job 30 (collect at GraphFrame.scala:574) with 21 output partitions
[2025-05-06T20:49:38.541+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (collect at GraphFrame.scala:574)
[2025-05-06T20:49:38.541+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58, ShuffleMapStage 59)
[2025-05-06T20:49:38.541+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:38.542+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[128] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T20:49:38.545+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 52.5 KiB, free 428.0 MiB)
[2025-05-06T20:49:38.546+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 428.0 MiB)
[2025-05-06T20:49:38.547+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 837932af135c:42719 (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:38.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO DAGScheduler: Submitting 21 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[128] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-06T20:49:38.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSchedulerImpl: Adding task set 60.0 with 21 tasks resource profile 0
[2025-05-06T20:49:38.549+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 51) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.557+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.18.0.4:45323 (size: 21.6 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.563+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.4:41314
[2025-05-06T20:49:38.573+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.4:45323 (size: 23.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:38.594+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 52) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.594+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 51) in 46 ms on 172.18.0.4 (executor 0) (1/21)
[2025-05-06T20:49:38.622+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 53) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 52) in 30 ms on 172.18.0.4 (executor 0) (2/21)
[2025-05-06T20:49:38.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 54) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 53) in 30 ms on 172.18.0.4 (executor 0) (3/21)
[2025-05-06T20:49:38.670+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 5.0 in stage 60.0 (TID 55) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.671+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 54) in 19 ms on 172.18.0.4 (executor 0) (4/21)
[2025-05-06T20:49:38.683+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 6.0 in stage 60.0 (TID 56) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.683+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 5.0 in stage 60.0 (TID 55) in 13 ms on 172.18.0.4 (executor 0) (5/21)
[2025-05-06T20:49:38.698+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 7.0 in stage 60.0 (TID 57) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.698+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 6.0 in stage 60.0 (TID 56) in 16 ms on 172.18.0.4 (executor 0) (6/21)
[2025-05-06T20:49:38.739+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 8.0 in stage 60.0 (TID 58) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.740+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 7.0 in stage 60.0 (TID 57) in 42 ms on 172.18.0.4 (executor 0) (7/21)
[2025-05-06T20:49:38.773+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 9.0 in stage 60.0 (TID 59) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.773+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 8.0 in stage 60.0 (TID 58) in 34 ms on 172.18.0.4 (executor 0) (8/21)
[2025-05-06T20:49:38.810+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 10.0 in stage 60.0 (TID 60) (172.18.0.4, executor 0, partition 10, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.811+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 9.0 in stage 60.0 (TID 59) in 38 ms on 172.18.0.4 (executor 0) (9/21)
[2025-05-06T20:49:38.858+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 11.0 in stage 60.0 (TID 61) (172.18.0.4, executor 0, partition 11, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.859+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 10.0 in stage 60.0 (TID 60) in 50 ms on 172.18.0.4 (executor 0) (10/21)
[2025-05-06T20:49:38.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.4:45323 (size: 58.2 KiB, free: 434.3 MiB)
[2025-05-06T20:49:38.918+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 12.0 in stage 60.0 (TID 62) (172.18.0.4, executor 0, partition 12, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.918+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 11.0 in stage 60.0 (TID 61) in 60 ms on 172.18.0.4 (executor 0) (11/21)
[2025-05-06T20:49:38.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 13.0 in stage 60.0 (TID 63) (172.18.0.4, executor 0, partition 13, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 12.0 in stage 60.0 (TID 62) in 13 ms on 172.18.0.4 (executor 0) (12/21)
[2025-05-06T20:49:38.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 14.0 in stage 60.0 (TID 64) (172.18.0.4, executor 0, partition 14, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 13.0 in stage 60.0 (TID 63) in 12 ms on 172.18.0.4 (executor 0) (13/21)
[2025-05-06T20:49:38.953+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 15.0 in stage 60.0 (TID 65) (172.18.0.4, executor 0, partition 15, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.954+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 14.0 in stage 60.0 (TID 64) in 12 ms on 172.18.0.4 (executor 0) (14/21)
[2025-05-06T20:49:38.966+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 16.0 in stage 60.0 (TID 66) (172.18.0.4, executor 0, partition 16, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.966+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 15.0 in stage 60.0 (TID 65) in 13 ms on 172.18.0.4 (executor 0) (15/21)
[2025-05-06T20:49:38.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 17.0 in stage 60.0 (TID 67) (172.18.0.4, executor 0, partition 17, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 16.0 in stage 60.0 (TID 66) in 11 ms on 172.18.0.4 (executor 0) (16/21)
[2025-05-06T20:49:38.994+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Starting task 18.0 in stage 60.0 (TID 68) (172.18.0.4, executor 0, partition 18, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:38.994+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:38 INFO TaskSetManager: Finished task 17.0 in stage 60.0 (TID 67) in 18 ms on 172.18.0.4 (executor 0) (17/21)
[2025-05-06T20:49:39.172+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Starting task 19.0 in stage 60.0 (TID 69) (172.18.0.4, executor 0, partition 19, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:39.172+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Finished task 18.0 in stage 60.0 (TID 68) in 178 ms on 172.18.0.4 (executor 0) (18/21)
[2025-05-06T20:49:39.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Starting task 20.0 in stage 60.0 (TID 70) (172.18.0.4, executor 0, partition 20, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:39.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Finished task 19.0 in stage 60.0 (TID 69) in 10 ms on 172.18.0.4 (executor 0) (19/21)
[2025-05-06T20:49:39.399+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 71) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:39.399+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Finished task 20.0 in stage 60.0 (TID 70) in 218 ms on 172.18.0.4 (executor 0) (20/21)
[2025-05-06T20:49:39.418+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 71) in 19 ms on 172.18.0.4 (executor 0) (21/21)
[2025-05-06T20:49:39.418+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-06T20:49:39.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: ShuffleMapStage 60 (collect at GraphFrame.scala:574) finished in 0.875 s
[2025-05-06T20:49:39.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:39.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:39.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:39.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:39.422+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 2502967, minimum partition size: 1048576
[2025-05-06T20:49:39.432+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:39.463+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO CodeGenerator: Code generated in 23.971359 ms
[2025-05-06T20:49:39.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: Registering RDD 131 (collect at GraphFrame.scala:574) as input to shuffle 18
[2025-05-06T20:49:39.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: Got map stage job 31 (collect at GraphFrame.scala:574) with 2 output partitions
[2025-05-06T20:49:39.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: Final stage: ShuffleMapStage 64 (collect at GraphFrame.scala:574)
[2025-05-06T20:49:39.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
[2025-05-06T20:49:39.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:39.474+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[131] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T20:49:39.476+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 59.5 KiB, free 427.9 MiB)
[2025-05-06T20:49:39.478+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 427.9 MiB)
[2025-05-06T20:49:39.478+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 837932af135c:42719 (size: 24.8 KiB, free: 434.2 MiB)
[2025-05-06T20:49:39.478+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:39.478+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[131] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-06T20:49:39.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks resource profile 0
[2025-05-06T20:49:39.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 72) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:39.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.18.0.4:45323 (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:39.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.18.0.4:41314
[2025-05-06T20:49:39.795+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 73) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:39.795+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 72) in 316 ms on 172.18.0.4 (executor 0) (1/2)
[2025-05-06T20:49:39.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 73) in 165 ms on 172.18.0.4 (executor 0) (2/2)
[2025-05-06T20:49:39.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-05-06T20:49:39.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: ShuffleMapStage 64 (collect at GraphFrame.scala:574) finished in 0.485 s
[2025-05-06T20:49:39.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:39.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:39.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:39.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:39.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:39.969+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:39.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO CodeGenerator: Code generated in 10.23001 ms
[2025-05-06T20:49:39.999+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:39 INFO SparkContext: Starting job: collect at GraphFrame.scala:574
[2025-05-06T20:49:40.000+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Got job 32 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-06T20:49:40.000+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Final stage: ResultStage 69 (collect at GraphFrame.scala:574)
[2025-05-06T20:49:40.000+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
[2025-05-06T20:49:40.000+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:40.001+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[134] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T20:49:40.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 54.8 KiB, free 427.8 MiB)
[2025-05-06T20:49:40.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 427.9 MiB)
[2025-05-06T20:49:40.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 837932af135c:42719 in memory (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 837932af135c:42719 (size: 23.8 KiB, free: 434.2 MiB)
[2025-05-06T20:49:40.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:40.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[134] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:40.014+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
[2025-05-06T20:49:40.014+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.18.0.4:45323 in memory (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.014+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 74) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:40.018+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 837932af135c:42719 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.019+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.18.0.4:45323 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.024+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.18.0.4:45323 (size: 23.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.046+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.18.0.4:41314
[2025-05-06T20:49:40.070+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 74) in 56 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:40.070+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-06T20:49:40.070+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: ResultStage 69 (collect at GraphFrame.scala:574) finished in 0.069 s
[2025-05-06T20:49:40.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:40.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
[2025-05-06T20:49:40.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Job 32 finished: collect at GraphFrame.scala:574, took 0.071901 s
[2025-05-06T20:49:40.206+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Registering RDD 143 (rdd at GraphFrame.scala:188) as input to shuffle 19
[2025-05-06T20:49:40.207+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Got map stage job 33 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-06T20:49:40.207+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (rdd at GraphFrame.scala:188)
[2025-05-06T20:49:40.207+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:40.207+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:40.207+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[143] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T20:49:40.208+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 12.8 KiB, free 428.0 MiB)
[2025-05-06T20:49:40.209+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 427.9 MiB)
[2025-05-06T20:49:40.209+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.209+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:40.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[143] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:40.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
[2025-05-06T20:49:40.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:40.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Registering RDD 145 (rdd at GraphFrame.scala:188) as input to shuffle 20
[2025-05-06T20:49:40.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Got map stage job 34 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-06T20:49:40.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Final stage: ShuffleMapStage 71 (rdd at GraphFrame.scala:188)
[2025-05-06T20:49:40.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:40.211+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 75) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:40.211+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:40.211+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T20:49:40.213+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.8 KiB, free 427.9 MiB)
[2025-05-06T20:49:40.214+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 427.9 MiB)
[2025-05-06T20:49:40.215+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.215+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:40.215+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:40.215+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0
[2025-05-06T20:49:40.219+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.221+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO CodeGenerator: Code generated in 9.136467 ms
[2025-05-06T20:49:40.224+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Registering RDD 147 (rdd at GraphFrame.scala:188) as input to shuffle 21
[2025-05-06T20:49:40.224+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Got map stage job 35 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-06T20:49:40.225+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Final stage: ShuffleMapStage 72 (rdd at GraphFrame.scala:188)
[2025-05-06T20:49:40.225+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:49:40.225+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:40.225+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[147] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T20:49:40.226+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 19.9 KiB, free 427.9 MiB)
[2025-05-06T20:49:40.235+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 427.9 MiB)
[2025-05-06T20:49:40.237+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 837932af135c:42719 (size: 9.7 KiB, free: 434.2 MiB)
[2025-05-06T20:49:40.237+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:40.237+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[147] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:40.238+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
[2025-05-06T20:49:40.239+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 837932af135c:42719 in memory (size: 23.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.18.0.4:45323 in memory (size: 23.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.246+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 76) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:40.247+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 75) in 37 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:40.248+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-05-06T20:49:40.249+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: ShuffleMapStage 70 (rdd at GraphFrame.scala:188) finished in 0.041 s
[2025-05-06T20:49:40.250+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:40.250+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: running: Set(ShuffleMapStage 71, ShuffleMapStage 72)
[2025-05-06T20:49:40.250+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:40.250+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:40.257+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.18.0.4:45323 in memory (size: 58.2 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.259+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 837932af135c:42719 in memory (size: 58.2 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.267+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 837932af135c:42719 in memory (size: 23.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.269+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.270+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.4:45323 in memory (size: 23.5 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.302+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 77) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:40.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 76) in 59 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:40.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-05-06T20:49:40.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: ShuffleMapStage 71 (rdd at GraphFrame.scala:188) finished in 0.095 s
[2025-05-06T20:49:40.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:40.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: running: Set(ShuffleMapStage 72)
[2025-05-06T20:49:40.310+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:40.310+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:40.317+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.18.0.4:45323 (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.326+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:40.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:40.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Got job 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:40.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Final stage: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:40.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
[2025-05-06T20:49:40.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:40.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[150] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:40.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.2 KiB, free 432.2 MiB)
[2025-05-06T20:49:40.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:40.358+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.360+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:40.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[150] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:40.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
[2025-05-06T20:49:40.382+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:40.396+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:40.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Got job 37 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:40.398+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Final stage: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:40.398+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
[2025-05-06T20:49:40.399+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:40.399+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[153] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:40.399+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 7.2 KiB, free 432.2 MiB)
[2025-05-06T20:49:40.399+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.2 MiB)
[2025-05-06T20:49:40.400+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.400+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:40.400+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[153] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:40.400+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
[2025-05-06T20:49:40.409+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 78) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 77) in 108 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:40.410+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-05-06T20:49:40.411+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: ShuffleMapStage 72 (rdd at GraphFrame.scala:188) finished in 0.186 s
[2025-05-06T20:49:40.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:40.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: running: Set(ResultStage 74, ResultStage 76)
[2025-05-06T20:49:40.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:40.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:40.420+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.18.0.4:41314
[2025-05-06T20:49:40.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 79) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:40.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 78) in 24 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:40.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool
[2025-05-06T20:49:40.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:40.434+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.084 s
[2025-05-06T20:49:40.435+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:40.435+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
[2025-05-06T20:49:40.435+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Job 36 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.085781 s
[2025-05-06T20:49:40.435+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:49:40.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:49:40.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.18.0.4:45323 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T20:49:40.457+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 837932af135c:42719 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 430.2 MiB)
[2025-05-06T20:49:40.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 837932af135c:42719 (size: 23.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 45 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:40.467+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.468+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.18.0.4:41314
[2025-05-06T20:49:40.475+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.483+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO CodeGenerator: Code generated in 25.765353 ms
[2025-05-06T20:49:40.484+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.487+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.487+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 79) in 55 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:40.487+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-05-06T20:49:40.491+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.092 s
[2025-05-06T20:49:40.495+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:40.496+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
[2025-05-06T20:49:40.498+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Job 37 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.101753 s
[2025-05-06T20:49:40.498+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.522+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 2.1 MiB, free 428.1 MiB)
[2025-05-06T20:49:40.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:40.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Got job 38 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:49:40.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Final stage: ResultStage 78 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:49:40.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
[2025-05-06T20:49:40.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:40.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 428.0 MiB)
[2025-05-06T20:49:40.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 837932af135c:42719 (size: 58.2 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[158] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:49:40.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 46 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:40.529+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 30.8 KiB, free 428.0 MiB)
[2025-05-06T20:49:40.530+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 14.4 KiB, free 428.0 MiB)
[2025-05-06T20:49:40.530+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 837932af135c:42719 (size: 14.4 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.530+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:40.530+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[158] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:40.531+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
[2025-05-06T20:49:40.536+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 80) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:40.550+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.559+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.18.0.4:41314
[2025-05-06T20:49:40.575+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO CodeGenerator: Code generated in 17.765476 ms
[2025-05-06T20:49:40.576+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.584+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.597+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO CodeGenerator: Code generated in 13.626285 ms
[2025-05-06T20:49:40.633+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO CodeGenerator: Code generated in 26.188815 ms
[2025-05-06T20:49:40.634+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 80) in 101 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:40.634+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-05-06T20:49:40.636+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: ResultStage 78 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.113 s
[2025-05-06T20:49:40.636+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:49:40.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
[2025-05-06T20:49:40.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Job 38 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.116063 s
[2025-05-06T20:49:40.640+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Registering RDD 167 (rdd at GraphFrame.scala:188) as input to shuffle 22
[2025-05-06T20:49:40.640+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Got map stage job 39 (rdd at GraphFrame.scala:188) with 21 output partitions
[2025-05-06T20:49:40.641+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Final stage: ShuffleMapStage 81 (rdd at GraphFrame.scala:188)
[2025-05-06T20:49:40.641+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-06T20:49:40.641+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:40.642+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[167] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T20:49:40.644+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 2.1 MiB, free 425.9 MiB)
[2025-05-06T20:49:40.648+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 425.9 MiB)
[2025-05-06T20:49:40.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 837932af135c:42719 (size: 19.9 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 48 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:49:40.673+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 49.4 KiB, free 425.9 MiB)
[2025-05-06T20:49:40.675+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 20.9 KiB, free 425.8 MiB)
[2025-05-06T20:49:40.676+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 837932af135c:42719 (size: 20.9 KiB, free: 434.2 MiB)
[2025-05-06T20:49:40.676+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:40.681+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO DAGScheduler: Submitting 21 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[167] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-06T20:49:40.682+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSchedulerImpl: Adding task set 81.0 with 21 tasks resource profile 0
[2025-05-06T20:49:40.682+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 81) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:40.690+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.18.0.4:45323 (size: 20.9 KiB, free: 434.4 MiB)
[2025-05-06T20:49:40.710+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.18.0.4:41314
[2025-05-06T20:49:40.722+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.18.0.4:45323 (size: 23.5 KiB, free: 434.3 MiB)
[2025-05-06T20:49:40.949+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 82) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:40.950+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:40 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 81) in 267 ms on 172.18.0.4 (executor 0) (1/21)
[2025-05-06T20:49:41.034+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 83) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.034+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 82) in 85 ms on 172.18.0.4 (executor 0) (2/21)
[2025-05-06T20:49:41.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 84) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 83) in 99 ms on 172.18.0.4 (executor 0) (3/21)
[2025-05-06T20:49:41.140+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 85) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.141+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 84) in 8 ms on 172.18.0.4 (executor 0) (4/21)
[2025-05-06T20:49:41.152+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 6.0 in stage 81.0 (TID 86) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.152+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 85) in 12 ms on 172.18.0.4 (executor 0) (5/21)
[2025-05-06T20:49:41.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 7.0 in stage 81.0 (TID 87) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 6.0 in stage 81.0 (TID 86) in 25 ms on 172.18.0.4 (executor 0) (6/21)
[2025-05-06T20:49:41.349+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 8.0 in stage 81.0 (TID 88) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.350+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 7.0 in stage 81.0 (TID 87) in 174 ms on 172.18.0.4 (executor 0) (7/21)
[2025-05-06T20:49:41.445+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 9.0 in stage 81.0 (TID 89) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.447+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 8.0 in stage 81.0 (TID 88) in 97 ms on 172.18.0.4 (executor 0) (8/21)
[2025-05-06T20:49:41.592+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 10.0 in stage 81.0 (TID 90) (172.18.0.4, executor 0, partition 10, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.592+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 9.0 in stage 81.0 (TID 89) in 148 ms on 172.18.0.4 (executor 0) (9/21)
[2025-05-06T20:49:41.775+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 11.0 in stage 81.0 (TID 91) (172.18.0.4, executor 0, partition 11, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.775+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 10.0 in stage 81.0 (TID 90) in 184 ms on 172.18.0.4 (executor 0) (10/21)
[2025-05-06T20:49:41.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.18.0.4:41314
[2025-05-06T20:49:41.793+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.18.0.4:45323 (size: 58.2 KiB, free: 434.3 MiB)
[2025-05-06T20:49:41.896+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 12.0 in stage 81.0 (TID 92) (172.18.0.4, executor 0, partition 12, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.896+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 11.0 in stage 81.0 (TID 91) in 122 ms on 172.18.0.4 (executor 0) (11/21)
[2025-05-06T20:49:41.922+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 13.0 in stage 81.0 (TID 93) (172.18.0.4, executor 0, partition 13, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.922+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 12.0 in stage 81.0 (TID 92) in 27 ms on 172.18.0.4 (executor 0) (12/21)
[2025-05-06T20:49:41.948+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 14.0 in stage 81.0 (TID 94) (172.18.0.4, executor 0, partition 14, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.948+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 13.0 in stage 81.0 (TID 93) in 26 ms on 172.18.0.4 (executor 0) (13/21)
[2025-05-06T20:49:41.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 15.0 in stage 81.0 (TID 95) (172.18.0.4, executor 0, partition 15, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.975+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 14.0 in stage 81.0 (TID 94) in 26 ms on 172.18.0.4 (executor 0) (14/21)
[2025-05-06T20:49:41.999+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Starting task 16.0 in stage 81.0 (TID 96) (172.18.0.4, executor 0, partition 16, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:41.999+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:41 INFO TaskSetManager: Finished task 15.0 in stage 81.0 (TID 95) in 25 ms on 172.18.0.4 (executor 0) (15/21)
[2025-05-06T20:49:42.014+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:42 INFO TaskSetManager: Starting task 17.0 in stage 81.0 (TID 97) (172.18.0.4, executor 0, partition 17, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:42.014+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:42 INFO TaskSetManager: Finished task 16.0 in stage 81.0 (TID 96) in 16 ms on 172.18.0.4 (executor 0) (16/21)
[2025-05-06T20:49:42.036+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:42 INFO TaskSetManager: Starting task 18.0 in stage 81.0 (TID 98) (172.18.0.4, executor 0, partition 18, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:42.036+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:42 INFO TaskSetManager: Finished task 17.0 in stage 81.0 (TID 97) in 22 ms on 172.18.0.4 (executor 0) (17/21)
[2025-05-06T20:49:42.678+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:42 INFO TaskSetManager: Starting task 19.0 in stage 81.0 (TID 99) (172.18.0.4, executor 0, partition 19, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:42.679+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:42 INFO TaskSetManager: Finished task 18.0 in stage 81.0 (TID 98) in 642 ms on 172.18.0.4 (executor 0) (18/21)
[2025-05-06T20:49:42.695+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:42 INFO TaskSetManager: Starting task 20.0 in stage 81.0 (TID 100) (172.18.0.4, executor 0, partition 20, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:42.696+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:42 INFO TaskSetManager: Finished task 19.0 in stage 81.0 (TID 99) in 17 ms on 172.18.0.4 (executor 0) (19/21)
[2025-05-06T20:49:43.384+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 101) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:43.384+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO TaskSetManager: Finished task 20.0 in stage 81.0 (TID 100) in 689 ms on 172.18.0.4 (executor 0) (20/21)
[2025-05-06T20:49:43.418+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 101) in 34 ms on 172.18.0.4 (executor 0) (21/21)
[2025-05-06T20:49:43.418+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-05-06T20:49:43.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: ShuffleMapStage 81 (rdd at GraphFrame.scala:188) finished in 2.775 s
[2025-05-06T20:49:43.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:43.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:43.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:43.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:43.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 3162157, minimum partition size: 1048576
[2025-05-06T20:49:43.436+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO CodeGenerator: Code generated in 5.510936 ms
[2025-05-06T20:49:43.439+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: Registering RDD 171 (rdd at GraphFrame.scala:188) as input to shuffle 23
[2025-05-06T20:49:43.439+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: Got map stage job 40 (rdd at GraphFrame.scala:188) with 2 output partitions
[2025-05-06T20:49:43.439+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: Final stage: ShuffleMapStage 85 (rdd at GraphFrame.scala:188)
[2025-05-06T20:49:43.439+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
[2025-05-06T20:49:43.439+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:49:43.440+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[171] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T20:49:43.451+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 50.0 KiB, free 425.8 MiB)
[2025-05-06T20:49:43.459+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 837932af135c:42719 in memory (size: 20.9 KiB, free: 434.3 MiB)
[2025-05-06T20:49:43.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 425.8 MiB)
[2025-05-06T20:49:43.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 837932af135c:42719 (size: 21.9 KiB, free: 434.2 MiB)
[2025-05-06T20:49:43.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:43.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[171] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-06T20:49:43.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks resource profile 0
[2025-05-06T20:49:43.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.18.0.4:45323 in memory (size: 20.9 KiB, free: 434.3 MiB)
[2025-05-06T20:49:43.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 102) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:43.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 837932af135c:42719 in memory (size: 14.4 KiB, free: 434.3 MiB)
[2025-05-06T20:49:43.466+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.18.0.4:45323 in memory (size: 14.4 KiB, free: 434.3 MiB)
[2025-05-06T20:49:43.468+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.18.0.4:45323 (size: 21.9 KiB, free: 434.3 MiB)
[2025-05-06T20:49:43.474+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.18.0.4:41314
[2025-05-06T20:49:44.061+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 103) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:44.061+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 102) in 601 ms on 172.18.0.4 (executor 0) (1/2)
[2025-05-06T20:49:44.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 103) in 462 ms on 172.18.0.4 (executor 0) (2/2)
[2025-05-06T20:49:44.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool
[2025-05-06T20:49:44.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: ShuffleMapStage 85 (rdd at GraphFrame.scala:188) finished in 1.083 s
[2025-05-06T20:49:44.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:44.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:44.524+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:44.524+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:44.549+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO CodeGenerator: Code generated in 12.298201 ms
[2025-05-06T20:49:44.555+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO CodeGenerator: Code generated in 4.616389 ms
[2025-05-06T20:49:44.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO CodeGenerator: Code generated in 5.651971 ms
[2025-05-06T20:49:44.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#519 - id.nullCount#518) > 0)
[2025-05-06T20:49:44.583+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Registering RDD 91 (rdd at GraphFrame.scala:187) as input to shuffle 14
[2025-05-06T20:49:44.583+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Registering RDD 180 (rdd at GraphFrame.scala:188) as input to shuffle 24
[2025-05-06T20:49:44.584+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Got map stage job 41 (rdd at GraphFrame.scala:188) with 10 output partitions
[2025-05-06T20:49:44.584+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Final stage: ShuffleMapStage 91 (rdd at GraphFrame.scala:188)
[2025-05-06T20:49:44.584+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89, ShuffleMapStage 90)
[2025-05-06T20:49:44.585+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 89)
[2025-05-06T20:49:44.586+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[91] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-06T20:49:44.587+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 19.7 KiB, free 425.9 MiB)
[2025-05-06T20:49:44.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 425.9 MiB)
[2025-05-06T20:49:44.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 837932af135c:42719 (size: 9.6 KiB, free: 434.2 MiB)
[2025-05-06T20:49:44.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:44.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[91] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:49:44.589+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
[2025-05-06T20:49:44.589+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 104) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:44.594+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.18.0.4:45323 (size: 9.6 KiB, free: 434.3 MiB)
[2025-05-06T20:49:44.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 104) in 24 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:49:44.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool
[2025-05-06T20:49:44.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: ShuffleMapStage 89 (rdd at GraphFrame.scala:187) finished in 0.027 s
[2025-05-06T20:49:44.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:44.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:44.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 91)
[2025-05-06T20:49:44.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:44.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[180] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T20:49:44.619+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 101.2 KiB, free 425.8 MiB)
[2025-05-06T20:49:44.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 837932af135c:42719 in memory (size: 21.9 KiB, free: 434.3 MiB)
[2025-05-06T20:49:44.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 40.3 KiB, free 425.8 MiB)
[2025-05-06T20:49:44.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 837932af135c:42719 (size: 40.3 KiB, free: 434.2 MiB)
[2025-05-06T20:49:44.628+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:44.628+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[180] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:49:44.628+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSchedulerImpl: Adding task set 91.0 with 10 tasks resource profile 0
[2025-05-06T20:49:44.629+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.18.0.4:45323 in memory (size: 21.9 KiB, free: 434.3 MiB)
[2025-05-06T20:49:44.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 105) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:44.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.18.0.4:45323 (size: 40.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:44.681+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.18.0.4:41314
[2025-05-06T20:49:44.700+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.18.0.4:41314
[2025-05-06T20:49:44.748+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Added rdd_95_0 in memory on 172.18.0.4:45323 (size: 1992.0 B, free: 434.3 MiB)
[2025-05-06T20:49:44.789+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.4:45323 (size: 19.9 KiB, free: 434.3 MiB)
[2025-05-06T20:49:44.891+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 106) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:44.892+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 105) in 263 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:49:44.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Added rdd_95_1 in memory on 172.18.0.4:45323 (size: 2.4 KiB, free: 434.2 MiB)
[2025-05-06T20:49:44.979+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 107) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:44.980+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 106) in 89 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:49:44.994+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:44 INFO BlockManagerInfo: Added rdd_95_2 in memory on 172.18.0.4:45323 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T20:49:45.053+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 108) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:45.053+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 107) in 74 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:49:45.070+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added rdd_95_3 in memory on 172.18.0.4:45323 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T20:49:45.129+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 109) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:45.129+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 108) in 76 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:49:45.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added rdd_95_4 in memory on 172.18.0.4:45323 (size: 2024.0 B, free: 434.2 MiB)
[2025-05-06T20:49:45.187+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 110) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:45.187+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 109) in 58 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:49:45.202+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added rdd_95_5 in memory on 172.18.0.4:45323 (size: 2040.0 B, free: 434.2 MiB)
[2025-05-06T20:49:45.241+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 111) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:45.241+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 110) in 55 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:49:45.255+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added rdd_95_6 in memory on 172.18.0.4:45323 (size: 2.1 KiB, free: 434.2 MiB)
[2025-05-06T20:49:45.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 112) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:45.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 111) in 56 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:49:45.312+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added rdd_95_7 in memory on 172.18.0.4:45323 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T20:49:45.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Starting task 8.0 in stage 91.0 (TID 113) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:45.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 112) in 56 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:49:45.364+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added rdd_95_8 in memory on 172.18.0.4:45323 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T20:49:45.403+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Starting task 9.0 in stage 91.0 (TID 114) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:45.404+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Finished task 8.0 in stage 91.0 (TID 113) in 50 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:49:45.415+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added rdd_95_9 in memory on 172.18.0.4:45323 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T20:49:45.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Finished task 9.0 in stage 91.0 (TID 114) in 49 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:49:45.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-05-06T20:49:45.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: ShuffleMapStage 91 (rdd at GraphFrame.scala:188) finished in 0.837 s
[2025-05-06T20:49:45.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:45.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:45.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:49:45.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:45.467+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO CodeGenerator: Code generated in 7.180806 ms
[2025-05-06T20:49:45.475+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO CodeGenerator: Code generated in 6.215221 ms
[2025-05-06T20:49:45.492+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO CodeGenerator: Code generated in 8.879182 ms
[2025-05-06T20:49:45.492+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#529 - id.nullCount#528) > 0)
[2025-05-06T20:49:45.565+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:49:45.566+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Registering RDD 103 (map at GraphFrame.scala:187) as input to shuffle 26
[2025-05-06T20:49:45.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Registering RDD 197 (mapPartitions at VertexRDD.scala:356) as input to shuffle 29
[2025-05-06T20:49:45.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Registering RDD 219 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 25
[2025-05-06T20:49:45.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Registering RDD 223 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 27
[2025-05-06T20:49:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Registering RDD 227 (mapPartitions at GraphImpl.scala:208) as input to shuffle 28
[2025-05-06T20:49:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Got job 42 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:49:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Final stage: ResultStage 103 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:49:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 99, ShuffleMapStage 93)
[2025-05-06T20:49:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 102, ShuffleMapStage 99, ShuffleMapStage 93)
[2025-05-06T20:49:45.569+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[103] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-06T20:49:45.580+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 67.6 KiB, free 425.7 MiB)
[2025-05-06T20:49:45.587+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 425.8 MiB)
[2025-05-06T20:49:45.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 837932af135c:42719 in memory (size: 40.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:45.589+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 837932af135c:42719 (size: 27.6 KiB, free: 434.2 MiB)
[2025-05-06T20:49:45.589+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:45.589+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[103] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:49:45.589+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSchedulerImpl: Adding task set 93.0 with 10 tasks resource profile 0
[2025-05-06T20:49:45.590+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Submitting ShuffleMapStage 99 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[197] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-06T20:49:45.590+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 115) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:45.592+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.18.0.4:45323 in memory (size: 40.3 KiB, free: 434.3 MiB)
[2025-05-06T20:49:45.597+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 837932af135c:42719 in memory (size: 9.6 KiB, free: 434.2 MiB)
[2025-05-06T20:49:45.598+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.18.0.4:45323 in memory (size: 9.6 KiB, free: 434.3 MiB)
[2025-05-06T20:49:45.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.18.0.4:45323 (size: 27.6 KiB, free: 434.3 MiB)
[2025-05-06T20:49:45.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 114.9 KiB, free 425.8 MiB)
[2025-05-06T20:49:45.617+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 45.9 KiB, free 425.7 MiB)
[2025-05-06T20:49:45.617+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 837932af135c:42719 (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T20:49:45.619+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:45.619+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 99 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[197] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:49:45.620+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO TaskSchedulerImpl: Adding task set 99.0 with 10 tasks resource profile 0
[2025-05-06T20:49:45.717+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:45 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.18.0.4:45323 (size: 27.1 KiB, free: 434.2 MiB)
[2025-05-06T20:49:46.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 116) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.454+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 115) in 865 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:49:46.468+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 117) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.469+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 116) in 15 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:49:46.480+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 118) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.481+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 117) in 13 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:49:46.494+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 4.0 in stage 93.0 (TID 119) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.496+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 118) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:49:46.518+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 5.0 in stage 93.0 (TID 120) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.519+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 4.0 in stage 93.0 (TID 119) in 20 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:49:46.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 6.0 in stage 93.0 (TID 121) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 5.0 in stage 93.0 (TID 120) in 21 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:49:46.549+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 7.0 in stage 93.0 (TID 122) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.550+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 6.0 in stage 93.0 (TID 121) in 18 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:49:46.566+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 8.0 in stage 93.0 (TID 123) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.566+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 7.0 in stage 93.0 (TID 122) in 18 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:49:46.577+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 9.0 in stage 93.0 (TID 124) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.577+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 8.0 in stage 93.0 (TID 123) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:49:46.590+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 125) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:46.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSetManager: Finished task 9.0 in stage 93.0 (TID 124) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:49:46.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-05-06T20:49:46.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO DAGScheduler: ShuffleMapStage 93 (map at GraphFrame.scala:187) finished in 1.021 s
[2025-05-06T20:49:46.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:46.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO DAGScheduler: running: Set(ShuffleMapStage 99)
[2025-05-06T20:49:46.592+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103, ShuffleMapStage 100, ShuffleMapStage 101)
[2025-05-06T20:49:46.592+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:46.600+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.18.0.4:45323 (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T20:49:46.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.18.0.4:41314
[2025-05-06T20:49:47.271+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:47 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 126) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:47.271+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:47 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 125) in 680 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:49:47.653+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:47 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 127) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:47.654+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:47 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 126) in 384 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:49:47.826+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:47 INFO TaskSetManager: Starting task 3.0 in stage 99.0 (TID 128) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:47.827+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:47 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 127) in 174 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:49:47.969+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:47 INFO TaskSetManager: Starting task 4.0 in stage 99.0 (TID 129) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:47.970+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:47 INFO TaskSetManager: Finished task 3.0 in stage 99.0 (TID 128) in 143 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:49:48.108+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 5.0 in stage 99.0 (TID 130) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.108+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 4.0 in stage 99.0 (TID 129) in 139 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:49:48.252+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 6.0 in stage 99.0 (TID 131) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 5.0 in stage 99.0 (TID 130) in 145 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:49:48.377+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 7.0 in stage 99.0 (TID 132) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.377+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 6.0 in stage 99.0 (TID 131) in 126 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:49:48.504+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 8.0 in stage 99.0 (TID 133) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.505+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 7.0 in stage 99.0 (TID 132) in 128 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:49:48.629+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 9.0 in stage 99.0 (TID 134) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.629+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 8.0 in stage 99.0 (TID 133) in 126 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:49:48.744+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 9.0 in stage 99.0 (TID 134) in 116 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:49:48.744+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool
[2025-05-06T20:49:48.744+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO DAGScheduler: ShuffleMapStage 99 (mapPartitions at VertexRDD.scala:356) finished in 3.153 s
[2025-05-06T20:49:48.744+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:48.745+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:48.745+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103, ShuffleMapStage 100, ShuffleMapStage 101)
[2025-05-06T20:49:48.745+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:48.745+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO DAGScheduler: Submitting ShuffleMapStage 100 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[219] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:49:48.753+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 10.3 KiB, free 425.7 MiB)
[2025-05-06T20:49:48.764+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 425.7 MiB)
[2025-05-06T20:49:48.765+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 837932af135c:42719 (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.766+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:48.767+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 837932af135c:42719 in memory (size: 27.6 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.767+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 100 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[219] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:49:48.767+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSchedulerImpl: Adding task set 100.0 with 10 tasks resource profile 0
[2025-05-06T20:49:48.767+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO DAGScheduler: Submitting ShuffleMapStage 101 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[223] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:49:48.768+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 135) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.770+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 9.9 KiB, free 425.8 MiB)
[2025-05-06T20:49:48.771+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 425.8 MiB)
[2025-05-06T20:49:48.771+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 837932af135c:42719 (size: 4.9 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.771+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.18.0.4:45323 in memory (size: 27.6 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.771+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:48.772+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 101 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[223] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:49:48.772+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSchedulerImpl: Adding task set 101.0 with 10 tasks resource profile 0
[2025-05-06T20:49:48.777+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.18.0.4:45323 (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.825+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.18.0.4:41314
[2025-05-06T20:49:48.828+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.18.0.4:41314
[2025-05-06T20:49:48.840+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 837932af135c:42719 in memory (size: 45.9 KiB, free: 434.3 MiB)
[2025-05-06T20:49:48.842+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.18.0.4:45323 in memory (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_200_0 in memory on 172.18.0.4:45323 (size: 27.8 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.883+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_205_0 in memory on 172.18.0.4:45323 (size: 13.9 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.886+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_211_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.892+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_215_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.908+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 136) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.909+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 135) in 142 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:49:48.927+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_200_1 in memory on 172.18.0.4:45323 (size: 27.4 KiB, free: 434.2 MiB)
[2025-05-06T20:49:48.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_205_1 in memory on 172.18.0.4:45323 (size: 13.8 KiB, free: 434.1 MiB)
[2025-05-06T20:49:48.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_211_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 434.1 MiB)
[2025-05-06T20:49:48.933+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_215_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 434.1 MiB)
[2025-05-06T20:49:48.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 2.0 in stage 100.0 (TID 137) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.938+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 136) in 29 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:49:48.950+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_200_2 in memory on 172.18.0.4:45323 (size: 26.8 KiB, free: 434.1 MiB)
[2025-05-06T20:49:48.952+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_205_2 in memory on 172.18.0.4:45323 (size: 13.6 KiB, free: 434.1 MiB)
[2025-05-06T20:49:48.954+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_211_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 434.1 MiB)
[2025-05-06T20:49:48.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_215_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 434.0 MiB)
[2025-05-06T20:49:48.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 3.0 in stage 100.0 (TID 138) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 2.0 in stage 100.0 (TID 137) in 24 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:49:48.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_200_3 in memory on 172.18.0.4:45323 (size: 26.7 KiB, free: 434.0 MiB)
[2025-05-06T20:49:48.979+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_205_3 in memory on 172.18.0.4:45323 (size: 13.6 KiB, free: 434.0 MiB)
[2025-05-06T20:49:48.982+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_211_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 434.0 MiB)
[2025-05-06T20:49:48.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO BlockManagerInfo: Added rdd_215_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 434.0 MiB)
[2025-05-06T20:49:48.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Starting task 4.0 in stage 100.0 (TID 139) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:48.991+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:48 INFO TaskSetManager: Finished task 3.0 in stage 100.0 (TID 138) in 31 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:49:49.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_200_4 in memory on 172.18.0.4:45323 (size: 26.9 KiB, free: 433.9 MiB)
[2025-05-06T20:49:49.005+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_205_4 in memory on 172.18.0.4:45323 (size: 13.7 KiB, free: 433.9 MiB)
[2025-05-06T20:49:49.008+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_211_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 433.9 MiB)
[2025-05-06T20:49:49.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_215_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 433.9 MiB)
[2025-05-06T20:49:49.015+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 5.0 in stage 100.0 (TID 140) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.016+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 4.0 in stage 100.0 (TID 139) in 25 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:49:49.032+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_200_5 in memory on 172.18.0.4:45323 (size: 26.9 KiB, free: 433.9 MiB)
[2025-05-06T20:49:49.034+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_205_5 in memory on 172.18.0.4:45323 (size: 13.7 KiB, free: 433.9 MiB)
[2025-05-06T20:49:49.036+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_211_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 433.9 MiB)
[2025-05-06T20:49:49.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_215_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 433.8 MiB)
[2025-05-06T20:49:49.043+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 6.0 in stage 100.0 (TID 141) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.043+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 5.0 in stage 100.0 (TID 140) in 28 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:49:49.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_200_6 in memory on 172.18.0.4:45323 (size: 26.8 KiB, free: 433.8 MiB)
[2025-05-06T20:49:49.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_205_6 in memory on 172.18.0.4:45323 (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-06T20:49:49.059+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_211_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 433.8 MiB)
[2025-05-06T20:49:49.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_215_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 433.8 MiB)
[2025-05-06T20:49:49.067+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 7.0 in stage 100.0 (TID 142) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.067+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 6.0 in stage 100.0 (TID 141) in 25 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:49:49.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_200_7 in memory on 172.18.0.4:45323 (size: 26.7 KiB, free: 433.7 MiB)
[2025-05-06T20:49:49.086+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_205_7 in memory on 172.18.0.4:45323 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-06T20:49:49.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_211_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 433.7 MiB)
[2025-05-06T20:49:49.091+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_215_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 433.7 MiB)
[2025-05-06T20:49:49.097+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 8.0 in stage 100.0 (TID 143) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.097+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 7.0 in stage 100.0 (TID 142) in 31 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:49:49.112+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_200_8 in memory on 172.18.0.4:45323 (size: 26.4 KiB, free: 433.7 MiB)
[2025-05-06T20:49:49.114+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_205_8 in memory on 172.18.0.4:45323 (size: 13.3 KiB, free: 433.7 MiB)
[2025-05-06T20:49:49.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_211_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 433.6 MiB)
[2025-05-06T20:49:49.119+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_215_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 433.6 MiB)
[2025-05-06T20:49:49.124+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 9.0 in stage 100.0 (TID 144) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.124+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 8.0 in stage 100.0 (TID 143) in 28 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:49:49.135+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_200_9 in memory on 172.18.0.4:45323 (size: 25.7 KiB, free: 433.6 MiB)
[2025-05-06T20:49:49.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_205_9 in memory on 172.18.0.4:45323 (size: 13.0 KiB, free: 433.6 MiB)
[2025-05-06T20:49:49.139+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_211_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 433.6 MiB)
[2025-05-06T20:49:49.142+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_215_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 433.6 MiB)
[2025-05-06T20:49:49.147+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 145) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.149+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 9.0 in stage 100.0 (TID 144) in 24 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:49:49.150+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-05-06T20:49:49.151+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: ShuffleMapStage 100 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.402 s
[2025-05-06T20:49:49.151+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:49.151+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: running: Set(ShuffleMapStage 101)
[2025-05-06T20:49:49.152+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103)
[2025-05-06T20:49:49.152+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:49.157+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.4:45323 (size: 4.9 KiB, free: 433.6 MiB)
[2025-05-06T20:49:49.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 146) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 145) in 18 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:49:49.173+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 147) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.174+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 146) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:49:49.183+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 148) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.184+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 147) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:49:49.191+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 4.0 in stage 101.0 (TID 149) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 148) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:49:49.202+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 5.0 in stage 101.0 (TID 150) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.202+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 4.0 in stage 101.0 (TID 149) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:49:49.212+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 6.0 in stage 101.0 (TID 151) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.213+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 5.0 in stage 101.0 (TID 150) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:49:49.220+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 7.0 in stage 101.0 (TID 152) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.221+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 6.0 in stage 101.0 (TID 151) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:49:49.227+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 8.0 in stage 101.0 (TID 153) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.227+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 7.0 in stage 101.0 (TID 152) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:49:49.234+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 9.0 in stage 101.0 (TID 154) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.235+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 8.0 in stage 101.0 (TID 153) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:49:49.243+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Finished task 9.0 in stage 101.0 (TID 154) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:49:49.243+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool
[2025-05-06T20:49:49.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: ShuffleMapStage 101 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.474 s
[2025-05-06T20:49:49.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:49:49.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: running: Set()
[2025-05-06T20:49:49.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103)
[2025-05-06T20:49:49.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: failed: Set()
[2025-05-06T20:49:49.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: Submitting ShuffleMapStage 102 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[227] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:49:49.252+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 119.3 KiB, free 425.8 MiB)
[2025-05-06T20:49:49.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 47.2 KiB, free 425.8 MiB)
[2025-05-06T20:49:49.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 837932af135c:42719 (size: 47.2 KiB, free: 434.2 MiB)
[2025-05-06T20:49:49.254+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:49:49.254+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 102 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[227] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:49:49.254+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSchedulerImpl: Adding task set 102.0 with 10 tasks resource profile 0
[2025-05-06T20:49:49.255+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 155) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:49.265+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.18.0.4:45323 (size: 47.2 KiB, free: 433.5 MiB)
[2025-05-06T20:49:49.285+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.18.0.4:41314
[2025-05-06T20:49:49.380+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_203_0 in memory on 172.18.0.4:45323 (size: 10.7 MiB, free: 422.8 MiB)
[2025-05-06T20:49:49.385+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_207_0 in memory on 172.18.0.4:45323 (size: 10.7 MiB, free: 412.1 MiB)
[2025-05-06T20:49:49.391+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_213_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 411.6 MiB)
[2025-05-06T20:49:49.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.18.0.4:41314
[2025-05-06T20:49:49.396+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO BlockManagerInfo: Added rdd_221_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 411.1 MiB)
[2025-05-06T20:49:49.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.18.0.4:41314
[2025-05-06T20:49:58.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:58 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 156) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:49:58.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:58 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 155) in 8834 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:49:58.225+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:58 INFO BlockManagerInfo: Added rdd_203_1 in memory on 172.18.0.4:45323 (size: 13.9 MiB, free: 397.2 MiB)
[2025-05-06T20:49:58.228+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:58 INFO BlockManagerInfo: Added rdd_207_1 in memory on 172.18.0.4:45323 (size: 13.9 MiB, free: 383.3 MiB)
[2025-05-06T20:49:58.233+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:58 INFO BlockManagerInfo: Added rdd_213_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 382.7 MiB)
[2025-05-06T20:49:58.236+0000] {spark_submit.py:571} INFO - 25/05/06 20:49:58 INFO BlockManagerInfo: Added rdd_221_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 382.1 MiB)
[2025-05-06T20:50:10.597+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:10 INFO TaskSetManager: Starting task 2.0 in stage 102.0 (TID 157) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:50:10.598+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:10 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 156) in 12510 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:50:10.719+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:10 INFO BlockManagerInfo: Added rdd_203_2 in memory on 172.18.0.4:45323 (size: 12.5 MiB, free: 369.6 MiB)
[2025-05-06T20:50:10.722+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:10 INFO BlockManagerInfo: Added rdd_207_2 in memory on 172.18.0.4:45323 (size: 12.5 MiB, free: 357.2 MiB)
[2025-05-06T20:50:10.724+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:10 INFO BlockManagerInfo: Added rdd_213_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 356.6 MiB)
[2025-05-06T20:50:10.727+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:10 INFO BlockManagerInfo: Added rdd_221_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 356.1 MiB)
[2025-05-06T20:50:21.537+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:21 INFO TaskSetManager: Starting task 3.0 in stage 102.0 (TID 158) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:50:21.537+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:21 INFO TaskSetManager: Finished task 2.0 in stage 102.0 (TID 157) in 10941 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:50:21.628+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:21 INFO BlockManagerInfo: Added rdd_203_3 in memory on 172.18.0.4:45323 (size: 11.7 MiB, free: 344.3 MiB)
[2025-05-06T20:50:21.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:21 INFO BlockManagerInfo: Added rdd_207_3 in memory on 172.18.0.4:45323 (size: 11.7 MiB, free: 332.6 MiB)
[2025-05-06T20:50:21.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:21 INFO BlockManagerInfo: Added rdd_213_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 332.0 MiB)
[2025-05-06T20:50:21.643+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:21 INFO BlockManagerInfo: Added rdd_221_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 331.5 MiB)
[2025-05-06T20:50:31.712+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:31 INFO TaskSetManager: Starting task 4.0 in stage 102.0 (TID 159) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:50:31.712+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:31 INFO TaskSetManager: Finished task 3.0 in stage 102.0 (TID 158) in 10176 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:50:31.777+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:31 INFO BlockManagerInfo: Added rdd_203_4 in memory on 172.18.0.4:45323 (size: 9.6 MiB, free: 321.9 MiB)
[2025-05-06T20:50:31.779+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:31 INFO BlockManagerInfo: Added rdd_207_4 in memory on 172.18.0.4:45323 (size: 9.6 MiB, free: 312.2 MiB)
[2025-05-06T20:50:31.782+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:31 INFO BlockManagerInfo: Added rdd_213_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 311.8 MiB)
[2025-05-06T20:50:31.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:31 INFO BlockManagerInfo: Added rdd_221_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 311.4 MiB)
[2025-05-06T20:50:38.741+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:38 INFO TaskSetManager: Starting task 5.0 in stage 102.0 (TID 160) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:50:38.741+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:38 INFO TaskSetManager: Finished task 4.0 in stage 102.0 (TID 159) in 7029 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:50:38.832+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:38 INFO BlockManagerInfo: Added rdd_203_5 in memory on 172.18.0.4:45323 (size: 11.5 MiB, free: 299.8 MiB)
[2025-05-06T20:50:38.835+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:38 INFO BlockManagerInfo: Added rdd_207_5 in memory on 172.18.0.4:45323 (size: 11.5 MiB, free: 288.3 MiB)
[2025-05-06T20:50:38.838+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:38 INFO BlockManagerInfo: Added rdd_213_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 287.8 MiB)
[2025-05-06T20:50:38.844+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:38 INFO BlockManagerInfo: Added rdd_221_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 287.3 MiB)
[2025-05-06T20:50:48.286+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:48 INFO TaskSetManager: Starting task 6.0 in stage 102.0 (TID 161) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:50:48.287+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:48 INFO TaskSetManager: Finished task 5.0 in stage 102.0 (TID 160) in 9547 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:50:48.358+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:48 INFO BlockManagerInfo: Added rdd_203_6 in memory on 172.18.0.4:45323 (size: 11.6 MiB, free: 275.6 MiB)
[2025-05-06T20:50:48.360+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:48 INFO BlockManagerInfo: Added rdd_207_6 in memory on 172.18.0.4:45323 (size: 11.6 MiB, free: 264.0 MiB)
[2025-05-06T20:50:48.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:48 INFO BlockManagerInfo: Added rdd_213_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 263.5 MiB)
[2025-05-06T20:50:48.364+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:48 INFO BlockManagerInfo: Added rdd_221_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 263.0 MiB)
[2025-05-06T20:50:57.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:57 INFO TaskSetManager: Starting task 7.0 in stage 102.0 (TID 162) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:50:57.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:57 INFO TaskSetManager: Finished task 6.0 in stage 102.0 (TID 161) in 9313 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:50:57.682+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:57 INFO BlockManagerInfo: Added rdd_203_7 in memory on 172.18.0.4:45323 (size: 13.2 MiB, free: 249.7 MiB)
[2025-05-06T20:50:57.684+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:57 INFO BlockManagerInfo: Added rdd_207_7 in memory on 172.18.0.4:45323 (size: 13.2 MiB, free: 236.5 MiB)
[2025-05-06T20:50:57.687+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:57 INFO BlockManagerInfo: Added rdd_213_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 235.9 MiB)
[2025-05-06T20:50:57.690+0000] {spark_submit.py:571} INFO - 25/05/06 20:50:57 INFO BlockManagerInfo: Added rdd_221_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 235.4 MiB)
[2025-05-06T20:51:09.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:09 INFO TaskSetManager: Starting task 8.0 in stage 102.0 (TID 163) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:09.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:09 INFO TaskSetManager: Finished task 7.0 in stage 102.0 (TID 162) in 12291 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:09.964+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:09 INFO BlockManagerInfo: Added rdd_203_8 in memory on 172.18.0.4:45323 (size: 12.1 MiB, free: 223.3 MiB)
[2025-05-06T20:51:09.968+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:09 INFO BlockManagerInfo: Added rdd_207_8 in memory on 172.18.0.4:45323 (size: 12.1 MiB, free: 211.2 MiB)
[2025-05-06T20:51:09.971+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:09 INFO BlockManagerInfo: Added rdd_213_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 210.6 MiB)
[2025-05-06T20:51:09.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:09 INFO BlockManagerInfo: Added rdd_221_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 210.1 MiB)
[2025-05-06T20:51:19.915+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:19 INFO TaskSetManager: Starting task 9.0 in stage 102.0 (TID 164) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:19.915+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:19 INFO TaskSetManager: Finished task 8.0 in stage 102.0 (TID 163) in 10026 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:20.009+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:20 INFO BlockManagerInfo: Added rdd_203_9 in memory on 172.18.0.4:45323 (size: 13.7 MiB, free: 196.4 MiB)
[2025-05-06T20:51:20.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:20 INFO BlockManagerInfo: Added rdd_207_9 in memory on 172.18.0.4:45323 (size: 13.7 MiB, free: 182.7 MiB)
[2025-05-06T20:51:20.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:20 INFO BlockManagerInfo: Added rdd_213_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 182.1 MiB)
[2025-05-06T20:51:20.016+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:20 INFO BlockManagerInfo: Added rdd_221_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 181.5 MiB)
[2025-05-06T20:51:32.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO TaskSetManager: Finished task 9.0 in stage 102.0 (TID 164) in 12570 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:32.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool
[2025-05-06T20:51:32.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO DAGScheduler: ShuffleMapStage 102 (mapPartitions at GraphImpl.scala:208) finished in 103.238 s
[2025-05-06T20:51:32.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:32.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:32.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO DAGScheduler: waiting: Set(ResultStage 103)
[2025-05-06T20:51:32.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:32.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[231] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:32.487+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 11.2 KiB, free 425.8 MiB)
[2025-05-06T20:51:32.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:32.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 837932af135c:42719 (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:32.501+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:32.502+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 103 (MapPartitionsRDD[231] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:32.502+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO TaskSchedulerImpl: Adding task set 103.0 with 10 tasks resource profile 0
[2025-05-06T20:51:32.502+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 837932af135c:42719 in memory (size: 4.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:32.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 165) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:32.504+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.4:45323 in memory (size: 4.9 KiB, free: 181.5 MiB)
[2025-05-06T20:51:32.508+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 837932af135c:42719 in memory (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:32.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.18.0.4:45323 in memory (size: 5.0 KiB, free: 181.5 MiB)
[2025-05-06T20:51:32.511+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.18.0.4:45323 (size: 5.3 KiB, free: 181.5 MiB)
[2025-05-06T20:51:32.522+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.18.0.4:41314
[2025-05-06T20:51:33.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:33 INFO BlockManagerInfo: Added rdd_229_0 in memory on 172.18.0.4:45323 (size: 3.6 MiB, free: 177.9 MiB)
[2025-05-06T20:51:33.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:33 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 166) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:33.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:33 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 165) in 555 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:33.495+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:33 INFO BlockManagerInfo: Added rdd_229_1 in memory on 172.18.0.4:45323 (size: 3.7 MiB, free: 174.2 MiB)
[2025-05-06T20:51:33.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:33 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 167) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:33.501+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:33 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 166) in 445 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:34.163+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:34 INFO BlockManagerInfo: Added rdd_229_2 in memory on 172.18.0.4:45323 (size: 3.4 MiB, free: 170.7 MiB)
[2025-05-06T20:51:34.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:34 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 168) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:34.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:34 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 167) in 667 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:34.576+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:34 INFO BlockManagerInfo: Added rdd_229_3 in memory on 172.18.0.4:45323 (size: 3.4 MiB, free: 167.3 MiB)
[2025-05-06T20:51:34.577+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:34 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 169) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:34.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:34 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 168) in 412 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:34.971+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:34 INFO BlockManagerInfo: Added rdd_229_4 in memory on 172.18.0.4:45323 (size: 3.5 MiB, free: 163.8 MiB)
[2025-05-06T20:51:34.972+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:34 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 170) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:34.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:34 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 169) in 396 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:35.362+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:35 INFO BlockManagerInfo: Added rdd_229_5 in memory on 172.18.0.4:45323 (size: 3.6 MiB, free: 160.2 MiB)
[2025-05-06T20:51:35.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:35 INFO TaskSetManager: Starting task 6.0 in stage 103.0 (TID 171) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:35.366+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:35 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 170) in 393 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:35.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:35 INFO BlockManagerInfo: Added rdd_229_6 in memory on 172.18.0.4:45323 (size: 3.4 MiB, free: 156.8 MiB)
[2025-05-06T20:51:35.738+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:35 INFO TaskSetManager: Starting task 7.0 in stage 103.0 (TID 172) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:35.738+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:35 INFO TaskSetManager: Finished task 6.0 in stage 103.0 (TID 171) in 373 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:36.135+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO BlockManagerInfo: Added rdd_229_7 in memory on 172.18.0.4:45323 (size: 3.6 MiB, free: 153.2 MiB)
[2025-05-06T20:51:36.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO TaskSetManager: Starting task 8.0 in stage 103.0 (TID 173) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:36.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO TaskSetManager: Finished task 7.0 in stage 103.0 (TID 172) in 399 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:36.579+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO BlockManagerInfo: Added rdd_229_8 in memory on 172.18.0.4:45323 (size: 3.5 MiB, free: 149.7 MiB)
[2025-05-06T20:51:36.580+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO TaskSetManager: Starting task 9.0 in stage 103.0 (TID 174) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:36.580+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO TaskSetManager: Finished task 8.0 in stage 103.0 (TID 173) in 443 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:36.972+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO BlockManagerInfo: Added rdd_229_9 in memory on 172.18.0.4:45323 (size: 3.3 MiB, free: 146.3 MiB)
[2025-05-06T20:51:36.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO TaskSetManager: Finished task 9.0 in stage 103.0 (TID 174) in 394 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:36.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-05-06T20:51:36.975+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: ResultStage 103 (fold at VertexRDDImpl.scala:90) finished in 4.488 s
[2025-05-06T20:51:36.975+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:36.975+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
[2025-05-06T20:51:36.975+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Job 42 finished: fold at VertexRDDImpl.scala:90, took 111.409604 s
[2025-05-06T20:51:36.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:36.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Registering RDD 236 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 30
[2025-05-06T20:51:36.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Registering RDD 240 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 31
[2025-05-06T20:51:36.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Registering RDD 244 (mapPartitions at GraphImpl.scala:208) as input to shuffle 32
[2025-05-06T20:51:36.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Got job 43 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:36.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Final stage: ResultStage 118 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:36.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 114, ShuffleMapStage 111, ShuffleMapStage 105)
[2025-05-06T20:51:36.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 117)
[2025-05-06T20:51:36.999+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:36 INFO DAGScheduler: Submitting ShuffleMapStage 115 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[236] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:37.000+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 11.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:37.001+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:37.001+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 837932af135c:42719 (size: 5.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:37.002+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:37.002+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 115 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[236] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:37.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSchedulerImpl: Adding task set 115.0 with 10 tasks resource profile 0
[2025-05-06T20:51:37.004+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: Submitting ShuffleMapStage 116 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[240] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:37.004+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 175) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.006+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 10.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:37.019+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:37.020+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 837932af135c:42719 (size: 5.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:37.020+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 837932af135c:42719 in memory (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:37.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:37.024+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.18.0.4:45323 in memory (size: 5.3 KiB, free: 146.3 MiB)
[2025-05-06T20:51:37.025+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 116 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[240] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:37.025+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSchedulerImpl: Adding task set 116.0 with 10 tasks resource profile 0
[2025-05-06T20:51:37.027+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.18.0.4:45323 (size: 5.4 KiB, free: 146.3 MiB)
[2025-05-06T20:51:37.029+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 837932af135c:42719 in memory (size: 47.2 KiB, free: 434.3 MiB)
[2025-05-06T20:51:37.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.18.0.4:45323 in memory (size: 47.2 KiB, free: 146.4 MiB)
[2025-05-06T20:51:37.056+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 146.4 MiB)
[2025-05-06T20:51:37.073+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 176) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.073+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 175) in 69 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:37.082+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 146.4 MiB)
[2025-05-06T20:51:37.091+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 2.0 in stage 115.0 (TID 177) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.092+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 176) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:37.098+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 146.3 MiB)
[2025-05-06T20:51:37.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 3.0 in stage 115.0 (TID 178) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 2.0 in stage 115.0 (TID 177) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:37.112+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 146.3 MiB)
[2025-05-06T20:51:37.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 4.0 in stage 115.0 (TID 179) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 3.0 in stage 115.0 (TID 178) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:37.131+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 146.3 MiB)
[2025-05-06T20:51:37.136+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 5.0 in stage 115.0 (TID 180) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 4.0 in stage 115.0 (TID 179) in 21 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:37.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 146.3 MiB)
[2025-05-06T20:51:37.151+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 6.0 in stage 115.0 (TID 181) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.151+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 5.0 in stage 115.0 (TID 180) in 16 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:37.163+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 146.3 MiB)
[2025-05-06T20:51:37.171+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 7.0 in stage 115.0 (TID 182) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.174+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 6.0 in stage 115.0 (TID 181) in 22 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:37.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 146.3 MiB)
[2025-05-06T20:51:37.188+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 8.0 in stage 115.0 (TID 183) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.188+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 7.0 in stage 115.0 (TID 182) in 17 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:37.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 146.3 MiB)
[2025-05-06T20:51:37.205+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 9.0 in stage 115.0 (TID 184) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.205+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 8.0 in stage 115.0 (TID 183) in 18 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:37.214+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_232_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 146.2 MiB)
[2025-05-06T20:51:37.219+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 185) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.220+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 9.0 in stage 115.0 (TID 184) in 15 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:37.220+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: ShuffleMapStage 115 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.221 s
[2025-05-06T20:51:37.220+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:37.221+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: running: Set(ShuffleMapStage 116)
[2025-05-06T20:51:37.221+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 117, ResultStage 118)
[2025-05-06T20:51:37.221+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:37.221+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool
[2025-05-06T20:51:37.227+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.18.0.4:45323 (size: 5.1 KiB, free: 146.2 MiB)
[2025-05-06T20:51:37.247+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 1.0 in stage 116.0 (TID 186) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.248+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 185) in 29 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:37.278+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 2.0 in stage 116.0 (TID 187) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.278+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 1.0 in stage 116.0 (TID 186) in 31 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:37.307+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 3.0 in stage 116.0 (TID 188) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.310+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 2.0 in stage 116.0 (TID 187) in 30 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:37.343+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 4.0 in stage 116.0 (TID 189) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.344+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 3.0 in stage 116.0 (TID 188) in 36 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:37.400+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 5.0 in stage 116.0 (TID 190) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.401+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 4.0 in stage 116.0 (TID 189) in 59 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:37.450+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 6.0 in stage 116.0 (TID 191) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 5.0 in stage 116.0 (TID 190) in 52 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:37.504+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 7.0 in stage 116.0 (TID 192) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.504+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 6.0 in stage 116.0 (TID 191) in 52 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:37.579+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 8.0 in stage 116.0 (TID 193) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.579+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 7.0 in stage 116.0 (TID 192) in 79 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:37.616+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 9.0 in stage 116.0 (TID 194) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.618+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 8.0 in stage 116.0 (TID 193) in 39 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:37.646+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Finished task 9.0 in stage 116.0 (TID 194) in 30 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:37.647+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool
[2025-05-06T20:51:37.647+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: ShuffleMapStage 116 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.643 s
[2025-05-06T20:51:37.647+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:37.647+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:37.647+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 117, ResultStage 118)
[2025-05-06T20:51:37.648+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:37.648+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: Submitting ShuffleMapStage 117 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[244] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:37.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 120.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:37.654+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:37.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 837932af135c:42719 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:37.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:37.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 117 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[244] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:37.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSchedulerImpl: Adding task set 117.0 with 10 tasks resource profile 0
[2025-05-06T20:51:37.656+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 195) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:37.665+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.18.0.4:45323 (size: 47.7 KiB, free: 146.2 MiB)
[2025-05-06T20:51:37.674+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.18.0.4:41314
[2025-05-06T20:51:37.677+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.18.0.4:41314
[2025-05-06T20:51:37.691+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Added rdd_238_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 145.7 MiB)
[2025-05-06T20:51:37.693+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.18.0.4:41314
[2025-05-06T20:51:37.707+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 837932af135c:42719 in memory (size: 5.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:37.709+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.18.0.4:45323 in memory (size: 5.4 KiB, free: 145.7 MiB)
[2025-05-06T20:51:37.719+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 837932af135c:42719 in memory (size: 5.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:37.719+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:37 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.18.0.4:45323 in memory (size: 5.1 KiB, free: 145.7 MiB)
[2025-05-06T20:51:38.290+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:38 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 196) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:38.291+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:38 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 195) in 634 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:38.301+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:38 INFO BlockManagerInfo: Added rdd_238_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 145.1 MiB)
[2025-05-06T20:51:38.725+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:38 INFO TaskSetManager: Starting task 2.0 in stage 117.0 (TID 197) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:38.726+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:38 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 196) in 436 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:38.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:38 INFO BlockManagerInfo: Added rdd_238_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 144.6 MiB)
[2025-05-06T20:51:39.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO TaskSetManager: Starting task 3.0 in stage 117.0 (TID 198) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:39.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO TaskSetManager: Finished task 2.0 in stage 117.0 (TID 197) in 337 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:39.072+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO BlockManagerInfo: Added rdd_238_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 144.0 MiB)
[2025-05-06T20:51:39.369+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO TaskSetManager: Starting task 4.0 in stage 117.0 (TID 199) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:39.369+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO TaskSetManager: Finished task 3.0 in stage 117.0 (TID 198) in 307 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:39.379+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO BlockManagerInfo: Added rdd_238_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 143.6 MiB)
[2025-05-06T20:51:39.620+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO TaskSetManager: Starting task 5.0 in stage 117.0 (TID 200) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:39.621+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO TaskSetManager: Finished task 4.0 in stage 117.0 (TID 199) in 252 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:39.629+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO BlockManagerInfo: Added rdd_238_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 143.1 MiB)
[2025-05-06T20:51:39.920+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO TaskSetManager: Starting task 6.0 in stage 117.0 (TID 201) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:39.920+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO TaskSetManager: Finished task 5.0 in stage 117.0 (TID 200) in 300 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:39.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:39 INFO BlockManagerInfo: Added rdd_238_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 142.6 MiB)
[2025-05-06T20:51:40.227+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:40 INFO TaskSetManager: Starting task 7.0 in stage 117.0 (TID 202) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:40.228+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:40 INFO TaskSetManager: Finished task 6.0 in stage 117.0 (TID 201) in 308 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:40.237+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:40 INFO BlockManagerInfo: Added rdd_238_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 142.0 MiB)
[2025-05-06T20:51:40.569+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:40 INFO TaskSetManager: Starting task 8.0 in stage 117.0 (TID 203) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:40.569+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:40 INFO TaskSetManager: Finished task 7.0 in stage 117.0 (TID 202) in 342 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:40.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:40 INFO BlockManagerInfo: Added rdd_238_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 141.4 MiB)
[2025-05-06T20:51:40.881+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:40 INFO TaskSetManager: Starting task 9.0 in stage 117.0 (TID 204) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:40.882+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:40 INFO TaskSetManager: Finished task 8.0 in stage 117.0 (TID 203) in 313 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:40.895+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:40 INFO BlockManagerInfo: Added rdd_238_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 140.8 MiB)
[2025-05-06T20:51:41.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 9.0 in stage 117.0 (TID 204) in 363 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:41.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-05-06T20:51:41.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: ShuffleMapStage 117 (mapPartitions at GraphImpl.scala:208) finished in 3.595 s
[2025-05-06T20:51:41.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:41.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:41.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: waiting: Set(ResultStage 118)
[2025-05-06T20:51:41.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:41.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[248] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:41.246+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 12.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:41.247+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:41.247+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 837932af135c:42719 (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:41.247+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:41.247+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 118 (MapPartitionsRDD[248] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:41.247+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSchedulerImpl: Adding task set 118.0 with 10 tasks resource profile 0
[2025-05-06T20:51:41.248+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 205) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.18.0.4:45323 (size: 5.6 KiB, free: 140.8 MiB)
[2025-05-06T20:51:41.256+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.18.0.4:41314
[2025-05-06T20:51:41.270+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_0 in memory on 172.18.0.4:45323 (size: 90.8 KiB, free: 140.7 MiB)
[2025-05-06T20:51:41.272+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 206) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.272+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 205) in 24 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:41.289+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_1 in memory on 172.18.0.4:45323 (size: 89.4 KiB, free: 140.6 MiB)
[2025-05-06T20:51:41.291+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 207) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.292+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 206) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:41.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_2 in memory on 172.18.0.4:45323 (size: 86.5 KiB, free: 140.6 MiB)
[2025-05-06T20:51:41.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 208) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 207) in 18 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:41.325+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_3 in memory on 172.18.0.4:45323 (size: 85.4 KiB, free: 140.5 MiB)
[2025-05-06T20:51:41.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 209) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 208) in 18 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:41.345+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_4 in memory on 172.18.0.4:45323 (size: 87.3 KiB, free: 140.4 MiB)
[2025-05-06T20:51:41.347+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 210) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.347+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 209) in 20 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:41.366+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_5 in memory on 172.18.0.4:45323 (size: 87.0 KiB, free: 140.3 MiB)
[2025-05-06T20:51:41.369+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 211) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.369+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 210) in 22 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:41.385+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_6 in memory on 172.18.0.4:45323 (size: 85.5 KiB, free: 140.2 MiB)
[2025-05-06T20:51:41.388+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 212) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.388+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 211) in 19 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:41.404+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_7 in memory on 172.18.0.4:45323 (size: 86.6 KiB, free: 140.1 MiB)
[2025-05-06T20:51:41.405+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 8.0 in stage 118.0 (TID 213) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.406+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 212) in 18 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:41.428+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_8 in memory on 172.18.0.4:45323 (size: 84.8 KiB, free: 140.1 MiB)
[2025-05-06T20:51:41.429+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 9.0 in stage 118.0 (TID 214) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.430+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 8.0 in stage 118.0 (TID 213) in 24 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:41.447+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_246_9 in memory on 172.18.0.4:45323 (size: 82.6 KiB, free: 140.0 MiB)
[2025-05-06T20:51:41.448+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 9.0 in stage 118.0 (TID 214) in 19 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:41.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-05-06T20:51:41.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: ResultStage 118 (fold at VertexRDDImpl.scala:90) finished in 0.204 s
[2025-05-06T20:51:41.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:41.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 118: Stage finished
[2025-05-06T20:51:41.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Job 43 finished: fold at VertexRDDImpl.scala:90, took 4.453044 s
[2025-05-06T20:51:41.451+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO Pregel: Pregel finished iteration 0
[2025-05-06T20:51:41.451+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO ZippedPartitionsRDD2: Removing RDD 229 from persistence list
[2025-05-06T20:51:41.456+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManager: Removing RDD 229
[2025-05-06T20:51:41.457+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MapPartitionsRDD: Removing RDD 215 from persistence list
[2025-05-06T20:51:41.459+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManager: Removing RDD 215
[2025-05-06T20:51:41.459+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO ZippedPartitionsRDD2: Removing RDD 221 from persistence list
[2025-05-06T20:51:41.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManager: Removing RDD 221
[2025-05-06T20:51:41.476+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:41.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Registering RDD 257 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 34
[2025-05-06T20:51:41.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Registering RDD 253 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 33
[2025-05-06T20:51:41.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Registering RDD 261 (mapPartitions at GraphImpl.scala:208) as input to shuffle 35
[2025-05-06T20:51:41.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Got job 44 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:41.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Final stage: ResultStage 136 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:41.480+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135, ShuffleMapStage 132, ShuffleMapStage 129, ShuffleMapStage 126, ShuffleMapStage 120)
[2025-05-06T20:51:41.480+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 135)
[2025-05-06T20:51:41.480+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Submitting ShuffleMapStage 133 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[257] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:41.482+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 11.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:41.492+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:41.495+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 837932af135c:42719 (size: 5.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:41.496+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 837932af135c:42719 in memory (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:41.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:41.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 133 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[257] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:41.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSchedulerImpl: Adding task set 133.0 with 10 tasks resource profile 0
[2025-05-06T20:51:41.498+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Submitting ShuffleMapStage 134 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[253] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:41.499+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 215) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.502+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 12.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:41.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.18.0.4:45323 in memory (size: 5.6 KiB, free: 180.6 MiB)
[2025-05-06T20:51:41.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:41.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 837932af135c:42719 (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:41.505+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:41.505+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 134 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[253] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:41.505+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSchedulerImpl: Adding task set 134.0 with 10 tasks resource profile 0
[2025-05-06T20:51:41.513+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 837932af135c:42719 in memory (size: 47.7 KiB, free: 434.3 MiB)
[2025-05-06T20:51:41.514+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.18.0.4:45323 in memory (size: 47.7 KiB, free: 180.7 MiB)
[2025-05-06T20:51:41.518+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.18.0.4:45323 (size: 5.4 KiB, free: 180.7 MiB)
[2025-05-06T20:51:41.543+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 1.0 in stage 133.0 (TID 216) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.544+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 215) in 45 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:41.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 2.0 in stage 133.0 (TID 217) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 1.0 in stage 133.0 (TID 216) in 17 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:41.572+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 3.0 in stage 133.0 (TID 218) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.573+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 2.0 in stage 133.0 (TID 217) in 13 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:41.587+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 4.0 in stage 133.0 (TID 219) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 3.0 in stage 133.0 (TID 218) in 15 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:41.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 5.0 in stage 133.0 (TID 220) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.600+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 4.0 in stage 133.0 (TID 219) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:41.612+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 6.0 in stage 133.0 (TID 221) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 5.0 in stage 133.0 (TID 220) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:41.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 7.0 in stage 133.0 (TID 222) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 6.0 in stage 133.0 (TID 221) in 15 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:41.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 8.0 in stage 133.0 (TID 223) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 7.0 in stage 133.0 (TID 222) in 18 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:41.656+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 9.0 in stage 133.0 (TID 224) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.657+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 8.0 in stage 133.0 (TID 223) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:41.668+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 225) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.669+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 9.0 in stage 133.0 (TID 224) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:41.669+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool
[2025-05-06T20:51:41.669+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: ShuffleMapStage 133 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.188 s
[2025-05-06T20:51:41.669+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:41.669+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: running: Set(ShuffleMapStage 134)
[2025-05-06T20:51:41.669+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 135, ResultStage 136)
[2025-05-06T20:51:41.669+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:41.673+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.18.0.4:45323 (size: 5.6 KiB, free: 180.7 MiB)
[2025-05-06T20:51:41.678+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 180.7 MiB)
[2025-05-06T20:51:41.682+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 226) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.683+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 225) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:41.688+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 180.6 MiB)
[2025-05-06T20:51:41.694+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 227) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.694+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 226) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:41.699+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 180.6 MiB)
[2025-05-06T20:51:41.704+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 228) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.704+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 227) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:41.709+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 180.6 MiB)
[2025-05-06T20:51:41.714+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 4.0 in stage 134.0 (TID 229) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.715+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 228) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:41.720+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 180.6 MiB)
[2025-05-06T20:51:41.725+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 5.0 in stage 134.0 (TID 230) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.726+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 4.0 in stage 134.0 (TID 229) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:41.730+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 180.6 MiB)
[2025-05-06T20:51:41.735+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 6.0 in stage 134.0 (TID 231) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 5.0 in stage 134.0 (TID 230) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:41.740+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 180.6 MiB)
[2025-05-06T20:51:41.746+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 7.0 in stage 134.0 (TID 232) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.746+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 6.0 in stage 134.0 (TID 231) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:41.750+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 180.6 MiB)
[2025-05-06T20:51:41.756+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 8.0 in stage 134.0 (TID 233) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.756+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 7.0 in stage 134.0 (TID 232) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:41.762+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 180.5 MiB)
[2025-05-06T20:51:41.768+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 9.0 in stage 134.0 (TID 234) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.769+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 8.0 in stage 134.0 (TID 233) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:41.773+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_249_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 180.5 MiB)
[2025-05-06T20:51:41.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 9.0 in stage 134.0 (TID 234) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:41.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool
[2025-05-06T20:51:41.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: ShuffleMapStage 134 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.280 s
[2025-05-06T20:51:41.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:41.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:41.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 135, ResultStage 136)
[2025-05-06T20:51:41.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:41.779+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Submitting ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[261] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:41.781+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 120.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:41.789+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:41.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 837932af135c:42719 in memory (size: 5.4 KiB, free: 434.3 MiB)
[2025-05-06T20:51:41.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 837932af135c:42719 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:41.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:41.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[261] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:41.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSchedulerImpl: Adding task set 135.0 with 10 tasks resource profile 0
[2025-05-06T20:51:41.791+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.18.0.4:45323 in memory (size: 5.4 KiB, free: 180.5 MiB)
[2025-05-06T20:51:41.792+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 235) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.18.0.4:45323 (size: 48.0 KiB, free: 180.5 MiB)
[2025-05-06T20:51:41.805+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.18.0.4:41314
[2025-05-06T20:51:41.810+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_255_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 180.0 MiB)
[2025-05-06T20:51:41.811+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.18.0.4:41314
[2025-05-06T20:51:41.900+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 236) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 235) in 110 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:41.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO BlockManagerInfo: Added rdd_255_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 179.4 MiB)
[2025-05-06T20:51:41.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 237) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:41.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:41 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 236) in 97 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:42.005+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_255_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 178.8 MiB)
[2025-05-06T20:51:42.078+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 238) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.078+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 237) in 81 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:42.086+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_255_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 178.3 MiB)
[2025-05-06T20:51:42.154+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 4.0 in stage 135.0 (TID 239) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.154+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 238) in 76 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:42.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_255_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 177.9 MiB)
[2025-05-06T20:51:42.223+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 5.0 in stage 135.0 (TID 240) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.223+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 4.0 in stage 135.0 (TID 239) in 70 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:42.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_255_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 177.4 MiB)
[2025-05-06T20:51:42.300+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 6.0 in stage 135.0 (TID 241) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.301+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 5.0 in stage 135.0 (TID 240) in 79 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:42.310+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_255_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 176.8 MiB)
[2025-05-06T20:51:42.379+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 7.0 in stage 135.0 (TID 242) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.380+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 6.0 in stage 135.0 (TID 241) in 79 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:42.388+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_255_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 176.3 MiB)
[2025-05-06T20:51:42.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 8.0 in stage 135.0 (TID 243) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 7.0 in stage 135.0 (TID 242) in 81 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:42.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_255_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 175.7 MiB)
[2025-05-06T20:51:42.540+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 9.0 in stage 135.0 (TID 244) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.540+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 8.0 in stage 135.0 (TID 243) in 80 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:42.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_255_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 175.1 MiB)
[2025-05-06T20:51:42.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 9.0 in stage 135.0 (TID 244) in 90 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:42.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool
[2025-05-06T20:51:42.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: ShuffleMapStage 135 (mapPartitions at GraphImpl.scala:208) finished in 0.851 s
[2025-05-06T20:51:42.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:42.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:42.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: waiting: Set(ResultStage 136)
[2025-05-06T20:51:42.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:42.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[265] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:42.632+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 12.9 KiB, free 425.8 MiB)
[2025-05-06T20:51:42.640+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:42.641+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 837932af135c:42719 (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T20:51:42.641+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 837932af135c:42719 in memory (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:42.641+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:42.641+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 136 (MapPartitionsRDD[265] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:42.642+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSchedulerImpl: Adding task set 136.0 with 10 tasks resource profile 0
[2025-05-06T20:51:42.642+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 245) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.643+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.18.0.4:45323 in memory (size: 5.6 KiB, free: 175.1 MiB)
[2025-05-06T20:51:42.647+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.18.0.4:45323 (size: 5.8 KiB, free: 175.1 MiB)
[2025-05-06T20:51:42.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.18.0.4:41314
[2025-05-06T20:51:42.662+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_0 in memory on 172.18.0.4:45323 (size: 37.2 KiB, free: 175.1 MiB)
[2025-05-06T20:51:42.664+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 246) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.664+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 245) in 22 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:42.686+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_1 in memory on 172.18.0.4:45323 (size: 36.8 KiB, free: 175.0 MiB)
[2025-05-06T20:51:42.689+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 2.0 in stage 136.0 (TID 247) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.690+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 246) in 25 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:42.699+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_2 in memory on 172.18.0.4:45323 (size: 35.9 KiB, free: 175.0 MiB)
[2025-05-06T20:51:42.701+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 3.0 in stage 136.0 (TID 248) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.703+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 2.0 in stage 136.0 (TID 247) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:42.712+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_3 in memory on 172.18.0.4:45323 (size: 35.9 KiB, free: 175.0 MiB)
[2025-05-06T20:51:42.714+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 4.0 in stage 136.0 (TID 249) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.714+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 3.0 in stage 136.0 (TID 248) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:42.725+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_4 in memory on 172.18.0.4:45323 (size: 36.2 KiB, free: 174.9 MiB)
[2025-05-06T20:51:42.726+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 5.0 in stage 136.0 (TID 250) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.727+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 4.0 in stage 136.0 (TID 249) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:42.738+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_5 in memory on 172.18.0.4:45323 (size: 35.9 KiB, free: 174.9 MiB)
[2025-05-06T20:51:42.741+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 6.0 in stage 136.0 (TID 251) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.741+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 5.0 in stage 136.0 (TID 250) in 15 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:42.754+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_6 in memory on 172.18.0.4:45323 (size: 35.7 KiB, free: 174.9 MiB)
[2025-05-06T20:51:42.756+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 7.0 in stage 136.0 (TID 252) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.756+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 6.0 in stage 136.0 (TID 251) in 16 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:42.772+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_7 in memory on 172.18.0.4:45323 (size: 35.7 KiB, free: 174.8 MiB)
[2025-05-06T20:51:42.774+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 8.0 in stage 136.0 (TID 253) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.774+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 7.0 in stage 136.0 (TID 252) in 18 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:42.782+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_8 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 174.8 MiB)
[2025-05-06T20:51:42.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 9.0 in stage 136.0 (TID 254) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.786+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 8.0 in stage 136.0 (TID 253) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:42.795+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added rdd_263_9 in memory on 172.18.0.4:45323 (size: 34.2 KiB, free: 174.8 MiB)
[2025-05-06T20:51:42.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 9.0 in stage 136.0 (TID 254) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:42.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-05-06T20:51:42.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: ResultStage 136 (fold at VertexRDDImpl.scala:90) finished in 0.166 s
[2025-05-06T20:51:42.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:42.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished
[2025-05-06T20:51:42.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Job 44 finished: fold at VertexRDDImpl.scala:90, took 1.321677 s
[2025-05-06T20:51:42.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO Pregel: Pregel finished iteration 1
[2025-05-06T20:51:42.799+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO ZippedPartitionsRDD2: Removing RDD 246 from persistence list
[2025-05-06T20:51:42.800+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManager: Removing RDD 246
[2025-05-06T20:51:42.800+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO ZippedPartitionsRDD2: Removing RDD 232 from persistence list
[2025-05-06T20:51:42.803+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO ZippedPartitionsRDD2: Removing RDD 238 from persistence list
[2025-05-06T20:51:42.804+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManager: Removing RDD 232
[2025-05-06T20:51:42.804+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManager: Removing RDD 238
[2025-05-06T20:51:42.811+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO MapPartitionsRDD: Removing RDD 215 from persistence list
[2025-05-06T20:51:42.812+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManager: Removing RDD 215
[2025-05-06T20:51:42.812+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO ZippedPartitionsRDD2: Removing RDD 225 from persistence list
[2025-05-06T20:51:42.813+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManager: Removing RDD 225
[2025-05-06T20:51:42.820+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO ZippedPartitionsRDD2: Removing RDD 229 from persistence list
[2025-05-06T20:51:42.822+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManager: Removing RDD 229
[2025-05-06T20:51:42.826+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:42.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Registering RDD 274 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 37
[2025-05-06T20:51:42.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Registering RDD 270 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 36
[2025-05-06T20:51:42.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Registering RDD 278 (mapPartitions at GraphImpl.scala:208) as input to shuffle 38
[2025-05-06T20:51:42.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Got job 45 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:42.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Final stage: ResultStage 157 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:42.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 153, ShuffleMapStage 150, ShuffleMapStage 147, ShuffleMapStage 144, ShuffleMapStage 156, ShuffleMapStage 138)
[2025-05-06T20:51:42.831+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 156)
[2025-05-06T20:51:42.832+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Submitting ShuffleMapStage 154 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[274] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:42.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 12.2 KiB, free 425.8 MiB)
[2025-05-06T20:51:42.846+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:42.846+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 837932af135c:42719 (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:42.847+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 837932af135c:42719 in memory (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T20:51:42.847+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:42.848+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.18.0.4:45323 in memory (size: 5.8 KiB, free: 181.1 MiB)
[2025-05-06T20:51:42.849+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 154 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[274] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:42.849+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSchedulerImpl: Adding task set 154.0 with 10 tasks resource profile 0
[2025-05-06T20:51:42.851+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Submitting ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[270] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:42.851+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 255) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 12.9 KiB, free 425.8 MiB)
[2025-05-06T20:51:42.856+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:42.857+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 837932af135c:42719 (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:42.857+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:42.858+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[270] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:42.858+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSchedulerImpl: Adding task set 155.0 with 10 tasks resource profile 0
[2025-05-06T20:51:42.859+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 837932af135c:42719 in memory (size: 48.0 KiB, free: 434.3 MiB)
[2025-05-06T20:51:42.861+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.18.0.4:45323 in memory (size: 48.0 KiB, free: 181.2 MiB)
[2025-05-06T20:51:42.864+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.18.0.4:45323 (size: 5.6 KiB, free: 181.2 MiB)
[2025-05-06T20:51:42.885+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 256) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.886+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 255) in 35 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:42.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 257) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.911+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 256) in 28 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:42.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 258) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 257) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:42.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 259) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 258) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:42.948+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 5.0 in stage 154.0 (TID 260) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.948+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 259) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:42.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 6.0 in stage 154.0 (TID 261) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 5.0 in stage 154.0 (TID 260) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:42.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 7.0 in stage 154.0 (TID 262) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 6.0 in stage 154.0 (TID 261) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:42.987+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 8.0 in stage 154.0 (TID 263) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.987+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 7.0 in stage 154.0 (TID 262) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:42.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Starting task 9.0 in stage 154.0 (TID 264) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:42.999+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:42 INFO TaskSetManager: Finished task 8.0 in stage 154.0 (TID 263) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:43.012+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 265) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 9.0 in stage 154.0 (TID 264) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:43.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool
[2025-05-06T20:51:43.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: ShuffleMapStage 154 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.181 s
[2025-05-06T20:51:43.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:43.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: running: Set(ShuffleMapStage 155)
[2025-05-06T20:51:43.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: waiting: Set(ResultStage 157, ShuffleMapStage 156)
[2025-05-06T20:51:43.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:43.017+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.18.0.4:45323 (size: 5.7 KiB, free: 181.2 MiB)
[2025-05-06T20:51:43.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:43.028+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 266) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.028+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 265) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:43.032+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 181.1 MiB)
[2025-05-06T20:51:43.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 267) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 266) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:43.042+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T20:51:43.046+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 268) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.046+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 267) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:43.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:43.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 4.0 in stage 155.0 (TID 269) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 268) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:43.061+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:43.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 5.0 in stage 155.0 (TID 270) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.066+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 4.0 in stage 155.0 (TID 269) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:43.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:43.075+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 6.0 in stage 155.0 (TID 271) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.076+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 5.0 in stage 155.0 (TID 270) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:43.079+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:43.086+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 7.0 in stage 155.0 (TID 272) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.087+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 6.0 in stage 155.0 (TID 271) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:43.091+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T20:51:43.094+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 8.0 in stage 155.0 (TID 273) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.094+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 7.0 in stage 155.0 (TID 272) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:43.097+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 181.0 MiB)
[2025-05-06T20:51:43.101+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 9.0 in stage 155.0 (TID 274) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.102+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 8.0 in stage 155.0 (TID 273) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:43.107+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_266_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:43.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 9.0 in stage 155.0 (TID 274) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:43.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool
[2025-05-06T20:51:43.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: ShuffleMapStage 155 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.260 s
[2025-05-06T20:51:43.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:43.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:43.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: waiting: Set(ResultStage 157, ShuffleMapStage 156)
[2025-05-06T20:51:43.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:43.112+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: Submitting ShuffleMapStage 156 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[278] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:43.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 121.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:43.127+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.8 MiB)
[2025-05-06T20:51:43.128+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 837932af135c:42719 in memory (size: 5.6 KiB, free: 434.3 MiB)
[2025-05-06T20:51:43.128+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 837932af135c:42719 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:43.129+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:43.129+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 156 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[278] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:43.129+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSchedulerImpl: Adding task set 156.0 with 10 tasks resource profile 0
[2025-05-06T20:51:43.129+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.18.0.4:45323 in memory (size: 5.6 KiB, free: 181.0 MiB)
[2025-05-06T20:51:43.130+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 275) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.136+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.18.0.4:45323 (size: 47.9 KiB, free: 181.0 MiB)
[2025-05-06T20:51:43.142+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.18.0.4:41314
[2025-05-06T20:51:43.148+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T20:51:43.149+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.18.0.4:41314
[2025-05-06T20:51:43.226+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 276) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.226+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 275) in 97 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:43.234+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T20:51:43.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 277) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 276) in 101 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:43.336+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 179.3 MiB)
[2025-05-06T20:51:43.420+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 278) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.420+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 277) in 94 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:43.428+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T20:51:43.496+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 4.0 in stage 156.0 (TID 279) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.496+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 278) in 77 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:43.506+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T20:51:43.574+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 5.0 in stage 156.0 (TID 280) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.574+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 4.0 in stage 156.0 (TID 279) in 79 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:43.585+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T20:51:43.651+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 6.0 in stage 156.0 (TID 281) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 5.0 in stage 156.0 (TID 280) in 77 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:43.660+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T20:51:43.728+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 7.0 in stage 156.0 (TID 282) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.729+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 6.0 in stage 156.0 (TID 281) in 77 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:43.737+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T20:51:43.812+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 8.0 in stage 156.0 (TID 283) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.812+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 7.0 in stage 156.0 (TID 282) in 84 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:43.822+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T20:51:43.895+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Starting task 9.0 in stage 156.0 (TID 284) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:43.895+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO TaskSetManager: Finished task 8.0 in stage 156.0 (TID 283) in 84 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:43.904+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:43 INFO BlockManagerInfo: Added rdd_272_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T20:51:44.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 9.0 in stage 156.0 (TID 284) in 116 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:44.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool
[2025-05-06T20:51:44.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: ShuffleMapStage 156 (mapPartitions at GraphImpl.scala:208) finished in 0.898 s
[2025-05-06T20:51:44.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:44.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:44.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: waiting: Set(ResultStage 157)
[2025-05-06T20:51:44.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:44.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[282] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:44.012+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 13.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:44.020+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T20:51:44.021+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 837932af135c:42719 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:44.021+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:44.022+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 157 (MapPartitionsRDD[282] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:44.022+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSchedulerImpl: Adding task set 157.0 with 10 tasks resource profile 0
[2025-05-06T20:51:44.022+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 837932af135c:42719 in memory (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:44.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 285) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.18.0.4:45323 in memory (size: 5.7 KiB, free: 175.6 MiB)
[2025-05-06T20:51:44.028+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.18.0.4:45323 (size: 5.9 KiB, free: 175.6 MiB)
[2025-05-06T20:51:44.036+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.18.0.4:41314
[2025-05-06T20:51:44.047+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_0 in memory on 172.18.0.4:45323 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:44.049+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 286) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 285) in 27 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:44.070+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_1 in memory on 172.18.0.4:45323 (size: 35.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:44.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 2.0 in stage 157.0 (TID 287) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.072+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 286) in 22 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:44.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_2 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:44.086+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 3.0 in stage 157.0 (TID 288) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.086+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 2.0 in stage 157.0 (TID 287) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:44.098+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_3 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:44.100+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 4.0 in stage 157.0 (TID 289) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.100+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 3.0 in stage 157.0 (TID 288) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:44.110+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_4 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:44.112+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 5.0 in stage 157.0 (TID 290) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.112+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 4.0 in stage 157.0 (TID 289) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:44.121+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_5 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:44.122+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 6.0 in stage 157.0 (TID 291) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.123+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 5.0 in stage 157.0 (TID 290) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:44.130+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_6 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T20:51:44.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 7.0 in stage 157.0 (TID 292) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 6.0 in stage 157.0 (TID 291) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:44.142+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_7 in memory on 172.18.0.4:45323 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T20:51:44.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 8.0 in stage 157.0 (TID 293) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 7.0 in stage 157.0 (TID 292) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:44.153+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_8 in memory on 172.18.0.4:45323 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T20:51:44.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 9.0 in stage 157.0 (TID 294) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 8.0 in stage 157.0 (TID 293) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:44.163+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_280_9 in memory on 172.18.0.4:45323 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T20:51:44.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 9.0 in stage 157.0 (TID 294) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:44.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool
[2025-05-06T20:51:44.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: ResultStage 157 (fold at VertexRDDImpl.scala:90) finished in 0.154 s
[2025-05-06T20:51:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 157: Stage finished
[2025-05-06T20:51:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Job 45 finished: fold at VertexRDDImpl.scala:90, took 1.339248 s
[2025-05-06T20:51:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO Pregel: Pregel finished iteration 2
[2025-05-06T20:51:44.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO ZippedPartitionsRDD2: Removing RDD 263 from persistence list
[2025-05-06T20:51:44.167+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO ZippedPartitionsRDD2: Removing RDD 249 from persistence list
[2025-05-06T20:51:44.167+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManager: Removing RDD 263
[2025-05-06T20:51:44.168+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO ZippedPartitionsRDD2: Removing RDD 255 from persistence list
[2025-05-06T20:51:44.169+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManager: Removing RDD 249
[2025-05-06T20:51:44.170+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManager: Removing RDD 255
[2025-05-06T20:51:44.175+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO ZippedPartitionsRDD2: Removing RDD 232 from persistence list
[2025-05-06T20:51:44.175+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO ZippedPartitionsRDD2: Removing RDD 238 from persistence list
[2025-05-06T20:51:44.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManager: Removing RDD 232
[2025-05-06T20:51:44.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManager: Removing RDD 238
[2025-05-06T20:51:44.181+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO ZippedPartitionsRDD2: Removing RDD 246 from persistence list
[2025-05-06T20:51:44.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManager: Removing RDD 246
[2025-05-06T20:51:44.187+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:44.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Registering RDD 287 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 39
[2025-05-06T20:51:44.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Registering RDD 291 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 40
[2025-05-06T20:51:44.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Registering RDD 295 (mapPartitions at GraphImpl.scala:208) as input to shuffle 41
[2025-05-06T20:51:44.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Got job 46 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:44.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Final stage: ResultStage 181 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:44.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 171, ShuffleMapStage 168, ShuffleMapStage 165, ShuffleMapStage 180, ShuffleMapStage 177, ShuffleMapStage 174, ShuffleMapStage 159)
[2025-05-06T20:51:44.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 180)
[2025-05-06T20:51:44.191+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Submitting ShuffleMapStage 178 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[287] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:44.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 13.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:44.204+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:44.204+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 837932af135c:42719 (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T20:51:44.205+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:44.205+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 178 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[287] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:44.206+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSchedulerImpl: Adding task set 178.0 with 10 tasks resource profile 0
[2025-05-06T20:51:44.207+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 837932af135c:42719 in memory (size: 47.9 KiB, free: 434.3 MiB)
[2025-05-06T20:51:44.207+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Submitting ShuffleMapStage 179 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[291] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:44.209+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 295) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.209+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 12.9 KiB, free 425.9 MiB)
[2025-05-06T20:51:44.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.18.0.4:45323 in memory (size: 47.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:44.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 425.9 MiB)
[2025-05-06T20:51:44.211+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 837932af135c:42719 (size: 5.7 KiB, free: 434.3 MiB)
[2025-05-06T20:51:44.211+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:44.212+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 179 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[291] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:44.212+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSchedulerImpl: Adding task set 179.0 with 10 tasks resource profile 0
[2025-05-06T20:51:44.213+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 837932af135c:42719 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-05-06T20:51:44.214+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.18.0.4:45323 (size: 5.8 KiB, free: 181.2 MiB)
[2025-05-06T20:51:44.214+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.18.0.4:45323 in memory (size: 5.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:44.218+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:44.223+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 1.0 in stage 178.0 (TID 296) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.224+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 295) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:44.227+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T20:51:44.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 2.0 in stage 178.0 (TID 297) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.232+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 1.0 in stage 178.0 (TID 296) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:44.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T20:51:44.262+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 3.0 in stage 178.0 (TID 298) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.263+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 2.0 in stage 178.0 (TID 297) in 31 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:44.272+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:44.276+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 4.0 in stage 178.0 (TID 299) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.277+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 3.0 in stage 178.0 (TID 298) in 15 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:44.281+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:44.287+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 5.0 in stage 178.0 (TID 300) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.287+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 4.0 in stage 178.0 (TID 299) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:44.291+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:44.295+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 6.0 in stage 178.0 (TID 301) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.295+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 5.0 in stage 178.0 (TID 300) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:44.299+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:44.304+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 7.0 in stage 178.0 (TID 302) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.304+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 6.0 in stage 178.0 (TID 301) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:44.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T20:51:44.312+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 8.0 in stage 178.0 (TID 303) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.312+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 7.0 in stage 178.0 (TID 302) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:44.316+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T20:51:44.322+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 9.0 in stage 178.0 (TID 304) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.322+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 8.0 in stage 178.0 (TID 303) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:44.325+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_283_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:44.329+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 305) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.329+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 9.0 in stage 178.0 (TID 304) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:44.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool
[2025-05-06T20:51:44.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: ShuffleMapStage 178 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.138 s
[2025-05-06T20:51:44.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:44.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: running: Set(ShuffleMapStage 179)
[2025-05-06T20:51:44.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 180, ResultStage 181)
[2025-05-06T20:51:44.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:44.334+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.18.0.4:45323 (size: 5.7 KiB, free: 181.0 MiB)
[2025-05-06T20:51:44.346+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 1.0 in stage 179.0 (TID 306) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.346+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 305) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:44.359+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 2.0 in stage 179.0 (TID 307) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.359+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 1.0 in stage 179.0 (TID 306) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:44.372+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 3.0 in stage 179.0 (TID 308) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.372+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 2.0 in stage 179.0 (TID 307) in 13 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:44.386+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 4.0 in stage 179.0 (TID 309) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.386+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 3.0 in stage 179.0 (TID 308) in 15 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:44.398+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 5.0 in stage 179.0 (TID 310) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.398+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 4.0 in stage 179.0 (TID 309) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:44.410+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 6.0 in stage 179.0 (TID 311) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.411+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 5.0 in stage 179.0 (TID 310) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:44.422+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 7.0 in stage 179.0 (TID 312) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.422+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 6.0 in stage 179.0 (TID 311) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:44.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 8.0 in stage 179.0 (TID 313) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 7.0 in stage 179.0 (TID 312) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:44.445+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 9.0 in stage 179.0 (TID 314) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.445+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 8.0 in stage 179.0 (TID 313) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:44.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 9.0 in stage 179.0 (TID 314) in 15 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:44.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool
[2025-05-06T20:51:44.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: ShuffleMapStage 179 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.254 s
[2025-05-06T20:51:44.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:44.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:44.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 180, ResultStage 181)
[2025-05-06T20:51:44.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:44.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Submitting ShuffleMapStage 180 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[295] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:44.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 121.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:44.472+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:44.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 837932af135c:42719 in memory (size: 5.8 KiB, free: 434.3 MiB)
[2025-05-06T20:51:44.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 837932af135c:42719 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:44.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:44.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 180 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[295] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:44.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSchedulerImpl: Adding task set 180.0 with 10 tasks resource profile 0
[2025-05-06T20:51:44.474+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 315) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.475+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.18.0.4:45323 in memory (size: 5.8 KiB, free: 181.0 MiB)
[2025-05-06T20:51:44.482+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.18.0.4:45323 (size: 48.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:44.491+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.18.0.4:41314
[2025-05-06T20:51:44.495+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_289_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T20:51:44.495+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.18.0.4:41314
[2025-05-06T20:51:44.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 1.0 in stage 180.0 (TID 316) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 315) in 156 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:44.646+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_289_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T20:51:44.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 2.0 in stage 180.0 (TID 317) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.799+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 1.0 in stage 180.0 (TID 316) in 170 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:44.809+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_289_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T20:51:44.905+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Starting task 3.0 in stage 180.0 (TID 318) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:44.905+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO TaskSetManager: Finished task 2.0 in stage 180.0 (TID 317) in 107 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:44.914+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:44 INFO BlockManagerInfo: Added rdd_289_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T20:51:45.004+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 4.0 in stage 180.0 (TID 319) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.006+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 3.0 in stage 180.0 (TID 318) in 101 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:45.017+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_289_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T20:51:45.109+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 5.0 in stage 180.0 (TID 320) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.109+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 4.0 in stage 180.0 (TID 319) in 106 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:45.117+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_289_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T20:51:45.203+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 6.0 in stage 180.0 (TID 321) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.203+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 5.0 in stage 180.0 (TID 320) in 95 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:45.211+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_289_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T20:51:45.293+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 7.0 in stage 180.0 (TID 322) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.294+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 6.0 in stage 180.0 (TID 321) in 91 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:45.302+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_289_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T20:51:45.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 8.0 in stage 180.0 (TID 323) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.393+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 7.0 in stage 180.0 (TID 322) in 99 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:45.400+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_289_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T20:51:45.477+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 9.0 in stage 180.0 (TID 324) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.478+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 8.0 in stage 180.0 (TID 323) in 85 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:45.484+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_289_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T20:51:45.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 9.0 in stage 180.0 (TID 324) in 90 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:45.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool
[2025-05-06T20:51:45.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: ShuffleMapStage 180 (mapPartitions at GraphImpl.scala:208) finished in 1.106 s
[2025-05-06T20:51:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: waiting: Set(ResultStage 181)
[2025-05-06T20:51:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:45.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[299] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:45.570+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 14.2 KiB, free 425.8 MiB)
[2025-05-06T20:51:45.577+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:45.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 837932af135c:42719 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:45.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 837932af135c:42719 in memory (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:45.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:45.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 181 (MapPartitionsRDD[299] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:45.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSchedulerImpl: Adding task set 181.0 with 10 tasks resource profile 0
[2025-05-06T20:51:45.579+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 325) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.579+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.18.0.4:45323 in memory (size: 5.7 KiB, free: 175.6 MiB)
[2025-05-06T20:51:45.583+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.18.0.4:45323 (size: 6.0 KiB, free: 175.6 MiB)
[2025-05-06T20:51:45.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.18.0.4:41314
[2025-05-06T20:51:45.594+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_0 in memory on 172.18.0.4:45323 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:45.597+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 1.0 in stage 181.0 (TID 326) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.598+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 325) in 18 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:45.606+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_1 in memory on 172.18.0.4:45323 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T20:51:45.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 2.0 in stage 181.0 (TID 327) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 1.0 in stage 181.0 (TID 326) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:45.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_2 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:45.628+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 3.0 in stage 181.0 (TID 328) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.629+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 2.0 in stage 181.0 (TID 327) in 20 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:45.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_3 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:45.639+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 4.0 in stage 181.0 (TID 329) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.640+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 3.0 in stage 181.0 (TID 328) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:45.648+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_4 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:45.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 5.0 in stage 181.0 (TID 330) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.650+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 4.0 in stage 181.0 (TID 329) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:45.659+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_5 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:45.660+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 6.0 in stage 181.0 (TID 331) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.660+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 5.0 in stage 181.0 (TID 330) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:45.668+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_6 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T20:51:45.671+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 7.0 in stage 181.0 (TID 332) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.671+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 6.0 in stage 181.0 (TID 331) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:45.679+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_7 in memory on 172.18.0.4:45323 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T20:51:45.681+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 8.0 in stage 181.0 (TID 333) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.681+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 7.0 in stage 181.0 (TID 332) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:45.689+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_8 in memory on 172.18.0.4:45323 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T20:51:45.691+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 9.0 in stage 181.0 (TID 334) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.691+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 8.0 in stage 181.0 (TID 333) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:45.700+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_297_9 in memory on 172.18.0.4:45323 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T20:51:45.701+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 9.0 in stage 181.0 (TID 334) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:45.702+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool
[2025-05-06T20:51:45.702+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: ResultStage 181 (fold at VertexRDDImpl.scala:90) finished in 0.133 s
[2025-05-06T20:51:45.702+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:45.702+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished
[2025-05-06T20:51:45.702+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Job 46 finished: fold at VertexRDDImpl.scala:90, took 1.514776 s
[2025-05-06T20:51:45.703+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO Pregel: Pregel finished iteration 3
[2025-05-06T20:51:45.704+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO ZippedPartitionsRDD2: Removing RDD 280 from persistence list
[2025-05-06T20:51:45.704+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManager: Removing RDD 280
[2025-05-06T20:51:45.705+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO ZippedPartitionsRDD2: Removing RDD 266 from persistence list
[2025-05-06T20:51:45.705+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManager: Removing RDD 266
[2025-05-06T20:51:45.705+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO ZippedPartitionsRDD2: Removing RDD 272 from persistence list
[2025-05-06T20:51:45.706+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManager: Removing RDD 272
[2025-05-06T20:51:45.710+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO ZippedPartitionsRDD2: Removing RDD 249 from persistence list
[2025-05-06T20:51:45.710+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManager: Removing RDD 249
[2025-05-06T20:51:45.710+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO ZippedPartitionsRDD2: Removing RDD 255 from persistence list
[2025-05-06T20:51:45.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManager: Removing RDD 255
[2025-05-06T20:51:45.714+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO ZippedPartitionsRDD2: Removing RDD 263 from persistence list
[2025-05-06T20:51:45.715+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManager: Removing RDD 263
[2025-05-06T20:51:45.719+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:45.722+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Registering RDD 308 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 43
[2025-05-06T20:51:45.723+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Registering RDD 304 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 42
[2025-05-06T20:51:45.723+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Registering RDD 312 (mapPartitions at GraphImpl.scala:208) as input to shuffle 44
[2025-05-06T20:51:45.723+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Got job 47 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:45.723+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Final stage: ResultStage 208 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:45.723+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 204, ShuffleMapStage 201, ShuffleMapStage 198, ShuffleMapStage 183, ShuffleMapStage 195, ShuffleMapStage 192, ShuffleMapStage 189, ShuffleMapStage 207)
[2025-05-06T20:51:45.723+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 207)
[2025-05-06T20:51:45.723+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Submitting ShuffleMapStage 205 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[308] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:45.725+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 13.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:45.731+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:45.732+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 837932af135c:42719 in memory (size: 48.0 KiB, free: 434.3 MiB)
[2025-05-06T20:51:45.732+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 837932af135c:42719 (size: 5.8 KiB, free: 434.3 MiB)
[2025-05-06T20:51:45.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:45.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 205 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[308] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:45.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSchedulerImpl: Adding task set 205.0 with 10 tasks resource profile 0
[2025-05-06T20:51:45.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Submitting ShuffleMapStage 206 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[304] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:45.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.18.0.4:45323 in memory (size: 48.0 KiB, free: 181.2 MiB)
[2025-05-06T20:51:45.737+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 335) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.739+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 14.2 KiB, free 425.9 MiB)
[2025-05-06T20:51:45.739+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.9 MiB)
[2025-05-06T20:51:45.740+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 837932af135c:42719 (size: 6.0 KiB, free: 434.3 MiB)
[2025-05-06T20:51:45.741+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:45.741+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 206 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[304] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:45.741+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSchedulerImpl: Adding task set 206.0 with 10 tasks resource profile 0
[2025-05-06T20:51:45.742+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 837932af135c:42719 in memory (size: 6.0 KiB, free: 434.3 MiB)
[2025-05-06T20:51:45.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.18.0.4:45323 in memory (size: 6.0 KiB, free: 181.2 MiB)
[2025-05-06T20:51:45.744+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.18.0.4:45323 (size: 5.8 KiB, free: 181.2 MiB)
[2025-05-06T20:51:45.760+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 1.0 in stage 205.0 (TID 336) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.760+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 335) in 24 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:45.783+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 2.0 in stage 205.0 (TID 337) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 1.0 in stage 205.0 (TID 336) in 23 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:45.806+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 3.0 in stage 205.0 (TID 338) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.806+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 2.0 in stage 205.0 (TID 337) in 23 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:45.817+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 4.0 in stage 205.0 (TID 339) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.818+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 3.0 in stage 205.0 (TID 338) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:45.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 5.0 in stage 205.0 (TID 340) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.831+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 4.0 in stage 205.0 (TID 339) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:45.843+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 6.0 in stage 205.0 (TID 341) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.843+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 5.0 in stage 205.0 (TID 340) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:45.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 7.0 in stage 205.0 (TID 342) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 6.0 in stage 205.0 (TID 341) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:45.865+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 8.0 in stage 205.0 (TID 343) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.865+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 7.0 in stage 205.0 (TID 342) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:45.877+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 9.0 in stage 205.0 (TID 344) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 8.0 in stage 205.0 (TID 343) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:45.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 345) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 9.0 in stage 205.0 (TID 344) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:45.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool
[2025-05-06T20:51:45.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: ShuffleMapStage 205 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.166 s
[2025-05-06T20:51:45.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:45.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: running: Set(ShuffleMapStage 206)
[2025-05-06T20:51:45.891+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: waiting: Set(ResultStage 208, ShuffleMapStage 207)
[2025-05-06T20:51:45.891+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:45.894+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.18.0.4:45323 (size: 6.0 KiB, free: 181.2 MiB)
[2025-05-06T20:51:45.898+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:45.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 1.0 in stage 206.0 (TID 346) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 345) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:45.906+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T20:51:45.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 2.0 in stage 206.0 (TID 347) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 1.0 in stage 206.0 (TID 346) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:45.914+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T20:51:45.919+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 3.0 in stage 206.0 (TID 348) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.919+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 2.0 in stage 206.0 (TID 347) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:45.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:45.927+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 4.0 in stage 206.0 (TID 349) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.927+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 3.0 in stage 206.0 (TID 348) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:45.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:45.935+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 5.0 in stage 206.0 (TID 350) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 4.0 in stage 206.0 (TID 349) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:45.940+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:45.944+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 6.0 in stage 206.0 (TID 351) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.944+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 5.0 in stage 206.0 (TID 350) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:45.947+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:45.951+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 7.0 in stage 206.0 (TID 352) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.952+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 6.0 in stage 206.0 (TID 351) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:45.956+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T20:51:45.960+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 8.0 in stage 206.0 (TID 353) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.960+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 7.0 in stage 206.0 (TID 352) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:45.963+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T20:51:45.967+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 9.0 in stage 206.0 (TID 354) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.968+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 8.0 in stage 206.0 (TID 353) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:45.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added rdd_300_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:45.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Finished task 9.0 in stage 206.0 (TID 354) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:45.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool
[2025-05-06T20:51:45.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: ShuffleMapStage 206 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.242 s
[2025-05-06T20:51:45.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:45.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:45.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: waiting: Set(ResultStage 208, ShuffleMapStage 207)
[2025-05-06T20:51:45.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:45.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Submitting ShuffleMapStage 207 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[312] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:45.980+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 121.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:45.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 837932af135c:42719 in memory (size: 5.8 KiB, free: 434.3 MiB)
[2025-05-06T20:51:45.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:45.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 837932af135c:42719 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:45.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:45.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 207 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[312] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:45.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSchedulerImpl: Adding task set 207.0 with 10 tasks resource profile 0
[2025-05-06T20:51:45.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.18.0.4:45323 in memory (size: 5.8 KiB, free: 181.0 MiB)
[2025-05-06T20:51:45.991+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 355) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:45.995+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:45 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.18.0.4:45323 (size: 48.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:46.001+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.18.0.4:41314
[2025-05-06T20:51:46.006+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T20:51:46.006+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.18.0.4:41314
[2025-05-06T20:51:46.090+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 1.0 in stage 207.0 (TID 356) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.091+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 355) in 99 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:46.097+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T20:51:46.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 2.0 in stage 207.0 (TID 357) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 1.0 in stage 207.0 (TID 356) in 92 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:46.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T20:51:46.263+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 3.0 in stage 207.0 (TID 358) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.263+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 2.0 in stage 207.0 (TID 357) in 81 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:46.271+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T20:51:46.338+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 4.0 in stage 207.0 (TID 359) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.339+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 3.0 in stage 207.0 (TID 358) in 75 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:46.345+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T20:51:46.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 5.0 in stage 207.0 (TID 360) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.398+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 4.0 in stage 207.0 (TID 359) in 59 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:46.406+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T20:51:46.469+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 6.0 in stage 207.0 (TID 361) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.470+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 5.0 in stage 207.0 (TID 360) in 72 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:46.477+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T20:51:46.544+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 7.0 in stage 207.0 (TID 362) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.545+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 6.0 in stage 207.0 (TID 361) in 76 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:46.550+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T20:51:46.629+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 8.0 in stage 207.0 (TID 363) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 7.0 in stage 207.0 (TID 362) in 85 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:46.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T20:51:46.703+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 9.0 in stage 207.0 (TID 364) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.704+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 8.0 in stage 207.0 (TID 363) in 74 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:46.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_306_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T20:51:46.789+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 9.0 in stage 207.0 (TID 364) in 87 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:46.789+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool
[2025-05-06T20:51:46.789+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: ShuffleMapStage 207 (mapPartitions at GraphImpl.scala:208) finished in 0.811 s
[2025-05-06T20:51:46.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:46.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:46.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: waiting: Set(ResultStage 208)
[2025-05-06T20:51:46.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:46.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Submitting ResultStage 208 (MapPartitionsRDD[316] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:46.791+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 14.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:46.796+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:46.796+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 837932af135c:42719 in memory (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:46.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 837932af135c:42719 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:46.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:46.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 208 (MapPartitionsRDD[316] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:46.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSchedulerImpl: Adding task set 208.0 with 10 tasks resource profile 0
[2025-05-06T20:51:46.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.18.0.4:45323 in memory (size: 6.0 KiB, free: 175.6 MiB)
[2025-05-06T20:51:46.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 365) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.802+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.18.0.4:45323 (size: 6.1 KiB, free: 175.6 MiB)
[2025-05-06T20:51:46.808+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.18.0.4:41314
[2025-05-06T20:51:46.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_0 in memory on 172.18.0.4:45323 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:46.816+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 1.0 in stage 208.0 (TID 366) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.817+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 365) in 20 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:46.825+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_1 in memory on 172.18.0.4:45323 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T20:51:46.827+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 2.0 in stage 208.0 (TID 367) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.828+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 1.0 in stage 208.0 (TID 366) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:46.848+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_2 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:46.850+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 3.0 in stage 208.0 (TID 368) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.851+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 2.0 in stage 208.0 (TID 367) in 23 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:46.860+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_3 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:46.862+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 4.0 in stage 208.0 (TID 369) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.862+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 3.0 in stage 208.0 (TID 368) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:46.873+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_4 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:46.875+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 5.0 in stage 208.0 (TID 370) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.875+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 4.0 in stage 208.0 (TID 369) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:46.887+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_5 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:46.892+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 6.0 in stage 208.0 (TID 371) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.892+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 5.0 in stage 208.0 (TID 370) in 17 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:46.904+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_6 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T20:51:46.906+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 7.0 in stage 208.0 (TID 372) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.906+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 6.0 in stage 208.0 (TID 371) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:46.914+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_7 in memory on 172.18.0.4:45323 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T20:51:46.916+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 8.0 in stage 208.0 (TID 373) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.916+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 7.0 in stage 208.0 (TID 372) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:46.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_8 in memory on 172.18.0.4:45323 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T20:51:46.926+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 9.0 in stage 208.0 (TID 374) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.926+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 8.0 in stage 208.0 (TID 373) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:46.934+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added rdd_314_9 in memory on 172.18.0.4:45323 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T20:51:46.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Finished task 9.0 in stage 208.0 (TID 374) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:46.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool
[2025-05-06T20:51:46.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: ResultStage 208 (fold at VertexRDDImpl.scala:90) finished in 0.146 s
[2025-05-06T20:51:46.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:46.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 208: Stage finished
[2025-05-06T20:51:46.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Job 47 finished: fold at VertexRDDImpl.scala:90, took 1.218586 s
[2025-05-06T20:51:46.938+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO Pregel: Pregel finished iteration 4
[2025-05-06T20:51:46.938+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO ZippedPartitionsRDD2: Removing RDD 297 from persistence list
[2025-05-06T20:51:46.939+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManager: Removing RDD 297
[2025-05-06T20:51:46.939+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO ZippedPartitionsRDD2: Removing RDD 283 from persistence list
[2025-05-06T20:51:46.940+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManager: Removing RDD 283
[2025-05-06T20:51:46.940+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO ZippedPartitionsRDD2: Removing RDD 289 from persistence list
[2025-05-06T20:51:46.940+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManager: Removing RDD 289
[2025-05-06T20:51:46.944+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO ZippedPartitionsRDD2: Removing RDD 266 from persistence list
[2025-05-06T20:51:46.945+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManager: Removing RDD 266
[2025-05-06T20:51:46.945+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO ZippedPartitionsRDD2: Removing RDD 272 from persistence list
[2025-05-06T20:51:46.945+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManager: Removing RDD 272
[2025-05-06T20:51:46.949+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO ZippedPartitionsRDD2: Removing RDD 280 from persistence list
[2025-05-06T20:51:46.949+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManager: Removing RDD 280
[2025-05-06T20:51:46.953+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:46.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Registering RDD 325 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 46
[2025-05-06T20:51:46.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Registering RDD 321 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 45
[2025-05-06T20:51:46.958+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Registering RDD 329 (mapPartitions at GraphImpl.scala:208) as input to shuffle 47
[2025-05-06T20:51:46.958+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Got job 48 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:46.958+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Final stage: ResultStage 238 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:46.958+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 222, ShuffleMapStage 219, ShuffleMapStage 216, ShuffleMapStage 234, ShuffleMapStage 237, ShuffleMapStage 231, ShuffleMapStage 228, ShuffleMapStage 225, ShuffleMapStage 210)
[2025-05-06T20:51:46.958+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 237)
[2025-05-06T20:51:46.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Submitting ShuffleMapStage 235 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[325] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:46.960+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 14.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:46.968+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T20:51:46.968+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 837932af135c:42719 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:46.968+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:46.971+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 235 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[325] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:46.971+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSchedulerImpl: Adding task set 235.0 with 10 tasks resource profile 0
[2025-05-06T20:51:46.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 837932af135c:42719 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:46.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Submitting ShuffleMapStage 236 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[321] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:46.975+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 375) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:46.975+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.18.0.4:45323 in memory (size: 6.1 KiB, free: 181.1 MiB)
[2025-05-06T20:51:46.976+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 14.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:46.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:46.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 837932af135c:42719 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:46.979+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 837932af135c:42719 in memory (size: 48.0 KiB, free: 434.3 MiB)
[2025-05-06T20:51:46.979+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:46.980+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 236 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[321] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:46.980+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO TaskSchedulerImpl: Adding task set 236.0 with 10 tasks resource profile 0
[2025-05-06T20:51:46.981+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.18.0.4:45323 in memory (size: 48.0 KiB, free: 181.2 MiB)
[2025-05-06T20:51:46.987+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:46 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.18.0.4:45323 (size: 5.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:47.000+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 1.0 in stage 235.0 (TID 376) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.001+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 375) in 26 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:47.019+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 2.0 in stage 235.0 (TID 377) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.020+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 1.0 in stage 235.0 (TID 376) in 20 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:47.035+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 3.0 in stage 235.0 (TID 378) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.035+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 2.0 in stage 235.0 (TID 377) in 16 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:47.046+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 4.0 in stage 235.0 (TID 379) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.047+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 3.0 in stage 235.0 (TID 378) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:47.058+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 5.0 in stage 235.0 (TID 380) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.058+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 4.0 in stage 235.0 (TID 379) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:47.068+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 6.0 in stage 235.0 (TID 381) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.069+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 5.0 in stage 235.0 (TID 380) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:47.080+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 7.0 in stage 235.0 (TID 382) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.080+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 6.0 in stage 235.0 (TID 381) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:47.090+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 8.0 in stage 235.0 (TID 383) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.091+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 7.0 in stage 235.0 (TID 382) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:47.101+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 9.0 in stage 235.0 (TID 384) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.101+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 8.0 in stage 235.0 (TID 383) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:47.112+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 385) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 9.0 in stage 235.0 (TID 384) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:47.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool
[2025-05-06T20:51:47.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: ShuffleMapStage 235 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.154 s
[2025-05-06T20:51:47.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:47.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: running: Set(ShuffleMapStage 236)
[2025-05-06T20:51:47.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 237, ResultStage 238)
[2025-05-06T20:51:47.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:47.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.18.0.4:45323 (size: 6.0 KiB, free: 181.2 MiB)
[2025-05-06T20:51:47.119+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:47.123+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 1.0 in stage 236.0 (TID 386) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.123+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 385) in 11 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:47.126+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T20:51:47.129+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 2.0 in stage 236.0 (TID 387) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.130+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 1.0 in stage 236.0 (TID 386) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:47.133+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T20:51:47.136+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 3.0 in stage 236.0 (TID 388) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 2.0 in stage 236.0 (TID 387) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:47.140+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:47.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 4.0 in stage 236.0 (TID 389) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 3.0 in stage 236.0 (TID 388) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:47.147+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:47.150+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 5.0 in stage 236.0 (TID 390) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.150+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 4.0 in stage 236.0 (TID 389) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:47.153+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:47.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 6.0 in stage 236.0 (TID 391) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 5.0 in stage 236.0 (TID 390) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:47.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:47.167+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 7.0 in stage 236.0 (TID 392) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.167+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 6.0 in stage 236.0 (TID 391) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:47.172+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T20:51:47.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 8.0 in stage 236.0 (TID 393) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 7.0 in stage 236.0 (TID 392) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:47.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T20:51:47.183+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 9.0 in stage 236.0 (TID 394) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.183+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 8.0 in stage 236.0 (TID 393) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:47.187+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_317_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:47.191+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 9.0 in stage 236.0 (TID 394) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:47.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool
[2025-05-06T20:51:47.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: ShuffleMapStage 236 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.218 s
[2025-05-06T20:51:47.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:47.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:47.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 237, ResultStage 238)
[2025-05-06T20:51:47.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:47.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: Submitting ShuffleMapStage 237 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[329] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:47.196+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 121.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:47.207+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:47.208+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 837932af135c:42719 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-05-06T20:51:47.208+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 837932af135c:42719 (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:47.208+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:47.208+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 237 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[329] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:47.208+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSchedulerImpl: Adding task set 237.0 with 10 tasks resource profile 0
[2025-05-06T20:51:47.209+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.18.0.4:45323 in memory (size: 5.9 KiB, free: 181.0 MiB)
[2025-05-06T20:51:47.209+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 0.0 in stage 237.0 (TID 395) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.214+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.18.0.4:45323 (size: 48.1 KiB, free: 181.0 MiB)
[2025-05-06T20:51:47.220+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.18.0.4:41314
[2025-05-06T20:51:47.224+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T20:51:47.224+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.18.0.4:41314
[2025-05-06T20:51:47.293+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 1.0 in stage 237.0 (TID 396) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.293+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 0.0 in stage 237.0 (TID 395) in 84 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:47.299+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T20:51:47.378+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 2.0 in stage 237.0 (TID 397) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.379+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 1.0 in stage 237.0 (TID 396) in 87 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:47.385+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T20:51:47.462+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 3.0 in stage 237.0 (TID 398) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.462+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 2.0 in stage 237.0 (TID 397) in 84 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:47.468+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T20:51:47.547+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 4.0 in stage 237.0 (TID 399) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 3.0 in stage 237.0 (TID 398) in 86 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:47.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T20:51:47.621+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 5.0 in stage 237.0 (TID 400) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.621+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 4.0 in stage 237.0 (TID 399) in 74 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:47.630+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T20:51:47.694+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 6.0 in stage 237.0 (TID 401) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.695+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 5.0 in stage 237.0 (TID 400) in 75 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:47.702+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T20:51:47.768+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 7.0 in stage 237.0 (TID 402) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.768+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 6.0 in stage 237.0 (TID 401) in 74 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:47.774+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T20:51:47.846+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 8.0 in stage 237.0 (TID 403) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.846+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 7.0 in stage 237.0 (TID 402) in 79 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:47.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T20:51:47.918+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Starting task 9.0 in stage 237.0 (TID 404) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:47.919+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO TaskSetManager: Finished task 8.0 in stage 237.0 (TID 403) in 72 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:47.925+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:47 INFO BlockManagerInfo: Added rdd_323_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T20:51:48.022+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 9.0 in stage 237.0 (TID 404) in 104 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:48.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSchedulerImpl: Removed TaskSet 237.0, whose tasks have all completed, from pool
[2025-05-06T20:51:48.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: ShuffleMapStage 237 (mapPartitions at GraphImpl.scala:208) finished in 0.829 s
[2025-05-06T20:51:48.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:48.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:48.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: waiting: Set(ResultStage 238)
[2025-05-06T20:51:48.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:48.023+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Submitting ResultStage 238 (MapPartitionsRDD[333] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:48.024+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 15.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:48.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 425.8 MiB)
[2025-05-06T20:51:48.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 837932af135c:42719 in memory (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:48.032+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 837932af135c:42719 (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T20:51:48.032+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:48.033+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.18.0.4:45323 in memory (size: 6.0 KiB, free: 175.6 MiB)
[2025-05-06T20:51:48.033+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 238 (MapPartitionsRDD[333] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:48.033+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSchedulerImpl: Adding task set 238.0 with 10 tasks resource profile 0
[2025-05-06T20:51:48.034+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 0.0 in stage 238.0 (TID 405) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.040+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.18.0.4:45323 (size: 6.2 KiB, free: 175.6 MiB)
[2025-05-06T20:51:48.043+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.18.0.4:41314
[2025-05-06T20:51:48.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_0 in memory on 172.18.0.4:45323 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:48.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 1.0 in stage 238.0 (TID 406) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 0.0 in stage 238.0 (TID 405) in 23 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:48.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_1 in memory on 172.18.0.4:45323 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T20:51:48.068+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 2.0 in stage 238.0 (TID 407) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.069+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 1.0 in stage 238.0 (TID 406) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:48.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_2 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:48.091+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 3.0 in stage 238.0 (TID 408) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.091+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 2.0 in stage 238.0 (TID 407) in 24 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:48.101+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_3 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:48.104+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 4.0 in stage 238.0 (TID 409) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.104+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 3.0 in stage 238.0 (TID 408) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:48.115+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_4 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:48.118+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 5.0 in stage 238.0 (TID 410) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.119+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 4.0 in stage 238.0 (TID 409) in 15 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:48.128+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_5 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:48.130+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 6.0 in stage 238.0 (TID 411) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.131+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 5.0 in stage 238.0 (TID 410) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:48.142+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_6 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T20:51:48.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 7.0 in stage 238.0 (TID 412) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 6.0 in stage 238.0 (TID 411) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:48.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_7 in memory on 172.18.0.4:45323 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T20:51:48.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 8.0 in stage 238.0 (TID 413) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.162+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 7.0 in stage 238.0 (TID 412) in 18 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:48.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_8 in memory on 172.18.0.4:45323 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T20:51:48.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 9.0 in stage 238.0 (TID 414) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 8.0 in stage 238.0 (TID 413) in 18 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:48.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_331_9 in memory on 172.18.0.4:45323 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T20:51:48.195+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 9.0 in stage 238.0 (TID 414) in 16 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:48.195+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool
[2025-05-06T20:51:48.196+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: ResultStage 238 (fold at VertexRDDImpl.scala:90) finished in 0.172 s
[2025-05-06T20:51:48.196+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:48.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 238: Stage finished
[2025-05-06T20:51:48.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Job 48 finished: fold at VertexRDDImpl.scala:90, took 1.243784 s
[2025-05-06T20:51:48.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO Pregel: Pregel finished iteration 5
[2025-05-06T20:51:48.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO ZippedPartitionsRDD2: Removing RDD 314 from persistence list
[2025-05-06T20:51:48.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManager: Removing RDD 314
[2025-05-06T20:51:48.199+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO ZippedPartitionsRDD2: Removing RDD 300 from persistence list
[2025-05-06T20:51:48.200+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO ZippedPartitionsRDD2: Removing RDD 306 from persistence list
[2025-05-06T20:51:48.204+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManager: Removing RDD 300
[2025-05-06T20:51:48.206+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManager: Removing RDD 306
[2025-05-06T20:51:48.213+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO ZippedPartitionsRDD2: Removing RDD 283 from persistence list
[2025-05-06T20:51:48.213+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManager: Removing RDD 283
[2025-05-06T20:51:48.214+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO ZippedPartitionsRDD2: Removing RDD 289 from persistence list
[2025-05-06T20:51:48.214+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManager: Removing RDD 289
[2025-05-06T20:51:48.224+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO ZippedPartitionsRDD2: Removing RDD 297 from persistence list
[2025-05-06T20:51:48.225+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManager: Removing RDD 297
[2025-05-06T20:51:48.232+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:48.236+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Registering RDD 342 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 49
[2025-05-06T20:51:48.238+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Registering RDD 338 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 48
[2025-05-06T20:51:48.238+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Registering RDD 346 (mapPartitions at GraphImpl.scala:208) as input to shuffle 50
[2025-05-06T20:51:48.238+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Got job 49 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:48.238+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Final stage: ResultStage 271 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:48.238+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 255, ShuffleMapStage 270, ShuffleMapStage 249, ShuffleMapStage 267, ShuffleMapStage 252, ShuffleMapStage 246, ShuffleMapStage 264, ShuffleMapStage 258, ShuffleMapStage 261, ShuffleMapStage 240)
[2025-05-06T20:51:48.240+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 270)
[2025-05-06T20:51:48.240+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Submitting ShuffleMapStage 268 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[342] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:48.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 14.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:48.264+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:48.264+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 837932af135c:42719 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:48.265+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:48.266+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 268 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[342] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:48.267+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSchedulerImpl: Adding task set 268.0 with 10 tasks resource profile 0
[2025-05-06T20:51:48.269+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 837932af135c:42719 in memory (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T20:51:48.272+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Submitting ShuffleMapStage 269 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:48.275+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 0.0 in stage 268.0 (TID 415) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.276+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 15.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:48.278+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 425.8 MiB)
[2025-05-06T20:51:48.279+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 837932af135c:42719 (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T20:51:48.280+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:48.281+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 269 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:48.282+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSchedulerImpl: Adding task set 269.0 with 10 tasks resource profile 0
[2025-05-06T20:51:48.284+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.18.0.4:45323 in memory (size: 6.2 KiB, free: 181.1 MiB)
[2025-05-06T20:51:48.299+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.18.0.4:45323 (size: 6.0 KiB, free: 181.1 MiB)
[2025-05-06T20:51:48.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 837932af135c:42719 in memory (size: 48.1 KiB, free: 434.3 MiB)
[2025-05-06T20:51:48.312+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.18.0.4:45323 in memory (size: 48.1 KiB, free: 181.2 MiB)
[2025-05-06T20:51:48.371+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 1.0 in stage 268.0 (TID 416) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.373+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 0.0 in stage 268.0 (TID 415) in 103 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:48.398+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 2.0 in stage 268.0 (TID 417) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.402+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 1.0 in stage 268.0 (TID 416) in 29 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:48.420+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 3.0 in stage 268.0 (TID 418) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.421+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 2.0 in stage 268.0 (TID 417) in 22 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:48.437+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 4.0 in stage 268.0 (TID 419) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.438+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 3.0 in stage 268.0 (TID 418) in 17 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:48.456+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 5.0 in stage 268.0 (TID 420) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.456+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 4.0 in stage 268.0 (TID 419) in 19 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:48.474+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 6.0 in stage 268.0 (TID 421) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.475+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 5.0 in stage 268.0 (TID 420) in 20 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:48.496+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 7.0 in stage 268.0 (TID 422) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 6.0 in stage 268.0 (TID 421) in 20 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:48.518+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 8.0 in stage 268.0 (TID 423) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.519+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 7.0 in stage 268.0 (TID 422) in 25 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:48.541+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 9.0 in stage 268.0 (TID 424) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.542+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 8.0 in stage 268.0 (TID 423) in 25 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:48.558+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 0.0 in stage 269.0 (TID 425) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.559+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 9.0 in stage 268.0 (TID 424) in 17 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:48.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool
[2025-05-06T20:51:48.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: ShuffleMapStage 268 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.318 s
[2025-05-06T20:51:48.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:48.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: running: Set(ShuffleMapStage 269)
[2025-05-06T20:51:48.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 270, ResultStage 271)
[2025-05-06T20:51:48.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:48.577+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.18.0.4:45323 (size: 6.2 KiB, free: 181.2 MiB)
[2025-05-06T20:51:48.583+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:48.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 1.0 in stage 269.0 (TID 426) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.589+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 0.0 in stage 269.0 (TID 425) in 30 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:48.594+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T20:51:48.597+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 2.0 in stage 269.0 (TID 427) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.598+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 1.0 in stage 269.0 (TID 426) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:48.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T20:51:48.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 3.0 in stage 269.0 (TID 428) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.609+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 2.0 in stage 269.0 (TID 427) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:48.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:48.616+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 4.0 in stage 269.0 (TID 429) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.617+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 3.0 in stage 269.0 (TID 428) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:48.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:48.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 5.0 in stage 269.0 (TID 430) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 4.0 in stage 269.0 (TID 429) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:48.631+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:48.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 6.0 in stage 269.0 (TID 431) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.636+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 5.0 in stage 269.0 (TID 430) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:48.641+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:48.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 7.0 in stage 269.0 (TID 432) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 6.0 in stage 269.0 (TID 431) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:48.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T20:51:48.654+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 8.0 in stage 269.0 (TID 433) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 7.0 in stage 269.0 (TID 432) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:48.660+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T20:51:48.665+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 9.0 in stage 269.0 (TID 434) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.665+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 8.0 in stage 269.0 (TID 433) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:48.673+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_334_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:48.677+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 9.0 in stage 269.0 (TID 434) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:48.678+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool
[2025-05-06T20:51:48.678+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: ShuffleMapStage 269 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.406 s
[2025-05-06T20:51:48.678+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:48.678+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:48.678+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 270, ResultStage 271)
[2025-05-06T20:51:48.678+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:48.678+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Submitting ShuffleMapStage 270 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[346] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:48.683+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 122.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:48.698+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 48.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:48.699+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 837932af135c:42719 (size: 48.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:48.700+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 837932af135c:42719 in memory (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:48.700+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:48.700+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 270 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[346] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:48.701+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSchedulerImpl: Adding task set 270.0 with 10 tasks resource profile 0
[2025-05-06T20:51:48.701+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 0.0 in stage 270.0 (TID 435) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.701+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.18.0.4:45323 in memory (size: 6.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:48.716+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.18.0.4:45323 (size: 48.3 KiB, free: 181.0 MiB)
[2025-05-06T20:51:48.729+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.18.0.4:41314
[2025-05-06T20:51:48.745+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_340_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T20:51:48.749+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.18.0.4:41314
[2025-05-06T20:51:48.861+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 1.0 in stage 270.0 (TID 436) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.862+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 0.0 in stage 270.0 (TID 435) in 164 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:48.876+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_340_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T20:51:48.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Starting task 2.0 in stage 270.0 (TID 437) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:48.977+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO TaskSetManager: Finished task 1.0 in stage 270.0 (TID 436) in 116 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:48.984+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:48 INFO BlockManagerInfo: Added rdd_340_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T20:51:49.069+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 3.0 in stage 270.0 (TID 438) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.069+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 2.0 in stage 270.0 (TID 437) in 92 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:49.077+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_340_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T20:51:49.149+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 4.0 in stage 270.0 (TID 439) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.149+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 3.0 in stage 270.0 (TID 438) in 81 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:49.156+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_340_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T20:51:49.212+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 5.0 in stage 270.0 (TID 440) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.213+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 4.0 in stage 270.0 (TID 439) in 64 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:49.220+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_340_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T20:51:49.283+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 6.0 in stage 270.0 (TID 441) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.283+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 5.0 in stage 270.0 (TID 440) in 71 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:49.291+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_340_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T20:51:49.355+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 7.0 in stage 270.0 (TID 442) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.356+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 6.0 in stage 270.0 (TID 441) in 73 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:49.362+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_340_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T20:51:49.435+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 8.0 in stage 270.0 (TID 443) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.435+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 7.0 in stage 270.0 (TID 442) in 80 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:49.443+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_340_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T20:51:49.508+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 9.0 in stage 270.0 (TID 444) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.509+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 8.0 in stage 270.0 (TID 443) in 73 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:49.515+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_340_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T20:51:49.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 9.0 in stage 270.0 (TID 444) in 82 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:49.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool
[2025-05-06T20:51:49.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: ShuffleMapStage 270 (mapPartitions at GraphImpl.scala:208) finished in 0.912 s
[2025-05-06T20:51:49.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:49.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:49.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: waiting: Set(ResultStage 271)
[2025-05-06T20:51:49.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:49.592+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[350] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:49.592+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 16.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:49.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:49.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 837932af135c:42719 in memory (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T20:51:49.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 837932af135c:42719 (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:49.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:49.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 271 (MapPartitionsRDD[350] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:49.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSchedulerImpl: Adding task set 271.0 with 10 tasks resource profile 0
[2025-05-06T20:51:49.600+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.18.0.4:45323 in memory (size: 6.2 KiB, free: 175.6 MiB)
[2025-05-06T20:51:49.600+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 0.0 in stage 271.0 (TID 445) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.18.0.4:45323 (size: 6.3 KiB, free: 175.6 MiB)
[2025-05-06T20:51:49.609+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.18.0.4:41314
[2025-05-06T20:51:49.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_0 in memory on 172.18.0.4:45323 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:49.616+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 1.0 in stage 271.0 (TID 446) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.616+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 0.0 in stage 271.0 (TID 445) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:49.624+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_1 in memory on 172.18.0.4:45323 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T20:51:49.626+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 2.0 in stage 271.0 (TID 447) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.626+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 1.0 in stage 271.0 (TID 446) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:49.634+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_2 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:49.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 3.0 in stage 271.0 (TID 448) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 2.0 in stage 271.0 (TID 447) in 19 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:49.653+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_3 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:49.654+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 4.0 in stage 271.0 (TID 449) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 3.0 in stage 271.0 (TID 448) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:49.664+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_4 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:49.665+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 5.0 in stage 271.0 (TID 450) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.666+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 4.0 in stage 271.0 (TID 449) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:49.674+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_5 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:49.676+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 6.0 in stage 271.0 (TID 451) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.676+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 5.0 in stage 271.0 (TID 450) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:49.686+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_6 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T20:51:49.688+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 7.0 in stage 271.0 (TID 452) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.689+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 6.0 in stage 271.0 (TID 451) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:49.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_7 in memory on 172.18.0.4:45323 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T20:51:49.699+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 8.0 in stage 271.0 (TID 453) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.699+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 7.0 in stage 271.0 (TID 452) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:49.709+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_8 in memory on 172.18.0.4:45323 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T20:51:49.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 9.0 in stage 271.0 (TID 454) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 8.0 in stage 271.0 (TID 453) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:49.721+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_348_9 in memory on 172.18.0.4:45323 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T20:51:49.724+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 9.0 in stage 271.0 (TID 454) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:49.724+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool
[2025-05-06T20:51:49.724+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: ResultStage 271 (fold at VertexRDDImpl.scala:90) finished in 0.132 s
[2025-05-06T20:51:49.724+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:49.724+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 271: Stage finished
[2025-05-06T20:51:49.725+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Job 49 finished: fold at VertexRDDImpl.scala:90, took 1.492814 s
[2025-05-06T20:51:49.725+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO Pregel: Pregel finished iteration 6
[2025-05-06T20:51:49.725+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO ZippedPartitionsRDD2: Removing RDD 331 from persistence list
[2025-05-06T20:51:49.726+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManager: Removing RDD 331
[2025-05-06T20:51:49.726+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO ZippedPartitionsRDD2: Removing RDD 317 from persistence list
[2025-05-06T20:51:49.726+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManager: Removing RDD 317
[2025-05-06T20:51:49.727+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO ZippedPartitionsRDD2: Removing RDD 323 from persistence list
[2025-05-06T20:51:49.727+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManager: Removing RDD 323
[2025-05-06T20:51:49.730+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO ZippedPartitionsRDD2: Removing RDD 300 from persistence list
[2025-05-06T20:51:49.731+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManager: Removing RDD 300
[2025-05-06T20:51:49.731+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO ZippedPartitionsRDD2: Removing RDD 306 from persistence list
[2025-05-06T20:51:49.731+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManager: Removing RDD 306
[2025-05-06T20:51:49.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO ZippedPartitionsRDD2: Removing RDD 314 from persistence list
[2025-05-06T20:51:49.735+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManager: Removing RDD 314
[2025-05-06T20:51:49.738+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:49.742+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Registering RDD 355 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 51
[2025-05-06T20:51:49.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Registering RDD 359 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 52
[2025-05-06T20:51:49.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Registering RDD 363 (mapPartitions at GraphImpl.scala:208) as input to shuffle 53
[2025-05-06T20:51:49.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Got job 50 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:49.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Final stage: ResultStage 307 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:49.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 291, ShuffleMapStage 288, ShuffleMapStage 306, ShuffleMapStage 303, ShuffleMapStage 300, ShuffleMapStage 285, ShuffleMapStage 273, ShuffleMapStage 282, ShuffleMapStage 279, ShuffleMapStage 297, ShuffleMapStage 294)
[2025-05-06T20:51:49.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 306)
[2025-05-06T20:51:49.744+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Submitting ShuffleMapStage 304 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[355] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:49.745+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 16.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:49.752+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:49.753+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 837932af135c:42719 in memory (size: 48.3 KiB, free: 434.3 MiB)
[2025-05-06T20:51:49.753+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 837932af135c:42719 (size: 6.3 KiB, free: 434.3 MiB)
[2025-05-06T20:51:49.753+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:49.754+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 304 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[355] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:49.754+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSchedulerImpl: Adding task set 304.0 with 10 tasks resource profile 0
[2025-05-06T20:51:49.754+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.18.0.4:45323 in memory (size: 48.3 KiB, free: 181.2 MiB)
[2025-05-06T20:51:49.754+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Submitting ShuffleMapStage 305 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[359] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:49.757+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 15.4 KiB, free 425.9 MiB)
[2025-05-06T20:51:49.759+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 455) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.760+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.9 MiB)
[2025-05-06T20:51:49.761+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 837932af135c:42719 (size: 6.1 KiB, free: 434.3 MiB)
[2025-05-06T20:51:49.762+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:49.762+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 305 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[359] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:49.762+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSchedulerImpl: Adding task set 305.0 with 10 tasks resource profile 0
[2025-05-06T20:51:49.762+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 837932af135c:42719 in memory (size: 6.3 KiB, free: 434.3 MiB)
[2025-05-06T20:51:49.763+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.18.0.4:45323 in memory (size: 6.3 KiB, free: 181.2 MiB)
[2025-05-06T20:51:49.765+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.18.0.4:45323 (size: 6.3 KiB, free: 181.2 MiB)
[2025-05-06T20:51:49.770+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:49.777+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 1.0 in stage 304.0 (TID 456) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 455) in 20 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:49.783+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T20:51:49.789+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 2.0 in stage 304.0 (TID 457) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.791+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 1.0 in stage 304.0 (TID 456) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:49.802+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T20:51:49.808+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 3.0 in stage 304.0 (TID 458) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.808+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 2.0 in stage 304.0 (TID 457) in 20 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:49.813+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:49.817+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 4.0 in stage 304.0 (TID 459) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.817+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 3.0 in stage 304.0 (TID 458) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:49.822+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:49.829+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 5.0 in stage 304.0 (TID 460) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.829+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 4.0 in stage 304.0 (TID 459) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:49.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:49.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 6.0 in stage 304.0 (TID 461) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 5.0 in stage 304.0 (TID 460) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:49.843+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:49.847+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 7.0 in stage 304.0 (TID 462) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.847+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 6.0 in stage 304.0 (TID 461) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:49.851+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T20:51:49.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 8.0 in stage 304.0 (TID 463) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 7.0 in stage 304.0 (TID 462) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:49.860+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T20:51:49.863+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 9.0 in stage 304.0 (TID 464) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.864+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 8.0 in stage 304.0 (TID 463) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:49.867+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added rdd_351_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:49.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 0.0 in stage 305.0 (TID 465) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 9.0 in stage 304.0 (TID 464) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:49.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool
[2025-05-06T20:51:49.872+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: ShuffleMapStage 304 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.128 s
[2025-05-06T20:51:49.873+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:49.873+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: running: Set(ShuffleMapStage 305)
[2025-05-06T20:51:49.873+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 306, ResultStage 307)
[2025-05-06T20:51:49.874+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:49.877+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.18.0.4:45323 (size: 6.1 KiB, free: 181.0 MiB)
[2025-05-06T20:51:49.887+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 1.0 in stage 305.0 (TID 466) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.887+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 0.0 in stage 305.0 (TID 465) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:49.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 2.0 in stage 305.0 (TID 467) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 1.0 in stage 305.0 (TID 466) in 14 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:49.912+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 3.0 in stage 305.0 (TID 468) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.912+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 2.0 in stage 305.0 (TID 467) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:49.921+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 4.0 in stage 305.0 (TID 469) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.921+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 3.0 in stage 305.0 (TID 468) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:49.932+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 5.0 in stage 305.0 (TID 470) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.932+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 4.0 in stage 305.0 (TID 469) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:49.942+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 6.0 in stage 305.0 (TID 471) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 5.0 in stage 305.0 (TID 470) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:49.951+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 7.0 in stage 305.0 (TID 472) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.952+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 6.0 in stage 305.0 (TID 471) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:49.962+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 8.0 in stage 305.0 (TID 473) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.962+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 7.0 in stage 305.0 (TID 472) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:49.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 9.0 in stage 305.0 (TID 474) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:49.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 8.0 in stage 305.0 (TID 473) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:49.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Finished task 9.0 in stage 305.0 (TID 474) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:49.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSchedulerImpl: Removed TaskSet 305.0, whose tasks have all completed, from pool
[2025-05-06T20:51:49.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: ShuffleMapStage 305 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.231 s
[2025-05-06T20:51:49.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:49.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:49.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 306, ResultStage 307)
[2025-05-06T20:51:49.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:49.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Submitting ShuffleMapStage 306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[363] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:49.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 122.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:49.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 837932af135c:42719 in memory (size: 6.3 KiB, free: 434.3 MiB)
[2025-05-06T20:51:49.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 48.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:49.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 837932af135c:42719 (size: 48.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:49.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:49.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[363] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:49.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSchedulerImpl: Adding task set 306.0 with 10 tasks resource profile 0
[2025-05-06T20:51:49.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.18.0.4:45323 in memory (size: 6.3 KiB, free: 181.0 MiB)
[2025-05-06T20:51:49.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:49 INFO TaskSetManager: Starting task 0.0 in stage 306.0 (TID 475) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.001+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.18.0.4:45323 (size: 48.4 KiB, free: 181.0 MiB)
[2025-05-06T20:51:50.009+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.18.0.4:41314
[2025-05-06T20:51:50.012+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T20:51:50.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.18.0.4:41314
[2025-05-06T20:51:50.085+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 1.0 in stage 306.0 (TID 476) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.085+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 0.0 in stage 306.0 (TID 475) in 88 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:50.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T20:51:50.178+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 2.0 in stage 306.0 (TID 477) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.178+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 1.0 in stage 306.0 (TID 476) in 93 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:50.184+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T20:51:50.260+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 3.0 in stage 306.0 (TID 478) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.260+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 2.0 in stage 306.0 (TID 477) in 83 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:50.266+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T20:51:50.333+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 4.0 in stage 306.0 (TID 479) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.333+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 3.0 in stage 306.0 (TID 478) in 74 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:50.340+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T20:51:50.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 5.0 in stage 306.0 (TID 480) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 4.0 in stage 306.0 (TID 479) in 64 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:50.403+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T20:51:50.466+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 6.0 in stage 306.0 (TID 481) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.466+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 5.0 in stage 306.0 (TID 480) in 70 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:50.471+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T20:51:50.535+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 7.0 in stage 306.0 (TID 482) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.535+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 6.0 in stage 306.0 (TID 481) in 70 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:50.547+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T20:51:50.618+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 8.0 in stage 306.0 (TID 483) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.619+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 7.0 in stage 306.0 (TID 482) in 83 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:50.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T20:51:50.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 9.0 in stage 306.0 (TID 484) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 8.0 in stage 306.0 (TID 483) in 79 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:50.703+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_357_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T20:51:50.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 9.0 in stage 306.0 (TID 484) in 83 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:50.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool
[2025-05-06T20:51:50.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: ShuffleMapStage 306 (mapPartitions at GraphImpl.scala:208) finished in 0.794 s
[2025-05-06T20:51:50.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:50.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:50.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: waiting: Set(ResultStage 307)
[2025-05-06T20:51:50.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:50.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Submitting ResultStage 307 (MapPartitionsRDD[367] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:50.781+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 16.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:50.786+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:50.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 837932af135c:42719 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:50.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 837932af135c:42719 (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:50.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:50.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 307 (MapPartitionsRDD[367] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:50.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSchedulerImpl: Adding task set 307.0 with 10 tasks resource profile 0
[2025-05-06T20:51:50.788+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.18.0.4:45323 in memory (size: 6.1 KiB, free: 175.6 MiB)
[2025-05-06T20:51:50.789+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 0.0 in stage 307.0 (TID 485) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.794+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.18.0.4:45323 (size: 6.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:50.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.18.0.4:41314
[2025-05-06T20:51:50.802+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_0 in memory on 172.18.0.4:45323 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:50.804+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 1.0 in stage 307.0 (TID 486) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.804+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 0.0 in stage 307.0 (TID 485) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:50.813+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_1 in memory on 172.18.0.4:45323 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T20:51:50.814+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 2.0 in stage 307.0 (TID 487) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.814+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 1.0 in stage 307.0 (TID 486) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:50.821+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_2 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:50.825+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 3.0 in stage 307.0 (TID 488) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 2.0 in stage 307.0 (TID 487) in 19 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:50.841+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_3 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:50.843+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 4.0 in stage 307.0 (TID 489) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.843+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 3.0 in stage 307.0 (TID 488) in 19 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:50.852+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_4 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:50.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 5.0 in stage 307.0 (TID 490) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 4.0 in stage 307.0 (TID 489) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:50.862+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_5 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:50.864+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 6.0 in stage 307.0 (TID 491) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.864+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 5.0 in stage 307.0 (TID 490) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:50.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_6 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T20:51:50.874+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 7.0 in stage 307.0 (TID 492) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.874+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 6.0 in stage 307.0 (TID 491) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:50.881+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_7 in memory on 172.18.0.4:45323 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T20:51:50.883+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 8.0 in stage 307.0 (TID 493) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.883+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 7.0 in stage 307.0 (TID 492) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:50.891+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_8 in memory on 172.18.0.4:45323 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T20:51:50.892+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 9.0 in stage 307.0 (TID 494) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.893+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 8.0 in stage 307.0 (TID 493) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:50.899+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added rdd_365_9 in memory on 172.18.0.4:45323 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T20:51:50.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 9.0 in stage 307.0 (TID 494) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:50.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSchedulerImpl: Removed TaskSet 307.0, whose tasks have all completed, from pool
[2025-05-06T20:51:50.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: ResultStage 307 (fold at VertexRDDImpl.scala:90) finished in 0.121 s
[2025-05-06T20:51:50.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:50.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 307: Stage finished
[2025-05-06T20:51:50.901+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Job 50 finished: fold at VertexRDDImpl.scala:90, took 1.163127 s
[2025-05-06T20:51:50.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO Pregel: Pregel finished iteration 7
[2025-05-06T20:51:50.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO ZippedPartitionsRDD2: Removing RDD 348 from persistence list
[2025-05-06T20:51:50.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManager: Removing RDD 348
[2025-05-06T20:51:50.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO ZippedPartitionsRDD2: Removing RDD 334 from persistence list
[2025-05-06T20:51:50.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManager: Removing RDD 334
[2025-05-06T20:51:50.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO ZippedPartitionsRDD2: Removing RDD 340 from persistence list
[2025-05-06T20:51:50.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManager: Removing RDD 340
[2025-05-06T20:51:50.909+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO ZippedPartitionsRDD2: Removing RDD 317 from persistence list
[2025-05-06T20:51:50.909+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManager: Removing RDD 317
[2025-05-06T20:51:50.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO ZippedPartitionsRDD2: Removing RDD 323 from persistence list
[2025-05-06T20:51:50.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManager: Removing RDD 323
[2025-05-06T20:51:50.914+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO ZippedPartitionsRDD2: Removing RDD 331 from persistence list
[2025-05-06T20:51:50.914+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManager: Removing RDD 331
[2025-05-06T20:51:50.918+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:50.923+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Registering RDD 376 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 55
[2025-05-06T20:51:50.923+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Registering RDD 372 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 54
[2025-05-06T20:51:50.923+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Registering RDD 380 (mapPartitions at GraphImpl.scala:208) as input to shuffle 56
[2025-05-06T20:51:50.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Got job 51 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:50.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Final stage: ResultStage 346 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:50.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 324, ShuffleMapStage 342, ShuffleMapStage 318, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 321, ShuffleMapStage 315, ShuffleMapStage 333, ShuffleMapStage 345, ShuffleMapStage 327, ShuffleMapStage 330, ShuffleMapStage 309)
[2025-05-06T20:51:50.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 345)
[2025-05-06T20:51:50.925+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Submitting ShuffleMapStage 343 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[376] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:50.926+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 16.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:50.933+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 425.8 MiB)
[2025-05-06T20:51:50.935+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 837932af135c:42719 (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T20:51:50.935+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 837932af135c:42719 in memory (size: 48.4 KiB, free: 434.3 MiB)
[2025-05-06T20:51:50.935+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:50.935+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 343 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[376] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:50.935+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSchedulerImpl: Adding task set 343.0 with 10 tasks resource profile 0
[2025-05-06T20:51:50.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Submitting ShuffleMapStage 344 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[372] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:50.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 0.0 in stage 343.0 (TID 495) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.18.0.4:45323 in memory (size: 48.4 KiB, free: 181.2 MiB)
[2025-05-06T20:51:50.939+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 16.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:50.941+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:50.941+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 837932af135c:42719 (size: 6.4 KiB, free: 434.3 MiB)
[2025-05-06T20:51:50.941+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:50.941+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 344 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[372] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:50.942+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSchedulerImpl: Adding task set 344.0 with 10 tasks resource profile 0
[2025-05-06T20:51:50.945+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 837932af135c:42719 in memory (size: 6.4 KiB, free: 434.3 MiB)
[2025-05-06T20:51:50.945+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.18.0.4:45323 in memory (size: 6.4 KiB, free: 181.2 MiB)
[2025-05-06T20:51:50.947+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.18.0.4:45323 (size: 6.2 KiB, free: 181.2 MiB)
[2025-05-06T20:51:50.964+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 1.0 in stage 343.0 (TID 496) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.964+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 0.0 in stage 343.0 (TID 495) in 28 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:50.983+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 2.0 in stage 343.0 (TID 497) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.984+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 1.0 in stage 343.0 (TID 496) in 20 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:50.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Starting task 3.0 in stage 343.0 (TID 498) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:50.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:50 INFO TaskSetManager: Finished task 2.0 in stage 343.0 (TID 497) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:51.009+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 4.0 in stage 343.0 (TID 499) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.009+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 3.0 in stage 343.0 (TID 498) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:51.019+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 5.0 in stage 343.0 (TID 500) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.019+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 4.0 in stage 343.0 (TID 499) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:51.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 6.0 in stage 343.0 (TID 501) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 5.0 in stage 343.0 (TID 500) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:51.042+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 7.0 in stage 343.0 (TID 502) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.042+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 6.0 in stage 343.0 (TID 501) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:51.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 8.0 in stage 343.0 (TID 503) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.058+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 7.0 in stage 343.0 (TID 502) in 15 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:51.072+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 9.0 in stage 343.0 (TID 504) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.073+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 8.0 in stage 343.0 (TID 503) in 16 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:51.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 0.0 in stage 344.0 (TID 505) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 9.0 in stage 343.0 (TID 504) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:51.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSchedulerImpl: Removed TaskSet 343.0, whose tasks have all completed, from pool
[2025-05-06T20:51:51.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: ShuffleMapStage 343 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.158 s
[2025-05-06T20:51:51.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:51.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: running: Set(ShuffleMapStage 344)
[2025-05-06T20:51:51.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 345, ResultStage 346)
[2025-05-06T20:51:51.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:51.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.18.0.4:45323 (size: 6.4 KiB, free: 181.2 MiB)
[2025-05-06T20:51:51.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:51.096+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 1.0 in stage 344.0 (TID 506) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.096+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 0.0 in stage 344.0 (TID 505) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:51.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 181.1 MiB)
[2025-05-06T20:51:51.102+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 2.0 in stage 344.0 (TID 507) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 1.0 in stage 344.0 (TID 506) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:51.107+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T20:51:51.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 3.0 in stage 344.0 (TID 508) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 2.0 in stage 344.0 (TID 507) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:51.114+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:51.117+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 4.0 in stage 344.0 (TID 509) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.117+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 3.0 in stage 344.0 (TID 508) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:51.120+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:51.125+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 5.0 in stage 344.0 (TID 510) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.125+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 4.0 in stage 344.0 (TID 509) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:51.128+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:51.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 6.0 in stage 344.0 (TID 511) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 5.0 in stage 344.0 (TID 510) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:51.136+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:51.141+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 7.0 in stage 344.0 (TID 512) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.142+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 6.0 in stage 344.0 (TID 511) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:51.145+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T20:51:51.150+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 8.0 in stage 344.0 (TID 513) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.150+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 7.0 in stage 344.0 (TID 512) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:51.153+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T20:51:51.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 9.0 in stage 344.0 (TID 514) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 8.0 in stage 344.0 (TID 513) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:51.162+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_368_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:51.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 9.0 in stage 344.0 (TID 514) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:51.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool
[2025-05-06T20:51:51.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: ShuffleMapStage 344 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.229 s
[2025-05-06T20:51:51.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:51.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:51.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 345, ResultStage 346)
[2025-05-06T20:51:51.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:51.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: Submitting ShuffleMapStage 345 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[380] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:51.168+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 122.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:51.178+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 837932af135c:42719 in memory (size: 6.2 KiB, free: 434.3 MiB)
[2025-05-06T20:51:51.178+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 48.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:51.178+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 837932af135c:42719 (size: 48.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:51.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:51.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 345 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[380] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:51.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSchedulerImpl: Adding task set 345.0 with 10 tasks resource profile 0
[2025-05-06T20:51:51.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.18.0.4:45323 in memory (size: 6.2 KiB, free: 181.0 MiB)
[2025-05-06T20:51:51.180+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 0.0 in stage 345.0 (TID 515) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.184+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.18.0.4:45323 (size: 48.4 KiB, free: 181.0 MiB)
[2025-05-06T20:51:51.191+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.18.0.4:41314
[2025-05-06T20:51:51.194+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T20:51:51.195+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.18.0.4:41314
[2025-05-06T20:51:51.280+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 1.0 in stage 345.0 (TID 516) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.280+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 0.0 in stage 345.0 (TID 515) in 101 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:51.286+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T20:51:51.367+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 2.0 in stage 345.0 (TID 517) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.367+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 1.0 in stage 345.0 (TID 516) in 87 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:51.375+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T20:51:51.445+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 3.0 in stage 345.0 (TID 518) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.445+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 2.0 in stage 345.0 (TID 517) in 79 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:51.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T20:51:51.520+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 4.0 in stage 345.0 (TID 519) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.520+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 3.0 in stage 345.0 (TID 518) in 76 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:51.528+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T20:51:51.582+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 5.0 in stage 345.0 (TID 520) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.582+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 4.0 in stage 345.0 (TID 519) in 63 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:51.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T20:51:51.674+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 6.0 in stage 345.0 (TID 521) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.674+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 5.0 in stage 345.0 (TID 520) in 92 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:51.681+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T20:51:51.747+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 7.0 in stage 345.0 (TID 522) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.747+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 6.0 in stage 345.0 (TID 521) in 72 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:51.753+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T20:51:51.825+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 8.0 in stage 345.0 (TID 523) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.825+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 7.0 in stage 345.0 (TID 522) in 79 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:51.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T20:51:51.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 9.0 in stage 345.0 (TID 524) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 8.0 in stage 345.0 (TID 523) in 77 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:51.908+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added rdd_374_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T20:51:51.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Finished task 9.0 in stage 345.0 (TID 524) in 76 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:51.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSchedulerImpl: Removed TaskSet 345.0, whose tasks have all completed, from pool
[2025-05-06T20:51:51.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: ShuffleMapStage 345 (mapPartitions at GraphImpl.scala:208) finished in 0.812 s
[2025-05-06T20:51:51.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:51.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:51.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: waiting: Set(ResultStage 346)
[2025-05-06T20:51:51.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:51.978+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: Submitting ResultStage 346 (MapPartitionsRDD[384] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:51.979+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 17.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:51.984+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:51.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 837932af135c:42719 in memory (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:51.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 837932af135c:42719 (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T20:51:51.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:51.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 346 (MapPartitionsRDD[384] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:51.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSchedulerImpl: Adding task set 346.0 with 10 tasks resource profile 0
[2025-05-06T20:51:51.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.18.0.4:45323 in memory (size: 6.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:51.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO TaskSetManager: Starting task 0.0 in stage 346.0 (TID 525) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:51.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.18.0.4:45323 (size: 6.5 KiB, free: 175.6 MiB)
[2025-05-06T20:51:51.992+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.18.0.4:41314
[2025-05-06T20:51:52.002+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_0 in memory on 172.18.0.4:45323 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:52.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 1.0 in stage 346.0 (TID 526) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 0.0 in stage 346.0 (TID 525) in 18 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:52.017+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_1 in memory on 172.18.0.4:45323 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T20:51:52.019+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 2.0 in stage 346.0 (TID 527) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.019+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 1.0 in stage 346.0 (TID 526) in 16 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:52.029+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_2 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:52.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 3.0 in stage 346.0 (TID 528) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 2.0 in stage 346.0 (TID 527) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:52.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_3 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:52.039+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 4.0 in stage 346.0 (TID 529) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.039+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 3.0 in stage 346.0 (TID 528) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:52.046+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_4 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:52.047+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 5.0 in stage 346.0 (TID 530) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.047+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 4.0 in stage 346.0 (TID 529) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:52.054+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_5 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:52.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 6.0 in stage 346.0 (TID 531) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 5.0 in stage 346.0 (TID 530) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:52.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_6 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T20:51:52.063+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 7.0 in stage 346.0 (TID 532) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 6.0 in stage 346.0 (TID 531) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:52.070+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_7 in memory on 172.18.0.4:45323 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T20:51:52.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 8.0 in stage 346.0 (TID 533) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 7.0 in stage 346.0 (TID 532) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:52.078+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_8 in memory on 172.18.0.4:45323 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T20:51:52.079+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 9.0 in stage 346.0 (TID 534) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.080+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 8.0 in stage 346.0 (TID 533) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:52.086+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_382_9 in memory on 172.18.0.4:45323 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T20:51:52.087+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 9.0 in stage 346.0 (TID 534) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:52.087+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool
[2025-05-06T20:51:52.087+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: ResultStage 346 (fold at VertexRDDImpl.scala:90) finished in 0.108 s
[2025-05-06T20:51:52.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:52.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 346: Stage finished
[2025-05-06T20:51:52.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Job 51 finished: fold at VertexRDDImpl.scala:90, took 1.169782 s
[2025-05-06T20:51:52.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO Pregel: Pregel finished iteration 8
[2025-05-06T20:51:52.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO ZippedPartitionsRDD2: Removing RDD 365 from persistence list
[2025-05-06T20:51:52.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManager: Removing RDD 365
[2025-05-06T20:51:52.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO ZippedPartitionsRDD2: Removing RDD 351 from persistence list
[2025-05-06T20:51:52.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManager: Removing RDD 351
[2025-05-06T20:51:52.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO ZippedPartitionsRDD2: Removing RDD 357 from persistence list
[2025-05-06T20:51:52.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManager: Removing RDD 357
[2025-05-06T20:51:52.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO ZippedPartitionsRDD2: Removing RDD 334 from persistence list
[2025-05-06T20:51:52.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManager: Removing RDD 334
[2025-05-06T20:51:52.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO ZippedPartitionsRDD2: Removing RDD 340 from persistence list
[2025-05-06T20:51:52.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManager: Removing RDD 340
[2025-05-06T20:51:52.096+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO ZippedPartitionsRDD2: Removing RDD 348 from persistence list
[2025-05-06T20:51:52.097+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManager: Removing RDD 348
[2025-05-06T20:51:52.100+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:52.102+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Registering RDD 389 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 57
[2025-05-06T20:51:52.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Registering RDD 393 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 58
[2025-05-06T20:51:52.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Registering RDD 397 (mapPartitions at GraphImpl.scala:208) as input to shuffle 59
[2025-05-06T20:51:52.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Got job 52 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:52.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Final stage: ResultStage 388 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:52.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 357, ShuffleMapStage 354, ShuffleMapStage 372, ShuffleMapStage 375, ShuffleMapStage 387, ShuffleMapStage 369, ShuffleMapStage 384, ShuffleMapStage 363, ShuffleMapStage 381, ShuffleMapStage 366, ShuffleMapStage 378, ShuffleMapStage 360, ShuffleMapStage 348)
[2025-05-06T20:51:52.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 387)
[2025-05-06T20:51:52.103+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Submitting ShuffleMapStage 385 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[389] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:52.104+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 17.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:52.109+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:52.110+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 837932af135c:42719 in memory (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T20:51:52.110+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 837932af135c:42719 (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T20:51:52.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.18.0.4:45323 in memory (size: 6.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:52.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:52.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 385 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[389] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:52.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSchedulerImpl: Adding task set 385.0 with 10 tasks resource profile 0
[2025-05-06T20:51:52.112+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Submitting ShuffleMapStage 386 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[393] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T20:51:52.112+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 0.0 in stage 385.0 (TID 535) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 16.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:52.114+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 837932af135c:42719 in memory (size: 48.4 KiB, free: 434.3 MiB)
[2025-05-06T20:51:52.115+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:52.115+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.18.0.4:45323 in memory (size: 48.4 KiB, free: 181.2 MiB)
[2025-05-06T20:51:52.115+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 837932af135c:42719 (size: 6.3 KiB, free: 434.3 MiB)
[2025-05-06T20:51:52.115+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:52.115+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 386 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[393] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:52.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSchedulerImpl: Adding task set 386.0 with 10 tasks resource profile 0
[2025-05-06T20:51:52.117+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.18.0.4:45323 (size: 6.5 KiB, free: 181.2 MiB)
[2025-05-06T20:51:52.122+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T20:51:52.125+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 1.0 in stage 385.0 (TID 536) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.125+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 0.0 in stage 385.0 (TID 535) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:52.130+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T20:51:52.133+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 2.0 in stage 385.0 (TID 537) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.134+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 1.0 in stage 385.0 (TID 536) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:52.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T20:51:52.140+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 3.0 in stage 385.0 (TID 538) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.140+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 2.0 in stage 385.0 (TID 537) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:52.152+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:52.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 4.0 in stage 385.0 (TID 539) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 3.0 in stage 385.0 (TID 538) in 16 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:52.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:52.162+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 5.0 in stage 385.0 (TID 540) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.163+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 4.0 in stage 385.0 (TID 539) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:52.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T20:51:52.170+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 6.0 in stage 385.0 (TID 541) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.170+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 5.0 in stage 385.0 (TID 540) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:52.173+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T20:51:52.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 7.0 in stage 385.0 (TID 542) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 6.0 in stage 385.0 (TID 541) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:52.181+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T20:51:52.184+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 8.0 in stage 385.0 (TID 543) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.184+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 7.0 in stage 385.0 (TID 542) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:52.187+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T20:51:52.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 9.0 in stage 385.0 (TID 544) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.191+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 8.0 in stage 385.0 (TID 543) in 6 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:52.194+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_385_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T20:51:52.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 0.0 in stage 386.0 (TID 545) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 9.0 in stage 385.0 (TID 544) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:52.199+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSchedulerImpl: Removed TaskSet 385.0, whose tasks have all completed, from pool
[2025-05-06T20:51:52.199+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: ShuffleMapStage 385 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.095 s
[2025-05-06T20:51:52.199+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:52.199+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: running: Set(ShuffleMapStage 386)
[2025-05-06T20:51:52.199+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 387, ResultStage 388)
[2025-05-06T20:51:52.199+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:52.202+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.18.0.4:45323 (size: 6.3 KiB, free: 181.0 MiB)
[2025-05-06T20:51:52.211+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 1.0 in stage 386.0 (TID 546) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.212+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 0.0 in stage 386.0 (TID 545) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:52.220+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 2.0 in stage 386.0 (TID 547) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.221+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 1.0 in stage 386.0 (TID 546) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:52.230+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 3.0 in stage 386.0 (TID 548) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.230+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 2.0 in stage 386.0 (TID 547) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:52.239+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 4.0 in stage 386.0 (TID 549) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.240+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 3.0 in stage 386.0 (TID 548) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:52.248+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 5.0 in stage 386.0 (TID 550) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.248+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 4.0 in stage 386.0 (TID 549) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:52.261+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 6.0 in stage 386.0 (TID 551) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.262+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 5.0 in stage 386.0 (TID 550) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:52.270+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 7.0 in stage 386.0 (TID 552) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.270+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 6.0 in stage 386.0 (TID 551) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:52.279+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 8.0 in stage 386.0 (TID 553) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.279+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 7.0 in stage 386.0 (TID 552) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:52.287+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 9.0 in stage 386.0 (TID 554) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.288+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 8.0 in stage 386.0 (TID 553) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:52.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 9.0 in stage 386.0 (TID 554) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:52.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool
[2025-05-06T20:51:52.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: ShuffleMapStage 386 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.185 s
[2025-05-06T20:51:52.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:52.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:52.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 387, ResultStage 388)
[2025-05-06T20:51:52.298+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:52.298+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Submitting ShuffleMapStage 387 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[397] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:52.300+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 123.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:52.307+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 837932af135c:42719 in memory (size: 6.5 KiB, free: 434.3 MiB)
[2025-05-06T20:51:52.307+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 48.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:52.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 837932af135c:42719 (size: 48.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:52.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:52.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 387 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[397] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:52.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSchedulerImpl: Adding task set 387.0 with 10 tasks resource profile 0
[2025-05-06T20:51:52.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.18.0.4:45323 in memory (size: 6.5 KiB, free: 181.0 MiB)
[2025-05-06T20:51:52.308+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 0.0 in stage 387.0 (TID 555) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.315+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.18.0.4:45323 (size: 48.6 KiB, free: 181.0 MiB)
[2025-05-06T20:51:52.323+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 172.18.0.4:41314
[2025-05-06T20:51:52.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_0 in memory on 172.18.0.4:45323 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T20:51:52.328+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.18.0.4:41314
[2025-05-06T20:51:52.400+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 1.0 in stage 387.0 (TID 556) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.400+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 0.0 in stage 387.0 (TID 555) in 92 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:52.408+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_1 in memory on 172.18.0.4:45323 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T20:51:52.490+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 2.0 in stage 387.0 (TID 557) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.491+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 1.0 in stage 387.0 (TID 556) in 91 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:52.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_2 in memory on 172.18.0.4:45323 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T20:51:52.570+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 3.0 in stage 387.0 (TID 558) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.571+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 2.0 in stage 387.0 (TID 557) in 81 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:52.580+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_3 in memory on 172.18.0.4:45323 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T20:51:52.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 4.0 in stage 387.0 (TID 559) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.650+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 3.0 in stage 387.0 (TID 558) in 79 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:52.656+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_4 in memory on 172.18.0.4:45323 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T20:51:52.710+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 5.0 in stage 387.0 (TID 560) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.710+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 4.0 in stage 387.0 (TID 559) in 61 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:52.716+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_5 in memory on 172.18.0.4:45323 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T20:51:52.777+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 6.0 in stage 387.0 (TID 561) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.777+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 5.0 in stage 387.0 (TID 560) in 67 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:52.783+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_6 in memory on 172.18.0.4:45323 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T20:51:52.843+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 7.0 in stage 387.0 (TID 562) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.844+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 6.0 in stage 387.0 (TID 561) in 67 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:52.849+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_7 in memory on 172.18.0.4:45323 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T20:51:52.918+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 8.0 in stage 387.0 (TID 563) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.919+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 7.0 in stage 387.0 (TID 562) in 75 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:52.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_8 in memory on 172.18.0.4:45323 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T20:51:52.987+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Starting task 9.0 in stage 387.0 (TID 564) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:52.988+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO TaskSetManager: Finished task 8.0 in stage 387.0 (TID 563) in 69 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:52.995+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:52 INFO BlockManagerInfo: Added rdd_391_9 in memory on 172.18.0.4:45323 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T20:51:53.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 9.0 in stage 387.0 (TID 564) in 77 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:53.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSchedulerImpl: Removed TaskSet 387.0, whose tasks have all completed, from pool
[2025-05-06T20:51:53.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: ShuffleMapStage 387 (mapPartitions at GraphImpl.scala:208) finished in 0.766 s
[2025-05-06T20:51:53.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:53.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:53.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: waiting: Set(ResultStage 388)
[2025-05-06T20:51:53.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:53.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Submitting ResultStage 388 (MapPartitionsRDD[401] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:53.066+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 18.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:53.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:53.072+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 837932af135c:42719 in memory (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:53.072+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 837932af135c:42719 (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:53.072+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:53.072+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 388 (MapPartitionsRDD[401] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:53.072+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSchedulerImpl: Adding task set 388.0 with 10 tasks resource profile 0
[2025-05-06T20:51:53.073+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.18.0.4:45323 in memory (size: 6.3 KiB, free: 175.6 MiB)
[2025-05-06T20:51:53.073+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 0.0 in stage 388.0 (TID 565) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.078+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.18.0.4:45323 (size: 6.6 KiB, free: 175.6 MiB)
[2025-05-06T20:51:53.081+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.18.0.4:41314
[2025-05-06T20:51:53.086+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_0 in memory on 172.18.0.4:45323 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T20:51:53.087+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 1.0 in stage 388.0 (TID 566) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 0.0 in stage 388.0 (TID 565) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:53.096+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_1 in memory on 172.18.0.4:45323 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T20:51:53.097+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 2.0 in stage 388.0 (TID 567) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.098+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 1.0 in stage 388.0 (TID 566) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:53.112+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_2 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:53.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 3.0 in stage 388.0 (TID 568) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.114+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 2.0 in stage 388.0 (TID 567) in 16 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:53.120+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_3 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T20:51:53.122+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 4.0 in stage 388.0 (TID 569) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.123+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 3.0 in stage 388.0 (TID 568) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:53.130+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_4 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:53.131+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 5.0 in stage 388.0 (TID 570) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.131+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 4.0 in stage 388.0 (TID 569) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:53.139+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_5 in memory on 172.18.0.4:45323 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T20:51:53.140+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 6.0 in stage 388.0 (TID 571) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.141+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 5.0 in stage 388.0 (TID 570) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:53.149+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_6 in memory on 172.18.0.4:45323 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T20:51:53.150+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 7.0 in stage 388.0 (TID 572) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.151+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 6.0 in stage 388.0 (TID 571) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:53.159+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_7 in memory on 172.18.0.4:45323 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T20:51:53.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 8.0 in stage 388.0 (TID 573) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 7.0 in stage 388.0 (TID 572) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:53.168+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_8 in memory on 172.18.0.4:45323 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T20:51:53.170+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 9.0 in stage 388.0 (TID 574) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.170+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 8.0 in stage 388.0 (TID 573) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:53.180+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_399_9 in memory on 172.18.0.4:45323 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T20:51:53.181+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 9.0 in stage 388.0 (TID 574) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:53.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSchedulerImpl: Removed TaskSet 388.0, whose tasks have all completed, from pool
[2025-05-06T20:51:53.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: ResultStage 388 (fold at VertexRDDImpl.scala:90) finished in 0.116 s
[2025-05-06T20:51:53.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:53.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 388: Stage finished
[2025-05-06T20:51:53.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Job 52 finished: fold at VertexRDDImpl.scala:90, took 1.082618 s
[2025-05-06T20:51:53.183+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO Pregel: Pregel finished iteration 9
[2025-05-06T20:51:53.183+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO ZippedPartitionsRDD2: Removing RDD 382 from persistence list
[2025-05-06T20:51:53.183+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManager: Removing RDD 382
[2025-05-06T20:51:53.183+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO ZippedPartitionsRDD2: Removing RDD 368 from persistence list
[2025-05-06T20:51:53.184+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManager: Removing RDD 368
[2025-05-06T20:51:53.184+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO ZippedPartitionsRDD2: Removing RDD 374 from persistence list
[2025-05-06T20:51:53.185+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManager: Removing RDD 374
[2025-05-06T20:51:53.186+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO ZippedPartitionsRDD2: Removing RDD 365 from persistence list
[2025-05-06T20:51:53.186+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManager: Removing RDD 365
[2025-05-06T20:51:53.187+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO ZippedPartitionsRDD2: Removing RDD 382 from persistence list
[2025-05-06T20:51:53.187+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManager: Removing RDD 382
[2025-05-06T20:51:53.187+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO ZippedPartitionsRDD2: Removing RDD 399 from persistence list
[2025-05-06T20:51:53.188+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManager: Removing RDD 399
[2025-05-06T20:51:53.480+0000] {spark_submit.py:571} INFO - 2025-05-06 20:51:53,480 [INFO] Вычисляем PageRank для определения влиятельности клиентов
[2025-05-06T20:51:53.526+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:53.526+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Registering RDD 404 (mapPartitions at GraphImpl.scala:208) as input to shuffle 61
[2025-05-06T20:51:53.527+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Registering RDD 412 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 60
[2025-05-06T20:51:53.527+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Registering RDD 422 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 62
[2025-05-06T20:51:53.527+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Registering RDD 426 (mapPartitions at GraphImpl.scala:208) as input to shuffle 64
[2025-05-06T20:51:53.527+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Registering RDD 434 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 63
[2025-05-06T20:51:53.527+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Got job 53 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:53.527+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Final stage: ResultStage 402 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:53.527+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 389, ShuffleMapStage 401, ShuffleMapStage 394, ShuffleMapStage 398, ShuffleMapStage 399)
[2025-05-06T20:51:53.528+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 401, ShuffleMapStage 398, ShuffleMapStage 399)
[2025-05-06T20:51:53.531+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Submitting ShuffleMapStage 396 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[404] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:53.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 117.8 KiB, free 425.7 MiB)
[2025-05-06T20:51:53.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 425.6 MiB)
[2025-05-06T20:51:53.550+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 837932af135c:42719 (size: 46.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:53.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:53.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 396 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[404] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:53.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSchedulerImpl: Adding task set 396.0 with 10 tasks resource profile 0
[2025-05-06T20:51:53.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 837932af135c:42719 in memory (size: 48.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:53.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 0.0 in stage 396.0 (TID 575) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.555+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.18.0.4:45323 in memory (size: 48.6 KiB, free: 181.5 MiB)
[2025-05-06T20:51:53.561+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManager: Removing RDD 399
[2025-05-06T20:51:53.563+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.18.0.4:45323 (size: 46.9 KiB, free: 181.5 MiB)
[2025-05-06T20:51:53.564+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 837932af135c:42719 in memory (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:53.566+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.18.0.4:45323 in memory (size: 6.6 KiB, free: 181.5 MiB)
[2025-05-06T20:51:53.619+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 1.0 in stage 396.0 (TID 576) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.620+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 0.0 in stage 396.0 (TID 575) in 67 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:53.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 2.0 in stage 396.0 (TID 577) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 1.0 in stage 396.0 (TID 576) in 36 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:53.695+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 3.0 in stage 396.0 (TID 578) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.696+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 2.0 in stage 396.0 (TID 577) in 41 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:53.756+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 4.0 in stage 396.0 (TID 579) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.756+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 3.0 in stage 396.0 (TID 578) in 66 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:53.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 5.0 in stage 396.0 (TID 580) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 4.0 in stage 396.0 (TID 579) in 25 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:53.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 6.0 in stage 396.0 (TID 581) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 5.0 in stage 396.0 (TID 580) in 19 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:53.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 7.0 in stage 396.0 (TID 582) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.816+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 6.0 in stage 396.0 (TID 581) in 17 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:53.838+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 8.0 in stage 396.0 (TID 583) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.839+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 7.0 in stage 396.0 (TID 582) in 23 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:53.860+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 9.0 in stage 396.0 (TID 584) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.861+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 8.0 in stage 396.0 (TID 583) in 24 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:53.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 9.0 in stage 396.0 (TID 584) in 17 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:53.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSchedulerImpl: Removed TaskSet 396.0, whose tasks have all completed, from pool
[2025-05-06T20:51:53.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: ShuffleMapStage 396 (mapPartitions at GraphImpl.scala:208) finished in 0.349 s
[2025-05-06T20:51:53.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:53.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:53.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ShuffleMapStage 398, ResultStage 402, ShuffleMapStage 399, ShuffleMapStage 400)
[2025-05-06T20:51:53.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:53.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Submitting ShuffleMapStage 398 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[412] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:53.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 10.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:53.892+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:53.893+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManager: Removing RDD 391
[2025-05-06T20:51:53.894+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 837932af135c:42719 (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:53.894+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:53.894+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 398 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[412] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:53.895+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSchedulerImpl: Adding task set 398.0 with 10 tasks resource profile 0
[2025-05-06T20:51:53.895+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Submitting ShuffleMapStage 399 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[422] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:53.895+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 0.0 in stage 398.0 (TID 585) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.897+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 10.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:53.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:53.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 837932af135c:42719 (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:53.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:53.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 399 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[422] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:53.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSchedulerImpl: Adding task set 399.0 with 10 tasks resource profile 0
[2025-05-06T20:51:53.903+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.18.0.4:45323 (size: 5.0 KiB, free: 186.9 MiB)
[2025-05-06T20:51:53.922+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.18.0.4:41314
[2025-05-06T20:51:53.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_408_0 in memory on 172.18.0.4:45323 (size: 13.9 KiB, free: 186.8 MiB)
[2025-05-06T20:51:53.951+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 1.0 in stage 398.0 (TID 586) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.952+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 0.0 in stage 398.0 (TID 585) in 56 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:53.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_408_1 in memory on 172.18.0.4:45323 (size: 13.8 KiB, free: 186.8 MiB)
[2025-05-06T20:51:53.965+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 2.0 in stage 398.0 (TID 587) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.965+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 1.0 in stage 398.0 (TID 586) in 14 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:53.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_408_2 in memory on 172.18.0.4:45323 (size: 13.6 KiB, free: 186.8 MiB)
[2025-05-06T20:51:53.979+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 3.0 in stage 398.0 (TID 588) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.979+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 2.0 in stage 398.0 (TID 587) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:53.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_408_3 in memory on 172.18.0.4:45323 (size: 13.5 KiB, free: 186.8 MiB)
[2025-05-06T20:51:53.991+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Starting task 4.0 in stage 398.0 (TID 589) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:53.991+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO TaskSetManager: Finished task 3.0 in stage 398.0 (TID 588) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:53.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:53 INFO BlockManagerInfo: Added rdd_408_4 in memory on 172.18.0.4:45323 (size: 13.7 KiB, free: 186.8 MiB)
[2025-05-06T20:51:54.001+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 5.0 in stage 398.0 (TID 590) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.001+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 4.0 in stage 398.0 (TID 589) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:54.009+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_408_5 in memory on 172.18.0.4:45323 (size: 13.7 KiB, free: 186.8 MiB)
[2025-05-06T20:51:54.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 6.0 in stage 398.0 (TID 591) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.014+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 5.0 in stage 398.0 (TID 590) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:54.019+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_408_6 in memory on 172.18.0.4:45323 (size: 13.5 KiB, free: 186.8 MiB)
[2025-05-06T20:51:54.025+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 7.0 in stage 398.0 (TID 592) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.026+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 6.0 in stage 398.0 (TID 591) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:54.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_408_7 in memory on 172.18.0.4:45323 (size: 13.4 KiB, free: 186.7 MiB)
[2025-05-06T20:51:54.036+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 8.0 in stage 398.0 (TID 593) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.037+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 7.0 in stage 398.0 (TID 592) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:54.044+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_408_8 in memory on 172.18.0.4:45323 (size: 13.3 KiB, free: 186.7 MiB)
[2025-05-06T20:51:54.048+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 9.0 in stage 398.0 (TID 594) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.048+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 8.0 in stage 398.0 (TID 593) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:54.053+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_408_9 in memory on 172.18.0.4:45323 (size: 13.0 KiB, free: 186.7 MiB)
[2025-05-06T20:51:54.063+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 0.0 in stage 399.0 (TID 595) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.063+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 9.0 in stage 398.0 (TID 594) in 16 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:54.063+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSchedulerImpl: Removed TaskSet 398.0, whose tasks have all completed, from pool
[2025-05-06T20:51:54.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: ShuffleMapStage 398 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.184 s
[2025-05-06T20:51:54.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:54.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: running: Set(ShuffleMapStage 399)
[2025-05-06T20:51:54.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ResultStage 402, ShuffleMapStage 400)
[2025-05-06T20:51:54.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:54.067+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.18.0.4:45323 (size: 5.3 KiB, free: 186.7 MiB)
[2025-05-06T20:51:54.076+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 186.7 MiB)
[2025-05-06T20:51:54.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 1.0 in stage 399.0 (TID 596) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 0.0 in stage 399.0 (TID 595) in 21 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:54.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 186.7 MiB)
[2025-05-06T20:51:54.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 2.0 in stage 399.0 (TID 597) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 1.0 in stage 399.0 (TID 596) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:54.097+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 186.7 MiB)
[2025-05-06T20:51:54.101+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 3.0 in stage 399.0 (TID 598) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.101+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 2.0 in stage 399.0 (TID 597) in 8 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:54.105+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 186.7 MiB)
[2025-05-06T20:51:54.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 4.0 in stage 399.0 (TID 599) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.111+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 3.0 in stage 399.0 (TID 598) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:54.114+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 186.6 MiB)
[2025-05-06T20:51:54.121+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 5.0 in stage 399.0 (TID 600) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.122+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 4.0 in stage 399.0 (TID 599) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:54.127+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 186.6 MiB)
[2025-05-06T20:51:54.131+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 6.0 in stage 399.0 (TID 601) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 5.0 in stage 399.0 (TID 600) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:54.136+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 186.6 MiB)
[2025-05-06T20:51:54.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 7.0 in stage 399.0 (TID 602) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 6.0 in stage 399.0 (TID 601) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:54.148+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 186.6 MiB)
[2025-05-06T20:51:54.154+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 8.0 in stage 399.0 (TID 603) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 7.0 in stage 399.0 (TID 602) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:54.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 186.6 MiB)
[2025-05-06T20:51:54.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 9.0 in stage 399.0 (TID 604) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 8.0 in stage 399.0 (TID 603) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:54.170+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_418_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 186.6 MiB)
[2025-05-06T20:51:54.175+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 9.0 in stage 399.0 (TID 604) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:54.175+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool
[2025-05-06T20:51:54.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: ShuffleMapStage 399 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.280 s
[2025-05-06T20:51:54.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:54.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:54.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ResultStage 402, ShuffleMapStage 400)
[2025-05-06T20:51:54.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:54.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: Submitting ShuffleMapStage 400 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[426] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:54.181+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 120.2 KiB, free 425.7 MiB)
[2025-05-06T20:51:54.195+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 837932af135c:42719 in memory (size: 46.9 KiB, free: 434.3 MiB)
[2025-05-06T20:51:54.195+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 47.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:54.196+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 837932af135c:42719 (size: 47.5 KiB, free: 434.2 MiB)
[2025-05-06T20:51:54.196+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:54.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 400 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[426] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:54.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSchedulerImpl: Adding task set 400.0 with 10 tasks resource profile 0
[2025-05-06T20:51:54.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.18.0.4:45323 in memory (size: 46.9 KiB, free: 186.6 MiB)
[2025-05-06T20:51:54.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 0.0 in stage 400.0 (TID 605) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.199+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 837932af135c:42719 in memory (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:54.200+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.18.0.4:45323 in memory (size: 5.0 KiB, free: 186.6 MiB)
[2025-05-06T20:51:54.205+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.18.0.4:45323 (size: 47.5 KiB, free: 186.6 MiB)
[2025-05-06T20:51:54.216+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_0 in memory on 172.18.0.4:45323 (size: 494.4 KiB, free: 186.1 MiB)
[2025-05-06T20:51:54.217+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 172.18.0.4:41314
[2025-05-06T20:51:54.249+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 185.5 MiB)
[2025-05-06T20:51:54.250+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.18.0.4:41314
[2025-05-06T20:51:54.280+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 1.0 in stage 400.0 (TID 606) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.280+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 0.0 in stage 400.0 (TID 605) in 83 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:54.288+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_1 in memory on 172.18.0.4:45323 (size: 618.0 KiB, free: 184.9 MiB)
[2025-05-06T20:51:54.295+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 184.1 MiB)
[2025-05-06T20:51:54.318+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 2.0 in stage 400.0 (TID 607) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.318+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 1.0 in stage 400.0 (TID 606) in 38 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:54.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_2 in memory on 172.18.0.4:45323 (size: 559.2 KiB, free: 183.5 MiB)
[2025-05-06T20:51:54.335+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 182.8 MiB)
[2025-05-06T20:51:54.360+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 3.0 in stage 400.0 (TID 608) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.360+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 2.0 in stage 400.0 (TID 607) in 42 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:54.370+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_3 in memory on 172.18.0.4:45323 (size: 535.8 KiB, free: 182.3 MiB)
[2025-05-06T20:51:54.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 181.6 MiB)
[2025-05-06T20:51:54.396+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 4.0 in stage 400.0 (TID 609) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.396+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 3.0 in stage 400.0 (TID 608) in 37 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:54.408+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_4 in memory on 172.18.0.4:45323 (size: 448.0 KiB, free: 181.2 MiB)
[2025-05-06T20:51:54.414+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 180.6 MiB)
[2025-05-06T20:51:54.428+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 5.0 in stage 400.0 (TID 610) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.428+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 4.0 in stage 400.0 (TID 609) in 32 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:54.437+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_5 in memory on 172.18.0.4:45323 (size: 522.5 KiB, free: 180.1 MiB)
[2025-05-06T20:51:54.444+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 179.4 MiB)
[2025-05-06T20:51:54.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 6.0 in stage 400.0 (TID 611) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 5.0 in stage 400.0 (TID 610) in 34 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:54.474+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_6 in memory on 172.18.0.4:45323 (size: 529.8 KiB, free: 178.9 MiB)
[2025-05-06T20:51:54.480+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 178.3 MiB)
[2025-05-06T20:51:54.509+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 7.0 in stage 400.0 (TID 612) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 6.0 in stage 400.0 (TID 611) in 48 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:54.521+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_7 in memory on 172.18.0.4:45323 (size: 596.6 KiB, free: 177.7 MiB)
[2025-05-06T20:51:54.529+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 176.9 MiB)
[2025-05-06T20:51:54.545+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 8.0 in stage 400.0 (TID 613) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.546+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 7.0 in stage 400.0 (TID 612) in 38 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:54.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_8 in memory on 172.18.0.4:45323 (size: 544.3 KiB, free: 176.4 MiB)
[2025-05-06T20:51:54.562+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 175.7 MiB)
[2025-05-06T20:51:54.580+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 9.0 in stage 400.0 (TID 614) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.580+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 8.0 in stage 400.0 (TID 613) in 35 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:54.588+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_410_9 in memory on 172.18.0.4:45323 (size: 610.2 KiB, free: 175.1 MiB)
[2025-05-06T20:51:54.594+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_420_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:54.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 9.0 in stage 400.0 (TID 614) in 28 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:54.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSchedulerImpl: Removed TaskSet 400.0, whose tasks have all completed, from pool
[2025-05-06T20:51:54.609+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: ShuffleMapStage 400 (mapPartitions at GraphImpl.scala:208) finished in 0.432 s
[2025-05-06T20:51:54.610+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:54.610+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:54.610+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ResultStage 402)
[2025-05-06T20:51:54.610+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:54.611+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: Submitting ShuffleMapStage 401 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[434] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:54.612+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 12.0 KiB, free 425.8 MiB)
[2025-05-06T20:51:54.634+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:54.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 837932af135c:42719 (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:54.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:54.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 401 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[434] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:54.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSchedulerImpl: Adding task set 401.0 with 10 tasks resource profile 0
[2025-05-06T20:51:54.639+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 837932af135c:42719 in memory (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:54.640+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 0.0 in stage 401.0 (TID 615) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.657+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.18.0.4:45323 in memory (size: 5.3 KiB, free: 174.3 MiB)
[2025-05-06T20:51:54.663+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.18.0.4:45323 (size: 5.7 KiB, free: 174.3 MiB)
[2025-05-06T20:51:54.675+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.18.0.4:41314
[2025-05-06T20:51:54.692+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:54.729+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 1.0 in stage 401.0 (TID 616) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.730+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 0.0 in stage 401.0 (TID 615) in 90 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:54.737+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:54.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 2.0 in stage 401.0 (TID 617) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.744+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 1.0 in stage 401.0 (TID 616) in 16 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:54.752+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:54.758+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 3.0 in stage 401.0 (TID 618) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.759+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 2.0 in stage 401.0 (TID 617) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:54.766+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:54.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 4.0 in stage 401.0 (TID 619) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 3.0 in stage 401.0 (TID 618) in 20 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:54.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:54.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 5.0 in stage 401.0 (TID 620) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.791+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 4.0 in stage 401.0 (TID 619) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:54.798+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:54.803+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 6.0 in stage 401.0 (TID 621) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.804+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 5.0 in stage 401.0 (TID 620) in 15 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:54.811+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:54.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 7.0 in stage 401.0 (TID 622) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 6.0 in stage 401.0 (TID 621) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:54.822+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:54.826+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 8.0 in stage 401.0 (TID 623) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.827+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 7.0 in stage 401.0 (TID 622) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:54.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:54.836+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 9.0 in stage 401.0 (TID 624) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 8.0 in stage 401.0 (TID 623) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:54.843+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_430_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:54.848+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 9.0 in stage 401.0 (TID 624) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:54.848+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSchedulerImpl: Removed TaskSet 401.0, whose tasks have all completed, from pool
[2025-05-06T20:51:54.848+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: ShuffleMapStage 401 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.237 s
[2025-05-06T20:51:54.848+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:54.848+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:54.848+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: waiting: Set(ResultStage 402)
[2025-05-06T20:51:54.849+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:54.849+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: Submitting ResultStage 402 (EdgeRDDImpl[437] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:54.851+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 120.0 KiB, free 425.7 MiB)
[2025-05-06T20:51:54.864+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 837932af135c:42719 in memory (size: 47.5 KiB, free: 434.3 MiB)
[2025-05-06T20:51:54.864+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 47.4 KiB, free 425.7 MiB)
[2025-05-06T20:51:54.864+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 837932af135c:42719 (size: 47.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:54.865+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:54.865+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 402 (EdgeRDDImpl[437] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:54.865+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSchedulerImpl: Adding task set 402.0 with 10 tasks resource profile 0
[2025-05-06T20:51:54.866+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 0.0 in stage 402.0 (TID 625) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.868+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.18.0.4:45323 in memory (size: 47.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:54.876+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.18.0.4:45323 (size: 47.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:54.887+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.18.0.4:41314
[2025-05-06T20:51:54.889+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 63 to 172.18.0.4:41314
[2025-05-06T20:51:54.896+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_436_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:54.900+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 1.0 in stage 402.0 (TID 626) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 0.0 in stage 402.0 (TID 625) in 35 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:54.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_436_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T20:51:54.932+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 2.0 in stage 402.0 (TID 627) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.932+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 1.0 in stage 402.0 (TID 626) in 32 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:54.945+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_436_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:54.948+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 3.0 in stage 402.0 (TID 628) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.949+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 2.0 in stage 402.0 (TID 627) in 16 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:54.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_436_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T20:51:54.963+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 4.0 in stage 402.0 (TID 629) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.963+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 3.0 in stage 402.0 (TID 628) in 15 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:54.971+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_436_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:54.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 5.0 in stage 402.0 (TID 630) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.974+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 4.0 in stage 402.0 (TID 629) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:54.983+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_436_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:54.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 6.0 in stage 402.0 (TID 631) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 5.0 in stage 402.0 (TID 630) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:54.994+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO BlockManagerInfo: Added rdd_436_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T20:51:54.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Starting task 7.0 in stage 402.0 (TID 632) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:54.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:54 INFO TaskSetManager: Finished task 6.0 in stage 402.0 (TID 631) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:55.006+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_436_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:55.007+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 8.0 in stage 402.0 (TID 633) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.008+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 7.0 in stage 402.0 (TID 632) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:55.020+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_436_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:55.022+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 9.0 in stage 402.0 (TID 634) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.022+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 8.0 in stage 402.0 (TID 633) in 15 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:55.034+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_436_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:55.036+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 9.0 in stage 402.0 (TID 634) in 15 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:55.037+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool
[2025-05-06T20:51:55.037+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: ResultStage 402 (foreachPartition at PageRank.scala:199) finished in 0.187 s
[2025-05-06T20:51:55.037+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:55.037+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 402: Stage finished
[2025-05-06T20:51:55.037+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Job 53 finished: foreachPartition at PageRank.scala:199, took 1.511599 s
[2025-05-06T20:51:55.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO PageRank: PageRank finished iteration 0.
[2025-05-06T20:51:55.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MapPartitionsRDD: Removing RDD 418 from persistence list
[2025-05-06T20:51:55.039+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManager: Removing RDD 418
[2025-05-06T20:51:55.039+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MapPartitionsRDD: Removing RDD 420 from persistence list
[2025-05-06T20:51:55.039+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManager: Removing RDD 420
[2025-05-06T20:51:55.049+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:55.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Registering RDD 438 (mapPartitions at GraphImpl.scala:208) as input to shuffle 66
[2025-05-06T20:51:55.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Registering RDD 446 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 65
[2025-05-06T20:51:55.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Got job 54 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:55.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Final stage: ResultStage 418 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:55.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 408, ShuffleMapStage 412, ShuffleMapStage 413, ShuffleMapStage 417, ShuffleMapStage 403, ShuffleMapStage 415)
[2025-05-06T20:51:55.051+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 417)
[2025-05-06T20:51:55.051+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting ShuffleMapStage 416 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[438] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:55.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 120.5 KiB, free 425.7 MiB)
[2025-05-06T20:51:55.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 47.8 KiB, free 425.6 MiB)
[2025-05-06T20:51:55.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 837932af135c:42719 in memory (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 837932af135c:42719 (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.18.0.4:45323 in memory (size: 5.7 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.066+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:55.066+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 416 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[438] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:55.066+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Adding task set 416.0 with 10 tasks resource profile 0
[2025-05-06T20:51:55.067+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 0.0 in stage 416.0 (TID 635) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.068+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 837932af135c:42719 in memory (size: 47.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.069+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.18.0.4:45323 in memory (size: 47.4 KiB, free: 174.4 MiB)
[2025-05-06T20:51:55.073+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.18.0.4:45323 (size: 47.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.087+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 1.0 in stage 416.0 (TID 636) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.087+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 0.0 in stage 416.0 (TID 635) in 20 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:55.113+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 2.0 in stage 416.0 (TID 637) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.114+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 1.0 in stage 416.0 (TID 636) in 26 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:55.127+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 3.0 in stage 416.0 (TID 638) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.127+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 2.0 in stage 416.0 (TID 637) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:55.140+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 4.0 in stage 416.0 (TID 639) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.141+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 3.0 in stage 416.0 (TID 638) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:55.153+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 5.0 in stage 416.0 (TID 640) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.154+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 4.0 in stage 416.0 (TID 639) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:55.169+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 6.0 in stage 416.0 (TID 641) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.169+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 5.0 in stage 416.0 (TID 640) in 16 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:55.185+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 7.0 in stage 416.0 (TID 642) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.185+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 6.0 in stage 416.0 (TID 641) in 16 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:55.199+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 8.0 in stage 416.0 (TID 643) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.200+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 7.0 in stage 416.0 (TID 642) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:55.217+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 9.0 in stage 416.0 (TID 644) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.217+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 8.0 in stage 416.0 (TID 643) in 18 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:55.230+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 9.0 in stage 416.0 (TID 644) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:55.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Removed TaskSet 416.0, whose tasks have all completed, from pool
[2025-05-06T20:51:55.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: ShuffleMapStage 416 (mapPartitions at GraphImpl.scala:208) finished in 0.179 s
[2025-05-06T20:51:55.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:55.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:55.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 417, ResultStage 418)
[2025-05-06T20:51:55.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:55.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting ShuffleMapStage 417 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[446] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:55.232+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 12.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:55.233+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T20:51:55.233+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 837932af135c:42719 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.233+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:55.233+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 417 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[446] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:55.233+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Adding task set 417.0 with 10 tasks resource profile 0
[2025-05-06T20:51:55.234+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 0.0 in stage 417.0 (TID 645) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.237+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.18.0.4:45323 (size: 5.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.239+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 66 to 172.18.0.4:41314
[2025-05-06T20:51:55.242+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.245+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 1.0 in stage 417.0 (TID 646) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.246+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 0.0 in stage 417.0 (TID 645) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:55.250+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.253+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 2.0 in stage 417.0 (TID 647) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.254+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 1.0 in stage 417.0 (TID 646) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:55.258+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.261+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 3.0 in stage 417.0 (TID 648) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.262+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 2.0 in stage 417.0 (TID 647) in 8 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:55.266+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.269+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 4.0 in stage 417.0 (TID 649) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.269+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 3.0 in stage 417.0 (TID 648) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:55.274+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.280+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 5.0 in stage 417.0 (TID 650) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.280+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 4.0 in stage 417.0 (TID 649) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:55.285+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.291+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 6.0 in stage 417.0 (TID 651) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.292+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 5.0 in stage 417.0 (TID 650) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:55.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.300+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 7.0 in stage 417.0 (TID 652) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.300+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 6.0 in stage 417.0 (TID 651) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:55.305+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.310+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 8.0 in stage 417.0 (TID 653) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.310+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 7.0 in stage 417.0 (TID 652) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:55.314+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.318+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 9.0 in stage 417.0 (TID 654) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.318+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 8.0 in stage 417.0 (TID 653) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:55.323+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_442_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.326+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 9.0 in stage 417.0 (TID 654) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:55.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Removed TaskSet 417.0, whose tasks have all completed, from pool
[2025-05-06T20:51:55.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: ShuffleMapStage 417 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.095 s
[2025-05-06T20:51:55.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:55.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:55.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: waiting: Set(ResultStage 418)
[2025-05-06T20:51:55.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:55.327+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting ResultStage 418 (EdgeRDDImpl[449] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:55.329+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 120.3 KiB, free 425.7 MiB)
[2025-05-06T20:51:55.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.6 MiB)
[2025-05-06T20:51:55.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 837932af135c:42719 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:55.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 418 (EdgeRDDImpl[449] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:55.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Adding task set 418.0 with 10 tasks resource profile 0
[2025-05-06T20:51:55.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 0.0 in stage 418.0 (TID 655) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.335+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.18.0.4:45323 (size: 47.7 KiB, free: 174.1 MiB)
[2025-05-06T20:51:55.339+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 65 to 172.18.0.4:41314
[2025-05-06T20:51:55.341+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:55.343+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 1.0 in stage 418.0 (TID 656) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.343+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 0.0 in stage 418.0 (TID 655) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:55.349+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T20:51:55.350+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 2.0 in stage 418.0 (TID 657) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.351+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 1.0 in stage 418.0 (TID 656) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:55.359+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:55.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 3.0 in stage 418.0 (TID 658) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 2.0 in stage 418.0 (TID 657) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:55.367+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T20:51:55.369+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 4.0 in stage 418.0 (TID 659) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.369+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 3.0 in stage 418.0 (TID 658) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:55.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:55.378+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 5.0 in stage 418.0 (TID 660) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.378+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 4.0 in stage 418.0 (TID 659) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:55.387+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:55.388+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 6.0 in stage 418.0 (TID 661) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.389+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 5.0 in stage 418.0 (TID 660) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:55.395+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T20:51:55.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 7.0 in stage 418.0 (TID 662) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 6.0 in stage 418.0 (TID 661) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:55.404+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:55.405+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 8.0 in stage 418.0 (TID 663) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.406+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 7.0 in stage 418.0 (TID 662) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:55.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:55.414+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 9.0 in stage 418.0 (TID 664) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.414+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 8.0 in stage 418.0 (TID 663) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:55.420+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_448_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:55.423+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 9.0 in stage 418.0 (TID 664) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:55.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Removed TaskSet 418.0, whose tasks have all completed, from pool
[2025-05-06T20:51:55.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: ResultStage 418 (foreachPartition at PageRank.scala:199) finished in 0.097 s
[2025-05-06T20:51:55.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:55.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 418: Stage finished
[2025-05-06T20:51:55.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Job 54 finished: foreachPartition at PageRank.scala:199, took 0.374976 s
[2025-05-06T20:51:55.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO PageRank: PageRank finished iteration 1.
[2025-05-06T20:51:55.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO ZippedPartitionsRDD2: Removing RDD 430 from persistence list
[2025-05-06T20:51:55.425+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManager: Removing RDD 430
[2025-05-06T20:51:55.425+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO ZippedPartitionsRDD2: Removing RDD 436 from persistence list
[2025-05-06T20:51:55.425+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManager: Removing RDD 436
[2025-05-06T20:51:55.436+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:55.438+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Registering RDD 450 (mapPartitions at GraphImpl.scala:208) as input to shuffle 68
[2025-05-06T20:51:55.438+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Registering RDD 458 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 67
[2025-05-06T20:51:55.438+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Got job 55 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:55.438+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Final stage: ResultStage 436 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:55.438+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 425, ShuffleMapStage 419, ShuffleMapStage 431, ShuffleMapStage 428, ShuffleMapStage 435, ShuffleMapStage 429, ShuffleMapStage 433)
[2025-05-06T20:51:55.438+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 435)
[2025-05-06T20:51:55.439+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting ShuffleMapStage 434 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[450] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:55.442+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 120.8 KiB, free 425.5 MiB)
[2025-05-06T20:51:55.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.5 MiB)
[2025-05-06T20:51:55.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 837932af135c:42719 (size: 47.7 KiB, free: 434.1 MiB)
[2025-05-06T20:51:55.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 837932af135c:42719 in memory (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:55.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 434 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[450] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:55.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Adding task set 434.0 with 10 tasks resource profile 0
[2025-05-06T20:51:55.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 0.0 in stage 434.0 (TID 665) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.456+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 172.18.0.4:45323 in memory (size: 47.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.458+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 837932af135c:42719 in memory (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.459+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 172.18.0.4:45323 in memory (size: 47.7 KiB, free: 174.4 MiB)
[2025-05-06T20:51:55.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.18.0.4:45323 (size: 47.7 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.462+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 837932af135c:42719 in memory (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.469+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.18.0.4:45323 in memory (size: 5.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.483+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 1.0 in stage 434.0 (TID 666) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.483+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 0.0 in stage 434.0 (TID 665) in 30 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:55.504+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 2.0 in stage 434.0 (TID 667) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.505+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 1.0 in stage 434.0 (TID 666) in 22 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:55.535+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 3.0 in stage 434.0 (TID 668) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.535+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 2.0 in stage 434.0 (TID 667) in 32 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:55.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 4.0 in stage 434.0 (TID 669) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.549+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 3.0 in stage 434.0 (TID 668) in 15 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:55.562+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 5.0 in stage 434.0 (TID 670) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.562+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 4.0 in stage 434.0 (TID 669) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:55.584+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 6.0 in stage 434.0 (TID 671) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.585+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 5.0 in stage 434.0 (TID 670) in 22 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:55.607+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 7.0 in stage 434.0 (TID 672) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 6.0 in stage 434.0 (TID 671) in 24 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:55.633+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 8.0 in stage 434.0 (TID 673) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.634+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 7.0 in stage 434.0 (TID 672) in 28 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:55.665+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 9.0 in stage 434.0 (TID 674) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.665+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 8.0 in stage 434.0 (TID 673) in 32 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:55.690+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 9.0 in stage 434.0 (TID 674) in 26 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:55.690+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Removed TaskSet 434.0, whose tasks have all completed, from pool
[2025-05-06T20:51:55.691+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: ShuffleMapStage 434 (mapPartitions at GraphImpl.scala:208) finished in 0.251 s
[2025-05-06T20:51:55.691+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:55.691+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:55.691+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 435, ResultStage 436)
[2025-05-06T20:51:55.691+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:55.692+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting ShuffleMapStage 435 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[458] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:55.693+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 13.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:55.695+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:55.696+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 837932af135c:42719 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:55.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 435 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[458] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:55.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Adding task set 435.0 with 10 tasks resource profile 0
[2025-05-06T20:51:55.698+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 0.0 in stage 435.0 (TID 675) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.705+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.18.0.4:45323 (size: 6.1 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.710+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 68 to 172.18.0.4:41314
[2025-05-06T20:51:55.714+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.718+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 1.0 in stage 435.0 (TID 676) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.719+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 0.0 in stage 435.0 (TID 675) in 20 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:55.727+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.732+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 2.0 in stage 435.0 (TID 677) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.732+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 1.0 in stage 435.0 (TID 676) in 14 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:55.737+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.742+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 3.0 in stage 435.0 (TID 678) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 2.0 in stage 435.0 (TID 677) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:55.749+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:55.754+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 4.0 in stage 435.0 (TID 679) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.755+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 3.0 in stage 435.0 (TID 678) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:55.763+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.769+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 5.0 in stage 435.0 (TID 680) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.769+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 4.0 in stage 435.0 (TID 679) in 15 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:55.777+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.782+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 6.0 in stage 435.0 (TID 681) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.783+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 5.0 in stage 435.0 (TID 680) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:55.791+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 7.0 in stage 435.0 (TID 682) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 6.0 in stage 435.0 (TID 681) in 15 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:55.803+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.810+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 8.0 in stage 435.0 (TID 683) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.810+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 7.0 in stage 435.0 (TID 682) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:55.817+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.820+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 9.0 in stage 435.0 (TID 684) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.821+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 8.0 in stage 435.0 (TID 683) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:55.828+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_454_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:55.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 9.0 in stage 435.0 (TID 684) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:55.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Removed TaskSet 435.0, whose tasks have all completed, from pool
[2025-05-06T20:51:55.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: ShuffleMapStage 435 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.141 s
[2025-05-06T20:51:55.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:55.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:55.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: waiting: Set(ResultStage 436)
[2025-05-06T20:51:55.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:55.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting ResultStage 436 (EdgeRDDImpl[461] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:55.837+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 120.6 KiB, free 425.7 MiB)
[2025-05-06T20:51:55.838+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.6 MiB)
[2025-05-06T20:51:55.838+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 837932af135c:42719 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:55.839+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:55.839+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 436 (EdgeRDDImpl[461] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:55.840+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Adding task set 436.0 with 10 tasks resource profile 0
[2025-05-06T20:51:55.841+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 0.0 in stage 436.0 (TID 685) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.846+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.18.0.4:45323 (size: 47.7 KiB, free: 174.1 MiB)
[2025-05-06T20:51:55.852+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 67 to 172.18.0.4:41314
[2025-05-06T20:51:55.856+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:55.859+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 1.0 in stage 436.0 (TID 686) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.860+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 0.0 in stage 436.0 (TID 685) in 20 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:55.868+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T20:51:55.870+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 2.0 in stage 436.0 (TID 687) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.870+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 1.0 in stage 436.0 (TID 686) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:55.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:55.881+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 3.0 in stage 436.0 (TID 688) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.882+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 2.0 in stage 436.0 (TID 687) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:55.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T20:51:55.894+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 4.0 in stage 436.0 (TID 689) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.895+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 3.0 in stage 436.0 (TID 688) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:55.904+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:55.908+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 5.0 in stage 436.0 (TID 690) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.909+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 4.0 in stage 436.0 (TID 689) in 15 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:55.920+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:55.922+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 6.0 in stage 436.0 (TID 691) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 5.0 in stage 436.0 (TID 690) in 15 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:55.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T20:51:55.938+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 7.0 in stage 436.0 (TID 692) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.939+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 6.0 in stage 436.0 (TID 691) in 16 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:55.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:55.960+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 8.0 in stage 436.0 (TID 693) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 7.0 in stage 436.0 (TID 692) in 22 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:55.967+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:55.969+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Starting task 9.0 in stage 436.0 (TID 694) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:55.970+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 8.0 in stage 436.0 (TID 693) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:55.980+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManagerInfo: Added rdd_460_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:55.982+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSetManager: Finished task 9.0 in stage 436.0 (TID 694) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:55.983+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Removed TaskSet 436.0, whose tasks have all completed, from pool
[2025-05-06T20:51:55.983+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: ResultStage 436 (foreachPartition at PageRank.scala:199) finished in 0.149 s
[2025-05-06T20:51:55.983+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:55.983+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 436: Stage finished
[2025-05-06T20:51:55.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO DAGScheduler: Job 55 finished: foreachPartition at PageRank.scala:199, took 0.547395 s
[2025-05-06T20:51:55.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO PageRank: PageRank finished iteration 2.
[2025-05-06T20:51:55.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO ZippedPartitionsRDD2: Removing RDD 442 from persistence list
[2025-05-06T20:51:55.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO ZippedPartitionsRDD2: Removing RDD 448 from persistence list
[2025-05-06T20:51:55.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManager: Removing RDD 442
[2025-05-06T20:51:55.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:55 INFO BlockManager: Removing RDD 448
[2025-05-06T20:51:56.007+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:56.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Registering RDD 462 (mapPartitions at GraphImpl.scala:208) as input to shuffle 70
[2025-05-06T20:51:56.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Registering RDD 470 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 69
[2025-05-06T20:51:56.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Got job 56 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:56.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Final stage: ResultStage 456 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:56.011+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 455, ShuffleMapStage 437, ShuffleMapStage 442, ShuffleMapStage 449, ShuffleMapStage 446, ShuffleMapStage 453, ShuffleMapStage 447, ShuffleMapStage 451)
[2025-05-06T20:51:56.012+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 455)
[2025-05-06T20:51:56.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting ShuffleMapStage 454 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[462] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:56.019+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 121.1 KiB, free 425.5 MiB)
[2025-05-06T20:51:56.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.4 MiB)
[2025-05-06T20:51:56.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 837932af135c:42719 (size: 47.9 KiB, free: 434.1 MiB)
[2025-05-06T20:51:56.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:56.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 454 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[462] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:56.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Adding task set 454.0 with 10 tasks resource profile 0
[2025-05-06T20:51:56.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 837932af135c:42719 in memory (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.039+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 0.0 in stage 454.0 (TID 695) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.042+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.18.0.4:45323 in memory (size: 47.7 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.049+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 837932af135c:42719 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.18.0.4:45323 in memory (size: 6.1 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.052+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.18.0.4:45323 (size: 47.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 837932af135c:42719 in memory (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.067+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.18.0.4:45323 in memory (size: 47.7 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.079+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 1.0 in stage 454.0 (TID 696) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.080+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 0.0 in stage 454.0 (TID 695) in 42 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:56.106+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 2.0 in stage 454.0 (TID 697) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.106+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 1.0 in stage 454.0 (TID 696) in 27 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:56.131+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 3.0 in stage 454.0 (TID 698) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.132+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 2.0 in stage 454.0 (TID 697) in 26 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:56.148+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 4.0 in stage 454.0 (TID 699) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.148+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 3.0 in stage 454.0 (TID 698) in 17 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:56.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 5.0 in stage 454.0 (TID 700) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.166+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 4.0 in stage 454.0 (TID 699) in 17 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:56.187+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 6.0 in stage 454.0 (TID 701) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.188+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 5.0 in stage 454.0 (TID 700) in 22 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:56.206+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 7.0 in stage 454.0 (TID 702) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.206+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 6.0 in stage 454.0 (TID 701) in 19 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:56.223+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 8.0 in stage 454.0 (TID 703) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.223+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 7.0 in stage 454.0 (TID 702) in 18 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:56.239+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 9.0 in stage 454.0 (TID 704) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.239+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 8.0 in stage 454.0 (TID 703) in 16 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:56.262+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 9.0 in stage 454.0 (TID 704) in 22 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:56.262+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Removed TaskSet 454.0, whose tasks have all completed, from pool
[2025-05-06T20:51:56.262+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: ShuffleMapStage 454 (mapPartitions at GraphImpl.scala:208) finished in 0.249 s
[2025-05-06T20:51:56.262+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:56.263+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:56.263+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 455, ResultStage 456)
[2025-05-06T20:51:56.263+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:56.263+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting ShuffleMapStage 455 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[470] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:56.264+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 14.2 KiB, free 425.8 MiB)
[2025-05-06T20:51:56.265+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:56.265+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 837932af135c:42719 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.265+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:56.266+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 455 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[470] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:56.266+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Adding task set 455.0 with 10 tasks resource profile 0
[2025-05-06T20:51:56.266+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 0.0 in stage 455.0 (TID 705) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.271+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.18.0.4:45323 (size: 6.1 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.275+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 70 to 172.18.0.4:41314
[2025-05-06T20:51:56.280+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.285+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 1.0 in stage 455.0 (TID 706) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.285+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 0.0 in stage 455.0 (TID 705) in 19 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:56.293+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 2.0 in stage 455.0 (TID 707) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 1.0 in stage 455.0 (TID 706) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:56.302+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.312+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 3.0 in stage 455.0 (TID 708) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.312+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 2.0 in stage 455.0 (TID 707) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:56.318+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.322+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 4.0 in stage 455.0 (TID 709) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.322+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 3.0 in stage 455.0 (TID 708) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:56.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.334+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 5.0 in stage 455.0 (TID 710) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.334+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 4.0 in stage 455.0 (TID 709) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:56.339+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.344+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 6.0 in stage 455.0 (TID 711) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.345+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 5.0 in stage 455.0 (TID 710) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:56.351+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.357+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 7.0 in stage 455.0 (TID 712) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.357+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 6.0 in stage 455.0 (TID 711) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:56.365+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.370+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 8.0 in stage 455.0 (TID 713) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.370+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 7.0 in stage 455.0 (TID 712) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:56.377+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.381+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 9.0 in stage 455.0 (TID 714) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.382+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 8.0 in stage 455.0 (TID 713) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:56.386+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_466_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.391+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 9.0 in stage 455.0 (TID 714) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:56.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Removed TaskSet 455.0, whose tasks have all completed, from pool
[2025-05-06T20:51:56.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: ShuffleMapStage 455 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.128 s
[2025-05-06T20:51:56.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:56.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:56.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: waiting: Set(ResultStage 456)
[2025-05-06T20:51:56.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:56.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting ResultStage 456 (EdgeRDDImpl[473] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:56.396+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 120.9 KiB, free 425.7 MiB)
[2025-05-06T20:51:56.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.6 MiB)
[2025-05-06T20:51:56.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 837932af135c:42719 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.397+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:56.398+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 456 (EdgeRDDImpl[473] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:56.398+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Adding task set 456.0 with 10 tasks resource profile 0
[2025-05-06T20:51:56.398+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 0.0 in stage 456.0 (TID 715) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.402+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.18.0.4:45323 (size: 47.7 KiB, free: 174.1 MiB)
[2025-05-06T20:51:56.408+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 69 to 172.18.0.4:41314
[2025-05-06T20:51:56.411+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:56.413+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 1.0 in stage 456.0 (TID 716) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.413+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 0.0 in stage 456.0 (TID 715) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:56.420+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T20:51:56.422+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 2.0 in stage 456.0 (TID 717) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.422+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 1.0 in stage 456.0 (TID 716) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:56.432+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:56.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 3.0 in stage 456.0 (TID 718) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 2.0 in stage 456.0 (TID 717) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:56.441+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T20:51:56.443+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 4.0 in stage 456.0 (TID 719) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.444+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 3.0 in stage 456.0 (TID 718) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:56.450+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:56.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 5.0 in stage 456.0 (TID 720) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 4.0 in stage 456.0 (TID 719) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:56.460+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:56.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 6.0 in stage 456.0 (TID 721) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.462+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 5.0 in stage 456.0 (TID 720) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:56.468+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T20:51:56.469+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 7.0 in stage 456.0 (TID 722) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.470+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 6.0 in stage 456.0 (TID 721) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:56.477+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:56.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 8.0 in stage 456.0 (TID 723) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.479+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 7.0 in stage 456.0 (TID 722) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:56.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:56.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 9.0 in stage 456.0 (TID 724) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.487+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 8.0 in stage 456.0 (TID 723) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:56.495+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_472_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:56.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 9.0 in stage 456.0 (TID 724) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:56.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Removed TaskSet 456.0, whose tasks have all completed, from pool
[2025-05-06T20:51:56.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: ResultStage 456 (foreachPartition at PageRank.scala:199) finished in 0.104 s
[2025-05-06T20:51:56.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:56.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 456: Stage finished
[2025-05-06T20:51:56.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Job 56 finished: foreachPartition at PageRank.scala:199, took 0.490860 s
[2025-05-06T20:51:56.498+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO PageRank: PageRank finished iteration 3.
[2025-05-06T20:51:56.498+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO ZippedPartitionsRDD2: Removing RDD 454 from persistence list
[2025-05-06T20:51:56.498+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManager: Removing RDD 454
[2025-05-06T20:51:56.499+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO ZippedPartitionsRDD2: Removing RDD 460 from persistence list
[2025-05-06T20:51:56.499+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManager: Removing RDD 460
[2025-05-06T20:51:56.514+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:56.516+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Registering RDD 474 (mapPartitions at GraphImpl.scala:208) as input to shuffle 72
[2025-05-06T20:51:56.517+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Registering RDD 482 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 71
[2025-05-06T20:51:56.517+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Got job 57 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:56.517+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Final stage: ResultStage 478 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:56.517+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 466, ShuffleMapStage 473, ShuffleMapStage 462, ShuffleMapStage 477, ShuffleMapStage 475, ShuffleMapStage 467, ShuffleMapStage 471, ShuffleMapStage 457, ShuffleMapStage 469)
[2025-05-06T20:51:56.518+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 477)
[2025-05-06T20:51:56.518+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting ShuffleMapStage 476 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[474] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:56.523+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 121.4 KiB, free 425.5 MiB)
[2025-05-06T20:51:56.533+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 837932af135c:42719 in memory (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.534+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.5 MiB)
[2025-05-06T20:51:56.534+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 837932af135c:42719 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.534+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:56.534+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 476 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[474] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:56.534+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Adding task set 476.0 with 10 tasks resource profile 0
[2025-05-06T20:51:56.535+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 0.0 in stage 476.0 (TID 725) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.535+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.18.0.4:45323 in memory (size: 47.7 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.537+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 837932af135c:42719 in memory (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.18.0.4:45323 in memory (size: 47.9 KiB, free: 174.4 MiB)
[2025-05-06T20:51:56.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 837932af135c:42719 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.540+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 172.18.0.4:45323 in memory (size: 6.1 KiB, free: 174.4 MiB)
[2025-05-06T20:51:56.541+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.18.0.4:45323 (size: 47.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.555+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 1.0 in stage 476.0 (TID 726) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.556+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 0.0 in stage 476.0 (TID 725) in 21 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:56.587+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 2.0 in stage 476.0 (TID 727) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.587+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 1.0 in stage 476.0 (TID 726) in 32 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:56.607+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 3.0 in stage 476.0 (TID 728) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.607+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 2.0 in stage 476.0 (TID 727) in 21 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:56.621+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 4.0 in stage 476.0 (TID 729) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.622+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 3.0 in stage 476.0 (TID 728) in 15 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:56.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 5.0 in stage 476.0 (TID 730) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 4.0 in stage 476.0 (TID 729) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:56.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 6.0 in stage 476.0 (TID 731) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.650+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 5.0 in stage 476.0 (TID 730) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:56.664+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 7.0 in stage 476.0 (TID 732) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.664+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 6.0 in stage 476.0 (TID 731) in 15 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:56.683+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 8.0 in stage 476.0 (TID 733) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.683+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 7.0 in stage 476.0 (TID 732) in 19 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:56.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 9.0 in stage 476.0 (TID 734) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 8.0 in stage 476.0 (TID 733) in 14 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:56.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 9.0 in stage 476.0 (TID 734) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:56.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Removed TaskSet 476.0, whose tasks have all completed, from pool
[2025-05-06T20:51:56.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: ShuffleMapStage 476 (mapPartitions at GraphImpl.scala:208) finished in 0.192 s
[2025-05-06T20:51:56.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:56.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:56.712+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 477, ResultStage 478)
[2025-05-06T20:51:56.712+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:56.712+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting ShuffleMapStage 477 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[482] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:56.713+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 14.9 KiB, free 425.8 MiB)
[2025-05-06T20:51:56.713+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.8 MiB)
[2025-05-06T20:51:56.713+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 837932af135c:42719 (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.713+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:56.714+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 477 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[482] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:56.714+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Adding task set 477.0 with 10 tasks resource profile 0
[2025-05-06T20:51:56.714+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 0.0 in stage 477.0 (TID 735) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.718+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.18.0.4:45323 (size: 6.3 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.720+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.18.0.4:41314
[2025-05-06T20:51:56.723+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.727+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 1.0 in stage 477.0 (TID 736) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.727+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 0.0 in stage 477.0 (TID 735) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:56.732+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.735+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 2.0 in stage 477.0 (TID 737) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.735+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 1.0 in stage 477.0 (TID 736) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:56.740+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.744+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 3.0 in stage 477.0 (TID 738) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.745+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 2.0 in stage 477.0 (TID 737) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:56.749+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.752+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 4.0 in stage 477.0 (TID 739) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.753+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 3.0 in stage 477.0 (TID 738) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:56.757+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.761+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 5.0 in stage 477.0 (TID 740) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.762+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 4.0 in stage 477.0 (TID 739) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:56.766+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.770+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 6.0 in stage 477.0 (TID 741) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.770+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 5.0 in stage 477.0 (TID 740) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:56.776+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 7.0 in stage 477.0 (TID 742) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 6.0 in stage 477.0 (TID 741) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:56.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.789+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 8.0 in stage 477.0 (TID 743) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.789+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 7.0 in stage 477.0 (TID 742) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:56.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.801+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 9.0 in stage 477.0 (TID 744) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.801+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 8.0 in stage 477.0 (TID 743) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:56.809+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_478_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:56.814+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 9.0 in stage 477.0 (TID 744) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:56.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Removed TaskSet 477.0, whose tasks have all completed, from pool
[2025-05-06T20:51:56.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: ShuffleMapStage 477 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.102 s
[2025-05-06T20:51:56.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:56.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:56.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: waiting: Set(ResultStage 478)
[2025-05-06T20:51:56.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:56.815+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting ResultStage 478 (EdgeRDDImpl[485] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:56.818+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 121.2 KiB, free 425.7 MiB)
[2025-05-06T20:51:56.819+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.6 MiB)
[2025-05-06T20:51:56.819+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 837932af135c:42719 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.819+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:56.819+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 478 (EdgeRDDImpl[485] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:56.819+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Adding task set 478.0 with 10 tasks resource profile 0
[2025-05-06T20:51:56.820+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 0.0 in stage 478.0 (TID 745) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.824+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.18.0.4:45323 (size: 47.7 KiB, free: 174.1 MiB)
[2025-05-06T20:51:56.831+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.18.0.4:41314
[2025-05-06T20:51:56.835+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:56.836+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 1.0 in stage 478.0 (TID 746) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.836+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 0.0 in stage 478.0 (TID 745) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:56.845+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T20:51:56.847+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 2.0 in stage 478.0 (TID 747) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.848+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 1.0 in stage 478.0 (TID 746) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:56.861+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:56.863+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 3.0 in stage 478.0 (TID 748) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.863+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 2.0 in stage 478.0 (TID 747) in 16 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:56.869+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T20:51:56.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 4.0 in stage 478.0 (TID 749) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 3.0 in stage 478.0 (TID 748) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:56.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:56.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 5.0 in stage 478.0 (TID 750) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 4.0 in stage 478.0 (TID 749) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:56.887+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:56.889+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 6.0 in stage 478.0 (TID 751) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.889+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 5.0 in stage 478.0 (TID 750) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:56.900+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T20:51:56.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 7.0 in stage 478.0 (TID 752) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.902+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 6.0 in stage 478.0 (TID 751) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:56.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:56.912+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 8.0 in stage 478.0 (TID 753) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.913+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 7.0 in stage 478.0 (TID 752) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:56.919+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:56.920+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 9.0 in stage 478.0 (TID 754) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.921+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 8.0 in stage 478.0 (TID 753) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:56.928+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added rdd_484_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:56.930+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 9.0 in stage 478.0 (TID 754) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:56.930+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Removed TaskSet 478.0, whose tasks have all completed, from pool
[2025-05-06T20:51:56.930+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: ResultStage 478 (foreachPartition at PageRank.scala:199) finished in 0.115 s
[2025-05-06T20:51:56.930+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:56.930+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 478: Stage finished
[2025-05-06T20:51:56.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Job 57 finished: foreachPartition at PageRank.scala:199, took 0.416694 s
[2025-05-06T20:51:56.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO PageRank: PageRank finished iteration 4.
[2025-05-06T20:51:56.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO ZippedPartitionsRDD2: Removing RDD 466 from persistence list
[2025-05-06T20:51:56.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManager: Removing RDD 466
[2025-05-06T20:51:56.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO ZippedPartitionsRDD2: Removing RDD 472 from persistence list
[2025-05-06T20:51:56.932+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManager: Removing RDD 472
[2025-05-06T20:51:56.940+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:56.942+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Registering RDD 486 (mapPartitions at GraphImpl.scala:208) as input to shuffle 74
[2025-05-06T20:51:56.942+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Registering RDD 494 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 73
[2025-05-06T20:51:56.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Got job 58 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:56.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Final stage: ResultStage 502 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:56.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 484, ShuffleMapStage 491, ShuffleMapStage 488, ShuffleMapStage 495, ShuffleMapStage 489, ShuffleMapStage 499, ShuffleMapStage 493, ShuffleMapStage 497, ShuffleMapStage 479, ShuffleMapStage 501)
[2025-05-06T20:51:56.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 501)
[2025-05-06T20:51:56.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting ShuffleMapStage 500 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[486] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:56.946+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 121.7 KiB, free 425.5 MiB)
[2025-05-06T20:51:56.954+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 837932af135c:42719 in memory (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.955+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.5 MiB)
[2025-05-06T20:51:56.955+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 837932af135c:42719 (size: 47.9 KiB, free: 434.1 MiB)
[2025-05-06T20:51:56.955+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:56.956+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 500 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[486] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:56.956+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSchedulerImpl: Adding task set 500.0 with 10 tasks resource profile 0
[2025-05-06T20:51:56.956+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.18.0.4:45323 in memory (size: 6.3 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.956+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 0.0 in stage 500.0 (TID 755) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.958+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 837932af135c:42719 in memory (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.18.0.4:45323 in memory (size: 47.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.963+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 837932af135c:42719 in memory (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:56.963+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 172.18.0.4:45323 in memory (size: 47.7 KiB, free: 174.4 MiB)
[2025-05-06T20:51:56.963+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.18.0.4:45323 (size: 47.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:56.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Starting task 1.0 in stage 500.0 (TID 756) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:56.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:56 INFO TaskSetManager: Finished task 0.0 in stage 500.0 (TID 755) in 27 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:57.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 2.0 in stage 500.0 (TID 757) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.010+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 1.0 in stage 500.0 (TID 756) in 28 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:57.024+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 3.0 in stage 500.0 (TID 758) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.025+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 2.0 in stage 500.0 (TID 757) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:57.044+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 4.0 in stage 500.0 (TID 759) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.044+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 3.0 in stage 500.0 (TID 758) in 20 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:57.056+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 5.0 in stage 500.0 (TID 760) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 4.0 in stage 500.0 (TID 759) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:57.070+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 6.0 in stage 500.0 (TID 761) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.070+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 5.0 in stage 500.0 (TID 760) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:57.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 7.0 in stage 500.0 (TID 762) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 6.0 in stage 500.0 (TID 761) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:57.104+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 8.0 in stage 500.0 (TID 763) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.104+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 7.0 in stage 500.0 (TID 762) in 20 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:57.117+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 9.0 in stage 500.0 (TID 764) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.118+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 8.0 in stage 500.0 (TID 763) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:57.134+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 9.0 in stage 500.0 (TID 764) in 17 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:57.134+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Removed TaskSet 500.0, whose tasks have all completed, from pool
[2025-05-06T20:51:57.134+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: ShuffleMapStage 500 (mapPartitions at GraphImpl.scala:208) finished in 0.190 s
[2025-05-06T20:51:57.135+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:57.135+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:57.135+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: waiting: Set(ResultStage 502, ShuffleMapStage 501)
[2025-05-06T20:51:57.135+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:57.135+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting ShuffleMapStage 501 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[494] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:57.136+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 15.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:57.136+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:57.136+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 837932af135c:42719 (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:57.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 501 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[494] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:57.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Adding task set 501.0 with 10 tasks resource profile 0
[2025-05-06T20:51:57.137+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 0.0 in stage 501.0 (TID 765) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.140+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.18.0.4:45323 (size: 6.4 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.18.0.4:41314
[2025-05-06T20:51:57.147+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.150+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 1.0 in stage 501.0 (TID 766) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.151+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 0.0 in stage 501.0 (TID 765) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:57.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 2.0 in stage 501.0 (TID 767) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.158+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 1.0 in stage 501.0 (TID 766) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:57.165+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.168+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 3.0 in stage 501.0 (TID 768) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.168+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 2.0 in stage 501.0 (TID 767) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:57.172+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.176+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 4.0 in stage 501.0 (TID 769) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 3.0 in stage 501.0 (TID 768) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:57.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.185+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 5.0 in stage 501.0 (TID 770) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.185+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 4.0 in stage 501.0 (TID 769) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:57.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.193+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 6.0 in stage 501.0 (TID 771) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.194+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 5.0 in stage 501.0 (TID 770) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:57.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.202+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 7.0 in stage 501.0 (TID 772) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.202+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 6.0 in stage 501.0 (TID 771) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:57.206+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 8.0 in stage 501.0 (TID 773) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.211+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 7.0 in stage 501.0 (TID 772) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:57.215+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.219+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 9.0 in stage 501.0 (TID 774) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.219+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 8.0 in stage 501.0 (TID 773) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:57.223+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_490_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.228+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 9.0 in stage 501.0 (TID 774) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:57.228+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Removed TaskSet 501.0, whose tasks have all completed, from pool
[2025-05-06T20:51:57.228+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: ShuffleMapStage 501 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.093 s
[2025-05-06T20:51:57.228+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:57.228+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:57.228+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: waiting: Set(ResultStage 502)
[2025-05-06T20:51:57.228+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:57.229+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting ResultStage 502 (EdgeRDDImpl[497] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:57.233+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 121.5 KiB, free 425.7 MiB)
[2025-05-06T20:51:57.234+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.6 MiB)
[2025-05-06T20:51:57.234+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 837932af135c:42719 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.234+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:57.234+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 502 (EdgeRDDImpl[497] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:57.234+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Adding task set 502.0 with 10 tasks resource profile 0
[2025-05-06T20:51:57.235+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 0.0 in stage 502.0 (TID 775) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.238+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.18.0.4:45323 (size: 47.9 KiB, free: 174.1 MiB)
[2025-05-06T20:51:57.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.18.0.4:41314
[2025-05-06T20:51:57.247+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:57.248+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 1.0 in stage 502.0 (TID 776) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.249+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 0.0 in stage 502.0 (TID 775) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:57.257+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T20:51:57.259+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 2.0 in stage 502.0 (TID 777) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.260+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 1.0 in stage 502.0 (TID 776) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:57.267+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:57.269+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 3.0 in stage 502.0 (TID 778) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.269+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 2.0 in stage 502.0 (TID 777) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:57.275+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T20:51:57.278+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 4.0 in stage 502.0 (TID 779) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.279+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 3.0 in stage 502.0 (TID 778) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:57.285+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:57.286+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 5.0 in stage 502.0 (TID 780) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.287+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 4.0 in stage 502.0 (TID 779) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:57.294+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:57.296+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 6.0 in stage 502.0 (TID 781) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.296+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 5.0 in stage 502.0 (TID 780) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:57.302+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T20:51:57.304+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 7.0 in stage 502.0 (TID 782) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.304+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 6.0 in stage 502.0 (TID 781) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:57.310+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:57.312+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 8.0 in stage 502.0 (TID 783) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.313+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 7.0 in stage 502.0 (TID 782) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:57.318+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:57.320+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 9.0 in stage 502.0 (TID 784) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.320+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 8.0 in stage 502.0 (TID 783) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:57.326+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_496_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:57.329+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 9.0 in stage 502.0 (TID 784) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:57.329+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Removed TaskSet 502.0, whose tasks have all completed, from pool
[2025-05-06T20:51:57.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: ResultStage 502 (foreachPartition at PageRank.scala:199) finished in 0.100 s
[2025-05-06T20:51:57.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:57.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 502: Stage finished
[2025-05-06T20:51:57.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Job 58 finished: foreachPartition at PageRank.scala:199, took 0.389175 s
[2025-05-06T20:51:57.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO PageRank: PageRank finished iteration 5.
[2025-05-06T20:51:57.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO ZippedPartitionsRDD2: Removing RDD 478 from persistence list
[2025-05-06T20:51:57.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManager: Removing RDD 478
[2025-05-06T20:51:57.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO ZippedPartitionsRDD2: Removing RDD 484 from persistence list
[2025-05-06T20:51:57.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManager: Removing RDD 484
[2025-05-06T20:51:57.339+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:57.340+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Registering RDD 498 (mapPartitions at GraphImpl.scala:208) as input to shuffle 76
[2025-05-06T20:51:57.340+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Registering RDD 506 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 75
[2025-05-06T20:51:57.340+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Got job 59 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:57.341+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Final stage: ResultStage 528 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:57.341+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 527, ShuffleMapStage 521, ShuffleMapStage 503, ShuffleMapStage 513, ShuffleMapStage 525, ShuffleMapStage 517, ShuffleMapStage 515, ShuffleMapStage 512, ShuffleMapStage 519, ShuffleMapStage 508, ShuffleMapStage 523)
[2025-05-06T20:51:57.341+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 527)
[2025-05-06T20:51:57.341+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting ShuffleMapStage 526 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[498] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:57.345+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 122.0 KiB, free 425.5 MiB)
[2025-05-06T20:51:57.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 837932af135c:42719 in memory (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.5 MiB)
[2025-05-06T20:51:57.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 837932af135c:42719 (size: 48.1 KiB, free: 434.1 MiB)
[2025-05-06T20:51:57.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:57.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 172.18.0.4:45323 in memory (size: 6.4 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 526 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[498] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:57.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Adding task set 526.0 with 10 tasks resource profile 0
[2025-05-06T20:51:57.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 0.0 in stage 526.0 (TID 785) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 837932af135c:42719 in memory (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.354+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 172.18.0.4:45323 in memory (size: 47.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.355+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 837932af135c:42719 in memory (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.357+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.18.0.4:45323 in memory (size: 47.9 KiB, free: 174.4 MiB)
[2025-05-06T20:51:57.358+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.18.0.4:45323 (size: 48.1 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.376+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 1.0 in stage 526.0 (TID 786) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.377+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 0.0 in stage 526.0 (TID 785) in 23 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:57.389+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 2.0 in stage 526.0 (TID 787) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.390+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 1.0 in stage 526.0 (TID 786) in 14 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:57.407+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 3.0 in stage 526.0 (TID 788) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.407+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 2.0 in stage 526.0 (TID 787) in 18 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:57.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 4.0 in stage 526.0 (TID 789) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.419+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 3.0 in stage 526.0 (TID 788) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:57.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 5.0 in stage 526.0 (TID 790) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.433+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 4.0 in stage 526.0 (TID 789) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:57.445+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 6.0 in stage 526.0 (TID 791) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.446+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 5.0 in stage 526.0 (TID 790) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:57.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 7.0 in stage 526.0 (TID 792) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 6.0 in stage 526.0 (TID 791) in 16 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:57.473+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 8.0 in stage 526.0 (TID 793) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.474+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 7.0 in stage 526.0 (TID 792) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:57.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 9.0 in stage 526.0 (TID 794) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 8.0 in stage 526.0 (TID 793) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:57.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 9.0 in stage 526.0 (TID 794) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:57.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Removed TaskSet 526.0, whose tasks have all completed, from pool
[2025-05-06T20:51:57.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: ShuffleMapStage 526 (mapPartitions at GraphImpl.scala:208) finished in 0.159 s
[2025-05-06T20:51:57.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:57.501+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:57.501+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 527, ResultStage 528)
[2025-05-06T20:51:57.501+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:57.501+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting ShuffleMapStage 527 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[506] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:57.502+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 16.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:57.502+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:57.502+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 837932af135c:42719 (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:57.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 527 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[506] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:57.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Adding task set 527.0 with 10 tasks resource profile 0
[2025-05-06T20:51:57.503+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 0.0 in stage 527.0 (TID 795) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.507+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.18.0.4:45323 (size: 6.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.511+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.18.0.4:41314
[2025-05-06T20:51:57.515+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.519+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 1.0 in stage 527.0 (TID 796) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.519+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 0.0 in stage 527.0 (TID 795) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:57.524+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.530+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 2.0 in stage 527.0 (TID 797) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.530+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 1.0 in stage 527.0 (TID 796) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:57.535+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 3.0 in stage 527.0 (TID 798) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 2.0 in stage 527.0 (TID 797) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:57.545+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 4.0 in stage 527.0 (TID 799) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 3.0 in stage 527.0 (TID 798) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:57.552+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.555+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 5.0 in stage 527.0 (TID 800) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.555+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 4.0 in stage 527.0 (TID 799) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:57.561+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.564+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 6.0 in stage 527.0 (TID 801) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.564+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 5.0 in stage 527.0 (TID 800) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:57.569+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.572+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 7.0 in stage 527.0 (TID 802) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.572+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 6.0 in stage 527.0 (TID 801) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:57.577+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.581+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 8.0 in stage 527.0 (TID 803) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.581+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 7.0 in stage 527.0 (TID 802) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:57.585+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.590+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 9.0 in stage 527.0 (TID 804) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 8.0 in stage 527.0 (TID 803) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:57.596+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_502_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 9.0 in stage 527.0 (TID 804) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:57.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Removed TaskSet 527.0, whose tasks have all completed, from pool
[2025-05-06T20:51:57.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: ShuffleMapStage 527 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.098 s
[2025-05-06T20:51:57.599+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:57.600+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:57.600+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: waiting: Set(ResultStage 528)
[2025-05-06T20:51:57.600+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:57.600+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting ResultStage 528 (EdgeRDDImpl[509] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:57.602+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 121.8 KiB, free 425.7 MiB)
[2025-05-06T20:51:57.603+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.6 MiB)
[2025-05-06T20:51:57.603+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 837932af135c:42719 (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.603+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:57.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 528 (EdgeRDDImpl[509] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:57.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Adding task set 528.0 with 10 tasks resource profile 0
[2025-05-06T20:51:57.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 0.0 in stage 528.0 (TID 805) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.18.0.4:45323 (size: 48.1 KiB, free: 174.1 MiB)
[2025-05-06T20:51:57.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.18.0.4:41314
[2025-05-06T20:51:57.616+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:57.617+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 1.0 in stage 528.0 (TID 806) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.618+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 0.0 in stage 528.0 (TID 805) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:57.624+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T20:51:57.626+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 2.0 in stage 528.0 (TID 807) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.629+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 1.0 in stage 528.0 (TID 806) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:57.637+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:57.639+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 3.0 in stage 528.0 (TID 808) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.639+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 2.0 in stage 528.0 (TID 807) in 13 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:57.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T20:51:57.651+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 4.0 in stage 528.0 (TID 809) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 3.0 in stage 528.0 (TID 808) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:57.662+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:57.664+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 5.0 in stage 528.0 (TID 810) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.665+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 4.0 in stage 528.0 (TID 809) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:57.671+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:57.673+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 6.0 in stage 528.0 (TID 811) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.673+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 5.0 in stage 528.0 (TID 810) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:57.680+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T20:51:57.681+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 7.0 in stage 528.0 (TID 812) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.682+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 6.0 in stage 528.0 (TID 811) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:57.688+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:57.690+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 8.0 in stage 528.0 (TID 813) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.690+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 7.0 in stage 528.0 (TID 812) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:57.698+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:57.699+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 9.0 in stage 528.0 (TID 814) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.700+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 8.0 in stage 528.0 (TID 813) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:57.706+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_508_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:57.707+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 9.0 in stage 528.0 (TID 814) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:57.707+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Removed TaskSet 528.0, whose tasks have all completed, from pool
[2025-05-06T20:51:57.707+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: ResultStage 528 (foreachPartition at PageRank.scala:199) finished in 0.107 s
[2025-05-06T20:51:57.707+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:57.707+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 528: Stage finished
[2025-05-06T20:51:57.707+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Job 59 finished: foreachPartition at PageRank.scala:199, took 0.368336 s
[2025-05-06T20:51:57.708+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO PageRank: PageRank finished iteration 6.
[2025-05-06T20:51:57.708+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO ZippedPartitionsRDD2: Removing RDD 490 from persistence list
[2025-05-06T20:51:57.708+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManager: Removing RDD 490
[2025-05-06T20:51:57.708+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO ZippedPartitionsRDD2: Removing RDD 496 from persistence list
[2025-05-06T20:51:57.708+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManager: Removing RDD 496
[2025-05-06T20:51:57.719+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:57.721+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Registering RDD 510 (mapPartitions at GraphImpl.scala:208) as input to shuffle 78
[2025-05-06T20:51:57.721+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Registering RDD 518 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 77
[2025-05-06T20:51:57.721+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Got job 60 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:57.721+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Final stage: ResultStage 556 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:57.721+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 538, ShuffleMapStage 553, ShuffleMapStage 545, ShuffleMapStage 539, ShuffleMapStage 543, ShuffleMapStage 547, ShuffleMapStage 529, ShuffleMapStage 551, ShuffleMapStage 555, ShuffleMapStage 534, ShuffleMapStage 549, ShuffleMapStage 541)
[2025-05-06T20:51:57.721+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 555)
[2025-05-06T20:51:57.722+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting ShuffleMapStage 554 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[510] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:57.724+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 122.3 KiB, free 425.5 MiB)
[2025-05-06T20:51:57.732+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 837932af135c:42719 in memory (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 425.6 MiB)
[2025-05-06T20:51:57.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 837932af135c:42719 (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:57.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 554 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[510] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:57.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Adding task set 554.0 with 10 tasks resource profile 0
[2025-05-06T20:51:57.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 172.18.0.4:45323 in memory (size: 48.1 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.733+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 0.0 in stage 554.0 (TID 815) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 837932af135c:42719 in memory (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.735+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 172.18.0.4:45323 in memory (size: 48.1 KiB, free: 174.4 MiB)
[2025-05-06T20:51:57.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 837932af135c:42719 in memory (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.737+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.18.0.4:45323 in memory (size: 6.5 KiB, free: 174.4 MiB)
[2025-05-06T20:51:57.738+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.18.0.4:45323 (size: 48.2 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.757+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 1.0 in stage 554.0 (TID 816) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.758+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 0.0 in stage 554.0 (TID 815) in 24 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:57.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 2.0 in stage 554.0 (TID 817) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.788+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 1.0 in stage 554.0 (TID 816) in 30 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:57.808+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 3.0 in stage 554.0 (TID 818) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.809+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 2.0 in stage 554.0 (TID 817) in 21 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:57.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 4.0 in stage 554.0 (TID 819) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 3.0 in stage 554.0 (TID 818) in 22 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:57.844+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 5.0 in stage 554.0 (TID 820) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.845+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 4.0 in stage 554.0 (TID 819) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:57.858+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 6.0 in stage 554.0 (TID 821) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.859+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 5.0 in stage 554.0 (TID 820) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:57.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 7.0 in stage 554.0 (TID 822) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 6.0 in stage 554.0 (TID 821) in 22 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:57.894+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 8.0 in stage 554.0 (TID 823) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.895+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 7.0 in stage 554.0 (TID 822) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:57.914+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 9.0 in stage 554.0 (TID 824) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.914+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 8.0 in stage 554.0 (TID 823) in 20 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:57.928+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 9.0 in stage 554.0 (TID 824) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:57.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Removed TaskSet 554.0, whose tasks have all completed, from pool
[2025-05-06T20:51:57.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: ShuffleMapStage 554 (mapPartitions at GraphImpl.scala:208) finished in 0.206 s
[2025-05-06T20:51:57.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:57.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:57.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: waiting: Set(ResultStage 556, ShuffleMapStage 555)
[2025-05-06T20:51:57.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:57.930+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting ShuffleMapStage 555 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[518] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:57.930+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 17.1 KiB, free 425.8 MiB)
[2025-05-06T20:51:57.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:57.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 837932af135c:42719 (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:57.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:57.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 555 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[518] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:57.931+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSchedulerImpl: Adding task set 555.0 with 10 tasks resource profile 0
[2025-05-06T20:51:57.932+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 0.0 in stage 555.0 (TID 825) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 172.18.0.4:45323 (size: 6.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.938+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.18.0.4:41314
[2025-05-06T20:51:57.944+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_514_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.950+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 1.0 in stage 555.0 (TID 826) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.950+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 0.0 in stage 555.0 (TID 825) in 18 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:57.955+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_514_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.960+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 2.0 in stage 555.0 (TID 827) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.961+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 1.0 in stage 555.0 (TID 826) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:57.966+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_514_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.969+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 3.0 in stage 555.0 (TID 828) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.970+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 2.0 in stage 555.0 (TID 827) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:57.976+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_514_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:57.980+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 4.0 in stage 555.0 (TID 829) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.981+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 3.0 in stage 555.0 (TID 828) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:57.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_514_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.988+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 5.0 in stage 555.0 (TID 830) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.988+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 4.0 in stage 555.0 (TID 829) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:57.994+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO BlockManagerInfo: Added rdd_514_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:57.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Starting task 6.0 in stage 555.0 (TID 831) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:57.999+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:57 INFO TaskSetManager: Finished task 5.0 in stage 555.0 (TID 830) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:58.003+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_514_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.006+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 7.0 in stage 555.0 (TID 832) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.006+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 6.0 in stage 555.0 (TID 831) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:58.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_514_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.016+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 8.0 in stage 555.0 (TID 833) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.017+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 7.0 in stage 555.0 (TID 832) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:58.021+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_514_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.026+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 9.0 in stage 555.0 (TID 834) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.027+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 8.0 in stage 555.0 (TID 833) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:58.033+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_514_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 9.0 in stage 555.0 (TID 834) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:58.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Removed TaskSet 555.0, whose tasks have all completed, from pool
[2025-05-06T20:51:58.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: ShuffleMapStage 555 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.109 s
[2025-05-06T20:51:58.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:58.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:58.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: waiting: Set(ResultStage 556)
[2025-05-06T20:51:58.039+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:58.039+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting ResultStage 556 (EdgeRDDImpl[521] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:58.043+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 122.1 KiB, free 425.7 MiB)
[2025-05-06T20:51:58.045+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.6 MiB)
[2025-05-06T20:51:58.045+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 837932af135c:42719 (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.045+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:58.045+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 556 (EdgeRDDImpl[521] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:58.046+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Adding task set 556.0 with 10 tasks resource profile 0
[2025-05-06T20:51:58.046+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 0.0 in stage 556.0 (TID 835) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 172.18.0.4:45323 (size: 48.1 KiB, free: 174.1 MiB)
[2025-05-06T20:51:58.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.18.0.4:41314
[2025-05-06T20:51:58.061+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:58.063+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 1.0 in stage 556.0 (TID 836) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.063+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 0.0 in stage 556.0 (TID 835) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:58.072+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T20:51:58.074+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 2.0 in stage 556.0 (TID 837) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.074+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 1.0 in stage 556.0 (TID 836) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:58.081+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:58.082+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 3.0 in stage 556.0 (TID 838) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 2.0 in stage 556.0 (TID 837) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:58.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T20:51:58.090+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 4.0 in stage 556.0 (TID 839) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.091+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 3.0 in stage 556.0 (TID 838) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:58.098+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:58.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 5.0 in stage 556.0 (TID 840) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 4.0 in stage 556.0 (TID 839) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:58.105+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:58.107+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 6.0 in stage 556.0 (TID 841) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.107+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 5.0 in stage 556.0 (TID 840) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:58.114+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T20:51:58.115+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 7.0 in stage 556.0 (TID 842) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.116+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 6.0 in stage 556.0 (TID 841) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:58.122+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:58.123+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 8.0 in stage 556.0 (TID 843) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.123+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 7.0 in stage 556.0 (TID 842) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:58.130+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:58.134+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 9.0 in stage 556.0 (TID 844) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.135+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 8.0 in stage 556.0 (TID 843) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:58.141+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_520_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:58.142+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 9.0 in stage 556.0 (TID 844) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:58.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Removed TaskSet 556.0, whose tasks have all completed, from pool
[2025-05-06T20:51:58.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: ResultStage 556 (foreachPartition at PageRank.scala:199) finished in 0.103 s
[2025-05-06T20:51:58.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:58.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 556: Stage finished
[2025-05-06T20:51:58.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Job 60 finished: foreachPartition at PageRank.scala:199, took 0.423997 s
[2025-05-06T20:51:58.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO PageRank: PageRank finished iteration 7.
[2025-05-06T20:51:58.144+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO ZippedPartitionsRDD2: Removing RDD 502 from persistence list
[2025-05-06T20:51:58.145+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManager: Removing RDD 502
[2025-05-06T20:51:58.145+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO ZippedPartitionsRDD2: Removing RDD 508 from persistence list
[2025-05-06T20:51:58.146+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManager: Removing RDD 508
[2025-05-06T20:51:58.156+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:58.160+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Registering RDD 522 (mapPartitions at GraphImpl.scala:208) as input to shuffle 80
[2025-05-06T20:51:58.160+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Registering RDD 530 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 79
[2025-05-06T20:51:58.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Got job 61 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:58.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Final stage: ResultStage 586 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:58.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 571, ShuffleMapStage 575, ShuffleMapStage 557, ShuffleMapStage 579, ShuffleMapStage 583, ShuffleMapStage 562, ShuffleMapStage 569, ShuffleMapStage 566, ShuffleMapStage 581, ShuffleMapStage 573, ShuffleMapStage 567, ShuffleMapStage 585, ShuffleMapStage 577)
[2025-05-06T20:51:58.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 585)
[2025-05-06T20:51:58.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting ShuffleMapStage 584 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[522] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:58.164+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 122.5 KiB, free 425.5 MiB)
[2025-05-06T20:51:58.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 837932af135c:42719 in memory (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 425.5 MiB)
[2025-05-06T20:51:58.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 837932af135c:42719 (size: 48.2 KiB, free: 434.1 MiB)
[2025-05-06T20:51:58.177+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:58.178+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 584 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[522] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:58.178+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Adding task set 584.0 with 10 tasks resource profile 0
[2025-05-06T20:51:58.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 0.0 in stage 584.0 (TID 845) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 172.18.0.4:45323 in memory (size: 6.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.180+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 837932af135c:42719 in memory (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.181+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 172.18.0.4:45323 in memory (size: 48.2 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.182+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 837932af135c:42719 in memory (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.183+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 172.18.0.4:45323 in memory (size: 48.1 KiB, free: 174.4 MiB)
[2025-05-06T20:51:58.184+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 172.18.0.4:45323 (size: 48.2 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 1.0 in stage 584.0 (TID 846) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.198+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 0.0 in stage 584.0 (TID 845) in 20 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:58.222+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 2.0 in stage 584.0 (TID 847) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.223+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 1.0 in stage 584.0 (TID 846) in 26 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:58.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 3.0 in stage 584.0 (TID 848) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.244+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 2.0 in stage 584.0 (TID 847) in 23 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:58.257+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 4.0 in stage 584.0 (TID 849) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.258+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 3.0 in stage 584.0 (TID 848) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:58.270+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 5.0 in stage 584.0 (TID 850) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.270+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 4.0 in stage 584.0 (TID 849) in 13 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:58.286+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 6.0 in stage 584.0 (TID 851) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.286+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 5.0 in stage 584.0 (TID 850) in 17 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:58.299+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 7.0 in stage 584.0 (TID 852) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.300+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 6.0 in stage 584.0 (TID 851) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:58.316+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 8.0 in stage 584.0 (TID 853) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.316+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 7.0 in stage 584.0 (TID 852) in 17 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:58.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 9.0 in stage 584.0 (TID 854) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.331+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 8.0 in stage 584.0 (TID 853) in 16 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:58.344+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 9.0 in stage 584.0 (TID 854) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:58.344+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Removed TaskSet 584.0, whose tasks have all completed, from pool
[2025-05-06T20:51:58.344+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: ShuffleMapStage 584 (mapPartitions at GraphImpl.scala:208) finished in 0.184 s
[2025-05-06T20:51:58.344+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:58.344+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:58.344+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: waiting: Set(ResultStage 586, ShuffleMapStage 585)
[2025-05-06T20:51:58.345+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:58.345+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting ShuffleMapStage 585 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[530] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:58.346+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 17.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:58.346+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:58.346+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 837932af135c:42719 (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.347+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:58.347+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 585 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[530] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:58.347+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Adding task set 585.0 with 10 tasks resource profile 0
[2025-05-06T20:51:58.347+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 0.0 in stage 585.0 (TID 855) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.351+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 172.18.0.4:45323 (size: 6.7 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.18.0.4:41314
[2025-05-06T20:51:58.357+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 1.0 in stage 585.0 (TID 856) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.361+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 0.0 in stage 585.0 (TID 855) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:58.367+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.371+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 2.0 in stage 585.0 (TID 857) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.371+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 1.0 in stage 585.0 (TID 856) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:58.378+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.382+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 3.0 in stage 585.0 (TID 858) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.382+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 2.0 in stage 585.0 (TID 857) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:58.387+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.391+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 4.0 in stage 585.0 (TID 859) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.392+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 3.0 in stage 585.0 (TID 858) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:58.396+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.402+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 5.0 in stage 585.0 (TID 860) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.402+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 4.0 in stage 585.0 (TID 859) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:58.408+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.412+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 6.0 in stage 585.0 (TID 861) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.413+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 5.0 in stage 585.0 (TID 860) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:58.418+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.423+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 7.0 in stage 585.0 (TID 862) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.423+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 6.0 in stage 585.0 (TID 861) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:58.428+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.431+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 8.0 in stage 585.0 (TID 863) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.431+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 7.0 in stage 585.0 (TID 862) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:58.436+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.439+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 9.0 in stage 585.0 (TID 864) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.440+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 8.0 in stage 585.0 (TID 863) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:58.445+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_526_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 9.0 in stage 585.0 (TID 864) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:58.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Removed TaskSet 585.0, whose tasks have all completed, from pool
[2025-05-06T20:51:58.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: ShuffleMapStage 585 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.104 s
[2025-05-06T20:51:58.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:58.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:58.449+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: waiting: Set(ResultStage 586)
[2025-05-06T20:51:58.450+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:58.450+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting ResultStage 586 (EdgeRDDImpl[533] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:58.452+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 122.3 KiB, free 425.7 MiB)
[2025-05-06T20:51:58.454+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.6 MiB)
[2025-05-06T20:51:58.454+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 837932af135c:42719 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.454+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:58.454+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 586 (EdgeRDDImpl[533] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:58.455+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Adding task set 586.0 with 10 tasks resource profile 0
[2025-05-06T20:51:58.455+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 0.0 in stage 586.0 (TID 865) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.459+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 172.18.0.4:45323 (size: 48.0 KiB, free: 174.1 MiB)
[2025-05-06T20:51:58.464+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.18.0.4:41314
[2025-05-06T20:51:58.466+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:58.467+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 1.0 in stage 586.0 (TID 866) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.467+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 0.0 in stage 586.0 (TID 865) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:58.472+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T20:51:58.474+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 2.0 in stage 586.0 (TID 867) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.474+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 1.0 in stage 586.0 (TID 866) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:58.482+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:58.483+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 3.0 in stage 586.0 (TID 868) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.483+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 2.0 in stage 586.0 (TID 867) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:58.488+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T20:51:58.490+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 4.0 in stage 586.0 (TID 869) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.490+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 3.0 in stage 586.0 (TID 868) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:58.498+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:58.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 5.0 in stage 586.0 (TID 870) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 4.0 in stage 586.0 (TID 869) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:58.506+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:58.507+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 6.0 in stage 586.0 (TID 871) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.507+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 5.0 in stage 586.0 (TID 870) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:58.514+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T20:51:58.515+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 7.0 in stage 586.0 (TID 872) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.515+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 6.0 in stage 586.0 (TID 871) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:58.521+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:58.522+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 8.0 in stage 586.0 (TID 873) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.522+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 7.0 in stage 586.0 (TID 872) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:58.528+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:58.530+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 9.0 in stage 586.0 (TID 874) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.530+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 8.0 in stage 586.0 (TID 873) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:58.536+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_532_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:58.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 9.0 in stage 586.0 (TID 874) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:58.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Removed TaskSet 586.0, whose tasks have all completed, from pool
[2025-05-06T20:51:58.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: ResultStage 586 (foreachPartition at PageRank.scala:199) finished in 0.088 s
[2025-05-06T20:51:58.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:58.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 586: Stage finished
[2025-05-06T20:51:58.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Job 61 finished: foreachPartition at PageRank.scala:199, took 0.382109 s
[2025-05-06T20:51:58.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO PageRank: PageRank finished iteration 8.
[2025-05-06T20:51:58.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO ZippedPartitionsRDD2: Removing RDD 514 from persistence list
[2025-05-06T20:51:58.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManager: Removing RDD 514
[2025-05-06T20:51:58.539+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO ZippedPartitionsRDD2: Removing RDD 520 from persistence list
[2025-05-06T20:51:58.540+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManager: Removing RDD 520
[2025-05-06T20:51:58.551+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T20:51:58.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Registering RDD 534 (mapPartitions at GraphImpl.scala:208) as input to shuffle 82
[2025-05-06T20:51:58.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Registering RDD 542 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 81
[2025-05-06T20:51:58.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Got job 62 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T20:51:58.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Final stage: ResultStage 618 (foreachPartition at PageRank.scala:199)
[2025-05-06T20:51:58.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 596, ShuffleMapStage 611, ShuffleMapStage 597, ShuffleMapStage 613, ShuffleMapStage 605, ShuffleMapStage 599, ShuffleMapStage 607, ShuffleMapStage 593, ShuffleMapStage 615, ShuffleMapStage 609, ShuffleMapStage 601, ShuffleMapStage 587, ShuffleMapStage 617, ShuffleMapStage 603)
[2025-05-06T20:51:58.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 617)
[2025-05-06T20:51:58.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting ShuffleMapStage 616 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[534] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T20:51:58.557+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 122.8 KiB, free 425.5 MiB)
[2025-05-06T20:51:58.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 837932af135c:42719 in memory (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 48.4 KiB, free 425.5 MiB)
[2025-05-06T20:51:58.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 837932af135c:42719 (size: 48.4 KiB, free: 434.1 MiB)
[2025-05-06T20:51:58.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:58.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 616 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[534] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:58.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Adding task set 616.0 with 10 tasks resource profile 0
[2025-05-06T20:51:58.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 172.18.0.4:45323 in memory (size: 6.7 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.568+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 0.0 in stage 616.0 (TID 875) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.569+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 837932af135c:42719 in memory (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.570+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 172.18.0.4:45323 in memory (size: 48.0 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.571+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 837932af135c:42719 in memory (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.572+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 172.18.0.4:45323 in memory (size: 48.2 KiB, free: 174.4 MiB)
[2025-05-06T20:51:58.573+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 172.18.0.4:45323 (size: 48.4 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.591+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 1.0 in stage 616.0 (TID 876) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.592+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 0.0 in stage 616.0 (TID 875) in 24 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:58.617+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 2.0 in stage 616.0 (TID 877) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.618+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 1.0 in stage 616.0 (TID 876) in 26 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:58.642+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 3.0 in stage 616.0 (TID 878) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.642+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 2.0 in stage 616.0 (TID 877) in 25 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:58.655+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 4.0 in stage 616.0 (TID 879) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.656+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 3.0 in stage 616.0 (TID 878) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:58.669+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 5.0 in stage 616.0 (TID 880) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.669+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 4.0 in stage 616.0 (TID 879) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:58.682+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 6.0 in stage 616.0 (TID 881) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.682+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 5.0 in stage 616.0 (TID 880) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:58.694+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 7.0 in stage 616.0 (TID 882) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.694+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 6.0 in stage 616.0 (TID 881) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:58.709+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 8.0 in stage 616.0 (TID 883) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.709+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 7.0 in stage 616.0 (TID 882) in 15 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:58.722+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 9.0 in stage 616.0 (TID 884) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.722+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 8.0 in stage 616.0 (TID 883) in 14 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:58.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 9.0 in stage 616.0 (TID 884) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:58.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Removed TaskSet 616.0, whose tasks have all completed, from pool
[2025-05-06T20:51:58.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: ShuffleMapStage 616 (mapPartitions at GraphImpl.scala:208) finished in 0.180 s
[2025-05-06T20:51:58.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:58.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:58.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 617, ResultStage 618)
[2025-05-06T20:51:58.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:58.734+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting ShuffleMapStage 617 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[542] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T20:51:58.735+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 18.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:58.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:58.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:58.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 617 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[542] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:58.736+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Adding task set 617.0 with 10 tasks resource profile 0
[2025-05-06T20:51:58.737+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 0.0 in stage 617.0 (TID 885) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.740+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.743+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.18.0.4:41314
[2025-05-06T20:51:58.748+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.752+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 1.0 in stage 617.0 (TID 886) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.752+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 0.0 in stage 617.0 (TID 885) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:58.758+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.762+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 2.0 in stage 617.0 (TID 887) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.762+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 1.0 in stage 617.0 (TID 886) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:58.767+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.769+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 3.0 in stage 617.0 (TID 888) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.770+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 2.0 in stage 617.0 (TID 887) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:58.773+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.777+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 4.0 in stage 617.0 (TID 889) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.777+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 3.0 in stage 617.0 (TID 888) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:58.782+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 5.0 in stage 617.0 (TID 890) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 4.0 in stage 617.0 (TID 889) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:58.788+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.791+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 6.0 in stage 617.0 (TID 891) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.791+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 5.0 in stage 617.0 (TID 890) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:58.797+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.800+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 7.0 in stage 617.0 (TID 892) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.800+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 6.0 in stage 617.0 (TID 891) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:58.804+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.807+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 8.0 in stage 617.0 (TID 893) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.808+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 7.0 in stage 617.0 (TID 892) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:58.813+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.816+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 9.0 in stage 617.0 (TID 894) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.816+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 8.0 in stage 617.0 (TID 893) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:58.820+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_538_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:51:58.823+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 9.0 in stage 617.0 (TID 894) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:58.823+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Removed TaskSet 617.0, whose tasks have all completed, from pool
[2025-05-06T20:51:58.823+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: ShuffleMapStage 617 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.089 s
[2025-05-06T20:51:58.823+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:58.823+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: running: Set()
[2025-05-06T20:51:58.823+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: waiting: Set(ResultStage 618)
[2025-05-06T20:51:58.823+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:58.823+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting ResultStage 618 (EdgeRDDImpl[545] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T20:51:58.827+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 122.6 KiB, free 425.7 MiB)
[2025-05-06T20:51:58.828+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 425.6 MiB)
[2025-05-06T20:51:58.829+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 837932af135c:42719 (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.829+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:58.829+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 618 (EdgeRDDImpl[545] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:58.829+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Adding task set 618.0 with 10 tasks resource profile 0
[2025-05-06T20:51:58.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 0.0 in stage 618.0 (TID 895) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 172.18.0.4:45323 (size: 48.2 KiB, free: 174.1 MiB)
[2025-05-06T20:51:58.838+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.18.0.4:41314
[2025-05-06T20:51:58.841+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_0 in memory on 172.18.0.4:45323 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T20:51:58.844+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 1.0 in stage 618.0 (TID 896) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.844+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 0.0 in stage 618.0 (TID 895) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:58.851+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_1 in memory on 172.18.0.4:45323 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T20:51:58.852+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 2.0 in stage 618.0 (TID 897) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.853+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 1.0 in stage 618.0 (TID 896) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:58.864+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_2 in memory on 172.18.0.4:45323 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T20:51:58.866+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 3.0 in stage 618.0 (TID 898) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.866+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 2.0 in stage 618.0 (TID 897) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:58.871+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_3 in memory on 172.18.0.4:45323 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T20:51:58.873+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 4.0 in stage 618.0 (TID 899) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.873+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 3.0 in stage 618.0 (TID 898) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:58.884+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_4 in memory on 172.18.0.4:45323 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T20:51:58.885+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 5.0 in stage 618.0 (TID 900) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.886+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 4.0 in stage 618.0 (TID 899) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:58.893+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_5 in memory on 172.18.0.4:45323 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T20:51:58.896+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 6.0 in stage 618.0 (TID 901) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.897+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 5.0 in stage 618.0 (TID 900) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:58.905+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_6 in memory on 172.18.0.4:45323 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T20:51:58.906+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 7.0 in stage 618.0 (TID 902) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.906+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 6.0 in stage 618.0 (TID 901) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:58.914+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_7 in memory on 172.18.0.4:45323 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T20:51:58.916+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 8.0 in stage 618.0 (TID 903) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.916+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 7.0 in stage 618.0 (TID 902) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:58.922+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_8 in memory on 172.18.0.4:45323 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T20:51:58.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 9.0 in stage 618.0 (TID 904) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.924+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 8.0 in stage 618.0 (TID 903) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:58.934+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added rdd_544_9 in memory on 172.18.0.4:45323 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T20:51:58.935+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Finished task 9.0 in stage 618.0 (TID 904) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:58.935+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Removed TaskSet 618.0, whose tasks have all completed, from pool
[2025-05-06T20:51:58.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: ResultStage 618 (foreachPartition at PageRank.scala:199) finished in 0.111 s
[2025-05-06T20:51:58.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:58.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 618: Stage finished
[2025-05-06T20:51:58.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Job 62 finished: foreachPartition at PageRank.scala:199, took 0.384400 s
[2025-05-06T20:51:58.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO PageRank: PageRank finished iteration 9.
[2025-05-06T20:51:58.936+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO ZippedPartitionsRDD2: Removing RDD 526 from persistence list
[2025-05-06T20:51:58.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManager: Removing RDD 526
[2025-05-06T20:51:58.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO ZippedPartitionsRDD2: Removing RDD 532 from persistence list
[2025-05-06T20:51:58.937+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManager: Removing RDD 532
[2025-05-06T20:51:58.955+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Starting job: sum at PageRank.scala:503
[2025-05-06T20:51:58.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Got job 63 (sum at PageRank.scala:503) with 10 output partitions
[2025-05-06T20:51:58.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Final stage: ResultStage 649 (sum at PageRank.scala:503)
[2025-05-06T20:51:58.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 625, ShuffleMapStage 640, ShuffleMapStage 644, ShuffleMapStage 626, ShuffleMapStage 630, ShuffleMapStage 648, ShuffleMapStage 627, ShuffleMapStage 634, ShuffleMapStage 646, ShuffleMapStage 638, ShuffleMapStage 632, ShuffleMapStage 642, ShuffleMapStage 636)
[2025-05-06T20:51:58.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:51:58.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting ResultStage 649 (MapPartitionsRDD[546] at values at PageRank.scala:503), which has no missing parents
[2025-05-06T20:51:58.959+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 18.9 KiB, free 425.6 MiB)
[2025-05-06T20:51:58.968+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 425.6 MiB)
[2025-05-06T20:51:58.969+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 837932af135c:42719 (size: 7.0 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.969+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.969+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:58.969+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 649 (MapPartitionsRDD[546] at values at PageRank.scala:503) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:58.969+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSchedulerImpl: Adding task set 649.0 with 10 tasks resource profile 0
[2025-05-06T20:51:58.970+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO TaskSetManager: Starting task 0.0 in stage 649.0 (TID 905) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:58.970+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.972+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 837932af135c:42719 in memory (size: 48.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:58.973+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 172.18.0.4:45323 in memory (size: 48.4 KiB, free: 174.3 MiB)
[2025-05-06T20:51:58.981+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 837932af135c:42719 in memory (size: 48.2 KiB, free: 434.3 MiB)
[2025-05-06T20:51:58.982+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 172.18.0.4:45323 in memory (size: 48.2 KiB, free: 174.4 MiB)
[2025-05-06T20:51:58.983+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:58 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 172.18.0.4:45323 (size: 7.0 KiB, free: 174.4 MiB)
[2025-05-06T20:51:59.007+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 1.0 in stage 649.0 (TID 906) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.008+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 0.0 in stage 649.0 (TID 905) in 37 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:59.022+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 2.0 in stage 649.0 (TID 907) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.022+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 1.0 in stage 649.0 (TID 906) in 15 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:59.028+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 3.0 in stage 649.0 (TID 908) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.029+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 2.0 in stage 649.0 (TID 907) in 6 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:59.034+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 4.0 in stage 649.0 (TID 909) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.034+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 3.0 in stage 649.0 (TID 908) in 6 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:59.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 5.0 in stage 649.0 (TID 910) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 4.0 in stage 649.0 (TID 909) in 5 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:59.043+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 6.0 in stage 649.0 (TID 911) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.044+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 5.0 in stage 649.0 (TID 910) in 5 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:59.048+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 7.0 in stage 649.0 (TID 912) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.048+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 6.0 in stage 649.0 (TID 911) in 6 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:59.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 8.0 in stage 649.0 (TID 913) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.050+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 7.0 in stage 649.0 (TID 912) in 3 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:59.053+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 9.0 in stage 649.0 (TID 914) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.053+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 8.0 in stage 649.0 (TID 913) in 3 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:59.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 9.0 in stage 649.0 (TID 914) in 2 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:59.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Removed TaskSet 649.0, whose tasks have all completed, from pool
[2025-05-06T20:51:59.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: ResultStage 649 (sum at PageRank.scala:503) finished in 0.097 s
[2025-05-06T20:51:59.056+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:59.056+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 649: Stage finished
[2025-05-06T20:51:59.056+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Job 63 finished: sum at PageRank.scala:503, took 0.100680 s
[2025-05-06T20:51:59.060+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T20:51:59.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Got job 64 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T20:51:59.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Final stage: ResultStage 680 (fold at VertexRDDImpl.scala:90)
[2025-05-06T20:51:59.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 661, ShuffleMapStage 679, ShuffleMapStage 673, ShuffleMapStage 658, ShuffleMapStage 665, ShuffleMapStage 677, ShuffleMapStage 663, ShuffleMapStage 667, ShuffleMapStage 656, ShuffleMapStage 671, ShuffleMapStage 675, ShuffleMapStage 657, ShuffleMapStage 669)
[2025-05-06T20:51:59.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:51:59.062+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting ResultStage 680 (MapPartitionsRDD[547] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T20:51:59.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 18.7 KiB, free 425.9 MiB)
[2025-05-06T20:51:59.064+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 425.9 MiB)
[2025-05-06T20:51:59.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 837932af135c:42719 (size: 6.9 KiB, free: 434.3 MiB)
[2025-05-06T20:51:59.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:59.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 680 (MapPartitionsRDD[547] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:59.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Adding task set 680.0 with 10 tasks resource profile 0
[2025-05-06T20:51:59.065+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 0.0 in stage 680.0 (TID 915) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.068+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 172.18.0.4:45323 (size: 6.9 KiB, free: 174.4 MiB)
[2025-05-06T20:51:59.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 1.0 in stage 680.0 (TID 916) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.071+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 0.0 in stage 680.0 (TID 915) in 6 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:59.073+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 2.0 in stage 680.0 (TID 917) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.073+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 1.0 in stage 680.0 (TID 916) in 3 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:59.077+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 3.0 in stage 680.0 (TID 918) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.078+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 2.0 in stage 680.0 (TID 917) in 4 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:59.080+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 4.0 in stage 680.0 (TID 919) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.081+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 3.0 in stage 680.0 (TID 918) in 3 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:59.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 5.0 in stage 680.0 (TID 920) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 4.0 in stage 680.0 (TID 919) in 3 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:59.086+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 6.0 in stage 680.0 (TID 921) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.086+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 5.0 in stage 680.0 (TID 920) in 3 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:59.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 7.0 in stage 680.0 (TID 922) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.089+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 6.0 in stage 680.0 (TID 921) in 3 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:59.092+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 8.0 in stage 680.0 (TID 923) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 7.0 in stage 680.0 (TID 922) in 4 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:59.096+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 9.0 in stage 680.0 (TID 924) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.097+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 8.0 in stage 680.0 (TID 923) in 4 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:59.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 9.0 in stage 680.0 (TID 924) in 3 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:59.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Removed TaskSet 680.0, whose tasks have all completed, from pool
[2025-05-06T20:51:59.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: ResultStage 680 (fold at VertexRDDImpl.scala:90) finished in 0.036 s
[2025-05-06T20:51:59.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:59.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 680: Stage finished
[2025-05-06T20:51:59.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Job 64 finished: fold at VertexRDDImpl.scala:90, took 0.039402 s
[2025-05-06T20:51:59.231+0000] {spark_submit.py:571} INFO - 2025-05-06 20:51:59,231 [INFO] Объединяем результаты анализа
[2025-05-06T20:51:59.334+0000] {spark_submit.py:571} INFO - 2025-05-06 20:51:59,334 [INFO] Сохраняем результаты в graph.client_communities
[2025-05-06T20:51:59.472+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 837932af135c:42719 in memory (size: 7.0 KiB, free: 434.3 MiB)
[2025-05-06T20:51:59.474+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 172.18.0.4:45323 in memory (size: 7.0 KiB, free: 174.4 MiB)
[2025-05-06T20:51:59.478+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 837932af135c:42719 in memory (size: 6.9 KiB, free: 434.3 MiB)
[2025-05-06T20:51:59.478+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 172.18.0.4:45323 in memory (size: 6.9 KiB, free: 174.4 MiB)
[2025-05-06T20:51:59.548+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:51:59.553+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Registering RDD 563 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 84
[2025-05-06T20:51:59.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Got map stage job 65 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:51:59.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Final stage: ShuffleMapStage 681 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:51:59.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T20:51:59.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:51:59.554+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting ShuffleMapStage 681 (MapPartitionsRDD[563] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:51:59.558+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 19.9 KiB, free 425.9 MiB)
[2025-05-06T20:51:59.562+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 425.9 MiB)
[2025-05-06T20:51:59.563+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 837932af135c:42719 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T20:51:59.563+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:59.564+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 681 (MapPartitionsRDD[563] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:51:59.564+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Adding task set 681.0 with 1 tasks resource profile 0
[2025-05-06T20:51:59.564+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO CodeGenerator: Code generated in 8.091486 ms
[2025-05-06T20:51:59.564+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 0.0 in stage 681.0 (TID 925) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.564+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#1005 - id.nullCount#1004) > 0)
[2025-05-06T20:51:59.572+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 172.18.0.4:45323 (size: 9.7 KiB, free: 174.4 MiB)
[2025-05-06T20:51:59.585+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:51:59.586+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Got job 66 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 10 output partitions
[2025-05-06T20:51:59.586+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Final stage: ResultStage 683 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:51:59.587+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 682)
[2025-05-06T20:51:59.587+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:51:59.587+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO CodeGenerator: Code generated in 14.638104 ms
[2025-05-06T20:51:59.589+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting ResultStage 683 (MapPartitionsRDD[568] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:51:59.595+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 49.9 KiB, free 425.9 MiB)
[2025-05-06T20:51:59.596+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 425.9 MiB)
[2025-05-06T20:51:59.596+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 837932af135c:42719 (size: 20.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:59.596+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:59.596+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 683 (MapPartitionsRDD[568] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:59.596+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Adding task set 683.0 with 10 tasks resource profile 0
[2025-05-06T20:51:59.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Registering RDD 571 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 85
[2025-05-06T20:51:59.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Got map stage job 67 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-06T20:51:59.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Final stage: ShuffleMapStage 721 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:51:59.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 711, ShuffleMapStage 705, ShuffleMapStage 702, ShuffleMapStage 699, ShuffleMapStage 717, ShuffleMapStage 714, ShuffleMapStage 696, ShuffleMapStage 684, ShuffleMapStage 693, ShuffleMapStage 690, ShuffleMapStage 708, ShuffleMapStage 720)
[2025-05-06T20:51:59.604+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:51:59.605+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting ShuffleMapStage 721 (MapPartitionsRDD[571] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:51:59.618+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 30.4 KiB, free 425.8 MiB)
[2025-05-06T20:51:59.618+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:59.619+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 837932af135c:42719 (size: 11.5 KiB, free: 434.2 MiB)
[2025-05-06T20:51:59.620+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:59.620+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 721 (MapPartitionsRDD[571] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:59.620+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Adding task set 721.0 with 10 tasks resource profile 0
[2025-05-06T20:51:59.621+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 0.0 in stage 683.0 (TID 926) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.622+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 0.0 in stage 681.0 (TID 925) in 63 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:51:59.622+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Removed TaskSet 681.0, whose tasks have all completed, from pool
[2025-05-06T20:51:59.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: ShuffleMapStage 681 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.068 s
[2025-05-06T20:51:59.624+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:51:59.624+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: running: Set(ShuffleMapStage 721, ResultStage 683)
[2025-05-06T20:51:59.624+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:51:59.624+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: failed: Set()
[2025-05-06T20:51:59.624+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO CodeGenerator: Code generated in 26.496732 ms
[2025-05-06T20:51:59.632+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 172.18.0.4:45323 (size: 20.4 KiB, free: 174.3 MiB)
[2025-05-06T20:51:59.632+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Registering RDD 574 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 86
[2025-05-06T20:51:59.633+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Got map stage job 68 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-06T20:51:59.633+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Final stage: ShuffleMapStage 744 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:51:59.633+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 727, ShuffleMapStage 731, ShuffleMapStage 743, ShuffleMapStage 684, ShuffleMapStage 735, ShuffleMapStage 729, ShuffleMapStage 739, ShuffleMapStage 733, ShuffleMapStage 725, ShuffleMapStage 722, ShuffleMapStage 737, ShuffleMapStage 690, ShuffleMapStage 741)
[2025-05-06T20:51:59.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:51:59.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting ShuffleMapStage 744 (MapPartitionsRDD[574] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:51:59.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 31.6 KiB, free 425.8 MiB)
[2025-05-06T20:51:59.663+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 425.8 MiB)
[2025-05-06T20:51:59.663+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 837932af135c:42719 (size: 11.8 KiB, free: 434.2 MiB)
[2025-05-06T20:51:59.665+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:59.666+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 744 (MapPartitionsRDD[574] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:59.666+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Adding task set 744.0 with 10 tasks resource profile 0
[2025-05-06T20:51:59.668+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 1.0 in stage 683.0 (TID 927) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.670+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 172.18.0.4:45323 in memory (size: 9.7 KiB, free: 174.3 MiB)
[2025-05-06T20:51:59.674+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 0.0 in stage 683.0 (TID 926) in 48 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:59.675+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO CodeGenerator: Code generated in 37.503887 ms
[2025-05-06T20:51:59.676+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 837932af135c:42719 in memory (size: 9.7 KiB, free: 434.2 MiB)
[2025-05-06T20:51:59.684+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 2.0 in stage 683.0 (TID 928) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.685+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 1.0 in stage 683.0 (TID 927) in 16 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:59.687+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Registering RDD 577 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 87
[2025-05-06T20:51:59.688+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Got map stage job 69 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-06T20:51:59.688+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Final stage: ShuffleMapStage 745 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:51:59.689+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 727, ShuffleMapStage 731, ShuffleMapStage 743, ShuffleMapStage 684, ShuffleMapStage 735, ShuffleMapStage 729, ShuffleMapStage 739, ShuffleMapStage 733, ShuffleMapStage 725, ShuffleMapStage 722, ShuffleMapStage 737, ShuffleMapStage 690, ShuffleMapStage 741)
[2025-05-06T20:51:59.692+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:51:59.695+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting ShuffleMapStage 745 (MapPartitionsRDD[577] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:51:59.695+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 3.0 in stage 683.0 (TID 929) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.697+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 2.0 in stage 683.0 (TID 928) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:59.705+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 26.7 KiB, free 425.8 MiB)
[2025-05-06T20:51:59.705+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 4.0 in stage 683.0 (TID 930) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.709+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 425.8 MiB)
[2025-05-06T20:51:59.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 837932af135c:42719 (size: 10.5 KiB, free: 434.2 MiB)
[2025-05-06T20:51:59.711+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:59.712+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 745 (MapPartitionsRDD[577] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T20:51:59.712+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Adding task set 745.0 with 10 tasks resource profile 0
[2025-05-06T20:51:59.713+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 3.0 in stage 683.0 (TID 929) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:59.718+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 5.0 in stage 683.0 (TID 931) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.719+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 4.0 in stage 683.0 (TID 930) in 15 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:59.728+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 6.0 in stage 683.0 (TID 932) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.729+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 5.0 in stage 683.0 (TID 931) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:59.738+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 7.0 in stage 683.0 (TID 933) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.741+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 6.0 in stage 683.0 (TID 932) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:51:59.762+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 7.0 in stage 683.0 (TID 933) in 24 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:51:59.763+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 8.0 in stage 683.0 (TID 934) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.773+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 9.0 in stage 683.0 (TID 935) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 8.0 in stage 683.0 (TID 934) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:51:59.782+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 0.0 in stage 721.0 (TID 936) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 9.0 in stage 683.0 (TID 935) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:51:59.784+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Removed TaskSet 683.0, whose tasks have all completed, from pool
[2025-05-06T20:51:59.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: ResultStage 683 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.194 s
[2025-05-06T20:51:59.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:51:59.785+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 683: Stage finished
[2025-05-06T20:51:59.786+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Job 66 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.200002 s
[2025-05-06T20:51:59.791+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 172.18.0.4:45323 (size: 11.5 KiB, free: 174.3 MiB)
[2025-05-06T20:51:59.799+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO CodeGenerator: Code generated in 9.665693 ms
[2025-05-06T20:51:59.803+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 2.1 MiB, free 423.7 MiB)
[2025-05-06T20:51:59.805+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 26.3 KiB, free 423.7 MiB)
[2025-05-06T20:51:59.805+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 837932af135c:42719 (size: 26.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:59.806+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Created broadcast 139 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:51:59.825+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:51:59.830+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:51:59.832+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:51:59.835+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:51:59.838+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:51:59.856+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 1.0 in stage 721.0 (TID 937) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.858+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 0.0 in stage 721.0 (TID 936) in 74 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:51:59.866+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO CodeGenerator: Code generated in 19.041946 ms
[2025-05-06T20:51:59.876+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 1.0 in stage 721.0 (TID 937) in 18 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:51:59.879+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 2.0 in stage 721.0 (TID 938) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Registering RDD 580 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 88
[2025-05-06T20:51:59.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Got map stage job 70 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:51:59.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Final stage: ShuffleMapStage 747 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:51:59.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 746)
[2025-05-06T20:51:59.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:51:59.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting ShuffleMapStage 747 (MapPartitionsRDD[580] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:51:59.884+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 66.4 KiB, free 423.6 MiB)
[2025-05-06T20:51:59.905+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 423.6 MiB)
[2025-05-06T20:51:59.909+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 3.0 in stage 721.0 (TID 939) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.915+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 2.0 in stage 721.0 (TID 938) in 31 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:51:59.917+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 837932af135c:42719 (size: 27.3 KiB, free: 434.2 MiB)
[2025-05-06T20:51:59.918+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 837932af135c:42719 in memory (size: 20.4 KiB, free: 434.2 MiB)
[2025-05-06T20:51:59.918+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 172.18.0.4:45323 in memory (size: 20.4 KiB, free: 174.4 MiB)
[2025-05-06T20:51:59.919+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:51:59.919+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 747 (MapPartitionsRDD[580] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:51:59.920+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSchedulerImpl: Adding task set 747.0 with 1 tasks resource profile 0
[2025-05-06T20:51:59.926+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 4.0 in stage 721.0 (TID 940) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 3.0 in stage 721.0 (TID 939) in 24 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:51:59.942+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 5.0 in stage 721.0 (TID 941) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.943+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 4.0 in stage 721.0 (TID 940) in 16 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:51:59.956+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 5.0 in stage 721.0 (TID 941) in 15 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:51:59.957+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 6.0 in stage 721.0 (TID 942) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.986+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Starting task 7.0 in stage 721.0 (TID 943) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:51:59.987+0000] {spark_submit.py:571} INFO - 25/05/06 20:51:59 INFO TaskSetManager: Finished task 6.0 in stage 721.0 (TID 942) in 27 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:52:00.006+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 8.0 in stage 721.0 (TID 944) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.012+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 7.0 in stage 721.0 (TID 943) in 26 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:52:00.018+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 9.0 in stage 721.0 (TID 945) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.020+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 8.0 in stage 721.0 (TID 944) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:52:00.031+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 9.0 in stage 721.0 (TID 945) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:52:00.032+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Removed TaskSet 721.0, whose tasks have all completed, from pool
[2025-05-06T20:52:00.033+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 0.0 in stage 744.0 (TID 946) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.033+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: ShuffleMapStage 721 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.429 s
[2025-05-06T20:52:00.034+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:52:00.035+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: running: Set(ShuffleMapStage 745, ShuffleMapStage 747, ShuffleMapStage 744)
[2025-05-06T20:52:00.035+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:52:00.036+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: failed: Set()
[2025-05-06T20:52:00.040+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 172.18.0.4:45323 (size: 11.8 KiB, free: 174.3 MiB)
[2025-05-06T20:52:00.049+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_0 in memory on 172.18.0.4:45323 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T20:52:00.057+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(85), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.063+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(85), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.074+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 1.0 in stage 744.0 (TID 947) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.075+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 0.0 in stage 744.0 (TID 946) in 41 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:52:00.077+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:00.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Got job 71 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:52:00.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Final stage: ResultStage 779 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:52:00.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 778)
[2025-05-06T20:52:00.085+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:00.085+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting ResultStage 779 (MapPartitionsRDD[582] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:52:00.087+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_1 in memory on 172.18.0.4:45323 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T20:52:00.091+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 7.2 KiB, free 423.7 MiB)
[2025-05-06T20:52:00.092+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 423.7 MiB)
[2025-05-06T20:52:00.092+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:00.094+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 779 (MapPartitionsRDD[582] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:00.094+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Adding task set 779.0 with 1 tasks resource profile 0
[2025-05-06T20:52:00.094+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 1.0 in stage 744.0 (TID 947) in 21 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:52:00.095+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 2.0 in stage 744.0 (TID 948) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.101+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_2 in memory on 172.18.0.4:45323 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T20:52:00.106+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 3.0 in stage 744.0 (TID 949) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.107+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 2.0 in stage 744.0 (TID 948) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:52:00.114+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_3 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T20:52:00.119+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 4.0 in stage 744.0 (TID 950) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.120+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 3.0 in stage 744.0 (TID 949) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:52:00.125+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_4 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T20:52:00.131+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 5.0 in stage 744.0 (TID 951) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.133+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 4.0 in stage 744.0 (TID 950) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:52:00.138+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_5 in memory on 172.18.0.4:45323 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T20:52:00.143+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 6.0 in stage 744.0 (TID 952) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.145+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 5.0 in stage 744.0 (TID 951) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:52:00.150+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_6 in memory on 172.18.0.4:45323 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 7.0 in stage 744.0 (TID 953) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.155+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 6.0 in stage 744.0 (TID 952) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:52:00.160+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_7 in memory on 172.18.0.4:45323 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.167+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 8.0 in stage 744.0 (TID 954) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.167+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 7.0 in stage 744.0 (TID 953) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:52:00.172+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_8 in memory on 172.18.0.4:45323 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.179+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 9.0 in stage 744.0 (TID 955) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.180+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 8.0 in stage 744.0 (TID 954) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:52:00.185+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added rdd_548_9 in memory on 172.18.0.4:45323 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 0.0 in stage 745.0 (TID 956) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 9.0 in stage 744.0 (TID 955) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:52:00.190+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Removed TaskSet 744.0, whose tasks have all completed, from pool
[2025-05-06T20:52:00.191+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: ShuffleMapStage 744 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.555 s
[2025-05-06T20:52:00.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:52:00.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: running: Set(ShuffleMapStage 745, ResultStage 779, ShuffleMapStage 747)
[2025-05-06T20:52:00.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:52:00.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: failed: Set()
[2025-05-06T20:52:00.202+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 172.18.0.4:45323 (size: 10.5 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.210+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(86), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.224+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:00.226+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Got job 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:52:00.230+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Final stage: ResultStage 781 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:52:00.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 780)
[2025-05-06T20:52:00.231+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:00.232+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting ResultStage 781 (MapPartitionsRDD[584] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:52:00.233+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 7.2 KiB, free 423.6 MiB)
[2025-05-06T20:52:00.234+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 423.6 MiB)
[2025-05-06T20:52:00.235+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.239+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:00.240+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 781 (MapPartitionsRDD[584] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:00.241+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Adding task set 781.0 with 1 tasks resource profile 0
[2025-05-06T20:52:00.250+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 1.0 in stage 745.0 (TID 957) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.251+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 0.0 in stage 745.0 (TID 956) in 61 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T20:52:00.263+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 2.0 in stage 745.0 (TID 958) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.267+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 1.0 in stage 745.0 (TID 957) in 15 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T20:52:00.279+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 3.0 in stage 745.0 (TID 959) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.281+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 2.0 in stage 745.0 (TID 958) in 18 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T20:52:00.292+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 4.0 in stage 745.0 (TID 960) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.297+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 3.0 in stage 745.0 (TID 959) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T20:52:00.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 4.0 in stage 745.0 (TID 960) in 17 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T20:52:00.311+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 5.0 in stage 745.0 (TID 961) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.328+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 6.0 in stage 745.0 (TID 962) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.330+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 5.0 in stage 745.0 (TID 961) in 19 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T20:52:00.341+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 7.0 in stage 745.0 (TID 963) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.342+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 6.0 in stage 745.0 (TID 962) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T20:52:00.352+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 8.0 in stage 745.0 (TID 964) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.353+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 7.0 in stage 745.0 (TID 963) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T20:52:00.359+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 9.0 in stage 745.0 (TID 965) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.360+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 8.0 in stage 745.0 (TID 964) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T20:52:00.372+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 0.0 in stage 747.0 (TID 966) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.372+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 9.0 in stage 745.0 (TID 965) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T20:52:00.373+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Removed TaskSet 745.0, whose tasks have all completed, from pool
[2025-05-06T20:52:00.373+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: ShuffleMapStage 745 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.677 s
[2025-05-06T20:52:00.373+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:52:00.373+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: running: Set(ResultStage 781, ResultStage 779, ShuffleMapStage 747)
[2025-05-06T20:52:00.373+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:52:00.373+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: failed: Set()
[2025-05-06T20:52:00.379+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 172.18.0.4:45323 (size: 27.3 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.386+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.18.0.4:41314
[2025-05-06T20:52:00.406+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(87), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.407+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 837932af135c:42719 in memory (size: 11.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.416+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 172.18.0.4:45323 in memory (size: 11.8 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.420+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:00.422+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Got job 73 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:52:00.423+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Final stage: ResultStage 783 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:52:00.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 782)
[2025-05-06T20:52:00.427+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:00.427+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting ResultStage 783 (MapPartitionsRDD[586] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:52:00.428+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 7.2 KiB, free 423.7 MiB)
[2025-05-06T20:52:00.429+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 423.7 MiB)
[2025-05-06T20:52:00.434+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.434+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 837932af135c:42719 in memory (size: 11.5 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.435+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:00.436+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 783 (MapPartitionsRDD[586] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:00.436+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Adding task set 783.0 with 1 tasks resource profile 0
[2025-05-06T20:52:00.461+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 172.18.0.4:45323 in memory (size: 11.5 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.465+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 837932af135c:42719 in memory (size: 10.5 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 172.18.0.4:45323 in memory (size: 10.5 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 172.18.0.4:45323 (size: 26.3 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.508+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 0.0 in stage 779.0 (TID 967) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 0.0 in stage 747.0 (TID 966) in 136 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:00.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Removed TaskSet 747.0, whose tasks have all completed, from pool
[2025-05-06T20:52:00.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: ShuffleMapStage 747 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.633 s
[2025-05-06T20:52:00.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:52:00.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: running: Set(ResultStage 781, ResultStage 779, ResultStage 783)
[2025-05-06T20:52:00.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:52:00.510+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: failed: Set()
[2025-05-06T20:52:00.524+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.527+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.18.0.4:41314
[2025-05-06T20:52:00.534+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 0.0 in stage 781.0 (TID 968) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.537+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 0.0 in stage 779.0 (TID 967) in 28 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:00.537+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Removed TaskSet 779.0, whose tasks have all completed, from pool
[2025-05-06T20:52:00.537+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: ResultStage 779 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.451 s
[2025-05-06T20:52:00.537+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:52:00.537+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 779: Stage finished
[2025-05-06T20:52:00.538+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Job 71 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.459355 s
[2025-05-06T20:52:00.545+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.546+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.18.0.4:41314
[2025-05-06T20:52:00.561+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO CodeGenerator: Code generated in 11.149518 ms
[2025-05-06T20:52:00.563+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 0.0 in stage 783.0 (TID 969) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.565+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 0.0 in stage 781.0 (TID 968) in 31 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:00.565+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Removed TaskSet 781.0, whose tasks have all completed, from pool
[2025-05-06T20:52:00.566+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: ResultStage 781 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.336 s
[2025-05-06T20:52:00.566+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:52:00.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 781: Stage finished
[2025-05-06T20:52:00.567+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Job 72 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.341047 s
[2025-05-06T20:52:00.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 1088.0 KiB, free 422.7 MiB)
[2025-05-06T20:52:00.578+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 1088.0 KiB, free 421.6 MiB)
[2025-05-06T20:52:00.579+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.582+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.18.0.4:41314
[2025-05-06T20:52:00.602+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 32.1 KiB, free 421.6 MiB)
[2025-05-06T20:52:00.602+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 22.8 KiB, free 421.6 MiB)
[2025-05-06T20:52:00.602+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 837932af135c:42719 (size: 32.1 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.607+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 837932af135c:42719 (size: 22.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 144 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:00.612+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.613+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 145 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:00.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 837932af135c:42719 in memory (size: 27.3 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.627+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 172.18.0.4:45323 in memory (size: 27.3 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.628+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 0.0 in stage 783.0 (TID 969) in 67 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:00.628+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Removed TaskSet 783.0, whose tasks have all completed, from pool
[2025-05-06T20:52:00.632+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: ResultStage 783 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.207 s
[2025-05-06T20:52:00.632+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:52:00.632+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 783: Stage finished
[2025-05-06T20:52:00.632+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Job 73 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.214875 s
[2025-05-06T20:52:00.633+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.645+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO CodeGenerator: Code generated in 7.342347 ms
[2025-05-06T20:52:00.647+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.649+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.650+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 1088.0 KiB, free 420.6 MiB)
[2025-05-06T20:52:00.652+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 420.6 MiB)
[2025-05-06T20:52:00.653+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 837932af135c:42719 (size: 21.7 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.654+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 146 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:00.656+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.670+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.744+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO CodeGenerator: Code generated in 7.797816 ms
[2025-05-06T20:52:00.754+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Registering RDD 589 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 89
[2025-05-06T20:52:00.755+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Got map stage job 74 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:52:00.756+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Final stage: ShuffleMapStage 786 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:52:00.758+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 785)
[2025-05-06T20:52:00.758+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:00.759+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting ShuffleMapStage 786 (MapPartitionsRDD[589] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:52:00.771+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 13.4 KiB, free 420.6 MiB)
[2025-05-06T20:52:00.773+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 420.6 MiB)
[2025-05-06T20:52:00.777+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 837932af135c:42719 (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.778+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:00.780+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 786 (MapPartitionsRDD[589] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:00.781+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Adding task set 786.0 with 1 tasks resource profile 0
[2025-05-06T20:52:00.787+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 0.0 in stage 786.0 (TID 970) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.791+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO CodeGenerator: Code generated in 34.770999 ms
[2025-05-06T20:52:00.805+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Registering RDD 592 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 90
[2025-05-06T20:52:00.805+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Got map stage job 75 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:52:00.806+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Final stage: ShuffleMapStage 787 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:52:00.807+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 785)
[2025-05-06T20:52:00.810+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:00.813+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting ShuffleMapStage 787 (MapPartitionsRDD[592] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:52:00.814+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 172.18.0.4:45323 (size: 6.7 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.818+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.18.0.4:41314
[2025-05-06T20:52:00.831+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 13.5 KiB, free 420.6 MiB)
[2025-05-06T20:52:00.832+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.832+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 420.6 MiB)
[2025-05-06T20:52:00.833+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 837932af135c:42719 (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.834+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:00.835+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 787 (MapPartitionsRDD[592] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:00.835+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Adding task set 787.0 with 1 tasks resource profile 0
[2025-05-06T20:52:00.846+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO CodeGenerator: Code generated in 7.021403 ms
[2025-05-06T20:52:00.851+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Registering RDD 595 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 91
[2025-05-06T20:52:00.852+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Got map stage job 76 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:52:00.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Final stage: ShuffleMapStage 788 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:52:00.854+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 785)
[2025-05-06T20:52:00.855+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:00.855+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting ShuffleMapStage 788 (MapPartitionsRDD[595] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:52:00.856+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 172.18.0.4:45323 (size: 22.8 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.856+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 12.9 KiB, free 420.5 MiB)
[2025-05-06T20:52:00.872+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 420.5 MiB)
[2025-05-06T20:52:00.876+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 837932af135c:42719 (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.876+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:00.877+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.878+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.880+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 788 (MapPartitionsRDD[595] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:00.881+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Adding task set 788.0 with 1 tasks resource profile 0
[2025-05-06T20:52:00.905+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Starting task 0.0 in stage 787.0 (TID 971) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:00.906+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSetManager: Finished task 0.0 in stage 786.0 (TID 970) in 119 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:00.907+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Removed TaskSet 786.0, whose tasks have all completed, from pool
[2025-05-06T20:52:00.908+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: ShuffleMapStage 786 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.152 s
[2025-05-06T20:52:00.910+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:52:00.911+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: running: Set(ShuffleMapStage 787, ShuffleMapStage 788)
[2025-05-06T20:52:00.912+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:52:00.913+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: failed: Set()
[2025-05-06T20:52:00.921+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 172.18.0.4:45323 (size: 6.8 KiB, free: 174.2 MiB)
[2025-05-06T20:52:00.922+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(89), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.933+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO ShufflePartitionsUtil: For shuffle(89), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:00.982+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:00.988+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Got job 77 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:52:00.989+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Final stage: ResultStage 790 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:52:00.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 789)
[2025-05-06T20:52:00.990+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:00.991+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting ResultStage 790 (MapPartitionsRDD[597] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:52:00.991+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 7.2 KiB, free 420.5 MiB)
[2025-05-06T20:52:00.992+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 420.5 MiB)
[2025-05-06T20:52:00.993+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 837932af135c:42719 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:00.993+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 172.18.0.4:45323 (size: 32.1 KiB, free: 174.1 MiB)
[2025-05-06T20:52:00.996+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:00.997+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 790 (MapPartitionsRDD[597] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:00.998+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:00 INFO TaskSchedulerImpl: Adding task set 790.0 with 1 tasks resource profile 0
[2025-05-06T20:52:01.013+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Starting task 0.0 in stage 788.0 (TID 972) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:01.014+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Finished task 0.0 in stage 787.0 (TID 971) in 110 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:01.015+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Removed TaskSet 787.0, whose tasks have all completed, from pool
[2025-05-06T20:52:01.015+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: ShuffleMapStage 787 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.209 s
[2025-05-06T20:52:01.015+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:52:01.015+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: running: Set(ResultStage 790, ShuffleMapStage 788)
[2025-05-06T20:52:01.015+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:52:01.016+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: failed: Set()
[2025-05-06T20:52:01.021+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 172.18.0.4:45323 (size: 6.6 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.038+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 172.18.0.4:45323 (size: 21.7 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.048+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Starting task 0.0 in stage 790.0 (TID 973) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:01.048+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Finished task 0.0 in stage 788.0 (TID 972) in 35 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:01.048+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Removed TaskSet 788.0, whose tasks have all completed, from pool
[2025-05-06T20:52:01.049+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: ShuffleMapStage 788 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.196 s
[2025-05-06T20:52:01.049+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:52:01.049+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: running: Set(ResultStage 790)
[2025-05-06T20:52:01.049+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:52:01.049+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: failed: Set()
[2025-05-06T20:52:01.055+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 172.18.0.4:45323 (size: 3.8 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.056+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.18.0.4:41314
[2025-05-06T20:52:01.076+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 837932af135c:42719 in memory (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T20:52:01.080+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 172.18.0.4:45323 in memory (size: 6.6 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.081+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Finished task 0.0 in stage 790.0 (TID 973) in 33 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:01.082+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Removed TaskSet 790.0, whose tasks have all completed, from pool
[2025-05-06T20:52:01.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: ResultStage 790 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.097 s
[2025-05-06T20:52:01.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:52:01.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 790: Stage finished
[2025-05-06T20:52:01.083+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 837932af135c:42719 in memory (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:01.084+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Job 77 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.098844 s
[2025-05-06T20:52:01.085+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 172.18.0.4:45323 in memory (size: 6.8 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.088+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 837932af135c:42719 in memory (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T20:52:01.093+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 2.1 MiB, free 418.5 MiB)
[2025-05-06T20:52:01.096+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 172.18.0.4:45323 in memory (size: 6.7 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.098+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 418.5 MiB)
[2025-05-06T20:52:01.099+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 837932af135c:42719 (size: 19.9 KiB, free: 434.2 MiB)
[2025-05-06T20:52:01.100+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO SparkContext: Created broadcast 151 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:01.108+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO ShufflePartitionsUtil: For shuffle(90), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:01.109+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO ShufflePartitionsUtil: For shuffle(91), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:01.135+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO CodeGenerator: Code generated in 18.323641 ms
[2025-05-06T20:52:01.160+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Registering RDD 600 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 92
[2025-05-06T20:52:01.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Got map stage job 78 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:52:01.161+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Final stage: ShuffleMapStage 794 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:52:01.162+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 793)
[2025-05-06T20:52:01.163+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:01.163+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Submitting ShuffleMapStage 794 (MapPartitionsRDD[600] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:52:01.189+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 14.1 KiB, free 418.5 MiB)
[2025-05-06T20:52:01.192+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 418.5 MiB)
[2025-05-06T20:52:01.193+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 837932af135c:42719 (size: 7.0 KiB, free: 434.1 MiB)
[2025-05-06T20:52:01.193+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:01.196+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 794 (MapPartitionsRDD[600] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:01.196+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Adding task set 794.0 with 1 tasks resource profile 0
[2025-05-06T20:52:01.197+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Starting task 0.0 in stage 794.0 (TID 974) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:01.215+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 172.18.0.4:45323 (size: 7.0 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.217+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.18.0.4:41314
[2025-05-06T20:52:01.237+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 172.18.0.4:45323 (size: 19.9 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.242+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO CodeGenerator: Code generated in 61.775914 ms
[2025-05-06T20:52:01.274+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Finished task 0.0 in stage 794.0 (TID 974) in 78 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:01.275+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Removed TaskSet 794.0, whose tasks have all completed, from pool
[2025-05-06T20:52:01.276+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: ShuffleMapStage 794 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.115 s
[2025-05-06T20:52:01.276+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:52:01.277+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: running: Set()
[2025-05-06T20:52:01.278+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:52:01.278+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: failed: Set()
[2025-05-06T20:52:01.284+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Registering RDD 603 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 93
[2025-05-06T20:52:01.284+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Got map stage job 79 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:52:01.284+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Final stage: ShuffleMapStage 798 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:52:01.285+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 797)
[2025-05-06T20:52:01.285+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:01.285+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Submitting ShuffleMapStage 798 (MapPartitionsRDD[603] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:52:01.289+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 116.2 KiB, free 418.4 MiB)
[2025-05-06T20:52:01.306+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 45.5 KiB, free 418.3 MiB)
[2025-05-06T20:52:01.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 837932af135c:42719 (size: 45.5 KiB, free: 434.1 MiB)
[2025-05-06T20:52:01.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:01.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 798 (MapPartitionsRDD[603] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:01.309+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Adding task set 798.0 with 1 tasks resource profile 0
[2025-05-06T20:52:01.310+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Starting task 0.0 in stage 798.0 (TID 975) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:01.310+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 837932af135c:42719 in memory (size: 3.8 KiB, free: 434.1 MiB)
[2025-05-06T20:52:01.314+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 172.18.0.4:45323 in memory (size: 3.8 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.320+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 172.18.0.4:45323 in memory (size: 7.0 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.321+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 837932af135c:42719 in memory (size: 7.0 KiB, free: 434.1 MiB)
[2025-05-06T20:52:01.322+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 172.18.0.4:45323 (size: 45.5 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.348+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.18.0.4:41314
[2025-05-06T20:52:01.423+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Finished task 0.0 in stage 798.0 (TID 975) in 115 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:01.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Removed TaskSet 798.0, whose tasks have all completed, from pool
[2025-05-06T20:52:01.424+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: ShuffleMapStage 798 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.139 s
[2025-05-06T20:52:01.431+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T20:52:01.431+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: running: Set()
[2025-05-06T20:52:01.432+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: waiting: Set()
[2025-05-06T20:52:01.432+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: failed: Set()
[2025-05-06T20:52:01.432+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO ShufflePartitionsUtil: For shuffle(93), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:01.435+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T20:52:01.453+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO CodeGenerator: Code generated in 14.303072 ms
[2025-05-06T20:52:01.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:01.485+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Got job 80 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T20:52:01.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Final stage: ResultStage 803 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T20:52:01.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 802)
[2025-05-06T20:52:01.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:01.486+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Submitting ResultStage 803 (MapPartitionsRDD[606] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T20:52:01.494+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 113.1 KiB, free 418.3 MiB)
[2025-05-06T20:52:01.497+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 42.8 KiB, free 418.2 MiB)
[2025-05-06T20:52:01.499+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 837932af135c:42719 (size: 42.8 KiB, free: 434.1 MiB)
[2025-05-06T20:52:01.499+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:01.500+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 803 (MapPartitionsRDD[606] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:01.501+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Adding task set 803.0 with 1 tasks resource profile 0
[2025-05-06T20:52:01.502+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Starting task 0.0 in stage 803.0 (TID 976) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:01.520+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 172.18.0.4:45323 (size: 42.8 KiB, free: 174.0 MiB)
[2025-05-06T20:52:01.535+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.18.0.4:41314
[2025-05-06T20:52:01.560+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Finished task 0.0 in stage 803.0 (TID 976) in 57 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:01.563+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Removed TaskSet 803.0, whose tasks have all completed, from pool
[2025-05-06T20:52:01.565+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: ResultStage 803 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.075 s
[2025-05-06T20:52:01.565+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:52:01.566+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 803: Stage finished
[2025-05-06T20:52:01.566+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Job 80 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.079734 s
[2025-05-06T20:52:01.584+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO CodeGenerator: Code generated in 9.432611 ms
[2025-05-06T20:52:01.586+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 1024.0 KiB, free 417.2 MiB)
[2025-05-06T20:52:01.606+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 209.0 B, free 417.2 MiB)
[2025-05-06T20:52:01.607+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 837932af135c:42719 (size: 209.0 B, free: 434.1 MiB)
[2025-05-06T20:52:01.607+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 837932af135c:42719 in memory (size: 45.5 KiB, free: 434.1 MiB)
[2025-05-06T20:52:01.608+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO SparkContext: Created broadcast 155 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T20:52:01.610+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 172.18.0.4:45323 in memory (size: 45.5 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.614+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO ShufflePartitionsUtil: For shuffle(92), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T20:52:01.621+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 837932af135c:42719 in memory (size: 42.8 KiB, free: 434.2 MiB)
[2025-05-06T20:52:01.623+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 172.18.0.4:45323 in memory (size: 42.8 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.635+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO CodeGenerator: Code generated in 14.952332 ms
[2025-05-06T20:52:01.728+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-05-06T20:52:01.729+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Got job 81 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T20:52:01.729+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Final stage: ResultStage 808 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T20:52:01.730+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 807)
[2025-05-06T20:52:01.730+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Missing parents: List()
[2025-05-06T20:52:01.730+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Submitting ResultStage 808 (MapPartitionsRDD[611] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T20:52:01.770+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 128.0 KiB, free 417.4 MiB)
[2025-05-06T20:52:01.771+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 48.3 KiB, free 417.4 MiB)
[2025-05-06T20:52:01.772+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 837932af135c:42719 (size: 48.3 KiB, free: 434.1 MiB)
[2025-05-06T20:52:01.772+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1474
[2025-05-06T20:52:01.772+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 808 (MapPartitionsRDD[611] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T20:52:01.772+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Adding task set 808.0 with 1 tasks resource profile 0
[2025-05-06T20:52:01.773+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Starting task 0.0 in stage 808.0 (TID 977) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T20:52:01.779+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 172.18.0.4:45323 (size: 48.3 KiB, free: 174.1 MiB)
[2025-05-06T20:52:01.790+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.18.0.4:41314
[2025-05-06T20:52:01.803+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 172.18.0.4:45323 (size: 209.0 B, free: 174.1 MiB)
[2025-05-06T20:52:01.890+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSetManager: Finished task 0.0 in stage 808.0 (TID 977) in 117 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T20:52:01.891+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Removed TaskSet 808.0, whose tasks have all completed, from pool
[2025-05-06T20:52:01.891+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: ResultStage 808 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.163 s
[2025-05-06T20:52:01.891+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T20:52:01.892+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 808: Stage finished
[2025-05-06T20:52:01.892+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO DAGScheduler: Job 81 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.164351 s
[2025-05-06T20:52:01.913+0000] {spark_submit.py:571} INFO - 2025-05-06 20:52:01,913 [INFO] Анализ графа успешно завершен
[2025-05-06T20:52:01.929+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO SparkUI: Stopped Spark web UI at http://837932af135c:4040
[2025-05-06T20:52:01.933+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-05-06T20:52:01.933+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2025-05-06T20:52:01.950+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-06T20:52:01.971+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO MemoryStore: MemoryStore cleared
[2025-05-06T20:52:01.975+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManager: BlockManager stopped
[2025-05-06T20:52:01.981+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-06T20:52:01.985+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-06T20:52:02.001+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:02 INFO SparkContext: Successfully stopped SparkContext
[2025-05-06T20:52:02.342+0000] {spark_submit.py:571} INFO - 2025-05-06 20:52:02,340 [INFO] SparkSession остановлена
[2025-05-06T20:52:02.431+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:02 INFO ShutdownHookManager: Shutdown hook called
[2025-05-06T20:52:02.431+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-80d42ff9-2753-4b9e-bd65-b57082cccf26
[2025-05-06T20:52:02.437+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-05c68645-d818-49a0-901b-7fc18f52cbe2
[2025-05-06T20:52:02.443+0000] {spark_submit.py:571} INFO - 25/05/06 20:52:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-80d42ff9-2753-4b9e-bd65-b57082cccf26/pyspark-429a8348-38d0-4b40-bd2b-03c9eb9554af
[2025-05-06T20:52:02.874+0000] {taskinstance.py:1345} INFO - Marking task as SUCCESS. dag_id=graph_analysis, task_id=build_graph, execution_date=20250506T204903, start_date=20250506T204910, end_date=20250506T205202
[2025-05-06T20:52:03.007+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2025-05-06T20:52:03.190+0000] {taskinstance.py:2653} INFO - 1 downstream tasks scheduled from follow-on schedule check
