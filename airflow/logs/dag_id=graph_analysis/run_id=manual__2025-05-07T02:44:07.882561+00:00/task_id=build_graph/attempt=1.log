[2025-05-07T02:44:15.691+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-07T02:44:07.882561+00:00 [queued]>
[2025-05-07T02:44:15.696+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-07T02:44:07.882561+00:00 [queued]>
[2025-05-07T02:44:15.697+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 2
[2025-05-07T02:44:15.706+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): build_graph> on 2025-05-07 02:44:07.882561+00:00
[2025-05-07T02:44:15.710+0000] {standard_task_runner.py:57} INFO - Started process 6233 to run task
[2025-05-07T02:44:15.712+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'graph_analysis', 'build_graph', 'manual__2025-05-07T02:44:07.882561+00:00', '--job-id', '252', '--raw', '--subdir', 'DAGS_FOLDER/graph_analysis.py', '--cfg-path', '/tmp/tmp4ac15i8s']
[2025-05-07T02:44:15.713+0000] {standard_task_runner.py:85} INFO - Job 252: Subtask build_graph
[2025-05-07T02:44:15.725+0000] {logging_mixin.py:150} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-07T02:44:15.752+0000] {task_command.py:410} INFO - Running <TaskInstance: graph_analysis.build_graph manual__2025-05-07T02:44:07.882561+00:00 [running]> on host 5c5d1775d94e
[2025-05-07T02:44:15.819+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='finbest' AIRFLOW_CTX_DAG_ID='graph_analysis' AIRFLOW_CTX_TASK_ID='build_graph' AIRFLOW_CTX_EXECUTION_DATE='2025-05-07T02:44:07.882561+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-07T02:44:07.882561+00:00'
[2025-05-07T02:44:15.827+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-05-07T02:44:15.828+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******
[2025-05-07T02:44:15.845+0000] {spark_submit.py:571} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-05-07T02:44:16.889+0000] {spark_submit.py:571} INFO - Using properties file: null
[2025-05-07T02:44:16.960+0000] {spark_submit.py:571} INFO - WARNING: An illegal reflective access operation has occurred
[2025-05-07T02:44:16.961+0000] {spark_submit.py:571} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2025-05-07T02:44:16.961+0000] {spark_submit.py:571} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2025-05-07T02:44:16.961+0000] {spark_submit.py:571} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-05-07T02:44:16.961+0000] {spark_submit.py:571} INFO - WARNING: All illegal access operations will be denied in a future release
[2025-05-07T02:44:16.999+0000] {spark_submit.py:571} INFO - Parsed arguments:
[2025-05-07T02:44:16.999+0000] {spark_submit.py:571} INFO - master                  spark://spark-master:7077
[2025-05-07T02:44:16.999+0000] {spark_submit.py:571} INFO - deployMode              null
[2025-05-07T02:44:16.999+0000] {spark_submit.py:571} INFO - executorMemory          1g
[2025-05-07T02:44:16.999+0000] {spark_submit.py:571} INFO - executorCores           1
[2025-05-07T02:44:16.999+0000] {spark_submit.py:571} INFO - totalExecutorCores      null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - propertiesFile          null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - driverMemory            1g
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - driverCores             null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - driverExtraClassPath    null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - driverExtraLibraryPath  null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - driverExtraJavaOptions  null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - supervise               false
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - queue                   null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - numExecutors            null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - files                   null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - pyFiles                 null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - archives                null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - mainClass               null
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - primaryResource         file:/opt/airflow/spark/build_graph.py
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - name                    arrow-spark
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - childArgs               [--jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ***]
[2025-05-07T02:44:17.000+0000] {spark_submit.py:571} INFO - jars                    null
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - packages                org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - packagesExclusions      null
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - repositories            null
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - verbose                 true
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - 
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - Spark properties used, including those specified through
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - --conf and those from the properties file null:
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - 
[2025-05-07T02:44:17.001+0000] {spark_submit.py:571} INFO - 
[2025-05-07T02:44:17.107+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-07T02:44:17.181+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-05-07T02:44:17.182+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-05-07T02:44:17.185+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql added as a dependency
[2025-05-07T02:44:17.185+0000] {spark_submit.py:571} INFO - graphframes#graphframes added as a dependency
[2025-05-07T02:44:17.186+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-779d2cf7-c704-4f9d-966d-f6e02f7a7dbd;1.0
[2025-05-07T02:44:17.186+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-07T02:44:17.275+0000] {spark_submit.py:571} INFO - found org.postgresql#postgresql;42.6.0 in central
[2025-05-07T02:44:17.292+0000] {spark_submit.py:571} INFO - found org.checkerframework#checker-qual;3.31.0 in central
[2025-05-07T02:44:17.311+0000] {spark_submit.py:571} INFO - found graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages
[2025-05-07T02:44:17.329+0000] {spark_submit.py:571} INFO - found org.slf4j#slf4j-api;1.7.16 in central
[2025-05-07T02:44:17.346+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 154ms :: artifacts dl 6ms
[2025-05-07T02:44:17.347+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-05-07T02:44:17.347+0000] {spark_submit.py:571} INFO - graphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]
[2025-05-07T02:44:17.347+0000] {spark_submit.py:571} INFO - org.checkerframework#checker-qual;3.31.0 from central in [default]
[2025-05-07T02:44:17.347+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql;42.6.0 from central in [default]
[2025-05-07T02:44:17.347+0000] {spark_submit.py:571} INFO - org.slf4j#slf4j-api;1.7.16 from central in [default]
[2025-05-07T02:44:17.347+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T02:44:17.348+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-05-07T02:44:17.348+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-07T02:44:17.348+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T02:44:17.348+0000] {spark_submit.py:571} INFO - |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
[2025-05-07T02:44:17.348+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T02:44:17.352+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-779d2cf7-c704-4f9d-966d-f6e02f7a7dbd
[2025-05-07T02:44:17.353+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-07T02:44:17.358+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 4 already retrieved (0kB/6ms)
[2025-05-07T02:44:17.545+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-07T02:44:17.712+0000] {spark_submit.py:571} INFO - Main class:
[2025-05-07T02:44:17.713+0000] {spark_submit.py:571} INFO - org.apache.spark.deploy.PythonRunner
[2025-05-07T02:44:17.713+0000] {spark_submit.py:571} INFO - Arguments:
[2025-05-07T02:44:17.713+0000] {spark_submit.py:571} INFO - file:/opt/airflow/spark/build_graph.py
[2025-05-07T02:44:17.713+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T02:44:17.713+0000] {spark_submit.py:571} INFO - --jdbc
[2025-05-07T02:44:17.713+0000] {spark_submit.py:571} INFO - jdbc:postgresql://postgres:5432/finbest
[2025-05-07T02:44:17.713+0000] {spark_submit.py:571} INFO - --user
[2025-05-07T02:44:17.713+0000] {spark_submit.py:571} INFO - finbest
[2025-05-07T02:44:17.713+0000] {spark_submit.py:571} INFO - --password
[2025-05-07T02:44:17.714+0000] {spark_submit.py:571} INFO - ***
[2025-05-07T02:44:17.715+0000] {spark_submit.py:571} INFO - Spark config:
[2025-05-07T02:44:17.715+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.app.name,arrow-spark)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,/home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,/home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,/home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.files,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.submit.deployMode,client)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.master,spark://spark-master:7077)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.executor.memory,1g)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.executor.cores,1)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - Classpath elements:
[2025-05-07T02:44:17.716+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar
[2025-05-07T02:44:17.717+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-07T02:44:17.717+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-07T02:44:17.717+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T02:44:17.717+0000] {spark_submit.py:571} INFO - 
[2025-05-07T02:44:17.718+0000] {spark_submit.py:571} INFO - 
[2025-05-07T02:44:18.812+0000] {spark_submit.py:571} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2025-05-07T02:44:18.818+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO SparkContext: Running Spark version 3.2.4
[2025-05-07T02:44:18.833+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO ResourceUtils: ==============================================================
[2025-05-07T02:44:18.833+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-07T02:44:18.834+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO ResourceUtils: ==============================================================
[2025-05-07T02:44:18.834+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO SparkContext: Submitted application: FinBestGraphAnalysis
[2025-05-07T02:44:18.855+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-07T02:44:18.865+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-05-07T02:44:18.867+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-07T02:44:18.912+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO SecurityManager: Changing view acls to: airflow
[2025-05-07T02:44:18.912+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO SecurityManager: Changing modify acls to: airflow
[2025-05-07T02:44:18.913+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO SecurityManager: Changing view acls groups to:
[2025-05-07T02:44:18.913+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO SecurityManager: Changing modify acls groups to:
[2025-05-07T02:44:18.913+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(airflow); groups with view permissions: Set(); users  with modify permissions: Set(airflow); groups with modify permissions: Set()
[2025-05-07T02:44:19.144+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO Utils: Successfully started service 'sparkDriver' on port 44269.
[2025-05-07T02:44:19.166+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkEnv: Registering MapOutputTracker
[2025-05-07T02:44:19.195+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-07T02:44:19.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-07T02:44:19.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-07T02:44:19.221+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-07T02:44:19.242+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9ac90797-ddb5-4ed9-8977-45083b04e67e
[2025-05-07T02:44:19.260+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-07T02:44:19.275+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-07T02:44:19.444+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-07T02:44:19.487+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://5c5d1775d94e:4040
[2025-05-07T02:44:19.497+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://5c5d1775d94e:44269/jars/org.postgresql_postgresql-42.6.0.jar with timestamp 1746585858810
[2025-05-07T02:44:19.497+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://5c5d1775d94e:44269/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746585858810
[2025-05-07T02:44:19.498+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://5c5d1775d94e:44269/jars/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746585858810
[2025-05-07T02:44:19.498+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://5c5d1775d94e:44269/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746585858810
[2025-05-07T02:44:19.500+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://5c5d1775d94e:44269/files/org.postgresql_postgresql-42.6.0.jar with timestamp 1746585858810
[2025-05-07T02:44:19.501+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO Utils: Copying /home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar to /tmp/spark-992f3ae9-878e-4bb7-a636-6ed043c1a517/userFiles-6c449bf2-89d1-47a1-9723-010b53a3fa6a/org.postgresql_postgresql-42.6.0.jar
[2025-05-07T02:44:19.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://5c5d1775d94e:44269/files/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746585858810
[2025-05-07T02:44:19.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO Utils: Copying /home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar to /tmp/spark-992f3ae9-878e-4bb7-a636-6ed043c1a517/userFiles-6c449bf2-89d1-47a1-9723-010b53a3fa6a/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-07T02:44:19.517+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://5c5d1775d94e:44269/files/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746585858810
[2025-05-07T02:44:19.517+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO Utils: Copying /home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar to /tmp/spark-992f3ae9-878e-4bb7-a636-6ed043c1a517/userFiles-6c449bf2-89d1-47a1-9723-010b53a3fa6a/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-07T02:44:19.520+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://5c5d1775d94e:44269/files/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746585858810
[2025-05-07T02:44:19.520+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO Utils: Copying /home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-992f3ae9-878e-4bb7-a636-6ed043c1a517/userFiles-6c449bf2-89d1-47a1-9723-010b53a3fa6a/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T02:44:19.655+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-05-07T02:44:19.690+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 23 ms (0 ms spent in bootstraps)
[2025-05-07T02:44:19.768+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250507024419-0005
[2025-05-07T02:44:19.770+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250507024419-0005/0 on worker-20250506210741-172.20.0.5-46203 (172.20.0.5:46203) with 1 core(s)
[2025-05-07T02:44:19.772+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO StandaloneSchedulerBackend: Granted executor ID app-20250507024419-0005/0 on hostPort 172.20.0.5:46203 with 1 core(s), 1024.0 MiB RAM
[2025-05-07T02:44:19.774+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37761.
[2025-05-07T02:44:19.774+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO NettyBlockTransferService: Server created on 5c5d1775d94e:37761
[2025-05-07T02:44:19.775+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-07T02:44:19.780+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5c5d1775d94e, 37761, None)
[2025-05-07T02:44:19.785+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO BlockManagerMasterEndpoint: Registering block manager 5c5d1775d94e:37761 with 434.4 MiB RAM, BlockManagerId(driver, 5c5d1775d94e, 37761, None)
[2025-05-07T02:44:19.788+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5c5d1775d94e, 37761, None)
[2025-05-07T02:44:19.789+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 5c5d1775d94e, 37761, None)
[2025-05-07T02:44:19.810+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507024419-0005/0 is now RUNNING
[2025-05-07T02:44:19.947+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:19 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-05-07T02:44:20.115+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-07T02:44:20.118+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:20 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-05-07T02:44:20.828+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:20,828 [INFO] SparkSession создана
[2025-05-07T02:44:20.829+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:20,828 [INFO] Загружаем клиентов и транзакции
[2025-05-07T02:44:22.376+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:52776) with ID 0,  ResourceProfileId 0
[2025-05-07T02:44:22.572+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:40657 with 434.4 MiB RAM, BlockManagerId(0, 172.20.0.5, 40657, None)
[2025-05-07T02:44:23.623+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO CodeGenerator: Code generated in 131.133327 ms
[2025-05-07T02:44:23.679+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-05-07T02:44:23.682+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:23.682+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:23.682+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:23.684+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:23.687+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:23.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-07T02:44:23.829+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-07T02:44:23.831+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 5c5d1775d94e:37761 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:23.835+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:23.848+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:23.848+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-07T02:44:23.880+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:24.072+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.5:40657 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:24.944+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1064 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:24.945+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-07T02:44:24.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:24 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.255 s
[2025-05-07T02:44:24.952+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:24.953+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:24 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:24.953+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:24 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:24.953+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:24 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:24.988+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:24 INFO CodeGenerator: Code generated in 12.283525 ms
[2025-05-07T02:44:25.020+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-07T02:44:25.023+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:25.024+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:25.024+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-07T02:44:25.024+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:25.025+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:25.031+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-07T02:44:25.033+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-07T02:44:25.034+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 5c5d1775d94e:37761 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.035+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:25.036+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:25.037+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-07T02:44:25.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:25.059+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.123+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.20.0.5:52776
[2025-05-07T02:44:25.217+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 178 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:25.218+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-07T02:44:25.219+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.189 s
[2025-05-07T02:44:25.220+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:25.220+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-07T02:44:25.221+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.200581 s
[2025-05-07T02:44:25.276+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Registering RDD 8 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-05-07T02:44:25.276+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:25.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:25.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:25.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:25.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:25.281+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-07T02:44:25.295+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.3 MiB)
[2025-05-07T02:44:25.296+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 5c5d1775d94e:37761 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.297+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:25.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:25.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-05-07T02:44:25.300+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:25.331+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 5c5d1775d94e:37761 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.332+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.5:40657 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.337+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.0.5:40657 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.353+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 5c5d1775d94e:37761 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.358+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.0.5:40657 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.367+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 67 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:25.367+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-07T02:44:25.369+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.090 s
[2025-05-07T02:44:25.370+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:25.370+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:25.370+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:25.371+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:25.395+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-07T02:44:25.397+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:25.397+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:25.397+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-07T02:44:25.397+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:25.398+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:25.402+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-07T02:44:25.415+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-07T02:44:25.416+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 5c5d1775d94e:37761 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.417+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:25.420+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:25.421+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-07T02:44:25.421+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 5c5d1775d94e:37761 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.423+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:25.431+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.0.5:40657 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.445+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.460+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.20.0.5:52776
[2025-05-07T02:44:25.474+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 52 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:25.474+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-07T02:44:25.475+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.076 s
[2025-05-07T02:44:25.476+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:25.476+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-05-07T02:44:25.476+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.080539 s
[2025-05-07T02:44:25.477+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:25,477 [INFO] Загружено 4652 транзакций и 1200 клиентов
[2025-05-07T02:44:25.662+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:25,662 [INFO] Создаем вершины двудольного графа
[2025-05-07T02:44:25.997+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 5c5d1775d94e:37761 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:25.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.5:40657 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:26.035+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:26,034 [INFO] Создаем ATM-хабы
[2025-05-07T02:44:26.204+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:26,203 [INFO] Объединяем ребра двудольного графа
[2025-05-07T02:44:26.298+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:26,298 [INFO] Создаем P2P-слой
[2025-05-07T02:44:26.319+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:26,319 [INFO] Создаем проекцию клиент-клиент
[2025-05-07T02:44:26.943+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:26,943 [INFO] Вычисляем метрики графа
[2025-05-07T02:44:27.243+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO CodeGenerator: Code generated in 15.2952 ms
[2025-05-07T02:44:27.247+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Registering RDD 15 (rdd at GraphFrame.scala:187) as input to shuffle 2
[2025-05-07T02:44:27.248+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Got map stage job 4 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-07T02:44:27.248+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (rdd at GraphFrame.scala:187)
[2025-05-07T02:44:27.248+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:27.248+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:27.248+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T02:44:27.260+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
[2025-05-07T02:44:27.265+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.4 MiB)
[2025-05-07T02:44:27.265+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 5c5d1775d94e:37761 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T02:44:27.266+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:27.266+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:27.266+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-05-07T02:44:27.268+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:27.283+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.5:40657 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T02:44:27.490+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 223 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:27.490+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-05-07T02:44:27.491+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: ShuffleMapStage 6 (rdd at GraphFrame.scala:187) finished in 0.242 s
[2025-05-07T02:44:27.491+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:27.492+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:27.492+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:27.492+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:27.516+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:27.548+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:27.549+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:27.549+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:27.549+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-07T02:44:27.549+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:27.550+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:27.555+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-07T02:44:27.564+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-07T02:44:27.566+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:27.566+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 5c5d1775d94e:37761 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T02:44:27.569+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:27.571+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.5:40657 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T02:44:27.572+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:27.573+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-07T02:44:27.575+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:27.609+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:27.621+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.20.0.5:52776
[2025-05-07T02:44:27.634+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 61 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:27.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-07T02:44:27.637+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.083 s
[2025-05-07T02:44:27.638+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:27.638+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-07T02:44:27.638+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.088584 s
[2025-05-07T02:44:27.662+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO CodeGenerator: Code generated in 7.237638 ms
[2025-05-07T02:44:27.681+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:27.688+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:27.695+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-07T02:44:27.711+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.8 KiB, free 432.3 MiB)
[2025-05-07T02:44:27.711+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 5c5d1775d94e:37761 (size: 28.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:27.712+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO SparkContext: Created broadcast 6 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:27.741+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO CodeGenerator: Code generated in 10.129449 ms
[2025-05-07T02:44:27.745+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:27.746+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:27.779+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO CodeGenerator: Code generated in 25.46065 ms
[2025-05-07T02:44:27.788+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO CodeGenerator: Code generated in 6.92235 ms
[2025-05-07T02:44:27.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:27 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#995 - id.nullCount#994) > 0)
[2025-05-07T02:44:28.372+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 6.724606 ms
[2025-05-07T02:44:28.378+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 4.108318 ms
[2025-05-07T02:44:28.384+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 4.490404 ms
[2025-05-07T02:44:28.406+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 14.014021 ms
[2025-05-07T02:44:28.412+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 4.503062 ms
[2025-05-07T02:44:28.604+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 11.583461 ms
[2025-05-07T02:44:28.632+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 15.986949 ms
[2025-05-07T02:44:28.658+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 17.082925 ms
[2025-05-07T02:44:28.674+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 10.451815 ms
[2025-05-07T02:44:28.693+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 11.624716 ms
[2025-05-07T02:44:28.721+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 15.865292 ms
[2025-05-07T02:44:28.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Registering RDD 60 (collect at GraphFrame.scala:574) as input to shuffle 4
[2025-05-07T02:44:28.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Got map stage job 6 (collect at GraphFrame.scala:574) with 6 output partitions
[2025-05-07T02:44:28.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:28.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:28.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:28.736+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:28.745+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 36.4 KiB, free 432.3 MiB)
[2025-05-07T02:44:28.750+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 9.922519 ms
[2025-05-07T02:44:28.751+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 432.3 MiB)
[2025-05-07T02:44:28.753+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 5c5d1775d94e:37761 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T02:44:28.756+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:28.757+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T02:44:28.757+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO TaskSchedulerImpl: Adding task set 9.0 with 6 tasks resource profile 0
[2025-05-07T02:44:28.757+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Registering RDD 62 (collect at GraphFrame.scala:574) as input to shuffle 5
[2025-05-07T02:44:28.757+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Got map stage job 7 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T02:44:28.757+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:28.757+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:28.757+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:28.757+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:28.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:28.760+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:28.764+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.6 KiB, free 432.3 MiB)
[2025-05-07T02:44:28.767+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 432.2 MiB)
[2025-05-07T02:44:28.772+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 5c5d1775d94e:37761 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T02:44:28.775+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:28.775+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:28.776+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2025-05-07T02:44:28.787+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.5:40657 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T02:44:28.793+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 27.233999 ms
[2025-05-07T02:44:28.818+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:28.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Registering RDD 64 (collect at GraphFrame.scala:574) as input to shuffle 6
[2025-05-07T02:44:28.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Got map stage job 8 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T02:44:28.823+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:28.826+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:28.827+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:28.832+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:28.846+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 27.3 KiB, free 432.2 MiB)
[2025-05-07T02:44:28.880+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.2 MiB)
[2025-05-07T02:44:28.884+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 5c5d1775d94e:37761 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T02:44:28.885+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 54.337521 ms
[2025-05-07T02:44:28.886+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:28.889+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:28.890+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-05-07T02:44:28.909+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:28.921+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Registering RDD 66 (collect at GraphFrame.scala:574) as input to shuffle 7
[2025-05-07T02:44:28.921+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Got map stage job 9 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T02:44:28.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:28.923+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:28.923+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:28.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:28.948+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 7) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:28.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 28.5 KiB, free 432.2 MiB)
[2025-05-07T02:44:28.953+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 194 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T02:44:28.955+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 432.2 MiB)
[2025-05-07T02:44:28.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 5c5d1775d94e:37761 (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-07T02:44:28.959+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:28.959+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:28.960+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-05-07T02:44:28.972+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO CodeGenerator: Code generated in 52.198702 ms
[2025-05-07T02:44:28.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:28.982+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Registering RDD 68 (collect at GraphFrame.scala:574) as input to shuffle 8
[2025-05-07T02:44:28.982+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Got map stage job 10 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T02:44:28.982+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:28.982+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:28.983+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:28.983+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:28.991+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:28 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-07T02:44:29.012+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 432.1 MiB)
[2025-05-07T02:44:29.013+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 5c5d1775d94e:37761 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T02:44:29.014+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:29.016+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:29.016+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-05-07T02:44:29.027+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO CodeGenerator: Code generated in 37.537721 ms
[2025-05-07T02:44:29.037+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Registering RDD 70 (collect at GraphFrame.scala:574) as input to shuffle 9
[2025-05-07T02:44:29.038+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Got map stage job 11 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T02:44:29.039+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:29.039+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:29.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:29.043+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:29.054+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:29.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 8) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:29.070+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 7) in 122 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T02:44:29.105+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 27.4 KiB, free 432.1 MiB)
[2025-05-07T02:44:29.112+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO CodeGenerator: Code generated in 53.168595 ms
[2025-05-07T02:44:29.116+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.1 MiB)
[2025-05-07T02:44:29.117+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 5c5d1775d94e:37761 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T02:44:29.117+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:29.119+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:29.119+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-05-07T02:44:29.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:29.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Registering RDD 72 (collect at GraphFrame.scala:574) as input to shuffle 10
[2025-05-07T02:44:29.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Got map stage job 12 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T02:44:29.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:29.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:29.138+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:29.147+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:29.159+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-07T02:44:29.161+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 432.0 MiB)
[2025-05-07T02:44:29.184+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 5c5d1775d94e:37761 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T02:44:29.185+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 9) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:29.185+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 8) in 117 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T02:44:29.186+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:29.189+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:29.190+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-05-07T02:44:29.213+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO CodeGenerator: Code generated in 51.891777 ms
[2025-05-07T02:44:29.225+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Registering RDD 74 (collect at GraphFrame.scala:574) as input to shuffle 11
[2025-05-07T02:44:29.227+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Got map stage job 13 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T02:44:29.229+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:29.230+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:29.230+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:29.230+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:29.237+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.7 KiB, free 432.0 MiB)
[2025-05-07T02:44:29.259+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 432.0 MiB)
[2025-05-07T02:44:29.262+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 5c5d1775d94e:37761 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T02:44:29.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:29.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 10) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:29.264+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:29.264+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-05-07T02:44:29.264+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 9) in 82 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T02:44:29.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 11) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:29.362+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 10) in 100 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T02:44:29.765+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 12) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:29.766+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 11) in 405 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T02:44:29.766+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-05-07T02:44:29.766+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: ShuffleMapStage 9 (collect at GraphFrame.scala:574) finished in 1.028 s
[2025-05-07T02:44:29.767+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:29.767+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 10, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-07T02:44:29.767+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:29.767+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:29.780+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.5:40657 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T02:44:29.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:29.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:29.824+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 13) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:29.825+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 12) in 59 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:29.825+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-05-07T02:44:29.826+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: ShuffleMapStage 10 (collect at GraphFrame.scala:574) finished in 1.065 s
[2025-05-07T02:44:29.826+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:29.826+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-07T02:44:29.826+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:29.826+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:29.844+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.5:40657 (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T02:44:29.849+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:29.850+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:29.850+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Final stage: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:29.850+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-05-07T02:44:29.850+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:29.853+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[77] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:29.855+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T02:44:29.865+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-07T02:44:29.867+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T02:44:29.872+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:29.873+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:29.873+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[77] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:29.874+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-05-07T02:44:29.882+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 5c5d1775d94e:37761 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-07T02:44:29.883+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.20.0.5:40657 in memory (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T02:44:29.910+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 5c5d1775d94e:37761 in memory (size: 11.2 KiB, free: 434.3 MiB)
[2025-05-07T02:44:29.913+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.20.0.5:40657 in memory (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T02:44:29.959+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:29.962+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:29.962+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Final stage: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:29.963+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2025-05-07T02:44:29.963+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:29.964+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[80] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:29.970+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T02:44:29.973+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-07T02:44:29.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T02:44:29.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:29.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[80] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:29.975+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:29 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2025-05-07T02:44:30.095+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 14) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:30.096+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 13) in 274 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:30.096+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-05-07T02:44:30.097+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: ShuffleMapStage 11 (collect at GraphFrame.scala:574) finished in 1.264 s
[2025-05-07T02:44:30.097+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:30.097+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T02:44:30.098+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:30.098+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:30.116+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.5:40657 (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:30.193+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 15) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:30.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 14) in 99 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:30.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-05-07T02:44:30.195+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: ShuffleMapStage 12 (collect at GraphFrame.scala:574) finished in 1.271 s
[2025-05-07T02:44:30.196+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:30.196+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T02:44:30.196+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:30.196+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:30.211+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.5:40657 (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T02:44:30.268+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 16) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:30.271+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 15) in 75 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:30.271+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-05-07T02:44:30.271+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: ShuffleMapStage 13 (collect at GraphFrame.scala:574) finished in 1.286 s
[2025-05-07T02:44:30.272+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:30.272+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T02:44:30.272+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:30.272+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:30.291+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.5:40657 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.348+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 17) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:30.348+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 16) in 81 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:30.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-05-07T02:44:30.350+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: ShuffleMapStage 14 (collect at GraphFrame.scala:574) finished in 1.295 s
[2025-05-07T02:44:30.351+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:30.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-07T02:44:30.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:30.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:30.367+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.5:40657 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.419+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:30.423+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 17) in 72 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:30.423+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-07T02:44:30.423+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: ShuffleMapStage 15 (collect at GraphFrame.scala:574) finished in 1.273 s
[2025-05-07T02:44:30.424+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:30.424+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: running: Set(ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-07T02:44:30.424+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:30.424+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:30.444+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:40657 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.557+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 19) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:30.558+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 141 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:30.558+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-05-07T02:44:30.559+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: ShuffleMapStage 16 (collect at GraphFrame.scala:574) finished in 1.330 s
[2025-05-07T02:44:30.563+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:30.564+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: running: Set(ResultStage 20, ResultStage 18)
[2025-05-07T02:44:30.564+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:30.564+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:30.588+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO ShufflePartitionsUtil: For shuffle(6, 7, 8, 9, 10, 11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:30.599+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.615+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.20.0.5:52776
[2025-05-07T02:44:30.669+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:30.673+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO CodeGenerator: Code generated in 21.019045 ms
[2025-05-07T02:44:30.677+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 19) in 118 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:30.677+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-05-07T02:44:30.678+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.824 s
[2025-05-07T02:44:30.679+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:30.679+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-05-07T02:44:30.682+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.828779 s
[2025-05-07T02:44:30.684+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:30.703+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO CodeGenerator: Code generated in 11.408827 ms
[2025-05-07T02:44:30.713+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO CodeGenerator: Code generated in 11.116246 ms
[2025-05-07T02:44:30.716+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.727+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:52776
[2025-05-07T02:44:30.727+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:30.743+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 74 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:30.743+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-05-07T02:44:30.744+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.778 s
[2025-05-07T02:44:30.744+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:30.745+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2025-05-07T02:44:30.745+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.785164 s
[2025-05-07T02:44:30.753+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO CodeGenerator: Code generated in 22.350992 ms
[2025-05-07T02:44:30.759+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 2.1 MiB, free 430.0 MiB)
[2025-05-07T02:44:30.760+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:30.760+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 430.0 MiB)
[2025-05-07T02:44:30.761+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 5c5d1775d94e:37761 (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.762+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:30.768+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 5.0 MiB, free 425.0 MiB)
[2025-05-07T02:44:30.788+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO CodeGenerator: Code generated in 25.559446 ms
[2025-05-07T02:44:30.793+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 5c5d1775d94e:37761 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.20.0.5:40657 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.809+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 5c5d1775d94e:37761 in memory (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.809+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:30.812+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.20.0.5:40657 in memory (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.813+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 424.6 MiB)
[2025-05-07T02:44:30.814+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 5c5d1775d94e:37761 (size: 502.1 KiB, free: 433.8 MiB)
[2025-05-07T02:44:30.815+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO SparkContext: Created broadcast 18 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:30.841+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T02:44:30.846+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T02:44:30.851+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO CodeGenerator: Code generated in 37.790525 ms
[2025-05-07T02:44:30.854+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 5c5d1775d94e:37761 in memory (size: 13.0 KiB, free: 433.8 MiB)
[2025-05-07T02:44:30.855+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.20.0.5:40657 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T02:44:30.862+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 5c5d1775d94e:37761 in memory (size: 13.4 KiB, free: 433.8 MiB)
[2025-05-07T02:44:30.864+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.20.0.5:40657 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T02:44:30.867+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:30.872+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T02:44:30.875+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:30.880+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 5c5d1775d94e:37761 in memory (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-07T02:44:30.881+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO CodeGenerator: Code generated in 10.959402 ms
[2025-05-07T02:44:30.883+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.20.0.5:40657 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:30.890+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:30.893+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 5c5d1775d94e:37761 in memory (size: 13.4 KiB, free: 433.9 MiB)
[2025-05-07T02:44:30.895+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.20.0.5:40657 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T02:44:30.905+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO CodeGenerator: Code generated in 11.900519 ms
[2025-05-07T02:44:30.921+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:30.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Got job 16 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T02:44:30.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Final stage: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:30.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24, ShuffleMapStage 21, ShuffleMapStage 25, ShuffleMapStage 22, ShuffleMapStage 26, ShuffleMapStage 23)
[2025-05-07T02:44:30.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:30.923+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[103] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:30.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 91.7 KiB, free 424.6 MiB)
[2025-05-07T02:44:30.929+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 424.6 MiB)
[2025-05-07T02:44:30.929+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 5c5d1775d94e:37761 (size: 30.3 KiB, free: 433.8 MiB)
[2025-05-07T02:44:30.929+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:30.930+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 27 (MapPartitionsRDD[103] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T02:44:30.930+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSchedulerImpl: Adding task set 27.0 with 6 tasks resource profile 0
[2025-05-07T02:44:30.931+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:30.945+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.20.0.5:40657 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T02:44:30.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.20.0.5:52776
[2025-05-07T02:44:31.005+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 22) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:31.006+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 74 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T02:44:31.021+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.20.0.5:52776
[2025-05-07T02:44:31.055+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 23) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:31.055+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 22) in 51 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T02:44:31.066+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.20.0.5:52776
[2025-05-07T02:44:31.093+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 24) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:31.093+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 23) in 39 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T02:44:31.107+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.20.0.5:52776
[2025-05-07T02:44:31.140+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 25) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:31.141+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 24) in 48 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T02:44:31.153+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.20.0.5:52776
[2025-05-07T02:44:31.186+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 26) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:31.188+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 25) in 48 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T02:44:31.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:52776
[2025-05-07T02:44:31.323+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 26) in 138 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T02:44:31.324+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-05-07T02:44:31.328+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.400 s
[2025-05-07T02:44:31.328+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:31.328+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-05-07T02:44:31.328+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: Job 16 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.404964 s
[2025-05-07T02:44:31.343+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 2.3 MiB, free 422.4 MiB)
[2025-05-07T02:44:31.348+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 422.3 MiB)
[2025-05-07T02:44:31.348+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 5c5d1775d94e:37761 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T02:44:31.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO SparkContext: Created broadcast 20 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:31.446+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO CodeGenerator: Code generated in 34.492943 ms
[2025-05-07T02:44:31.448+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:31.500+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO CodeGenerator: Code generated in 34.56951 ms
[2025-05-07T02:44:31.571+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO CodeGenerator: Code generated in 8.286743 ms
[2025-05-07T02:44:31.591+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: Registering RDD 110 (collect at GraphFrame.scala:574) as input to shuffle 12
[2025-05-07T02:44:31.592+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: Got map stage job 17 (collect at GraphFrame.scala:574) with 11 output partitions
[2025-05-07T02:44:31.593+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:31.596+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
[2025-05-07T02:44:31.597+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:31.598+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[110] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:31.616+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 141.0 KiB, free 422.1 MiB)
[2025-05-07T02:44:31.622+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 49.7 KiB, free 422.1 MiB)
[2025-05-07T02:44:31.623+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 5c5d1775d94e:37761 (size: 49.7 KiB, free: 433.7 MiB)
[2025-05-07T02:44:31.627+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:31.628+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[110] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T02:44:31.628+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSchedulerImpl: Adding task set 29.0 with 11 tasks resource profile 0
[2025-05-07T02:44:31.638+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 27) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:31.664+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.20.0.5:40657 (size: 49.7 KiB, free: 434.3 MiB)
[2025-05-07T02:44:31.805+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:52776
[2025-05-07T02:44:31.878+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.20.0.5:40657 (size: 502.1 KiB, free: 433.8 MiB)
[2025-05-07T02:44:31.927+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.20.0.5:40657 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T02:44:31.949+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:31 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.20.0.5:40657 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T02:44:32.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 28) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.105+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 27) in 473 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T02:44:32.164+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 29) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.165+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 28) in 64 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T02:44:32.197+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 30) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.197+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 29) in 33 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T02:44:32.238+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 31) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.240+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 30) in 42 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T02:44:32.293+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 32) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.294+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 31) in 57 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T02:44:32.326+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 6.0 in stage 29.0 (TID 33) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.326+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 32) in 33 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-07T02:44:32.365+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 7.0 in stage 29.0 (TID 34) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.365+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 6.0 in stage 29.0 (TID 33) in 39 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-07T02:44:32.399+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 8.0 in stage 29.0 (TID 35) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.399+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 7.0 in stage 29.0 (TID 34) in 35 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-07T02:44:32.444+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 9.0 in stage 29.0 (TID 36) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.444+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 8.0 in stage 29.0 (TID 35) in 45 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-07T02:44:32.482+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 10.0 in stage 29.0 (TID 37) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.483+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 9.0 in stage 29.0 (TID 36) in 40 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-07T02:44:32.578+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 10.0 in stage 29.0 (TID 37) in 96 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-07T02:44:32.578+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-05-07T02:44:32.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: ShuffleMapStage 29 (collect at GraphFrame.scala:574) finished in 0.982 s
[2025-05-07T02:44:32.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:32.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:32.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:32.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:32.584+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:32.616+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:32.664+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO CodeGenerator: Code generated in 34.312901 ms
[2025-05-07T02:44:32.687+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Registering RDD 113 (collect at GraphFrame.scala:574) as input to shuffle 13
[2025-05-07T02:44:32.688+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Got map stage job 18 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T02:44:32.688+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:32.688+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
[2025-05-07T02:44:32.688+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:32.690+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[113] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:32.697+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 129.7 KiB, free 421.9 MiB)
[2025-05-07T02:44:32.698+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 44.3 KiB, free 421.9 MiB)
[2025-05-07T02:44:32.699+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 5c5d1775d94e:37761 (size: 44.3 KiB, free: 433.6 MiB)
[2025-05-07T02:44:32.702+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:32.702+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[113] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:32.702+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-05-07T02:44:32.703+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 38) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.732+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.20.0.5:40657 (size: 44.3 KiB, free: 433.7 MiB)
[2025-05-07T02:44:32.761+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:52776
[2025-05-07T02:44:32.774+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 5c5d1775d94e:37761 in memory (size: 30.3 KiB, free: 433.7 MiB)
[2025-05-07T02:44:32.776+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.20.0.5:40657 in memory (size: 30.3 KiB, free: 433.7 MiB)
[2025-05-07T02:44:32.786+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 5c5d1775d94e:37761 in memory (size: 49.7 KiB, free: 433.7 MiB)
[2025-05-07T02:44:32.792+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.20.0.5:40657 in memory (size: 49.7 KiB, free: 433.7 MiB)
[2025-05-07T02:44:32.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 38) in 189 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:32.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-05-07T02:44:32.892+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: ShuffleMapStage 32 (collect at GraphFrame.scala:574) finished in 0.202 s
[2025-05-07T02:44:32.892+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:32.892+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:32.893+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:32.893+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:32.893+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:32.912+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:32.929+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO CodeGenerator: Code generated in 12.574192 ms
[2025-05-07T02:44:32.956+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO SparkContext: Starting job: collect at GraphFrame.scala:574
[2025-05-07T02:44:32.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Got job 19 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T02:44:32.959+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Final stage: ResultStage 36 (collect at GraphFrame.scala:574)
[2025-05-07T02:44:32.959+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-05-07T02:44:32.959+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:32.959+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[116] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T02:44:32.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 122.6 KiB, free 422.1 MiB)
[2025-05-07T02:44:32.968+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 422.0 MiB)
[2025-05-07T02:44:32.968+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 5c5d1775d94e:37761 (size: 41.8 KiB, free: 433.7 MiB)
[2025-05-07T02:44:32.969+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:32.975+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[116] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:32.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-05-07T02:44:32.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 39) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:32.991+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:32 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.20.0.5:40657 (size: 41.8 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.002+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:52776
[2025-05-07T02:44:33.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 39) in 64 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:33.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-05-07T02:44:33.041+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: ResultStage 36 (collect at GraphFrame.scala:574) finished in 0.080 s
[2025-05-07T02:44:33.041+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:33.042+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-05-07T02:44:33.042+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Job 19 finished: collect at GraphFrame.scala:574, took 0.085043 s
[2025-05-07T02:44:33.254+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 5c5d1775d94e:37761 in memory (size: 44.3 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.257+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.20.0.5:40657 in memory (size: 44.3 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 5c5d1775d94e:37761 in memory (size: 41.8 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.264+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.20.0.5:40657 in memory (size: 41.8 KiB, free: 433.8 MiB)
[2025-05-07T02:44:33.575+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Registering RDD 147 (rdd at GraphFrame.scala:188) as input to shuffle 14
[2025-05-07T02:44:33.575+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Got map stage job 20 (rdd at GraphFrame.scala:188) with 6 output partitions
[2025-05-07T02:44:33.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:33.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:33.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:33.592+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[147] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:33.593+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:33.595+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 36.4 KiB, free 422.3 MiB)
[2025-05-07T02:44:33.596+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 422.3 MiB)
[2025-05-07T02:44:33.597+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 5c5d1775d94e:37761 (size: 11.2 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.597+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:33.597+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[147] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T02:44:33.598+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Adding task set 37.0 with 6 tasks resource profile 0
[2025-05-07T02:44:33.598+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:33.598+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Registering RDD 149 (rdd at GraphFrame.scala:188) as input to shuffle 15
[2025-05-07T02:44:33.598+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Got map stage job 21 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T02:44:33.599+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:33.599+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:33.599+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:33.599+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 40) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:33.601+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:33.608+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 12.6 KiB, free 422.3 MiB)
[2025-05-07T02:44:33.609+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 422.3 MiB)
[2025-05-07T02:44:33.609+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 5c5d1775d94e:37761 (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.609+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:33.610+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:33.610+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
[2025-05-07T02:44:33.610+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:33.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Registering RDD 151 (rdd at GraphFrame.scala:188) as input to shuffle 16
[2025-05-07T02:44:33.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Got map stage job 22 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T02:44:33.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:33.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:33.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:33.612+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:33.615+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 27.3 KiB, free 422.3 MiB)
[2025-05-07T02:44:33.615+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 422.3 MiB)
[2025-05-07T02:44:33.616+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 5c5d1775d94e:37761 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.617+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.20.0.5:40657 (size: 11.2 KiB, free: 433.8 MiB)
[2025-05-07T02:44:33.617+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:33.618+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:33.618+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-05-07T02:44:33.619+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Registering RDD 153 (rdd at GraphFrame.scala:188) as input to shuffle 17
[2025-05-07T02:44:33.619+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Got map stage job 23 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T02:44:33.619+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:33.619+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:33.619+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:33.620+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:33.623+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:33.624+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-07T02:44:33.638+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 422.2 MiB)
[2025-05-07T02:44:33.640+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 5c5d1775d94e:37761 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.641+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:33.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:33.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-05-07T02:44:33.645+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Registering RDD 155 (rdd at GraphFrame.scala:188) as input to shuffle 18
[2025-05-07T02:44:33.645+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Got map stage job 24 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T02:44:33.645+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:33.645+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:33.645+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:33.648+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:33.651+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[155] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:33.657+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-07T02:44:33.657+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:33.657+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 422.2 MiB)
[2025-05-07T02:44:33.657+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 41) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:33.662+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 40) in 59 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T02:44:33.663+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 5c5d1775d94e:37761 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.664+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:33.664+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[155] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:33.664+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-05-07T02:44:33.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Registering RDD 157 (rdd at GraphFrame.scala:188) as input to shuffle 19
[2025-05-07T02:44:33.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Got map stage job 25 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T02:44:33.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:33.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:33.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:33.676+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[157] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:33.678+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 27.4 KiB, free 422.2 MiB)
[2025-05-07T02:44:33.679+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 422.1 MiB)
[2025-05-07T02:44:33.684+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 5c5d1775d94e:37761 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.686+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:33.690+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[157] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:33.690+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-05-07T02:44:33.691+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Registering RDD 159 (rdd at GraphFrame.scala:188) as input to shuffle 20
[2025-05-07T02:44:33.691+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Got map stage job 26 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T02:44:33.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:33.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:33.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:33.697+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[159] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:33.701+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 28.5 KiB, free 422.1 MiB)
[2025-05-07T02:44:33.703+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 422.1 MiB)
[2025-05-07T02:44:33.704+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 5c5d1775d94e:37761 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.722+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:33.723+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[159] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:33.723+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
[2025-05-07T02:44:33.724+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Registering RDD 161 (rdd at GraphFrame.scala:188) as input to shuffle 21
[2025-05-07T02:44:33.724+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Got map stage job 27 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T02:44:33.724+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Final stage: ShuffleMapStage 44 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:33.725+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:33.725+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 42) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:33.725+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:33.725+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 41) in 69 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T02:44:33.727+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[161] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:33.732+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 31.7 KiB, free 422.1 MiB)
[2025-05-07T02:44:33.733+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 422.1 MiB)
[2025-05-07T02:44:33.733+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 5c5d1775d94e:37761 (size: 14.9 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:33.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[161] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:33.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-05-07T02:44:33.763+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 43) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:33.764+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 42) in 39 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T02:44:33.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 44) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:33.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 43) in 33 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T02:44:33.824+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 45) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:33.825+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 44) in 30 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T02:44:33.875+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 46) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:33.880+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 45) in 55 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T02:44:33.882+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-05-07T02:44:33.883+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: ShuffleMapStage 37 (rdd at GraphFrame.scala:188) finished in 0.290 s
[2025-05-07T02:44:33.883+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:33.883+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: running: Set(ShuffleMapStage 38, ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T02:44:33.883+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:33.883+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:33.918+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.20.0.5:40657 (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-07T02:44:33.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:33.923+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:33.934+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:33.940+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:33.940+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Final stage: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:33.940+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
[2025-05-07T02:44:33.940+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:33.941+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[164] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:33.943+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.2 KiB, free 422.1 MiB)
[2025-05-07T02:44:33.957+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 422.1 MiB)
[2025-05-07T02:44:33.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 5c5d1775d94e:37761 (size: 3.9 KiB, free: 433.6 MiB)
[2025-05-07T02:44:33.960+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 47) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:33.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:33.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 46) in 90 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:33.968+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 5c5d1775d94e:37761 in memory (size: 11.2 KiB, free: 433.7 MiB)
[2025-05-07T02:44:33.972+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2025-05-07T02:44:33.973+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[164] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:33.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-05-07T02:44:33.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.20.0.5:40657 in memory (size: 11.2 KiB, free: 433.8 MiB)
[2025-05-07T02:44:33.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: ShuffleMapStage 38 (rdd at GraphFrame.scala:188) finished in 0.365 s
[2025-05-07T02:44:33.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:33.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: running: Set(ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T02:44:33.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:33.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:33.978+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.20.0.5:40657 (size: 13.0 KiB, free: 433.8 MiB)
[2025-05-07T02:44:33.996+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:33.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:33.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:33 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:34.032+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 48) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.034+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 47) in 73 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:34.036+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-05-07T02:44:34.039+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: ShuffleMapStage 39 (rdd at GraphFrame.scala:188) finished in 0.426 s
[2025-05-07T02:44:34.041+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:34.041+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: running: Set(ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T02:44:34.042+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:34.042+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:34.042+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:34.044+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:34.044+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:34.046+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-05-07T02:44:34.046+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:34.053+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[167] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:34.054+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.2 KiB, free 422.1 MiB)
[2025-05-07T02:44:34.056+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 422.1 MiB)
[2025-05-07T02:44:34.059+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.062+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:34.062+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[167] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:34.063+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-05-07T02:44:34.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.20.0.5:40657 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.099+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 49) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.099+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 48) in 70 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:34.099+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-05-07T02:44:34.099+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: ShuffleMapStage 40 (rdd at GraphFrame.scala:188) finished in 0.478 s
[2025-05-07T02:44:34.100+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:34.100+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T02:44:34.100+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:34.100+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:34.110+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.20.0.5:40657 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.135+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 50) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.136+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 49) in 37 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:34.136+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-05-07T02:44:34.136+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: ShuffleMapStage 41 (rdd at GraphFrame.scala:188) finished in 0.485 s
[2025-05-07T02:44:34.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:34.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-07T02:44:34.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:34.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:34.149+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.20.0.5:40657 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.180+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 51) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.180+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 50) in 46 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:34.180+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-05-07T02:44:34.181+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: ShuffleMapStage 42 (rdd at GraphFrame.scala:188) finished in 0.506 s
[2025-05-07T02:44:34.181+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:34.181+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-07T02:44:34.181+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:34.182+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:34.190+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.20.0.5:40657 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 52) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 51) in 35 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:34.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-05-07T02:44:34.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: ShuffleMapStage 43 (rdd at GraphFrame.scala:188) finished in 0.518 s
[2025-05-07T02:44:34.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:34.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 44)
[2025-05-07T02:44:34.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:34.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:34.227+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.20.0.5:40657 (size: 14.9 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.274+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 53) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.275+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 52) in 61 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:34.275+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-05-07T02:44:34.275+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: ShuffleMapStage 44 (rdd at GraphFrame.scala:188) finished in 0.548 s
[2025-05-07T02:44:34.276+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:34.276+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46)
[2025-05-07T02:44:34.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:34.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:34.293+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.20.0.5:40657 (size: 3.9 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO ShufflePartitionsUtil: For shuffle(16, 17, 18, 19, 20, 21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:34.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:52776
[2025-05-07T02:44:34.318+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO CodeGenerator: Code generated in 4.570464 ms
[2025-05-07T02:44:34.319+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:34.319+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 54) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.319+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 53) in 45 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:34.319+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-05-07T02:44:34.320+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.378 s
[2025-05-07T02:44:34.322+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:34.323+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
[2025-05-07T02:44:34.324+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.387333 s
[2025-05-07T02:44:34.335+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 5c5d1775d94e:37761 in memory (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.347+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.347+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:52776
[2025-05-07T02:44:34.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.20.0.5:40657 in memory (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.351+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO CodeGenerator: Code generated in 28.450599 ms
[2025-05-07T02:44:34.358+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 5.0 MiB, free 417.1 MiB)
[2025-05-07T02:44:34.362+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 5c5d1775d94e:37761 in memory (size: 3.9 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.362+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 54) in 44 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:34.362+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-05-07T02:44:34.363+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.313 s
[2025-05-07T02:44:34.363+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:34.363+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-05-07T02:44:34.365+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.321899 s
[2025-05-07T02:44:34.366+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:34.369+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.20.0.5:40657 in memory (size: 3.9 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.378+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 2.1 MiB, free 415.1 MiB)
[2025-05-07T02:44:34.379+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 415.1 MiB)
[2025-05-07T02:44:34.381+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 5c5d1775d94e:37761 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.383+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:34.395+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 414.6 MiB)
[2025-05-07T02:44:34.395+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 5c5d1775d94e:37761 in memory (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.395+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.20.0.5:40657 in memory (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.395+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 5c5d1775d94e:37761 (size: 502.1 KiB, free: 433.2 MiB)
[2025-05-07T02:44:34.396+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO SparkContext: Created broadcast 34 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:34.402+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO CodeGenerator: Code generated in 25.986422 ms
[2025-05-07T02:44:34.414+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 5c5d1775d94e:37761 in memory (size: 114.2 KiB, free: 433.3 MiB)
[2025-05-07T02:44:34.424+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.20.0.5:40657 in memory (size: 114.2 KiB, free: 433.8 MiB)
[2025-05-07T02:44:34.428+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:34.445+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:34.454+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 5c5d1775d94e:37761 in memory (size: 20.6 KiB, free: 433.3 MiB)
[2025-05-07T02:44:34.454+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.20.0.5:40657 in memory (size: 20.6 KiB, free: 433.8 MiB)
[2025-05-07T02:44:34.460+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 5c5d1775d94e:37761 in memory (size: 502.1 KiB, free: 433.8 MiB)
[2025-05-07T02:44:34.462+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.20.0.5:40657 in memory (size: 502.1 KiB, free: 434.3 MiB)
[2025-05-07T02:44:34.462+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO CodeGenerator: Code generated in 15.01051 ms
[2025-05-07T02:44:34.467+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:34.471+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 5c5d1775d94e:37761 in memory (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-07T02:44:34.476+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.20.0.5:40657 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-07T02:44:34.482+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 5c5d1775d94e:37761 in memory (size: 13.4 KiB, free: 433.8 MiB)
[2025-05-07T02:44:34.482+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO CodeGenerator: Code generated in 12.61638 ms
[2025-05-07T02:44:34.483+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.20.0.5:40657 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T02:44:34.487+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:34.493+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 5c5d1775d94e:37761 in memory (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-07T02:44:34.494+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.20.0.5:40657 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T02:44:34.498+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 5c5d1775d94e:37761 in memory (size: 14.9 KiB, free: 433.8 MiB)
[2025-05-07T02:44:34.500+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.20.0.5:40657 in memory (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-07T02:44:34.502+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO CodeGenerator: Code generated in 10.268214 ms
[2025-05-07T02:44:34.508+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 5c5d1775d94e:37761 in memory (size: 13.0 KiB, free: 433.9 MiB)
[2025-05-07T02:44:34.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.20.0.5:40657 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T02:44:34.524+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:34.525+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T02:44:34.526+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:34.526+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 49, ShuffleMapStage 53, ShuffleMapStage 50, ShuffleMapStage 54)
[2025-05-07T02:44:34.526+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:34.526+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[190] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:34.530+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 91.7 KiB, free 424.6 MiB)
[2025-05-07T02:44:34.541+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 424.6 MiB)
[2025-05-07T02:44:34.545+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 5c5d1775d94e:37761 (size: 30.3 KiB, free: 433.8 MiB)
[2025-05-07T02:44:34.545+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T02:44:34.546+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:34.546+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 55 (MapPartitionsRDD[190] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T02:44:34.547+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Adding task set 55.0 with 6 tasks resource profile 0
[2025-05-07T02:44:34.547+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.551+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T02:44:34.563+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.20.0.5:40657 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T02:44:34.574+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:52776
[2025-05-07T02:44:34.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 56) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.617+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 66 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T02:44:34.625+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:52776
[2025-05-07T02:44:34.658+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 57) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.658+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 56) in 48 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T02:44:34.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:52776
[2025-05-07T02:44:34.677+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 58) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.678+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 57) in 21 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T02:44:34.685+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.20.0.5:52776
[2025-05-07T02:44:34.705+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 4.0 in stage 55.0 (TID 59) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.705+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 58) in 28 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T02:44:34.711+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.20.0.5:52776
[2025-05-07T02:44:34.741+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 5.0 in stage 55.0 (TID 60) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.742+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 4.0 in stage 55.0 (TID 59) in 37 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T02:44:34.749+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.20.0.5:52776
[2025-05-07T02:44:34.792+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Finished task 5.0 in stage 55.0 (TID 60) in 48 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T02:44:34.793+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-05-07T02:44:34.795+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.266 s
[2025-05-07T02:44:34.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:34.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-05-07T02:44:34.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.270196 s
[2025-05-07T02:44:34.816+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 2.3 MiB, free 422.4 MiB)
[2025-05-07T02:44:34.827+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 422.3 MiB)
[2025-05-07T02:44:34.829+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 5c5d1775d94e:37761 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.830+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO SparkContext: Created broadcast 37 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:34.852+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:34.887+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO CodeGenerator: Code generated in 24.833622 ms
[2025-05-07T02:44:34.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO CodeGenerator: Code generated in 8.987256 ms
[2025-05-07T02:44:34.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Registering RDD 197 (rdd at GraphFrame.scala:188) as input to shuffle 22
[2025-05-07T02:44:34.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Got map stage job 31 (rdd at GraphFrame.scala:188) with 11 output partitions
[2025-05-07T02:44:34.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Final stage: ShuffleMapStage 57 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:34.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-05-07T02:44:34.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:34.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[197] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:34.941+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 129.6 KiB, free 422.1 MiB)
[2025-05-07T02:44:34.949+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 45.0 KiB, free 422.1 MiB)
[2025-05-07T02:44:34.950+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 5c5d1775d94e:37761 (size: 45.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.954+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 5c5d1775d94e:37761 in memory (size: 30.3 KiB, free: 433.7 MiB)
[2025-05-07T02:44:34.955+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:34.956+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.20.0.5:40657 in memory (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T02:44:34.956+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[197] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T02:44:34.957+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSchedulerImpl: Adding task set 57.0 with 11 tasks resource profile 0
[2025-05-07T02:44:34.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 61) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:34.982+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:34 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.20.0.5:40657 (size: 45.0 KiB, free: 434.4 MiB)
[2025-05-07T02:44:35.016+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:52776
[2025-05-07T02:44:35.073+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.20.0.5:40657 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-07T02:44:35.106+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.20.0.5:40657 (size: 114.2 KiB, free: 433.8 MiB)
[2025-05-07T02:44:35.147+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:40657 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T02:44:35.207+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 62) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.208+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 61) in 251 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T02:44:35.270+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 63) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.272+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 62) in 63 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T02:44:35.324+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 64) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.330+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 63) in 59 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T02:44:35.379+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 4.0 in stage 57.0 (TID 65) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.380+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 64) in 57 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T02:44:35.430+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 5.0 in stage 57.0 (TID 66) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.435+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 4.0 in stage 57.0 (TID 65) in 56 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T02:44:35.479+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 6.0 in stage 57.0 (TID 67) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.479+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 5.0 in stage 57.0 (TID 66) in 48 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-07T02:44:35.513+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 7.0 in stage 57.0 (TID 68) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.514+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 6.0 in stage 57.0 (TID 67) in 36 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-07T02:44:35.535+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 8.0 in stage 57.0 (TID 69) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.536+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 7.0 in stage 57.0 (TID 68) in 22 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-07T02:44:35.566+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 9.0 in stage 57.0 (TID 70) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.567+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 8.0 in stage 57.0 (TID 69) in 33 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-07T02:44:35.590+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 10.0 in stage 57.0 (TID 71) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.592+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 9.0 in stage 57.0 (TID 70) in 25 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-07T02:44:35.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Finished task 10.0 in stage 57.0 (TID 71) in 231 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-07T02:44:35.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-05-07T02:44:35.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: ShuffleMapStage 57 (rdd at GraphFrame.scala:188) finished in 0.890 s
[2025-05-07T02:44:35.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:35.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:35.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:35.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:35.828+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:35.847+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO CodeGenerator: Code generated in 9.252488 ms
[2025-05-07T02:44:35.863+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:35.864+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: Got job 32 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:35.864+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: Final stage: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:35.864+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
[2025-05-07T02:44:35.864+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:35.864+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[201] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:35.869+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 116.0 KiB, free 422.1 MiB)
[2025-05-07T02:44:35.870+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 422.1 MiB)
[2025-05-07T02:44:35.870+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 5c5d1775d94e:37761 (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T02:44:35.871+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:35.871+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[201] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:35.871+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
[2025-05-07T02:44:35.872+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 72) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:35.882+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.20.0.5:40657 (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T02:44:35.890+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.20.0.5:52776
[2025-05-07T02:44:35.911+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 5c5d1775d94e:37761 in memory (size: 45.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:35.917+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:35 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.20.0.5:40657 in memory (size: 45.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.019+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 72) in 147 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:36.019+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-07T02:44:36.020+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.154 s
[2025-05-07T02:44:36.020+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:36.020+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
[2025-05-07T02:44:36.020+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Job 32 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.156733 s
[2025-05-07T02:44:36.028+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 2.0 MiB, free 420.2 MiB)
[2025-05-07T02:44:36.030+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 96.0 KiB, free 420.1 MiB)
[2025-05-07T02:44:36.031+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 5c5d1775d94e:37761 (size: 96.0 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.033+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO SparkContext: Created broadcast 40 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:36.064+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO CodeGenerator: Code generated in 11.674569 ms
[2025-05-07T02:44:36.065+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1522 - id.nullCount#1521) > 0)
[2025-05-07T02:44:36.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Registering RDD 19 (rdd at GraphFrame.scala:187) as input to shuffle 3
[2025-05-07T02:44:36.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Registering RDD 206 (rdd at GraphFrame.scala:188) as input to shuffle 23
[2025-05-07T02:44:36.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Got map stage job 33 (rdd at GraphFrame.scala:188) with 10 output partitions
[2025-05-07T02:44:36.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (rdd at GraphFrame.scala:188)
[2025-05-07T02:44:36.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
[2025-05-07T02:44:36.071+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
[2025-05-07T02:44:36.072+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T02:44:36.074+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.6 KiB, free 420.1 MiB)
[2025-05-07T02:44:36.088+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 420.1 MiB)
[2025-05-07T02:44:36.092+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 5c5d1775d94e:37761 in memory (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.092+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 5c5d1775d94e:37761 (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.096+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:36.097+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:36.098+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
[2025-05-07T02:44:36.098+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.20.0.5:40657 in memory (size: 39.3 KiB, free: 433.8 MiB)
[2025-05-07T02:44:36.099+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 73) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.118+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.20.0.5:40657 (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-07T02:44:36.188+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 73) in 88 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:36.189+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool
[2025-05-07T02:44:36.190+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: ShuffleMapStage 61 (rdd at GraphFrame.scala:187) finished in 0.114 s
[2025-05-07T02:44:36.190+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:36.190+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:36.191+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 62)
[2025-05-07T02:44:36.193+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:36.198+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[206] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T02:44:36.220+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 51.0 KiB, free 420.2 MiB)
[2025-05-07T02:44:36.235+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 420.2 MiB)
[2025-05-07T02:44:36.236+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 5c5d1775d94e:37761 (size: 21.7 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.236+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:36.237+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[206] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:36.237+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Adding task set 62.0 with 10 tasks resource profile 0
[2025-05-07T02:44:36.238+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 74) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.251+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.20.0.5:40657 (size: 21.7 KiB, free: 433.8 MiB)
[2025-05-07T02:44:36.301+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:52776
[2025-05-07T02:44:36.356+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.20.0.5:40657 (size: 2.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.401+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.20.0.5:40657 (size: 96.0 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.411+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 75) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.412+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 74) in 173 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:36.438+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.20.0.5:40657 (size: 2.5 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.459+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 76) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.460+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 75) in 48 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:36.476+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.486+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 77) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.486+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 76) in 28 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:36.514+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.20.0.5:40657 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.533+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 4.0 in stage 62.0 (TID 78) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.534+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 77) in 48 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:36.556+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.20.0.5:40657 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.573+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 5.0 in stage 62.0 (TID 79) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.573+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 4.0 in stage 62.0 (TID 78) in 39 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:36.593+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.20.0.5:40657 (size: 2.0 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.605+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 6.0 in stage 62.0 (TID 80) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.607+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 5.0 in stage 62.0 (TID 79) in 36 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:36.624+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.20.0.5:40657 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.636+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 7.0 in stage 62.0 (TID 81) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.637+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 6.0 in stage 62.0 (TID 80) in 31 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:36.649+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.20.0.5:40657 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.661+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 7.0 in stage 62.0 (TID 81) in 25 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:36.662+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 8.0 in stage 62.0 (TID 82) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.690+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.20.0.5:40657 (size: 2.4 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.703+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 9.0 in stage 62.0 (TID 83) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.704+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 8.0 in stage 62.0 (TID 82) in 44 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:36.721+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.20.0.5:40657 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.729+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 9.0 in stage 62.0 (TID 83) in 26 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:36.729+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-05-07T02:44:36.729+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: ShuffleMapStage 62 (rdd at GraphFrame.scala:188) finished in 0.531 s
[2025-05-07T02:44:36.729+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:36.730+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:36.730+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:36.730+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:36.742+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:36.748+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:36.749+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Got job 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:36.750+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Final stage: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:36.752+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
[2025-05-07T02:44:36.753+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:36.753+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[208] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:36.753+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.2 KiB, free 420.2 MiB)
[2025-05-07T02:44:36.762+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 420.1 MiB)
[2025-05-07T02:44:36.763+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.763+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:36.764+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[208] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:36.764+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
[2025-05-07T02:44:36.765+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 84) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.769+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 5c5d1775d94e:37761 in memory (size: 21.7 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.773+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.20.0.5:40657 in memory (size: 21.7 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.779+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 5c5d1775d94e:37761 in memory (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.784+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.20.0.5:40657 in memory (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.785+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.792+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.20.0.5:52776
[2025-05-07T02:44:36.803+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 84) in 38 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:36.804+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool
[2025-05-07T02:44:36.805+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.054 s
[2025-05-07T02:44:36.805+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:36.805+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
[2025-05-07T02:44:36.806+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Job 34 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.057023 s
[2025-05-07T02:44:36.822+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 2.0 MiB, free 418.2 MiB)
[2025-05-07T02:44:36.825+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 98.0 KiB, free 418.1 MiB)
[2025-05-07T02:44:36.825+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 5c5d1775d94e:37761 (size: 98.0 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.826+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO SparkContext: Created broadcast 44 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:36.843+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO CodeGenerator: Code generated in 6.808036 ms
[2025-05-07T02:44:36.844+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1532 - id.nullCount#1531) > 0)
[2025-05-07T02:44:36.913+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-07T02:44:36.914+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Registering RDD 31 (map at GraphFrame.scala:187) as input to shuffle 25
[2025-05-07T02:44:36.914+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Registering RDD 221 (mapPartitions at VertexRDD.scala:356) as input to shuffle 28
[2025-05-07T02:44:36.914+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Registering RDD 243 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 24
[2025-05-07T02:44:36.914+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Registering RDD 247 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 26
[2025-05-07T02:44:36.914+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Registering RDD 251 (mapPartitions at GraphImpl.scala:208) as input to shuffle 27
[2025-05-07T02:44:36.915+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Got job 35 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-07T02:44:36.915+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Final stage: ResultStage 72 (fold at VertexRDDImpl.scala:90)
[2025-05-07T02:44:36.915+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-07T02:44:36.915+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-07T02:44:36.916+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[31] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-07T02:44:36.929+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 59.1 KiB, free 418.1 MiB)
[2025-05-07T02:44:36.935+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 418.0 MiB)
[2025-05-07T02:44:36.935+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 5c5d1775d94e:37761 (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:36.935+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:36.936+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[31] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:36.937+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSchedulerImpl: Adding task set 67.0 with 10 tasks resource profile 0
[2025-05-07T02:44:36.939+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 433.5 MiB)
[2025-05-07T02:44:36.939+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T02:44:36.939+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO DAGScheduler: Submitting ShuffleMapStage 68 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[221] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-07T02:44:36.940+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 85) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:36.960+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.20.0.5:40657 (size: 26.0 KiB, free: 433.6 MiB)
[2025-05-07T02:44:36.996+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 158.2 KiB, free 417.9 MiB)
[2025-05-07T02:44:36.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:36 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 55.6 KiB, free 417.8 MiB)
[2025-05-07T02:44:37.016+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:37 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 5c5d1775d94e:37761 (size: 55.6 KiB, free: 433.5 MiB)
[2025-05-07T02:44:37.017+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:37 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:37.018+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 68 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[221] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:37.018+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:37 INFO TaskSchedulerImpl: Adding task set 68.0 with 10 tasks resource profile 0
[2025-05-07T02:44:37.100+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.5:40657 (size: 28.8 KiB, free: 433.6 MiB)
[2025-05-07T02:44:37.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:37 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 86) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:37.999+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:37 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 85) in 1059 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:38.020+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 87) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.020+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 86) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:38.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 88) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.041+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 2.0 in stage 67.0 (TID 87) in 21 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:38.054+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 4.0 in stage 67.0 (TID 89) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.054+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 3.0 in stage 67.0 (TID 88) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:38.075+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 5.0 in stage 67.0 (TID 90) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.077+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 4.0 in stage 67.0 (TID 89) in 23 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:38.096+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 6.0 in stage 67.0 (TID 91) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.097+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 5.0 in stage 67.0 (TID 90) in 23 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:38.115+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 7.0 in stage 67.0 (TID 92) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.115+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 6.0 in stage 67.0 (TID 91) in 20 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:38.130+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 8.0 in stage 67.0 (TID 93) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.131+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 7.0 in stage 67.0 (TID 92) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:38.150+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 9.0 in stage 67.0 (TID 94) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.150+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 8.0 in stage 67.0 (TID 93) in 20 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:38.180+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 95) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.180+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 9.0 in stage 67.0 (TID 94) in 30 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:38.181+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool
[2025-05-07T02:44:38.183+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: ShuffleMapStage 67 (map at GraphFrame.scala:187) finished in 1.265 s
[2025-05-07T02:44:38.183+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:38.184+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: running: Set(ShuffleMapStage 68)
[2025-05-07T02:44:38.184+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-07T02:44:38.184+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:38.193+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:40657 (size: 55.6 KiB, free: 433.6 MiB)
[2025-05-07T02:44:38.235+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.20.0.5:40657 (size: 98.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.305+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 96) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.305+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 95) in 126 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:38.326+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 97) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.327+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 96) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:38.345+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 98) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.345+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 97) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:38.362+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 4.0 in stage 68.0 (TID 99) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.363+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 98) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:38.380+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 5.0 in stage 68.0 (TID 100) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.380+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 4.0 in stage 68.0 (TID 99) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:38.402+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 6.0 in stage 68.0 (TID 101) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.402+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 5.0 in stage 68.0 (TID 100) in 23 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:38.419+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 7.0 in stage 68.0 (TID 102) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.419+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 6.0 in stage 68.0 (TID 101) in 18 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:38.435+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 8.0 in stage 68.0 (TID 103) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.436+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 7.0 in stage 68.0 (TID 102) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:38.452+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 9.0 in stage 68.0 (TID 104) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.452+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 8.0 in stage 68.0 (TID 103) in 17 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:38.469+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 9.0 in stage 68.0 (TID 104) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:38.469+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool
[2025-05-07T02:44:38.469+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: ShuffleMapStage 68 (mapPartitions at VertexRDD.scala:356) finished in 1.528 s
[2025-05-07T02:44:38.469+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:38.469+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:38.469+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-07T02:44:38.470+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:38.470+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: Submitting ShuffleMapStage 70 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[247] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:38.483+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 9.9 KiB, free 417.8 MiB)
[2025-05-07T02:44:38.499+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 417.8 MiB)
[2025-05-07T02:44:38.500+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 5c5d1775d94e:37761 (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.501+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:38.501+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 5c5d1775d94e:37761 in memory (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.502+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 70 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[247] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:38.502+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSchedulerImpl: Adding task set 70.0 with 10 tasks resource profile 0
[2025-05-07T02:44:38.503+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: Submitting ShuffleMapStage 69 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[243] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:38.506+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 105) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.508+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 10.3 KiB, free 417.9 MiB)
[2025-05-07T02:44:38.510+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.9 MiB)
[2025-05-07T02:44:38.511+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 5c5d1775d94e:37761 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:38.518+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 69 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[243] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:38.519+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSchedulerImpl: Adding task set 69.0 with 10 tasks resource profile 0
[2025-05-07T02:44:38.519+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.20.0.5:40657 in memory (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.530+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.20.0.5:40657 (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.600+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.20.0.5:52776
[2025-05-07T02:44:38.615+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 5c5d1775d94e:37761 in memory (size: 55.6 KiB, free: 433.6 MiB)
[2025-05-07T02:44:38.619+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.20.0.5:40657 in memory (size: 55.6 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.637+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.20.0.5:52776
[2025-05-07T02:44:38.853+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_224_0 in memory on 172.20.0.5:40657 (size: 18.6 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.859+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_229_0 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.862+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_235_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.864+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_239_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.873+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 106) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.874+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 105) in 371 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:38.880+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.20.0.5:40657 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.895+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 107) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.895+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 106) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:38.916+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_224_1 in memory on 172.20.0.5:40657 (size: 18.6 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.919+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_229_1 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.921+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_235_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.926+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_239_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T02:44:38.931+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 108) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.931+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 107) in 36 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:38.953+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_224_2 in memory on 172.20.0.5:40657 (size: 18.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:38.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_229_2 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:38.960+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_235_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:38.964+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_239_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:38.969+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 109) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:38.969+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 108) in 38 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:38.988+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_224_3 in memory on 172.20.0.5:40657 (size: 18.2 KiB, free: 433.4 MiB)
[2025-05-07T02:44:38.991+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_229_3 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:38.994+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_235_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:38.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:38 INFO BlockManagerInfo: Added rdd_239_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:39.004+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 110) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.005+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 109) in 37 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:39.022+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_224_4 in memory on 172.20.0.5:40657 (size: 18.8 KiB, free: 433.4 MiB)
[2025-05-07T02:44:39.027+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_229_4 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:39.029+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_235_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:39.033+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_239_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:39.038+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 111) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.039+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 110) in 35 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:39.062+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_224_5 in memory on 172.20.0.5:40657 (size: 18.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.065+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_229_5 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_235_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.070+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_239_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.078+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 6.0 in stage 69.0 (TID 112) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.079+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 111) in 41 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:39.098+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_224_6 in memory on 172.20.0.5:40657 (size: 18.4 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.100+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_229_6 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_235_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.107+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_239_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.112+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 7.0 in stage 69.0 (TID 113) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.113+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 6.0 in stage 69.0 (TID 112) in 34 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:39.127+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_224_7 in memory on 172.20.0.5:40657 (size: 18.4 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.129+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_229_7 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.131+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_235_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.133+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_239_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T02:44:39.139+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 8.0 in stage 69.0 (TID 114) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.140+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 7.0 in stage 69.0 (TID 113) in 27 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:39.154+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_224_8 in memory on 172.20.0.5:40657 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-07T02:44:39.158+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_229_8 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T02:44:39.161+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_235_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T02:44:39.165+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_239_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T02:44:39.170+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 9.0 in stage 69.0 (TID 115) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.171+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 8.0 in stage 69.0 (TID 114) in 32 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:39.184+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_224_9 in memory on 172.20.0.5:40657 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-07T02:44:39.192+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_229_9 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T02:44:39.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_235_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T02:44:39.198+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_239_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T02:44:39.207+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 116) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.208+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 9.0 in stage 69.0 (TID 115) in 36 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:39.209+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-07T02:44:39.210+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: ShuffleMapStage 69 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.703 s
[2025-05-07T02:44:39.210+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:39.210+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: running: Set(ShuffleMapStage 70)
[2025-05-07T02:44:39.210+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-07T02:44:39.211+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:39.232+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 117) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.233+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 116) in 27 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:39.244+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 118) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.244+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 117) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:39.256+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 119) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.257+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 118) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:39.267+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 5.0 in stage 70.0 (TID 120) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.267+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 119) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:39.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 6.0 in stage 70.0 (TID 121) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 5.0 in stage 70.0 (TID 120) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:39.286+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 7.0 in stage 70.0 (TID 122) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.287+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 6.0 in stage 70.0 (TID 121) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:39.295+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 8.0 in stage 70.0 (TID 123) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.296+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 7.0 in stage 70.0 (TID 122) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:39.302+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 9.0 in stage 70.0 (TID 124) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.302+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 8.0 in stage 70.0 (TID 123) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:39.310+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 9.0 in stage 70.0 (TID 124) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:39.310+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-05-07T02:44:39.311+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: ShuffleMapStage 70 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.838 s
[2025-05-07T02:44:39.311+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:39.311+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:39.311+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-07T02:44:39.311+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:39.311+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: Submitting ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[251] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:39.316+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 162.8 KiB, free 417.9 MiB)
[2025-05-07T02:44:39.322+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 57.7 KiB, free 417.9 MiB)
[2025-05-07T02:44:39.323+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 5c5d1775d94e:37761 (size: 57.7 KiB, free: 433.5 MiB)
[2025-05-07T02:44:39.324+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:39.325+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[251] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:39.326+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSchedulerImpl: Adding task set 71.0 with 10 tasks resource profile 0
[2025-05-07T02:44:39.327+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 5c5d1775d94e:37761 in memory (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:39.328+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.20.0.5:40657 in memory (size: 5.0 KiB, free: 433.2 MiB)
[2025-05-07T02:44:39.328+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 125) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.335+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.20.0.5:40657 (size: 57.7 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.381+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.383+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.385+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.386+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.20.0.5:52776
[2025-05-07T02:44:39.393+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.394+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.20.0.5:52776
[2025-05-07T02:44:39.404+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 5c5d1775d94e:37761 in memory (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-07T02:44:39.404+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.20.0.5:40657 in memory (size: 4.9 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.415+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 126) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.415+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 125) in 87 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:39.449+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.450+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.452+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.458+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.464+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 127) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.465+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 126) in 51 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:39.488+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.491+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.494+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.499+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.506+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 128) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.507+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 127) in 43 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:39.524+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.527+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.529+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.533+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.539+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 129) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.541+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 128) in 36 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:39.561+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.563+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.565+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.570+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.578+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 130) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 129) in 40 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:39.599+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.601+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.603+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.608+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.614+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 6.0 in stage 71.0 (TID 131) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.614+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 130) in 37 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:39.647+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.649+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.651+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.679+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 7.0 in stage 71.0 (TID 132) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.693+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 6.0 in stage 71.0 (TID 131) in 78 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:39.720+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.723+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.727+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.731+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.736+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 8.0 in stage 71.0 (TID 133) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.736+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 7.0 in stage 71.0 (TID 132) in 44 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:39.754+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.756+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.759+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.763+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.768+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 9.0 in stage 71.0 (TID 134) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.768+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 8.0 in stage 71.0 (TID 133) in 32 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:39.784+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_227_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.786+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_231_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.787+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_237_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.791+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_245_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 9.0 in stage 71.0 (TID 134) in 30 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:39.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-05-07T02:44:39.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: ShuffleMapStage 71 (mapPartitions at GraphImpl.scala:208) finished in 0.485 s
[2025-05-07T02:44:39.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:39.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:39.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: waiting: Set(ResultStage 72)
[2025-05-07T02:44:39.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:39.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[255] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-07T02:44:39.799+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 11.2 KiB, free 417.9 MiB)
[2025-05-07T02:44:39.805+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.9 MiB)
[2025-05-07T02:44:39.805+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 5c5d1775d94e:37761 (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T02:44:39.805+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:39.806+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 72 (MapPartitionsRDD[255] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:39.806+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSchedulerImpl: Adding task set 72.0 with 10 tasks resource profile 0
[2025-05-07T02:44:39.808+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 135) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.814+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.20.0.5:40657 (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.819+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.20.0.5:52776
[2025-05-07T02:44:39.823+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_0 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.827+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 136) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.827+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 135) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:39.834+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_1 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.1 MiB)
[2025-05-07T02:44:39.837+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 137) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.838+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 136) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:39.856+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_2 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T02:44:39.859+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 138) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.860+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 137) in 22 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:39.865+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_3 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T02:44:39.867+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 4.0 in stage 72.0 (TID 139) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.867+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 138) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:39.874+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_4 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T02:44:39.877+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 5.0 in stage 72.0 (TID 140) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.877+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 4.0 in stage 72.0 (TID 139) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:39.882+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_5 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T02:44:39.884+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 6.0 in stage 72.0 (TID 141) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.885+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 5.0 in stage 72.0 (TID 140) in 7 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:39.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_6 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T02:44:39.895+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 7.0 in stage 72.0 (TID 142) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.895+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 6.0 in stage 72.0 (TID 141) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:39.901+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_7 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T02:44:39.904+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 8.0 in stage 72.0 (TID 143) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.904+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 7.0 in stage 72.0 (TID 142) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:39.911+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_8 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T02:44:39.913+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Starting task 9.0 in stage 72.0 (TID 144) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:39.914+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 8.0 in stage 72.0 (TID 143) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:39.919+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManagerInfo: Added rdd_253_9 in memory on 172.20.0.5:40657 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T02:44:39.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSetManager: Finished task 9.0 in stage 72.0 (TID 144) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:39.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-05-07T02:44:39.922+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: ResultStage 72 (fold at VertexRDDImpl.scala:90) finished in 0.123 s
[2025-05-07T02:44:39.923+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:39.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-05-07T02:44:39.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO DAGScheduler: Job 35 finished: fold at VertexRDDImpl.scala:90, took 3.010709 s
[2025-05-07T02:44:39.926+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO ZippedPartitionsRDD2: Removing RDD 253 from persistence list
[2025-05-07T02:44:39.931+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:39 INFO BlockManager: Removing RDD 253
[2025-05-07T02:44:40.191+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:40.193+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Registering RDD 258 (mapPartitions at GraphImpl.scala:208) as input to shuffle 30
[2025-05-07T02:44:40.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 5c5d1775d94e:37761 in memory (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T02:44:40.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Registering RDD 276 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 31
[2025-05-07T02:44:40.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Registering RDD 266 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 29
[2025-05-07T02:44:40.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Registering RDD 280 (mapPartitions at GraphImpl.scala:208) as input to shuffle 33
[2025-05-07T02:44:40.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Registering RDD 288 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 32
[2025-05-07T02:44:40.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Got job 36 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:40.194+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Final stage: ResultStage 81 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:40.195+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78, ShuffleMapStage 73, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T02:44:40.195+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.20.0.5:40657 in memory (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.195+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T02:44:40.196+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting ShuffleMapStage 75 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[258] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:40.197+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 5c5d1775d94e:37761 in memory (size: 57.7 KiB, free: 433.6 MiB)
[2025-05-07T02:44:40.198+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.20.0.5:40657 in memory (size: 57.7 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.201+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManager: Removing RDD 253
[2025-05-07T02:44:40.202+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 161.1 KiB, free 418.0 MiB)
[2025-05-07T02:44:40.211+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 56.8 KiB, free 417.9 MiB)
[2025-05-07T02:44:40.213+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 5c5d1775d94e:37761 (size: 56.8 KiB, free: 433.5 MiB)
[2025-05-07T02:44:40.213+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:40.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 75 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[258] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:40.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSchedulerImpl: Adding task set 75.0 with 10 tasks resource profile 0
[2025-05-07T02:44:40.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManager: Removing RDD 245
[2025-05-07T02:44:40.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 145) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.224+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.20.0.5:40657 (size: 56.8 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.266+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 146) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.267+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 145) in 51 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:40.278+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 147) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.278+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 146) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:40.287+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 148) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.287+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 147) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:40.297+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 149) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 148) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:40.310+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 5.0 in stage 75.0 (TID 150) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.310+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 4.0 in stage 75.0 (TID 149) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:40.323+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 6.0 in stage 75.0 (TID 151) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.324+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 5.0 in stage 75.0 (TID 150) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:40.336+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 7.0 in stage 75.0 (TID 152) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.336+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 6.0 in stage 75.0 (TID 151) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:40.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 8.0 in stage 75.0 (TID 153) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 7.0 in stage 75.0 (TID 152) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:40.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 9.0 in stage 75.0 (TID 154) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 8.0 in stage 75.0 (TID 153) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:40.372+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 9.0 in stage 75.0 (TID 154) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:40.373+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool
[2025-05-07T02:44:40.373+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: ShuffleMapStage 75 (mapPartitions at GraphImpl.scala:208) finished in 0.177 s
[2025-05-07T02:44:40.373+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:40.373+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:40.373+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 78, ShuffleMapStage 79, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T02:44:40.374+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:40.374+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[266] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:40.376+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 10.1 KiB, free 417.9 MiB)
[2025-05-07T02:44:40.384+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.9 MiB)
[2025-05-07T02:44:40.384+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 5c5d1775d94e:37761 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:40.384+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:40.385+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[266] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:40.385+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSchedulerImpl: Adding task set 78.0 with 10 tasks resource profile 0
[2025-05-07T02:44:40.386+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 155) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.386+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[276] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:40.389+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 10.7 KiB, free 417.9 MiB)
[2025-05-07T02:44:40.389+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.9 MiB)
[2025-05-07T02:44:40.390+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 5c5d1775d94e:37761 (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T02:44:40.390+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:40.391+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[276] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:40.391+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSchedulerImpl: Adding task set 77.0 with 10 tasks resource profile 0
[2025-05-07T02:44:40.401+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.20.0.5:40657 (size: 5.0 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.417+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.20.0.5:52776
[2025-05-07T02:44:40.439+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_0 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.446+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 156) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.447+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 155) in 62 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:40.452+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.20.0.5:40657 (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.460+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.468+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 157) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.468+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 156) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:40.479+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_1 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.481+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.486+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 158) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.486+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 157) in 18 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:40.496+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_2 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T02:44:40.498+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.502+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 159) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.502+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 158) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:40.513+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_3 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.514+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.521+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 4.0 in stage 77.0 (TID 160) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.522+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 159) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:40.533+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_4 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.536+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.541+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 5.0 in stage 77.0 (TID 161) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.541+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 4.0 in stage 77.0 (TID 160) in 21 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:40.551+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_5 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.552+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.558+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 6.0 in stage 77.0 (TID 162) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.559+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 5.0 in stage 77.0 (TID 161) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:40.567+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_6 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.569+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 7.0 in stage 77.0 (TID 163) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 6.0 in stage 77.0 (TID 162) in 18 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:40.585+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_7 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.587+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.594+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 8.0 in stage 77.0 (TID 164) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.594+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 7.0 in stage 77.0 (TID 163) in 19 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:40.602+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_8 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.603+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 9.0 in stage 77.0 (TID 165) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 8.0 in stage 77.0 (TID 164) in 18 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:40.618+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_262_9 in memory on 172.20.0.5:40657 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.620+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_272_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.625+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 166) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.626+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 9.0 in stage 77.0 (TID 165) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:40.626+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool
[2025-05-07T02:44:40.626+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: ShuffleMapStage 77 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.240 s
[2025-05-07T02:44:40.626+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:40.626+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: running: Set(ShuffleMapStage 78)
[2025-05-07T02:44:40.626+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-07T02:44:40.627+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:40.632+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 167) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.633+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 166) in 7 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:40.638+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 168) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.639+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 167) in 7 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:40.647+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 169) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.647+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 168) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:40.653+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 5.0 in stage 78.0 (TID 170) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.653+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 169) in 7 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:40.661+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 6.0 in stage 78.0 (TID 171) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.661+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 5.0 in stage 78.0 (TID 170) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:40.667+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 7.0 in stage 78.0 (TID 172) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.668+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 6.0 in stage 78.0 (TID 171) in 6 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:40.674+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 8.0 in stage 78.0 (TID 173) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.675+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 7.0 in stage 78.0 (TID 172) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:40.683+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 9.0 in stage 78.0 (TID 174) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.683+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 8.0 in stage 78.0 (TID 173) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:40.691+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 9.0 in stage 78.0 (TID 174) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:40.691+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-05-07T02:44:40.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: ShuffleMapStage 78 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.316 s
[2025-05-07T02:44:40.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:40.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:40.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-07T02:44:40.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:40.693+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[280] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:40.698+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 163.7 KiB, free 417.7 MiB)
[2025-05-07T02:44:40.709+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.7 MiB)
[2025-05-07T02:44:40.710+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 5c5d1775d94e:37761 (size: 58.0 KiB, free: 433.4 MiB)
[2025-05-07T02:44:40.710+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:40.710+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[280] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:40.710+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSchedulerImpl: Adding task set 79.0 with 10 tasks resource profile 0
[2025-05-07T02:44:40.711+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 5c5d1775d94e:37761 in memory (size: 5.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:40.712+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.20.0.5:40657 in memory (size: 5.3 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.712+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 175) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.715+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 5c5d1775d94e:37761 in memory (size: 56.8 KiB, free: 433.5 MiB)
[2025-05-07T02:44:40.716+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.20.0.5:40657 in memory (size: 56.8 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.719+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.20.0.5:40657 (size: 58.0 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.735+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:52776
[2025-05-07T02:44:40.743+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.745+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:52776
[2025-05-07T02:44:40.763+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 176) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.764+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 175) in 52 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:40.783+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.789+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 177) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 176) in 33 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:40.818+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.822+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.829+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 178) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.830+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 177) in 33 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:40.844+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.847+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.851+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 4.0 in stage 79.0 (TID 179) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.852+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 178) in 22 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:40.862+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.865+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.869+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 5.0 in stage 79.0 (TID 180) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.869+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 4.0 in stage 79.0 (TID 179) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:40.878+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.881+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.887+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 6.0 in stage 79.0 (TID 181) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.887+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 5.0 in stage 79.0 (TID 180) in 19 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:40.899+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.903+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.910+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 7.0 in stage 79.0 (TID 182) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.911+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 6.0 in stage 79.0 (TID 181) in 24 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:40.920+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.925+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T02:44:40.930+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 8.0 in stage 79.0 (TID 183) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.930+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 7.0 in stage 79.0 (TID 182) in 21 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:40.943+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:40.946+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:40.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 9.0 in stage 79.0 (TID 184) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.952+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 8.0 in stage 79.0 (TID 183) in 21 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:40.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_264_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:40.970+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added rdd_274_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:40.975+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Finished task 9.0 in stage 79.0 (TID 184) in 24 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:40.975+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-05-07T02:44:40.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: ShuffleMapStage 79 (mapPartitions at GraphImpl.scala:208) finished in 0.281 s
[2025-05-07T02:44:40.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:40.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:40.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 80)
[2025-05-07T02:44:40.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:40.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[288] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:40.978+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 12.0 KiB, free 417.9 MiB)
[2025-05-07T02:44:40.984+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 417.9 MiB)
[2025-05-07T02:44:40.984+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 5c5d1775d94e:37761 (size: 5.7 KiB, free: 433.5 MiB)
[2025-05-07T02:44:40.984+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 5c5d1775d94e:37761 in memory (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:40.985+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:40.985+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[288] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:40.985+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSchedulerImpl: Adding task set 80.0 with 10 tasks resource profile 0
[2025-05-07T02:44:40.986+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 185) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:40.986+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.20.0.5:40657 in memory (size: 5.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:40.993+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.20.0.5:40657 (size: 5.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.000+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:52776
[2025-05-07T02:44:41.009+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.016+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 186) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.016+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 185) in 31 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:41.032+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.037+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 187) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.037+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 186) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:41.046+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.050+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 188) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.050+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 187) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:41.062+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.066+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 4.0 in stage 80.0 (TID 189) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 188) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:41.076+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.080+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 5.0 in stage 80.0 (TID 190) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.080+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 4.0 in stage 80.0 (TID 189) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:41.087+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.093+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 6.0 in stage 80.0 (TID 191) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.093+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 5.0 in stage 80.0 (TID 190) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:41.100+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.104+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 7.0 in stage 80.0 (TID 192) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.105+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 6.0 in stage 80.0 (TID 191) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:41.113+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.117+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 8.0 in stage 80.0 (TID 193) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.118+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 7.0 in stage 80.0 (TID 192) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:41.125+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.129+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 9.0 in stage 80.0 (TID 194) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.130+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 8.0 in stage 80.0 (TID 193) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:41.136+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_284_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.141+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 9.0 in stage 80.0 (TID 194) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:41.141+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool
[2025-05-07T02:44:41.141+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: ShuffleMapStage 80 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.164 s
[2025-05-07T02:44:41.141+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:41.142+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:41.142+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: waiting: Set(ResultStage 81)
[2025-05-07T02:44:41.142+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:41.142+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Submitting ResultStage 81 (EdgeRDDImpl[291] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:41.146+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 163.5 KiB, free 417.7 MiB)
[2025-05-07T02:44:41.155+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 57.7 KiB, free 417.7 MiB)
[2025-05-07T02:44:41.156+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 5c5d1775d94e:37761 (size: 57.7 KiB, free: 433.4 MiB)
[2025-05-07T02:44:41.156+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:41.156+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 81 (EdgeRDDImpl[291] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:41.157+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Adding task set 81.0 with 10 tasks resource profile 0
[2025-05-07T02:44:41.158+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 195) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.159+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 5c5d1775d94e:37761 in memory (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:41.160+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.20.0.5:40657 in memory (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.179+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.20.0.5:40657 (size: 57.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.192+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:52776
[2025-05-07T02:44:41.195+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:52776
[2025-05-07T02:44:41.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.220+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 196) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.221+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 195) in 64 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:41.238+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.241+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 197) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.241+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 196) in 21 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:41.252+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.255+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 198) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.256+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 197) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:41.267+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.269+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 199) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.269+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 198) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:41.281+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.283+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 200) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.284+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 199) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:41.294+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.296+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 6.0 in stage 81.0 (TID 201) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.297+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 200) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:41.308+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.311+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 7.0 in stage 81.0 (TID 202) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.311+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 6.0 in stage 81.0 (TID 201) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:41.323+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.326+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 8.0 in stage 81.0 (TID 203) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.326+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 7.0 in stage 81.0 (TID 202) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:41.337+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.341+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 9.0 in stage 81.0 (TID 204) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.341+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 8.0 in stage 81.0 (TID 203) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:41.351+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_290_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.353+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 9.0 in stage 81.0 (TID 204) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:41.354+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-05-07T02:44:41.355+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: ResultStage 81 (foreachPartition at PageRank.scala:199) finished in 0.211 s
[2025-05-07T02:44:41.355+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:41.355+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
[2025-05-07T02:44:41.356+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Job 36 finished: foreachPartition at PageRank.scala:199, took 1.164056 s
[2025-05-07T02:44:41.357+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO PageRank: PageRank finished iteration 0.
[2025-05-07T02:44:41.358+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MapPartitionsRDD: Removing RDD 272 from persistence list
[2025-05-07T02:44:41.359+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManager: Removing RDD 272
[2025-05-07T02:44:41.360+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MapPartitionsRDD: Removing RDD 274 from persistence list
[2025-05-07T02:44:41.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManager: Removing RDD 274
[2025-05-07T02:44:41.377+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:41.379+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Registering RDD 292 (mapPartitions at GraphImpl.scala:208) as input to shuffle 35
[2025-05-07T02:44:41.379+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Registering RDD 300 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 34
[2025-05-07T02:44:41.379+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Got job 37 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:41.379+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Final stage: ResultStage 92 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:41.380+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82, ShuffleMapStage 89, ShuffleMapStage 86, ShuffleMapStage 87, ShuffleMapStage 91)
[2025-05-07T02:44:41.380+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
[2025-05-07T02:44:41.380+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Submitting ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[292] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:41.386+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 164.0 KiB, free 417.7 MiB)
[2025-05-07T02:44:41.397+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-07T02:44:41.398+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 5c5d1775d94e:37761 in memory (size: 57.7 KiB, free: 433.6 MiB)
[2025-05-07T02:44:41.398+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 5c5d1775d94e:37761 (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T02:44:41.398+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:41.399+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[292] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:41.399+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Adding task set 90.0 with 10 tasks resource profile 0
[2025-05-07T02:44:41.400+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.20.0.5:40657 in memory (size: 57.7 KiB, free: 433.0 MiB)
[2025-05-07T02:44:41.401+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 205) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.407+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.20.0.5:40657 in memory (size: 5.7 KiB, free: 433.0 MiB)
[2025-05-07T02:44:41.410+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 5c5d1775d94e:37761 in memory (size: 5.7 KiB, free: 433.5 MiB)
[2025-05-07T02:44:41.415+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.20.0.5:40657 (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.429+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 206) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.430+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 205) in 31 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:41.459+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 207) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.461+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 206) in 33 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:41.476+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 208) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.477+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 207) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:41.495+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 4.0 in stage 90.0 (TID 209) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.497+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 208) in 20 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:41.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 5.0 in stage 90.0 (TID 210) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.513+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 4.0 in stage 90.0 (TID 209) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:41.527+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 6.0 in stage 90.0 (TID 211) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.528+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 5.0 in stage 90.0 (TID 210) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:41.542+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 7.0 in stage 90.0 (TID 212) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.543+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 6.0 in stage 90.0 (TID 211) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:41.557+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 8.0 in stage 90.0 (TID 213) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.558+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 7.0 in stage 90.0 (TID 212) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:41.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 9.0 in stage 90.0 (TID 214) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 8.0 in stage 90.0 (TID 213) in 22 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:41.593+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 9.0 in stage 90.0 (TID 214) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:41.594+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-05-07T02:44:41.594+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: ShuffleMapStage 90 (mapPartitions at GraphImpl.scala:208) finished in 0.212 s
[2025-05-07T02:44:41.594+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:41.595+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:41.595+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 91, ResultStage 92)
[2025-05-07T02:44:41.595+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:41.595+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Submitting ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[300] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:41.596+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.8 KiB, free 417.9 MiB)
[2025-05-07T02:44:41.614+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 417.9 MiB)
[2025-05-07T02:44:41.615+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 5c5d1775d94e:37761 (size: 5.9 KiB, free: 433.5 MiB)
[2025-05-07T02:44:41.616+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:41.616+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[300] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:41.616+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Adding task set 91.0 with 10 tasks resource profile 0
[2025-05-07T02:44:41.620+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 215) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.629+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.20.0.5:40657 (size: 5.9 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.633+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:52776
[2025-05-07T02:44:41.640+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.647+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 216) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.647+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 215) in 27 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:41.668+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.675+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 217) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.676+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 216) in 29 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:41.684+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.691+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 218) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.692+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 217) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:41.701+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.708+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 219) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.709+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 218) in 18 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:41.717+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.724+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 220) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.724+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 219) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:41.733+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.738+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 221) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.739+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 220) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:41.749+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.754+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 222) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.754+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 221) in 16 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:41.764+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.769+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 8.0 in stage 91.0 (TID 223) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.770+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 222) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:41.780+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.785+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 9.0 in stage 91.0 (TID 224) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.785+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 8.0 in stage 91.0 (TID 223) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:41.794+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_296_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.801+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 9.0 in stage 91.0 (TID 224) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:41.802+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-05-07T02:44:41.802+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: ShuffleMapStage 91 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.208 s
[2025-05-07T02:44:41.802+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:41.802+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:41.802+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: waiting: Set(ResultStage 92)
[2025-05-07T02:44:41.802+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:41.803+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Submitting ResultStage 92 (EdgeRDDImpl[303] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:41.810+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 163.8 KiB, free 417.7 MiB)
[2025-05-07T02:44:41.819+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.9 MiB)
[2025-05-07T02:44:41.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 5c5d1775d94e:37761 in memory (size: 58.1 KiB, free: 433.6 MiB)
[2025-05-07T02:44:41.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 5c5d1775d94e:37761 (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:41.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:41.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 92 (EdgeRDDImpl[303] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:41.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Adding task set 92.0 with 10 tasks resource profile 0
[2025-05-07T02:44:41.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.20.0.5:40657 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.823+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 225) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.830+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.20.0.5:40657 (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.842+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:52776
[2025-05-07T02:44:41.847+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.850+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 226) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.850+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 225) in 29 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:41.868+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.871+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 227) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.872+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 226) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:41.882+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.885+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 228) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.885+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 227) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:41.896+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.898+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 229) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.899+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 228) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:41.909+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.911+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 5.0 in stage 92.0 (TID 230) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.912+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 229) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:41.920+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 6.0 in stage 92.0 (TID 231) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 5.0 in stage 92.0 (TID 230) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:41.933+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.935+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 7.0 in stage 92.0 (TID 232) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.935+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 6.0 in stage 92.0 (TID 231) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:41.945+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.947+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 8.0 in stage 92.0 (TID 233) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.948+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 7.0 in stage 92.0 (TID 232) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:41.960+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.963+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Starting task 9.0 in stage 92.0 (TID 234) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:41.964+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 8.0 in stage 92.0 (TID 233) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:41.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManagerInfo: Added rdd_302_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:41.978+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSetManager: Finished task 9.0 in stage 92.0 (TID 234) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:41.978+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool
[2025-05-07T02:44:41.978+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: ResultStage 92 (foreachPartition at PageRank.scala:199) finished in 0.175 s
[2025-05-07T02:44:41.979+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:41.979+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
[2025-05-07T02:44:41.979+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Job 37 finished: foreachPartition at PageRank.scala:199, took 0.601811 s
[2025-05-07T02:44:41.979+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO PageRank: PageRank finished iteration 1.
[2025-05-07T02:44:41.979+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO ZippedPartitionsRDD2: Removing RDD 284 from persistence list
[2025-05-07T02:44:41.980+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManager: Removing RDD 284
[2025-05-07T02:44:41.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO ZippedPartitionsRDD2: Removing RDD 290 from persistence list
[2025-05-07T02:44:41.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO BlockManager: Removing RDD 290
[2025-05-07T02:44:41.996+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:41.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Registering RDD 304 (mapPartitions at GraphImpl.scala:208) as input to shuffle 37
[2025-05-07T02:44:41.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Registering RDD 312 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 36
[2025-05-07T02:44:41.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Got job 38 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:41.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Final stage: ResultStage 105 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:41.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 100, ShuffleMapStage 104, ShuffleMapStage 93, ShuffleMapStage 97, ShuffleMapStage 98)
[2025-05-07T02:44:41.999+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
[2025-05-07T02:44:41.999+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:41 INFO DAGScheduler: Submitting ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[304] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:42.003+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 164.3 KiB, free 417.7 MiB)
[2025-05-07T02:44:42.014+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.7 MiB)
[2025-05-07T02:44:42.014+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 5c5d1775d94e:37761 in memory (size: 58.0 KiB, free: 433.6 MiB)
[2025-05-07T02:44:42.014+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 5c5d1775d94e:37761 (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-07T02:44:42.015+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:42.015+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[304] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:42.015+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.20.0.5:40657 in memory (size: 58.0 KiB, free: 433.0 MiB)
[2025-05-07T02:44:42.015+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Adding task set 103.0 with 10 tasks resource profile 0
[2025-05-07T02:44:42.016+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 235) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.017+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 5c5d1775d94e:37761 in memory (size: 5.9 KiB, free: 433.5 MiB)
[2025-05-07T02:44:42.019+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.20.0.5:40657 in memory (size: 5.9 KiB, free: 433.0 MiB)
[2025-05-07T02:44:42.023+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.20.0.5:40657 (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.035+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 236) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.036+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 235) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:42.047+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 237) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.048+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 236) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:42.061+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 238) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.062+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 237) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:42.070+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 239) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.070+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 238) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:42.082+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 240) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.083+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 239) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:42.091+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 6.0 in stage 103.0 (TID 241) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.091+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 240) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:42.099+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 7.0 in stage 103.0 (TID 242) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.100+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 6.0 in stage 103.0 (TID 241) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:42.108+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 8.0 in stage 103.0 (TID 243) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.109+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 7.0 in stage 103.0 (TID 242) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:42.118+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 9.0 in stage 103.0 (TID 244) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.118+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 8.0 in stage 103.0 (TID 243) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:42.127+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 9.0 in stage 103.0 (TID 244) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:42.127+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-05-07T02:44:42.127+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: ShuffleMapStage 103 (mapPartitions at GraphImpl.scala:208) finished in 0.127 s
[2025-05-07T02:44:42.127+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:42.128+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:42.128+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: waiting: Set(ShuffleMapStage 104, ResultStage 105)
[2025-05-07T02:44:42.128+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:42.128+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[312] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:42.129+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 13.5 KiB, free 417.9 MiB)
[2025-05-07T02:44:42.134+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.9 MiB)
[2025-05-07T02:44:42.135+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 5c5d1775d94e:37761 (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T02:44:42.135+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:42.135+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[312] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:42.135+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Adding task set 104.0 with 10 tasks resource profile 0
[2025-05-07T02:44:42.136+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 245) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.144+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.20.0.5:40657 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.149+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:52776
[2025-05-07T02:44:42.155+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.162+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 246) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.162+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 245) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:42.171+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.186+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 247) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.187+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 246) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:42.195+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.201+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 248) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.201+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 247) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:42.210+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 4.0 in stage 104.0 (TID 249) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 248) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:42.220+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.226+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 5.0 in stage 104.0 (TID 250) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.227+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 4.0 in stage 104.0 (TID 249) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:42.233+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.238+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 6.0 in stage 104.0 (TID 251) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.238+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 5.0 in stage 104.0 (TID 250) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:42.245+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.250+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 7.0 in stage 104.0 (TID 252) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.250+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 6.0 in stage 104.0 (TID 251) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:42.257+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.264+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 8.0 in stage 104.0 (TID 253) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.264+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 7.0 in stage 104.0 (TID 252) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:42.272+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.279+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 9.0 in stage 104.0 (TID 254) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.279+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 8.0 in stage 104.0 (TID 253) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:42.290+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_308_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.297+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 9.0 in stage 104.0 (TID 254) in 19 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:42.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool
[2025-05-07T02:44:42.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: ShuffleMapStage 104 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.170 s
[2025-05-07T02:44:42.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:42.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:42.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: waiting: Set(ResultStage 105)
[2025-05-07T02:44:42.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:42.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting ResultStage 105 (EdgeRDDImpl[315] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:42.304+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 164.1 KiB, free 417.7 MiB)
[2025-05-07T02:44:42.317+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 5c5d1775d94e:37761 in memory (size: 58.3 KiB, free: 433.6 MiB)
[2025-05-07T02:44:42.318+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.9 MiB)
[2025-05-07T02:44:42.318+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 5c5d1775d94e:37761 (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:42.318+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:42.318+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 105 (EdgeRDDImpl[315] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:42.318+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Adding task set 105.0 with 10 tasks resource profile 0
[2025-05-07T02:44:42.319+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 255) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.335+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.20.0.5:40657 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.339+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.20.0.5:40657 (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.348+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:52776
[2025-05-07T02:44:42.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.355+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 256) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.356+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 255) in 37 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:42.377+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.380+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 257) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.380+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 256) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:42.389+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.393+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 258) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.394+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 257) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:42.404+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.407+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 4.0 in stage 105.0 (TID 259) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.408+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 258) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:42.417+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.419+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 5.0 in stage 105.0 (TID 260) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.419+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 4.0 in stage 105.0 (TID 259) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:42.429+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.431+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 6.0 in stage 105.0 (TID 261) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.431+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 5.0 in stage 105.0 (TID 260) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:42.439+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.443+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 7.0 in stage 105.0 (TID 262) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.443+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 6.0 in stage 105.0 (TID 261) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:42.452+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.454+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 8.0 in stage 105.0 (TID 263) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.454+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 7.0 in stage 105.0 (TID 262) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:42.465+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.467+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 9.0 in stage 105.0 (TID 264) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.468+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 8.0 in stage 105.0 (TID 263) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:42.477+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_314_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.480+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 9.0 in stage 105.0 (TID 264) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:42.480+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool
[2025-05-07T02:44:42.480+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: ResultStage 105 (foreachPartition at PageRank.scala:199) finished in 0.180 s
[2025-05-07T02:44:42.480+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:42.480+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
[2025-05-07T02:44:42.480+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Job 38 finished: foreachPartition at PageRank.scala:199, took 0.484008 s
[2025-05-07T02:44:42.480+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO PageRank: PageRank finished iteration 2.
[2025-05-07T02:44:42.481+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO ZippedPartitionsRDD2: Removing RDD 296 from persistence list
[2025-05-07T02:44:42.481+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManager: Removing RDD 296
[2025-05-07T02:44:42.481+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO ZippedPartitionsRDD2: Removing RDD 302 from persistence list
[2025-05-07T02:44:42.482+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManager: Removing RDD 302
[2025-05-07T02:44:42.494+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:42.496+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Registering RDD 316 (mapPartitions at GraphImpl.scala:208) as input to shuffle 39
[2025-05-07T02:44:42.496+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Registering RDD 324 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 38
[2025-05-07T02:44:42.496+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Got job 39 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:42.496+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Final stage: ResultStage 120 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:42.496+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 115, ShuffleMapStage 119, ShuffleMapStage 111, ShuffleMapStage 106, ShuffleMapStage 113, ShuffleMapStage 110)
[2025-05-07T02:44:42.496+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
[2025-05-07T02:44:42.497+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[316] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:42.502+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 164.6 KiB, free 417.7 MiB)
[2025-05-07T02:44:42.515+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 5c5d1775d94e:37761 in memory (size: 58.0 KiB, free: 433.6 MiB)
[2025-05-07T02:44:42.516+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.7 MiB)
[2025-05-07T02:44:42.516+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 5c5d1775d94e:37761 (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:42.516+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:42.516+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[316] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:42.516+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Adding task set 118.0 with 10 tasks resource profile 0
[2025-05-07T02:44:42.517+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.20.0.5:40657 in memory (size: 58.0 KiB, free: 433.0 MiB)
[2025-05-07T02:44:42.517+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 265) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.519+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 5c5d1775d94e:37761 in memory (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T02:44:42.520+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.20.0.5:40657 in memory (size: 6.1 KiB, free: 433.0 MiB)
[2025-05-07T02:44:42.527+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.20.0.5:40657 (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.534+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 266) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.534+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 265) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:42.545+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 267) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.546+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 266) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:42.553+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 268) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.553+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 267) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:42.569+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 269) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.569+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 268) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:42.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 270) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 269) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:42.587+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 271) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.588+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 270) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:42.597+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 272) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.597+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 271) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:42.610+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 8.0 in stage 118.0 (TID 273) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.610+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 272) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:42.618+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 9.0 in stage 118.0 (TID 274) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.618+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 8.0 in stage 118.0 (TID 273) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:42.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 9.0 in stage 118.0 (TID 274) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:42.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-05-07T02:44:42.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: ShuffleMapStage 118 (mapPartitions at GraphImpl.scala:208) finished in 0.138 s
[2025-05-07T02:44:42.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:42.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:42.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: waiting: Set(ShuffleMapStage 119, ResultStage 120)
[2025-05-07T02:44:42.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:42.636+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[324] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:42.637+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 14.2 KiB, free 417.9 MiB)
[2025-05-07T02:44:42.649+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.9 MiB)
[2025-05-07T02:44:42.649+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 5c5d1775d94e:37761 (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T02:44:42.649+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:42.649+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[324] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:42.649+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Adding task set 119.0 with 10 tasks resource profile 0
[2025-05-07T02:44:42.650+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 275) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.655+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.20.0.5:40657 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.660+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:52776
[2025-05-07T02:44:42.663+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.667+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 276) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.668+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 275) in 18 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:42.680+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.685+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 277) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.685+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 276) in 17 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:42.693+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.706+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 278) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.707+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 277) in 22 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:42.715+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.720+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 4.0 in stage 119.0 (TID 279) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.720+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 278) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:42.730+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 5.0 in stage 119.0 (TID 280) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 4.0 in stage 119.0 (TID 279) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:42.741+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.747+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 6.0 in stage 119.0 (TID 281) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.747+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 5.0 in stage 119.0 (TID 280) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:42.753+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 7.0 in stage 119.0 (TID 282) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 6.0 in stage 119.0 (TID 281) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:42.766+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.773+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 8.0 in stage 119.0 (TID 283) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.774+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 7.0 in stage 119.0 (TID 282) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:42.781+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.785+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 9.0 in stage 119.0 (TID 284) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.785+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 8.0 in stage 119.0 (TID 283) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:42.793+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_320_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:42.796+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 9.0 in stage 119.0 (TID 284) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:42.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-05-07T02:44:42.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: ShuffleMapStage 119 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.161 s
[2025-05-07T02:44:42.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:42.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:42.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: waiting: Set(ResultStage 120)
[2025-05-07T02:44:42.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:42.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting ResultStage 120 (EdgeRDDImpl[327] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:42.802+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 164.4 KiB, free 417.7 MiB)
[2025-05-07T02:44:42.803+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 57.9 KiB, free 417.7 MiB)
[2025-05-07T02:44:42.803+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 5c5d1775d94e:37761 (size: 57.9 KiB, free: 433.4 MiB)
[2025-05-07T02:44:42.803+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:42.803+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 120 (EdgeRDDImpl[327] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:42.804+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Adding task set 120.0 with 10 tasks resource profile 0
[2025-05-07T02:44:42.804+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 285) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.811+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.20.0.5:40657 (size: 57.9 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.818+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:52776
[2025-05-07T02:44:42.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.824+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 286) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.825+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 285) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:42.834+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.836+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 287) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.837+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 286) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:42.847+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.849+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 288) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.850+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 287) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:42.860+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.862+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 4.0 in stage 120.0 (TID 289) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.862+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 288) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:42.870+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.872+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 5.0 in stage 120.0 (TID 290) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.872+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 4.0 in stage 120.0 (TID 289) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:42.882+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.884+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 6.0 in stage 120.0 (TID 291) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.884+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 5.0 in stage 120.0 (TID 290) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:42.897+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.899+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 7.0 in stage 120.0 (TID 292) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.899+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 6.0 in stage 120.0 (TID 291) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:42.910+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.912+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 8.0 in stage 120.0 (TID 293) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.913+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 7.0 in stage 120.0 (TID 292) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:42.930+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.933+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 9.0 in stage 120.0 (TID 294) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.935+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 8.0 in stage 120.0 (TID 293) in 22 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:42.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added rdd_326_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:42.962+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Finished task 9.0 in stage 120.0 (TID 294) in 29 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:42.962+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool
[2025-05-07T02:44:42.962+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: ResultStage 120 (foreachPartition at PageRank.scala:199) finished in 0.164 s
[2025-05-07T02:44:42.962+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:42.962+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished
[2025-05-07T02:44:42.963+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Job 39 finished: foreachPartition at PageRank.scala:199, took 0.468677 s
[2025-05-07T02:44:42.963+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO PageRank: PageRank finished iteration 3.
[2025-05-07T02:44:42.963+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO ZippedPartitionsRDD2: Removing RDD 308 from persistence list
[2025-05-07T02:44:42.964+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManager: Removing RDD 308
[2025-05-07T02:44:42.964+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO ZippedPartitionsRDD2: Removing RDD 314 from persistence list
[2025-05-07T02:44:42.965+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManager: Removing RDD 314
[2025-05-07T02:44:42.978+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:42.980+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Registering RDD 328 (mapPartitions at GraphImpl.scala:208) as input to shuffle 41
[2025-05-07T02:44:42.980+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Registering RDD 336 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 40
[2025-05-07T02:44:42.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Got job 40 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:42.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Final stage: ResultStage 137 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:42.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132, ShuffleMapStage 121, ShuffleMapStage 136, ShuffleMapStage 125, ShuffleMapStage 126, ShuffleMapStage 130, ShuffleMapStage 134, ShuffleMapStage 128)
[2025-05-07T02:44:42.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
[2025-05-07T02:44:42.982+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[328] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:42.986+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 164.9 KiB, free 417.5 MiB)
[2025-05-07T02:44:42.988+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.5 MiB)
[2025-05-07T02:44:42.989+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 5c5d1775d94e:37761 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:42.989+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:42.989+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[328] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:42.989+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSchedulerImpl: Adding task set 135.0 with 10 tasks resource profile 0
[2025-05-07T02:44:42.990+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 295) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:42.995+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:42 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.20.0.5:40657 (size: 58.3 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.002+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 296) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.002+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 295) in 12 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:43.011+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 297) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.012+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 296) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:43.019+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 298) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.019+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 297) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:43.028+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 4.0 in stage 135.0 (TID 299) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.028+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 298) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:43.037+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 5.0 in stage 135.0 (TID 300) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.038+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 4.0 in stage 135.0 (TID 299) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:43.048+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 6.0 in stage 135.0 (TID 301) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.048+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 5.0 in stage 135.0 (TID 300) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:43.059+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 7.0 in stage 135.0 (TID 302) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.060+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 6.0 in stage 135.0 (TID 301) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:43.072+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 8.0 in stage 135.0 (TID 303) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.073+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 7.0 in stage 135.0 (TID 302) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:43.087+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 9.0 in stage 135.0 (TID 304) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.088+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 8.0 in stage 135.0 (TID 303) in 17 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:43.101+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 9.0 in stage 135.0 (TID 304) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:43.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool
[2025-05-07T02:44:43.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: ShuffleMapStage 135 (mapPartitions at GraphImpl.scala:208) finished in 0.120 s
[2025-05-07T02:44:43.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:43.103+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:43.103+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 136, ResultStage 137)
[2025-05-07T02:44:43.103+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:43.103+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[336] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:43.106+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 14.9 KiB, free 417.4 MiB)
[2025-05-07T02:44:43.113+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 417.4 MiB)
[2025-05-07T02:44:43.114+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 5c5d1775d94e:37761 (size: 6.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.114+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 5c5d1775d94e:37761 in memory (size: 57.9 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.114+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:43.114+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[336] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:43.114+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Adding task set 136.0 with 10 tasks resource profile 0
[2025-05-07T02:44:43.115+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.20.0.5:40657 in memory (size: 57.9 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.116+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 305) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.118+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 5c5d1775d94e:37761 in memory (size: 6.1 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.118+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.20.0.5:40657 in memory (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.122+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 5c5d1775d94e:37761 in memory (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:43.123+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.20.0.5:40657 in memory (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.125+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.20.0.5:40657 (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.129+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:52776
[2025-05-07T02:44:43.134+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.141+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 306) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.141+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 305) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:43.150+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.157+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 2.0 in stage 136.0 (TID 307) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.157+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 306) in 17 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:43.173+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.177+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 3.0 in stage 136.0 (TID 308) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.177+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 2.0 in stage 136.0 (TID 307) in 21 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:43.183+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.187+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 4.0 in stage 136.0 (TID 309) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.188+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 3.0 in stage 136.0 (TID 308) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:43.193+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.197+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 5.0 in stage 136.0 (TID 310) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.197+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 4.0 in stage 136.0 (TID 309) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:43.201+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.208+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 6.0 in stage 136.0 (TID 311) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.209+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 5.0 in stage 136.0 (TID 310) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:43.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.217+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 7.0 in stage 136.0 (TID 312) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.218+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 6.0 in stage 136.0 (TID 311) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:43.224+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.236+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 8.0 in stage 136.0 (TID 313) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.236+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 7.0 in stage 136.0 (TID 312) in 19 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:43.243+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.247+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 9.0 in stage 136.0 (TID 314) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.247+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 8.0 in stage 136.0 (TID 313) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:43.252+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_332_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.257+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 9.0 in stage 136.0 (TID 314) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:43.257+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-05-07T02:44:43.257+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: ShuffleMapStage 136 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.153 s
[2025-05-07T02:44:43.258+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:43.258+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:43.258+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: waiting: Set(ResultStage 137)
[2025-05-07T02:44:43.258+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:43.258+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting ResultStage 137 (EdgeRDDImpl[339] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:43.262+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 164.7 KiB, free 417.7 MiB)
[2025-05-07T02:44:43.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-07T02:44:43.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 5c5d1775d94e:37761 (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:43.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 137 (EdgeRDDImpl[339] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:43.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Adding task set 137.0 with 10 tasks resource profile 0
[2025-05-07T02:44:43.264+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 315) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.268+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.20.0.5:40657 (size: 58.1 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.275+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:52776
[2025-05-07T02:44:43.278+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.280+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 316) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.280+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 315) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:43.288+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.290+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 2.0 in stage 137.0 (TID 317) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.291+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 316) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:43.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.300+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 3.0 in stage 137.0 (TID 318) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.300+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 2.0 in stage 137.0 (TID 317) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:43.308+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.309+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 4.0 in stage 137.0 (TID 319) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.310+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 3.0 in stage 137.0 (TID 318) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:43.317+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.319+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 5.0 in stage 137.0 (TID 320) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.320+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 4.0 in stage 137.0 (TID 319) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:43.332+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.334+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 6.0 in stage 137.0 (TID 321) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.334+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 5.0 in stage 137.0 (TID 320) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:43.344+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.346+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 7.0 in stage 137.0 (TID 322) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.347+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 6.0 in stage 137.0 (TID 321) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:43.355+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.358+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 8.0 in stage 137.0 (TID 323) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.358+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 7.0 in stage 137.0 (TID 322) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:43.365+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.367+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 9.0 in stage 137.0 (TID 324) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.367+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 8.0 in stage 137.0 (TID 323) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:43.375+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_338_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.377+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 9.0 in stage 137.0 (TID 324) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:43.377+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool
[2025-05-07T02:44:43.377+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: ResultStage 137 (foreachPartition at PageRank.scala:199) finished in 0.119 s
[2025-05-07T02:44:43.377+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:43.377+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
[2025-05-07T02:44:43.378+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Job 40 finished: foreachPartition at PageRank.scala:199, took 0.399324 s
[2025-05-07T02:44:43.378+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO PageRank: PageRank finished iteration 4.
[2025-05-07T02:44:43.378+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO ZippedPartitionsRDD2: Removing RDD 320 from persistence list
[2025-05-07T02:44:43.378+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManager: Removing RDD 320
[2025-05-07T02:44:43.379+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO ZippedPartitionsRDD2: Removing RDD 326 from persistence list
[2025-05-07T02:44:43.379+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManager: Removing RDD 326
[2025-05-07T02:44:43.388+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:43.391+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Registering RDD 340 (mapPartitions at GraphImpl.scala:208) as input to shuffle 43
[2025-05-07T02:44:43.391+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Registering RDD 348 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 42
[2025-05-07T02:44:43.391+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Got job 41 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:43.391+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Final stage: ResultStage 156 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:43.391+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143, ShuffleMapStage 153, ShuffleMapStage 147, ShuffleMapStage 151, ShuffleMapStage 155, ShuffleMapStage 138, ShuffleMapStage 145, ShuffleMapStage 142, ShuffleMapStage 149)
[2025-05-07T02:44:43.392+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 155)
[2025-05-07T02:44:43.392+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[340] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:43.395+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 165.2 KiB, free 417.5 MiB)
[2025-05-07T02:44:43.396+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.4 MiB)
[2025-05-07T02:44:43.397+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 5c5d1775d94e:37761 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.397+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:43.397+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[340] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:43.397+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Adding task set 154.0 with 10 tasks resource profile 0
[2025-05-07T02:44:43.398+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 325) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.402+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.20.0.5:40657 (size: 58.3 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.410+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 326) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.410+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 325) in 12 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:43.417+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 327) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.417+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 326) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:43.425+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 328) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.426+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 327) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:43.432+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 329) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.433+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 328) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:43.443+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 5.0 in stage 154.0 (TID 330) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.444+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 329) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:43.451+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 6.0 in stage 154.0 (TID 331) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.451+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 5.0 in stage 154.0 (TID 330) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:43.460+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 7.0 in stage 154.0 (TID 332) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.460+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 6.0 in stage 154.0 (TID 331) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:43.477+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 8.0 in stage 154.0 (TID 333) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.478+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 7.0 in stage 154.0 (TID 332) in 19 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:43.485+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 9.0 in stage 154.0 (TID 334) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.485+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 8.0 in stage 154.0 (TID 333) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:43.494+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 9.0 in stage 154.0 (TID 334) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:43.495+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool
[2025-05-07T02:44:43.495+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: ShuffleMapStage 154 (mapPartitions at GraphImpl.scala:208) finished in 0.103 s
[2025-05-07T02:44:43.495+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:43.495+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:43.495+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 155, ResultStage 156)
[2025-05-07T02:44:43.495+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:43.495+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[348] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:43.497+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 15.6 KiB, free 417.4 MiB)
[2025-05-07T02:44:43.510+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 417.4 MiB)
[2025-05-07T02:44:43.510+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 5c5d1775d94e:37761 (size: 6.4 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.511+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 5c5d1775d94e:37761 in memory (size: 6.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:43.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[348] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:43.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Adding task set 155.0 with 10 tasks resource profile 0
[2025-05-07T02:44:43.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.20.0.5:40657 in memory (size: 6.3 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.513+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 335) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.515+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 5c5d1775d94e:37761 in memory (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.516+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.20.0.5:40657 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.518+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 5c5d1775d94e:37761 in memory (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-07T02:44:43.519+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.20.0.5:40657 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.520+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.20.0.5:40657 (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.525+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:52776
[2025-05-07T02:44:43.529+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.532+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 336) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.533+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 335) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:43.542+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.556+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 337) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.558+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 336) in 24 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:43.565+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.581+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 338) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.581+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 337) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:43.588+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.594+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 4.0 in stage 155.0 (TID 339) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.594+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 338) in 24 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:43.599+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.605+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 5.0 in stage 155.0 (TID 340) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.605+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 4.0 in stage 155.0 (TID 339) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:43.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.614+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 6.0 in stage 155.0 (TID 341) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.615+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 5.0 in stage 155.0 (TID 340) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:43.621+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.625+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 7.0 in stage 155.0 (TID 342) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.625+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 6.0 in stage 155.0 (TID 341) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:43.630+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.634+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 8.0 in stage 155.0 (TID 343) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 7.0 in stage 155.0 (TID 342) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:43.640+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 9.0 in stage 155.0 (TID 344) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 8.0 in stage 155.0 (TID 343) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:43.649+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_344_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.655+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 9.0 in stage 155.0 (TID 344) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:43.655+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool
[2025-05-07T02:44:43.655+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: ShuffleMapStage 155 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.159 s
[2025-05-07T02:44:43.655+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:43.656+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:43.656+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: waiting: Set(ResultStage 156)
[2025-05-07T02:44:43.656+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:43.656+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting ResultStage 156 (EdgeRDDImpl[351] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:43.659+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 165.0 KiB, free 417.7 MiB)
[2025-05-07T02:44:43.660+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.7 MiB)
[2025-05-07T02:44:43.660+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 5c5d1775d94e:37761 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.661+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:43.661+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 156 (EdgeRDDImpl[351] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:43.661+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Adding task set 156.0 with 10 tasks resource profile 0
[2025-05-07T02:44:43.662+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 345) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.20.0.5:40657 (size: 58.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.673+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:52776
[2025-05-07T02:44:43.676+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.678+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 346) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.678+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 345) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:43.688+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.690+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 347) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.690+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 346) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:43.698+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.701+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 348) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.701+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 347) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:43.711+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.713+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 4.0 in stage 156.0 (TID 349) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.714+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 348) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:43.727+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.729+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 5.0 in stage 156.0 (TID 350) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.730+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 4.0 in stage 156.0 (TID 349) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:43.739+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.742+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 6.0 in stage 156.0 (TID 351) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.742+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 5.0 in stage 156.0 (TID 350) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:43.759+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.762+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 7.0 in stage 156.0 (TID 352) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.762+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 6.0 in stage 156.0 (TID 351) in 21 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:43.774+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.775+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 8.0 in stage 156.0 (TID 353) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.776+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 7.0 in stage 156.0 (TID 352) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:43.783+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.787+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 9.0 in stage 156.0 (TID 354) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.787+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 8.0 in stage 156.0 (TID 353) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:43.795+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_350_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 9.0 in stage 156.0 (TID 354) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:43.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool
[2025-05-07T02:44:43.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: ResultStage 156 (foreachPartition at PageRank.scala:199) finished in 0.141 s
[2025-05-07T02:44:43.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:43.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished
[2025-05-07T02:44:43.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Job 41 finished: foreachPartition at PageRank.scala:199, took 0.409560 s
[2025-05-07T02:44:43.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO PageRank: PageRank finished iteration 5.
[2025-05-07T02:44:43.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO ZippedPartitionsRDD2: Removing RDD 332 from persistence list
[2025-05-07T02:44:43.799+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManager: Removing RDD 332
[2025-05-07T02:44:43.799+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO ZippedPartitionsRDD2: Removing RDD 338 from persistence list
[2025-05-07T02:44:43.799+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManager: Removing RDD 338
[2025-05-07T02:44:43.811+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:43.813+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Registering RDD 352 (mapPartitions at GraphImpl.scala:208) as input to shuffle 45
[2025-05-07T02:44:43.813+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Registering RDD 360 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 44
[2025-05-07T02:44:43.814+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Got job 42 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:43.814+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Final stage: ResultStage 177 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:43.814+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 161, ShuffleMapStage 168, ShuffleMapStage 157, ShuffleMapStage 172, ShuffleMapStage 166, ShuffleMapStage 176, ShuffleMapStage 170, ShuffleMapStage 162, ShuffleMapStage 174, ShuffleMapStage 164)
[2025-05-07T02:44:43.814+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 176)
[2025-05-07T02:44:43.814+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[352] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:43.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 165.5 KiB, free 417.5 MiB)
[2025-05-07T02:44:43.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 417.4 MiB)
[2025-05-07T02:44:43.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 5c5d1775d94e:37761 (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:43.822+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[352] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:43.822+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Adding task set 175.0 with 10 tasks resource profile 0
[2025-05-07T02:44:43.823+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 355) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.827+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.20.0.5:40657 (size: 58.4 KiB, free: 432.8 MiB)
[2025-05-07T02:44:43.837+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 1.0 in stage 175.0 (TID 356) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.837+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 355) in 15 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:43.848+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 2.0 in stage 175.0 (TID 357) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.848+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 1.0 in stage 175.0 (TID 356) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:43.860+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 3.0 in stage 175.0 (TID 358) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.860+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 2.0 in stage 175.0 (TID 357) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:43.875+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 4.0 in stage 175.0 (TID 359) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.876+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 3.0 in stage 175.0 (TID 358) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:43.886+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 5.0 in stage 175.0 (TID 360) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.886+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 4.0 in stage 175.0 (TID 359) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:43.893+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 6.0 in stage 175.0 (TID 361) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.894+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 5.0 in stage 175.0 (TID 360) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:43.900+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 7.0 in stage 175.0 (TID 362) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.901+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 6.0 in stage 175.0 (TID 361) in 7 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:43.908+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 8.0 in stage 175.0 (TID 363) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.909+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 7.0 in stage 175.0 (TID 362) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:43.915+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 9.0 in stage 175.0 (TID 364) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.915+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 8.0 in stage 175.0 (TID 363) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:43.926+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 9.0 in stage 175.0 (TID 364) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:43.926+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool
[2025-05-07T02:44:43.926+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: ShuffleMapStage 175 (mapPartitions at GraphImpl.scala:208) finished in 0.111 s
[2025-05-07T02:44:43.927+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:43.927+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:43.927+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 176, ResultStage 177)
[2025-05-07T02:44:43.927+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:43.927+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[360] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:43.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 16.4 KiB, free 417.4 MiB)
[2025-05-07T02:44:43.936+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 417.4 MiB)
[2025-05-07T02:44:43.937+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 5c5d1775d94e:37761 (size: 6.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.937+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:43.939+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[360] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:43.939+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSchedulerImpl: Adding task set 176.0 with 10 tasks resource profile 0
[2025-05-07T02:44:43.940+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 365) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.940+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 5c5d1775d94e:37761 in memory (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T02:44:43.941+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.20.0.5:40657 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.944+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 5c5d1775d94e:37761 in memory (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-07T02:44:43.945+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.20.0.5:40657 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.949+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 5c5d1775d94e:37761 in memory (size: 6.4 KiB, free: 433.5 MiB)
[2025-05-07T02:44:43.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.20.0.5:40657 in memory (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.952+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.20.0.5:40657 (size: 6.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.957+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:52776
[2025-05-07T02:44:43.963+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_356_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.969+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 1.0 in stage 176.0 (TID 366) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.970+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 365) in 31 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:43.989+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO BlockManagerInfo: Added rdd_356_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:43.993+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Starting task 2.0 in stage 176.0 (TID 367) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:43.993+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:43 INFO TaskSetManager: Finished task 1.0 in stage 176.0 (TID 366) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:44.000+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_356_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.006+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 3.0 in stage 176.0 (TID 368) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.007+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 2.0 in stage 176.0 (TID 367) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:44.013+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_356_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.020+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 4.0 in stage 176.0 (TID 369) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.020+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 3.0 in stage 176.0 (TID 368) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:44.026+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_356_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.029+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 5.0 in stage 176.0 (TID 370) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.030+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 4.0 in stage 176.0 (TID 369) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:44.035+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_356_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 6.0 in stage 176.0 (TID 371) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 5.0 in stage 176.0 (TID 370) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:44.053+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_356_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.057+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 7.0 in stage 176.0 (TID 372) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.058+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 6.0 in stage 176.0 (TID 371) in 18 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:44.063+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_356_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 8.0 in stage 176.0 (TID 373) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 7.0 in stage 176.0 (TID 372) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:44.074+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_356_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.078+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 9.0 in stage 176.0 (TID 374) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.078+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 8.0 in stage 176.0 (TID 373) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:44.083+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_356_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.088+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 9.0 in stage 176.0 (TID 374) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:44.088+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool
[2025-05-07T02:44:44.089+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: ShuffleMapStage 176 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.161 s
[2025-05-07T02:44:44.089+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:44.089+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:44.089+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: waiting: Set(ResultStage 177)
[2025-05-07T02:44:44.089+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:44.089+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting ResultStage 177 (EdgeRDDImpl[363] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:44.093+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 165.3 KiB, free 417.7 MiB)
[2025-05-07T02:44:44.094+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.7 MiB)
[2025-05-07T02:44:44.094+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 5c5d1775d94e:37761 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.094+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:44.094+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 177 (EdgeRDDImpl[363] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:44.095+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Adding task set 177.0 with 10 tasks resource profile 0
[2025-05-07T02:44:44.095+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 375) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.099+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.20.0.5:40657 (size: 58.3 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.106+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:52776
[2025-05-07T02:44:44.109+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.111+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 376) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.112+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 375) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:44.121+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.123+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 2.0 in stage 177.0 (TID 377) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.123+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 376) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:44.131+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.133+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 3.0 in stage 177.0 (TID 378) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.134+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 2.0 in stage 177.0 (TID 377) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:44.144+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.146+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 4.0 in stage 177.0 (TID 379) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.147+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 3.0 in stage 177.0 (TID 378) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:44.156+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.158+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 5.0 in stage 177.0 (TID 380) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.158+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 4.0 in stage 177.0 (TID 379) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:44.166+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.168+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 6.0 in stage 177.0 (TID 381) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.168+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 5.0 in stage 177.0 (TID 380) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:44.177+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.179+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 7.0 in stage 177.0 (TID 382) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.179+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 6.0 in stage 177.0 (TID 381) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:44.188+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.190+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 8.0 in stage 177.0 (TID 383) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.191+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 7.0 in stage 177.0 (TID 382) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:44.200+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.203+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 9.0 in stage 177.0 (TID 384) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.203+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 8.0 in stage 177.0 (TID 383) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:44.213+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_362_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 9.0 in stage 177.0 (TID 384) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:44.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool
[2025-05-07T02:44:44.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: ResultStage 177 (foreachPartition at PageRank.scala:199) finished in 0.126 s
[2025-05-07T02:44:44.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:44.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished
[2025-05-07T02:44:44.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Job 42 finished: foreachPartition at PageRank.scala:199, took 0.404899 s
[2025-05-07T02:44:44.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO PageRank: PageRank finished iteration 6.
[2025-05-07T02:44:44.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO ZippedPartitionsRDD2: Removing RDD 344 from persistence list
[2025-05-07T02:44:44.217+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManager: Removing RDD 344
[2025-05-07T02:44:44.217+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO ZippedPartitionsRDD2: Removing RDD 350 from persistence list
[2025-05-07T02:44:44.217+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManager: Removing RDD 350
[2025-05-07T02:44:44.228+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:44.231+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Registering RDD 364 (mapPartitions at GraphImpl.scala:208) as input to shuffle 47
[2025-05-07T02:44:44.231+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Registering RDD 372 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 46
[2025-05-07T02:44:44.232+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Got job 43 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:44.232+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Final stage: ResultStage 200 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:44.232+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 197, ShuffleMapStage 183, ShuffleMapStage 187, ShuffleMapStage 191, ShuffleMapStage 195, ShuffleMapStage 189, ShuffleMapStage 199, ShuffleMapStage 178, ShuffleMapStage 193, ShuffleMapStage 185, ShuffleMapStage 182)
[2025-05-07T02:44:44.232+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 199)
[2025-05-07T02:44:44.233+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[364] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:44.237+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 165.8 KiB, free 417.5 MiB)
[2025-05-07T02:44:44.239+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 58.6 KiB, free 417.4 MiB)
[2025-05-07T02:44:44.239+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 5c5d1775d94e:37761 (size: 58.6 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.240+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:44.240+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[364] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:44.240+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Adding task set 198.0 with 10 tasks resource profile 0
[2025-05-07T02:44:44.241+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 385) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.245+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.20.0.5:40657 (size: 58.6 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.256+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 1.0 in stage 198.0 (TID 386) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.256+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 385) in 15 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:44.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 2.0 in stage 198.0 (TID 387) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.264+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 1.0 in stage 198.0 (TID 386) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:44.274+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 3.0 in stage 198.0 (TID 388) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.274+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 2.0 in stage 198.0 (TID 387) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:44.282+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 4.0 in stage 198.0 (TID 389) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.283+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 3.0 in stage 198.0 (TID 388) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:44.292+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 5.0 in stage 198.0 (TID 390) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.292+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 4.0 in stage 198.0 (TID 389) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:44.309+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 6.0 in stage 198.0 (TID 391) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.309+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 5.0 in stage 198.0 (TID 390) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:44.317+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 7.0 in stage 198.0 (TID 392) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.317+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 6.0 in stage 198.0 (TID 391) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:44.326+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 8.0 in stage 198.0 (TID 393) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.327+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 7.0 in stage 198.0 (TID 392) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:44.333+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 9.0 in stage 198.0 (TID 394) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.334+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 8.0 in stage 198.0 (TID 393) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:44.342+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 9.0 in stage 198.0 (TID 394) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:44.343+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool
[2025-05-07T02:44:44.343+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: ShuffleMapStage 198 (mapPartitions at GraphImpl.scala:208) finished in 0.109 s
[2025-05-07T02:44:44.343+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:44.343+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:44.343+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 199, ResultStage 200)
[2025-05-07T02:44:44.343+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:44.343+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[372] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:44.344+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 17.1 KiB, free 417.4 MiB)
[2025-05-07T02:44:44.351+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.4 MiB)
[2025-05-07T02:44:44.351+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 5c5d1775d94e:37761 (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 5c5d1775d94e:37761 in memory (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:44.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[372] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:44.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Adding task set 199.0 with 10 tasks resource profile 0
[2025-05-07T02:44:44.353+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 395) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.353+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.20.0.5:40657 in memory (size: 58.4 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.357+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 5c5d1775d94e:37761 in memory (size: 6.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.359+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.20.0.5:40657 in memory (size: 6.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.20.0.5:40657 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 5c5d1775d94e:37761 in memory (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-07T02:44:44.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.20.0.5:40657 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.365+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:52776
[2025-05-07T02:44:44.369+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.374+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 1.0 in stage 199.0 (TID 396) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.374+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 395) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:44.380+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.388+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 2.0 in stage 199.0 (TID 397) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.389+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 1.0 in stage 199.0 (TID 396) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:44.402+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.408+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 3.0 in stage 199.0 (TID 398) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.408+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 2.0 in stage 199.0 (TID 397) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:44.414+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.417+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 4.0 in stage 199.0 (TID 399) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.417+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 3.0 in stage 199.0 (TID 398) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:44.423+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.427+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 5.0 in stage 199.0 (TID 400) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.428+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 4.0 in stage 199.0 (TID 399) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:44.433+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.437+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 6.0 in stage 199.0 (TID 401) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.438+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 5.0 in stage 199.0 (TID 400) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:44.444+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.448+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 7.0 in stage 199.0 (TID 402) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.448+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 6.0 in stage 199.0 (TID 401) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:44.454+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.459+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 8.0 in stage 199.0 (TID 403) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.459+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 7.0 in stage 199.0 (TID 402) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:44.464+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.468+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 9.0 in stage 199.0 (TID 404) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.468+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 8.0 in stage 199.0 (TID 403) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:44.475+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_368_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.478+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 9.0 in stage 199.0 (TID 404) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:44.478+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool
[2025-05-07T02:44:44.478+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: ShuffleMapStage 199 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.135 s
[2025-05-07T02:44:44.478+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:44.478+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:44.479+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: waiting: Set(ResultStage 200)
[2025-05-07T02:44:44.479+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:44.479+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting ResultStage 200 (EdgeRDDImpl[375] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:44.484+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 165.6 KiB, free 417.7 MiB)
[2025-05-07T02:44:44.486+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.7 MiB)
[2025-05-07T02:44:44.486+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 5c5d1775d94e:37761 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.486+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:44.487+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 200 (EdgeRDDImpl[375] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:44.487+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Adding task set 200.0 with 10 tasks resource profile 0
[2025-05-07T02:44:44.489+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 405) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.496+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.20.0.5:40657 (size: 58.3 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.503+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:52776
[2025-05-07T02:44:44.507+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.510+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 406) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.510+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 405) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:44.519+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.522+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 2.0 in stage 200.0 (TID 407) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.523+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 406) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:44.534+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.537+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 3.0 in stage 200.0 (TID 408) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.537+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 2.0 in stage 200.0 (TID 407) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:44.548+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.550+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 4.0 in stage 200.0 (TID 409) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.550+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 3.0 in stage 200.0 (TID 408) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:44.569+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.572+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 5.0 in stage 200.0 (TID 410) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.573+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 4.0 in stage 200.0 (TID 409) in 23 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:44.581+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.583+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 6.0 in stage 200.0 (TID 411) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.584+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 5.0 in stage 200.0 (TID 410) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:44.592+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.595+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 7.0 in stage 200.0 (TID 412) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.595+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 6.0 in stage 200.0 (TID 411) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:44.603+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.606+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 8.0 in stage 200.0 (TID 413) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.606+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 7.0 in stage 200.0 (TID 412) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:44.614+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.616+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 9.0 in stage 200.0 (TID 414) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.616+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 8.0 in stage 200.0 (TID 413) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:44.625+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_374_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.627+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 9.0 in stage 200.0 (TID 414) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:44.628+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool
[2025-05-07T02:44:44.628+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: ResultStage 200 (foreachPartition at PageRank.scala:199) finished in 0.149 s
[2025-05-07T02:44:44.628+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:44.628+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished
[2025-05-07T02:44:44.628+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Job 43 finished: foreachPartition at PageRank.scala:199, took 0.400072 s
[2025-05-07T02:44:44.628+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO PageRank: PageRank finished iteration 7.
[2025-05-07T02:44:44.628+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO ZippedPartitionsRDD2: Removing RDD 356 from persistence list
[2025-05-07T02:44:44.629+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManager: Removing RDD 356
[2025-05-07T02:44:44.629+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO ZippedPartitionsRDD2: Removing RDD 362 from persistence list
[2025-05-07T02:44:44.630+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManager: Removing RDD 362
[2025-05-07T02:44:44.641+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:44.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Registering RDD 376 (mapPartitions at GraphImpl.scala:208) as input to shuffle 49
[2025-05-07T02:44:44.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Registering RDD 384 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 48
[2025-05-07T02:44:44.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Got job 44 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:44.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Final stage: ResultStage 225 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:44.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 212, ShuffleMapStage 222, ShuffleMapStage 201, ShuffleMapStage 216, ShuffleMapStage 208, ShuffleMapStage 205, ShuffleMapStage 220, ShuffleMapStage 224, ShuffleMapStage 206, ShuffleMapStage 210, ShuffleMapStage 214, ShuffleMapStage 218)
[2025-05-07T02:44:44.644+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 224)
[2025-05-07T02:44:44.645+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[376] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:44.650+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 166.0 KiB, free 417.5 MiB)
[2025-05-07T02:44:44.651+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 58.7 KiB, free 417.4 MiB)
[2025-05-07T02:44:44.652+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 5c5d1775d94e:37761 (size: 58.7 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.652+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:44.652+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[376] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:44.652+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Adding task set 223.0 with 10 tasks resource profile 0
[2025-05-07T02:44:44.653+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 415) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.659+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.20.0.5:40657 (size: 58.7 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 1.0 in stage 223.0 (TID 416) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 415) in 13 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:44.677+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 2.0 in stage 223.0 (TID 417) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.678+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 1.0 in stage 223.0 (TID 416) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:44.685+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 3.0 in stage 223.0 (TID 418) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.685+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 2.0 in stage 223.0 (TID 417) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:44.693+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 4.0 in stage 223.0 (TID 419) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.694+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 3.0 in stage 223.0 (TID 418) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:44.701+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 5.0 in stage 223.0 (TID 420) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.701+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 4.0 in stage 223.0 (TID 419) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:44.709+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 6.0 in stage 223.0 (TID 421) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.710+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 5.0 in stage 223.0 (TID 420) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:44.720+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 7.0 in stage 223.0 (TID 422) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.720+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 6.0 in stage 223.0 (TID 421) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:44.731+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 8.0 in stage 223.0 (TID 423) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.732+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 7.0 in stage 223.0 (TID 422) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:44.744+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 9.0 in stage 223.0 (TID 424) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.745+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 8.0 in stage 223.0 (TID 423) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:44.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 9.0 in stage 223.0 (TID 424) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:44.759+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool
[2025-05-07T02:44:44.759+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: ShuffleMapStage 223 (mapPartitions at GraphImpl.scala:208) finished in 0.114 s
[2025-05-07T02:44:44.759+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:44.760+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:44.760+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 224, ResultStage 225)
[2025-05-07T02:44:44.760+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:44.760+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[384] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:44.763+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 17.8 KiB, free 417.4 MiB)
[2025-05-07T02:44:44.778+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.4 MiB)
[2025-05-07T02:44:44.778+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 5c5d1775d94e:37761 (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.779+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 5c5d1775d94e:37761 in memory (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.779+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:44.779+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[384] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:44.779+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Adding task set 224.0 with 10 tasks resource profile 0
[2025-05-07T02:44:44.780+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.20.0.5:40657 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.780+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 425) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.783+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 5c5d1775d94e:37761 in memory (size: 58.6 KiB, free: 433.5 MiB)
[2025-05-07T02:44:44.784+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.20.0.5:40657 in memory (size: 58.6 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.787+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 5c5d1775d94e:37761 in memory (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T02:44:44.787+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.20.0.5:40657 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.788+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.20.0.5:40657 in memory (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.794+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:52776
[2025-05-07T02:44:44.798+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.808+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 1.0 in stage 224.0 (TID 426) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.808+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 425) in 28 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:44.816+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.820+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 2.0 in stage 224.0 (TID 427) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.821+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 1.0 in stage 224.0 (TID 426) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:44.849+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.853+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 3.0 in stage 224.0 (TID 428) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.854+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 2.0 in stage 224.0 (TID 427) in 33 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:44.861+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.865+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 4.0 in stage 224.0 (TID 429) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.866+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 3.0 in stage 224.0 (TID 428) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:44.872+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.876+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 5.0 in stage 224.0 (TID 430) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.876+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 4.0 in stage 224.0 (TID 429) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:44.882+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.885+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 6.0 in stage 224.0 (TID 431) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.885+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 5.0 in stage 224.0 (TID 430) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:44.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.894+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 7.0 in stage 224.0 (TID 432) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.895+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 6.0 in stage 224.0 (TID 431) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:44.900+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.903+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 8.0 in stage 224.0 (TID 433) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.904+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 7.0 in stage 224.0 (TID 432) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:44.910+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.914+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 9.0 in stage 224.0 (TID 434) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.914+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 8.0 in stage 224.0 (TID 433) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:44.919+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_380_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:44.923+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 9.0 in stage 224.0 (TID 434) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:44.923+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool
[2025-05-07T02:44:44.923+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: ShuffleMapStage 224 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.162 s
[2025-05-07T02:44:44.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:44.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:44.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: waiting: Set(ResultStage 225)
[2025-05-07T02:44:44.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:44.924+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting ResultStage 225 (EdgeRDDImpl[387] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:44.927+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 165.8 KiB, free 417.7 MiB)
[2025-05-07T02:44:44.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-07T02:44:44.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 5c5d1775d94e:37761 (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-07T02:44:44.928+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:44.929+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 225 (EdgeRDDImpl[387] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:44.929+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSchedulerImpl: Adding task set 225.0 with 10 tasks resource profile 0
[2025-05-07T02:44:44.929+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 435) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.933+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.20.0.5:40657 (size: 58.1 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.939+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.20.0.5:52776
[2025-05-07T02:44:44.942+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_386_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.944+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 1.0 in stage 225.0 (TID 436) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.944+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 435) in 15 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:44.953+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_386_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.955+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 2.0 in stage 225.0 (TID 437) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.956+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 1.0 in stage 225.0 (TID 436) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:44.963+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_386_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.965+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 3.0 in stage 225.0 (TID 438) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 2.0 in stage 225.0 (TID 437) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:44.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_386_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 4.0 in stage 225.0 (TID 439) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.976+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 3.0 in stage 225.0 (TID 438) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:44.984+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_386_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.985+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 5.0 in stage 225.0 (TID 440) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.986+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 4.0 in stage 225.0 (TID 439) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:44.993+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO BlockManagerInfo: Added rdd_386_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:44.995+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Starting task 6.0 in stage 225.0 (TID 441) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:44.995+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:44 INFO TaskSetManager: Finished task 5.0 in stage 225.0 (TID 440) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:45.002+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_386_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.004+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 7.0 in stage 225.0 (TID 442) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.004+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 6.0 in stage 225.0 (TID 441) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:45.013+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_386_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.015+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 8.0 in stage 225.0 (TID 443) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.015+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 7.0 in stage 225.0 (TID 442) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:45.025+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_386_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.028+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 9.0 in stage 225.0 (TID 444) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.028+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 8.0 in stage 225.0 (TID 443) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:45.037+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_386_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 9.0 in stage 225.0 (TID 444) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:45.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool
[2025-05-07T02:44:45.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: ResultStage 225 (foreachPartition at PageRank.scala:199) finished in 0.116 s
[2025-05-07T02:44:45.041+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:45.041+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished
[2025-05-07T02:44:45.041+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Job 44 finished: foreachPartition at PageRank.scala:199, took 0.399888 s
[2025-05-07T02:44:45.041+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO PageRank: PageRank finished iteration 8.
[2025-05-07T02:44:45.042+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO ZippedPartitionsRDD2: Removing RDD 368 from persistence list
[2025-05-07T02:44:45.042+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManager: Removing RDD 368
[2025-05-07T02:44:45.042+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO ZippedPartitionsRDD2: Removing RDD 374 from persistence list
[2025-05-07T02:44:45.043+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManager: Removing RDD 374
[2025-05-07T02:44:45.056+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T02:44:45.060+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Registering RDD 388 (mapPartitions at GraphImpl.scala:208) as input to shuffle 51
[2025-05-07T02:44:45.060+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Registering RDD 396 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 50
[2025-05-07T02:44:45.061+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Got job 45 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T02:44:45.061+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Final stage: ResultStage 252 (foreachPartition at PageRank.scala:199)
[2025-05-07T02:44:45.061+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 251, ShuffleMapStage 230, ShuffleMapStage 233, ShuffleMapStage 237, ShuffleMapStage 249, ShuffleMapStage 241, ShuffleMapStage 235, ShuffleMapStage 245, ShuffleMapStage 239, ShuffleMapStage 231, ShuffleMapStage 243, ShuffleMapStage 247, ShuffleMapStage 226)
[2025-05-07T02:44:45.061+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 251)
[2025-05-07T02:44:45.062+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[388] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T02:44:45.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 166.3 KiB, free 417.5 MiB)
[2025-05-07T02:44:45.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.4 MiB)
[2025-05-07T02:44:45.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 5c5d1775d94e:37761 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-07T02:44:45.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:45.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[388] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:45.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Adding task set 250.0 with 10 tasks resource profile 0
[2025-05-07T02:44:45.070+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 0.0 in stage 250.0 (TID 445) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.076+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.20.0.5:40657 (size: 58.5 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.087+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 1.0 in stage 250.0 (TID 446) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.088+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 0.0 in stage 250.0 (TID 445) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:45.100+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 2.0 in stage 250.0 (TID 447) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.101+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 1.0 in stage 250.0 (TID 446) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:45.116+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 3.0 in stage 250.0 (TID 448) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.116+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 2.0 in stage 250.0 (TID 447) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:45.122+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 4.0 in stage 250.0 (TID 449) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.123+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 3.0 in stage 250.0 (TID 448) in 6 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:45.130+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 5.0 in stage 250.0 (TID 450) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.131+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 4.0 in stage 250.0 (TID 449) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:45.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 6.0 in stage 250.0 (TID 451) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.138+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 5.0 in stage 250.0 (TID 450) in 7 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:45.145+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 7.0 in stage 250.0 (TID 452) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.145+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 6.0 in stage 250.0 (TID 451) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:45.151+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 8.0 in stage 250.0 (TID 453) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.152+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 7.0 in stage 250.0 (TID 452) in 6 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:45.159+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 9.0 in stage 250.0 (TID 454) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.159+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 8.0 in stage 250.0 (TID 453) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:45.166+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 9.0 in stage 250.0 (TID 454) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:45.166+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool
[2025-05-07T02:44:45.167+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: ShuffleMapStage 250 (mapPartitions at GraphImpl.scala:208) finished in 0.104 s
[2025-05-07T02:44:45.167+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:45.167+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:45.167+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 251, ResultStage 252)
[2025-05-07T02:44:45.167+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:45.167+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[396] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T02:44:45.168+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 18.5 KiB, free 417.4 MiB)
[2025-05-07T02:44:45.173+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 417.4 MiB)
[2025-05-07T02:44:45.174+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 5c5d1775d94e:37761 in memory (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T02:44:45.174+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 5c5d1775d94e:37761 (size: 6.8 KiB, free: 433.4 MiB)
[2025-05-07T02:44:45.175+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:45.176+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[396] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:45.176+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Adding task set 251.0 with 10 tasks resource profile 0
[2025-05-07T02:44:45.176+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.20.0.5:40657 in memory (size: 6.7 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.177+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 455) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.179+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 5c5d1775d94e:37761 in memory (size: 58.7 KiB, free: 433.4 MiB)
[2025-05-07T02:44:45.179+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.20.0.5:40657 in memory (size: 58.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.182+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 5c5d1775d94e:37761 in memory (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T02:44:45.184+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.20.0.5:40657 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.185+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.20.0.5:40657 (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.188+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.20.0.5:52776
[2025-05-07T02:44:45.193+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.196+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 1.0 in stage 251.0 (TID 456) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.197+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 455) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:45.202+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.205+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 2.0 in stage 251.0 (TID 457) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.206+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 1.0 in stage 251.0 (TID 456) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:45.219+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.223+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 3.0 in stage 251.0 (TID 458) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.223+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 2.0 in stage 251.0 (TID 457) in 18 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:45.230+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.233+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 4.0 in stage 251.0 (TID 459) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.233+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 3.0 in stage 251.0 (TID 458) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:45.239+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.244+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 5.0 in stage 251.0 (TID 460) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.244+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 4.0 in stage 251.0 (TID 459) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:45.250+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.253+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 6.0 in stage 251.0 (TID 461) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.253+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 5.0 in stage 251.0 (TID 460) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:45.259+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 7.0 in stage 251.0 (TID 462) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.263+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 6.0 in stage 251.0 (TID 461) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:45.269+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.272+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 8.0 in stage 251.0 (TID 463) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.272+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 7.0 in stage 251.0 (TID 462) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:45.280+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.283+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 9.0 in stage 251.0 (TID 464) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.283+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 8.0 in stage 251.0 (TID 463) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:45.288+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_392_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.292+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 9.0 in stage 251.0 (TID 464) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:45.293+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool
[2025-05-07T02:44:45.293+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: ShuffleMapStage 251 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.126 s
[2025-05-07T02:44:45.293+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:45.293+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:45.293+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: waiting: Set(ResultStage 252)
[2025-05-07T02:44:45.293+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:45.293+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting ResultStage 252 (EdgeRDDImpl[399] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T02:44:45.297+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 166.1 KiB, free 417.7 MiB)
[2025-05-07T02:44:45.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-07T02:44:45.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 5c5d1775d94e:37761 (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-07T02:44:45.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:45.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 252 (EdgeRDDImpl[399] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:45.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Adding task set 252.0 with 10 tasks resource profile 0
[2025-05-07T02:44:45.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 0.0 in stage 252.0 (TID 465) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.303+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.20.0.5:40657 (size: 58.1 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.314+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:52776
[2025-05-07T02:44:45.316+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_0 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.319+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 1.0 in stage 252.0 (TID 466) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.320+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 0.0 in stage 252.0 (TID 465) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:45.329+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_1 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.332+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 2.0 in stage 252.0 (TID 467) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.332+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 1.0 in stage 252.0 (TID 466) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:45.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_2 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 3.0 in stage 252.0 (TID 468) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 2.0 in stage 252.0 (TID 467) in 21 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:45.363+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_3 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.365+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 4.0 in stage 252.0 (TID 469) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.365+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 3.0 in stage 252.0 (TID 468) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:45.373+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_4 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.377+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 5.0 in stage 252.0 (TID 470) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.377+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 4.0 in stage 252.0 (TID 469) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:45.386+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_5 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.388+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 6.0 in stage 252.0 (TID 471) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.389+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 5.0 in stage 252.0 (TID 470) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:45.401+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_6 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.403+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 7.0 in stage 252.0 (TID 472) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.404+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 6.0 in stage 252.0 (TID 471) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:45.415+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_7 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.419+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 8.0 in stage 252.0 (TID 473) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.419+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 7.0 in stage 252.0 (TID 472) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:45.428+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_8 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.431+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 9.0 in stage 252.0 (TID 474) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.431+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 8.0 in stage 252.0 (TID 473) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:45.441+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added rdd_398_9 in memory on 172.20.0.5:40657 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:45.444+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 9.0 in stage 252.0 (TID 474) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:45.445+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool
[2025-05-07T02:44:45.445+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: ResultStage 252 (foreachPartition at PageRank.scala:199) finished in 0.151 s
[2025-05-07T02:44:45.445+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:45.445+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished
[2025-05-07T02:44:45.445+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Job 45 finished: foreachPartition at PageRank.scala:199, took 0.389540 s
[2025-05-07T02:44:45.446+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO PageRank: PageRank finished iteration 9.
[2025-05-07T02:44:45.446+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO ZippedPartitionsRDD2: Removing RDD 380 from persistence list
[2025-05-07T02:44:45.447+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManager: Removing RDD 380
[2025-05-07T02:44:45.447+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO ZippedPartitionsRDD2: Removing RDD 386 from persistence list
[2025-05-07T02:44:45.448+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManager: Removing RDD 386
[2025-05-07T02:44:45.466+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO SparkContext: Starting job: sum at PageRank.scala:503
[2025-05-07T02:44:45.470+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Got job 46 (sum at PageRank.scala:503) with 10 output partitions
[2025-05-07T02:44:45.470+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Final stage: ResultStage 278 (sum at PageRank.scala:503)
[2025-05-07T02:44:45.470+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 269, ShuffleMapStage 263, ShuffleMapStage 273, ShuffleMapStage 255, ShuffleMapStage 267, ShuffleMapStage 277, ShuffleMapStage 256, ShuffleMapStage 271, ShuffleMapStage 259, ShuffleMapStage 275, ShuffleMapStage 261, ShuffleMapStage 265, ShuffleMapStage 254)
[2025-05-07T02:44:45.471+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:45.471+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting ResultStage 278 (MapPartitionsRDD[400] at values at PageRank.scala:503), which has no missing parents
[2025-05-07T02:44:45.472+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 18.9 KiB, free 417.6 MiB)
[2025-05-07T02:44:45.473+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 417.6 MiB)
[2025-05-07T02:44:45.474+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 5c5d1775d94e:37761 (size: 7.0 KiB, free: 433.4 MiB)
[2025-05-07T02:44:45.474+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:45.476+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 278 (MapPartitionsRDD[400] at values at PageRank.scala:503) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:45.477+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Adding task set 278.0 with 10 tasks resource profile 0
[2025-05-07T02:44:45.477+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 475) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.483+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.20.0.5:40657 (size: 7.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.505+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 1.0 in stage 278.0 (TID 476) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.506+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 475) in 31 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:45.512+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 2.0 in stage 278.0 (TID 477) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.514+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 1.0 in stage 278.0 (TID 476) in 7 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:45.519+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 3.0 in stage 278.0 (TID 478) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.520+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 2.0 in stage 278.0 (TID 477) in 7 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:45.527+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 4.0 in stage 278.0 (TID 479) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.528+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 3.0 in stage 278.0 (TID 478) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:45.532+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 5.0 in stage 278.0 (TID 480) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.533+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 4.0 in stage 278.0 (TID 479) in 6 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:45.538+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 6.0 in stage 278.0 (TID 481) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.538+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 5.0 in stage 278.0 (TID 480) in 6 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:45.543+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 7.0 in stage 278.0 (TID 482) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.543+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 6.0 in stage 278.0 (TID 481) in 6 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:45.548+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 8.0 in stage 278.0 (TID 483) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.549+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 7.0 in stage 278.0 (TID 482) in 6 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:45.553+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 9.0 in stage 278.0 (TID 484) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.553+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 8.0 in stage 278.0 (TID 483) in 5 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:45.557+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 9.0 in stage 278.0 (TID 484) in 4 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:45.557+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool
[2025-05-07T02:44:45.559+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: ResultStage 278 (sum at PageRank.scala:503) finished in 0.087 s
[2025-05-07T02:44:45.559+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:45.560+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 278: Stage finished
[2025-05-07T02:44:45.564+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Job 46 finished: sum at PageRank.scala:503, took 0.095029 s
[2025-05-07T02:44:45.567+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-07T02:44:45.571+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Got job 47 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-07T02:44:45.571+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Final stage: ResultStage 304 (fold at VertexRDDImpl.scala:90)
[2025-05-07T02:44:45.571+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 287, ShuffleMapStage 299, ShuffleMapStage 281, ShuffleMapStage 291, ShuffleMapStage 303, ShuffleMapStage 285, ShuffleMapStage 289, ShuffleMapStage 293, ShuffleMapStage 282, ShuffleMapStage 297, ShuffleMapStage 301, ShuffleMapStage 280, ShuffleMapStage 295)
[2025-05-07T02:44:45.571+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:45.571+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting ResultStage 304 (MapPartitionsRDD[401] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-07T02:44:45.573+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 18.7 KiB, free 417.6 MiB)
[2025-05-07T02:44:45.591+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 417.6 MiB)
[2025-05-07T02:44:45.592+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 5c5d1775d94e:37761 (size: 6.9 KiB, free: 433.4 MiB)
[2025-05-07T02:44:45.593+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 5c5d1775d94e:37761 in memory (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T02:44:45.596+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:45.596+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 304 (MapPartitionsRDD[401] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:45.598+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Adding task set 304.0 with 10 tasks resource profile 0
[2025-05-07T02:44:45.599+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.20.0.5:40657 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.599+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 485) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.603+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 5c5d1775d94e:37761 in memory (size: 6.8 KiB, free: 433.5 MiB)
[2025-05-07T02:44:45.603+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.20.0.5:40657 in memory (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.611+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 5c5d1775d94e:37761 in memory (size: 7.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:45.612+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.20.0.5:40657 in memory (size: 7.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:45.618+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.20.0.5:40657 in memory (size: 58.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:45.618+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.20.0.5:40657 (size: 6.9 KiB, free: 433.0 MiB)
[2025-05-07T02:44:45.618+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 5c5d1775d94e:37761 in memory (size: 58.5 KiB, free: 433.6 MiB)
[2025-05-07T02:44:45.622+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 1.0 in stage 304.0 (TID 486) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.623+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 485) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:45.630+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 2.0 in stage 304.0 (TID 487) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.631+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 1.0 in stage 304.0 (TID 486) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:45.634+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 3.0 in stage 304.0 (TID 488) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 2.0 in stage 304.0 (TID 487) in 5 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:45.655+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 4.0 in stage 304.0 (TID 489) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.656+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 3.0 in stage 304.0 (TID 488) in 22 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:45.662+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 5.0 in stage 304.0 (TID 490) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.662+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 4.0 in stage 304.0 (TID 489) in 7 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:45.666+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 6.0 in stage 304.0 (TID 491) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.667+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 5.0 in stage 304.0 (TID 490) in 5 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:45.671+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 7.0 in stage 304.0 (TID 492) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.671+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 6.0 in stage 304.0 (TID 491) in 5 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:45.678+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 8.0 in stage 304.0 (TID 493) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.681+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 7.0 in stage 304.0 (TID 492) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:45.682+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Starting task 9.0 in stage 304.0 (TID 494) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:45.683+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 8.0 in stage 304.0 (TID 493) in 5 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:45.686+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSetManager: Finished task 9.0 in stage 304.0 (TID 494) in 5 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:45.686+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool
[2025-05-07T02:44:45.687+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: ResultStage 304 (fold at VertexRDDImpl.scala:90) finished in 0.114 s
[2025-05-07T02:44:45.687+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:45.688+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 304: Stage finished
[2025-05-07T02:44:45.688+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:45 INFO DAGScheduler: Job 47 finished: fold at VertexRDDImpl.scala:90, took 0.120077 s
[2025-05-07T02:44:46.058+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:46,057 [INFO] Сохраняем результаты в graph.client_communities
[2025-05-07T02:44:46.164+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 5c5d1775d94e:37761 in memory (size: 6.9 KiB, free: 433.6 MiB)
[2025-05-07T02:44:46.165+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.20.0.5:40657 in memory (size: 6.9 KiB, free: 433.0 MiB)
[2025-05-07T02:44:46.559+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 7.281267 ms
[2025-05-07T02:44:46.561+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#2030 - id.nullCount#2029) > 0)
[2025-05-07T02:44:46.574+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 15.117711 ms
[2025-05-07T02:44:46.575+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:46.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Got job 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 10 output partitions
[2025-05-07T02:44:46.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Final stage: ResultStage 306 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:46.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 305)
[2025-05-07T02:44:46.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:46.576+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting ResultStage 306 (MapPartitionsRDD[440] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:46.578+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 43.9 KiB, free 418.1 MiB)
[2025-05-07T02:44:46.581+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 418.1 MiB)
[2025-05-07T02:44:46.582+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 5c5d1775d94e:37761 (size: 19.4 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.584+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:46.584+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 306 (MapPartitionsRDD[440] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:46.584+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Adding task set 306.0 with 10 tasks resource profile 0
[2025-05-07T02:44:46.585+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Registering RDD 443 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 53
[2025-05-07T02:44:46.585+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 0.0 in stage 306.0 (TID 495) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.586+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Got map stage job 49 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-07T02:44:46.586+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Final stage: ShuffleMapStage 309 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:46.587+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 307, ShuffleMapStage 308)
[2025-05-07T02:44:46.587+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:46.587+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting ShuffleMapStage 309 (MapPartitionsRDD[443] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:46.597+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 23.3 KiB, free 418.0 MiB)
[2025-05-07T02:44:46.601+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 418.0 MiB)
[2025-05-07T02:44:46.601+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 5c5d1775d94e:37761 (size: 9.9 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.602+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:46.603+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 309 (MapPartitionsRDD[443] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:46.603+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Adding task set 309.0 with 10 tasks resource profile 0
[2025-05-07T02:44:46.604+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.20.0.5:40657 (size: 19.4 KiB, free: 433.0 MiB)
[2025-05-07T02:44:46.605+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 16.227096 ms
[2025-05-07T02:44:46.612+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Registering RDD 446 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 54
[2025-05-07T02:44:46.612+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Got map stage job 50 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-07T02:44:46.613+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Final stage: ShuffleMapStage 332 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:46.613+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 317, ShuffleMapStage 321, ShuffleMapStage 310, ShuffleMapStage 325, ShuffleMapStage 307, ShuffleMapStage 329, ShuffleMapStage 308, ShuffleMapStage 323, ShuffleMapStage 315, ShuffleMapStage 327, ShuffleMapStage 319, ShuffleMapStage 331, ShuffleMapStage 313)
[2025-05-07T02:44:46.615+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:46.618+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting ShuffleMapStage 332 (MapPartitionsRDD[446] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:46.619+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 1.0 in stage 306.0 (TID 496) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.620+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 0.0 in stage 306.0 (TID 495) in 34 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:46.623+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 31.6 KiB, free 418.0 MiB)
[2025-05-07T02:44:46.634+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 418.0 MiB)
[2025-05-07T02:44:46.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 5c5d1775d94e:37761 (size: 11.8 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 2.0 in stage 306.0 (TID 497) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:46.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 332 (MapPartitionsRDD[446] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T02:44:46.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Adding task set 332.0 with 10 tasks resource profile 0
[2025-05-07T02:44:46.635+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 1.0 in stage 306.0 (TID 496) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:46.636+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 22.220472 ms
[2025-05-07T02:44:46.651+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 3.0 in stage 306.0 (TID 498) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.651+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 2.0 in stage 306.0 (TID 497) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:46.662+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 10.587185 ms
[2025-05-07T02:44:46.664+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 4.0 in stage 306.0 (TID 499) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.664+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 3.0 in stage 306.0 (TID 498) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:46.679+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 5.0 in stage 306.0 (TID 500) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.683+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 4.0 in stage 306.0 (TID 499) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:46.685+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 14.256866 ms
[2025-05-07T02:44:46.693+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 6.0 in stage 306.0 (TID 501) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.695+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 5.0 in stage 306.0 (TID 500) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:46.720+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 7.0 in stage 306.0 (TID 502) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.722+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 6.0 in stage 306.0 (TID 501) in 27 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:46.723+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 32.741047 ms
[2025-05-07T02:44:46.742+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 13.04103 ms
[2025-05-07T02:44:46.743+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 8.0 in stage 306.0 (TID 503) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.743+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 7.0 in stage 306.0 (TID 502) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:46.755+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 9.0 in stage 306.0 (TID 504) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.761+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 8.0 in stage 306.0 (TID 503) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:46.762+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 12.045157 ms
[2025-05-07T02:44:46.767+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 505) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.769+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 9.0 in stage 306.0 (TID 504) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:46.769+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool
[2025-05-07T02:44:46.770+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: ResultStage 306 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.193 s
[2025-05-07T02:44:46.771+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:46.772+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 306: Stage finished
[2025-05-07T02:44:46.773+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Job 48 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.197487 s
[2025-05-07T02:44:46.774+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Registering RDD 454 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 55
[2025-05-07T02:44:46.775+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Got map stage job 51 (jdbc at NativeMethodAccessorImpl.java:0) with 6 output partitions
[2025-05-07T02:44:46.775+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Final stage: ShuffleMapStage 333 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:46.776+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:46.776+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:46.780+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 5.362403 ms
[2025-05-07T02:44:46.783+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting ShuffleMapStage 333 (MapPartitionsRDD[454] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:46.787+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 36.4 KiB, free 418.0 MiB)
[2025-05-07T02:44:46.788+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 417.9 MiB)
[2025-05-07T02:44:46.793+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 11.704268 ms
[2025-05-07T02:44:46.794+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:46.794+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 5c5d1775d94e:37761 (size: 11.2 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.794+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:46.795+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 333 (MapPartitionsRDD[454] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T02:44:46.795+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Adding task set 333.0 with 6 tasks resource profile 0
[2025-05-07T02:44:46.795+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Registering RDD 456 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 56
[2025-05-07T02:44:46.795+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Got map stage job 52 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:46.795+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Final stage: ShuffleMapStage 334 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:46.795+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:46.795+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:46.802+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting ShuffleMapStage 334 (MapPartitionsRDD[456] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:46.803+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 12.7 KiB, free 417.9 MiB)
[2025-05-07T02:44:46.833+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.9 MiB)
[2025-05-07T02:44:46.838+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 5c5d1775d94e:37761 (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.839+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.20.0.5:40657 (size: 9.9 KiB, free: 433.0 MiB)
[2025-05-07T02:44:46.840+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 5c5d1775d94e:37761 in memory (size: 19.4 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.840+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:46.840+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 334 (MapPartitionsRDD[456] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:46.840+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 47.390261 ms
[2025-05-07T02:44:46.840+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Adding task set 334.0 with 1 tasks resource profile 0
[2025-05-07T02:44:46.843+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 2.1 MiB, free 415.9 MiB)
[2025-05-07T02:44:46.844+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:46.846+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Registering RDD 458 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 57
[2025-05-07T02:44:46.848+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Got map stage job 53 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:46.851+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Final stage: ShuffleMapStage 335 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:46.851+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:46.851+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:46.851+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting ShuffleMapStage 335 (MapPartitionsRDD[458] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:46.851+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.20.0.5:40657 in memory (size: 19.4 KiB, free: 433.0 MiB)
[2025-05-07T02:44:46.852+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 415.9 MiB)
[2025-05-07T02:44:46.852+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 27.3 KiB, free 415.9 MiB)
[2025-05-07T02:44:46.853+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 415.9 MiB)
[2025-05-07T02:44:46.862+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 5c5d1775d94e:37761 (size: 27.5 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.863+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 5c5d1775d94e:37761 (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.865+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 91 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:46.866+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:46.867+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 335 (MapPartitionsRDD[458] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:46.868+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Adding task set 335.0 with 1 tasks resource profile 0
[2025-05-07T02:44:46.873+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 18.149668 ms
[2025-05-07T02:44:46.878+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Registering RDD 460 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 58
[2025-05-07T02:44:46.879+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Got map stage job 54 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:46.880+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Final stage: ShuffleMapStage 336 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:46.880+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:46.881+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:46.881+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting ShuffleMapStage 336 (MapPartitionsRDD[460] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:46.882+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:46.885+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 28.5 KiB, free 415.8 MiB)
[2025-05-07T02:44:46.892+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 415.8 MiB)
[2025-05-07T02:44:46.895+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 5c5d1775d94e:37761 (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.896+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:46.897+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 336 (MapPartitionsRDD[460] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:46.897+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Adding task set 336.0 with 1 tasks resource profile 0
[2025-05-07T02:44:46.936+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 1.0 in stage 309.0 (TID 506) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.936+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 505) in 169 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:46.940+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 52.585086 ms
[2025-05-07T02:44:46.950+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Registering RDD 462 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 59
[2025-05-07T02:44:46.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Got map stage job 55 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:46.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Final stage: ShuffleMapStage 337 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:46.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:46.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:46.954+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:46.954+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting ShuffleMapStage 337 (MapPartitionsRDD[462] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:46.954+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 2.0 in stage 309.0 (TID 507) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.957+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 28.5 KiB, free 415.8 MiB)
[2025-05-07T02:44:46.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 415.8 MiB)
[2025-05-07T02:44:46.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 5c5d1775d94e:37761 (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T02:44:46.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:46.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 337 (MapPartitionsRDD[462] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:46.958+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Adding task set 337.0 with 1 tasks resource profile 0
[2025-05-07T02:44:46.959+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 1.0 in stage 309.0 (TID 506) in 24 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:46.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO CodeGenerator: Code generated in 18.156576 ms
[2025-05-07T02:44:46.982+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Starting task 3.0 in stage 309.0 (TID 508) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:46.983+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSetManager: Finished task 2.0 in stage 309.0 (TID 507) in 24 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:46.987+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Registering RDD 464 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 60
[2025-05-07T02:44:46.987+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Got map stage job 56 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:46.988+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Final stage: ShuffleMapStage 338 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:46.988+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:46.988+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:46.988+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:46.988+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting ShuffleMapStage 338 (MapPartitionsRDD[464] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:46.993+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 27.4 KiB, free 415.7 MiB)
[2025-05-07T02:44:46.993+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 415.7 MiB)
[2025-05-07T02:44:46.994+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 5c5d1775d94e:37761 (size: 13.0 KiB, free: 433.4 MiB)
[2025-05-07T02:44:46.994+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:46.996+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 338 (MapPartitionsRDD[464] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:46.999+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:46 INFO TaskSchedulerImpl: Adding task set 338.0 with 1 tasks resource profile 0
[2025-05-07T02:44:47.008+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 4.0 in stage 309.0 (TID 509) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.009+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 3.0 in stage 309.0 (TID 508) in 32 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:47.026+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 5.0 in stage 309.0 (TID 510) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.027+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 4.0 in stage 309.0 (TID 509) in 24 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:47.031+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO CodeGenerator: Code generated in 39.036307 ms
[2025-05-07T02:44:47.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 6.0 in stage 309.0 (TID 511) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:47.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Registering RDD 466 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 61
[2025-05-07T02:44:47.067+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Got map stage job 57 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:47.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Final stage: ShuffleMapStage 339 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:47.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:47.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:47.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting ShuffleMapStage 339 (MapPartitionsRDD[466] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:47.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 28.5 KiB, free 415.7 MiB)
[2025-05-07T02:44:47.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 5.0 in stage 309.0 (TID 510) in 41 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:47.124+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 415.7 MiB)
[2025-05-07T02:44:47.127+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 5c5d1775d94e:37761 (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-07T02:44:47.132+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:47.133+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 339 (MapPartitionsRDD[466] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:47.133+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSchedulerImpl: Adding task set 339.0 with 1 tasks resource profile 0
[2025-05-07T02:44:47.141+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 7.0 in stage 309.0 (TID 512) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.142+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 6.0 in stage 309.0 (TID 511) in 84 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:47.152+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO CodeGenerator: Code generated in 89.961414 ms
[2025-05-07T02:44:47.160+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Registering RDD 468 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 62
[2025-05-07T02:44:47.161+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Got map stage job 58 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:47.164+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Final stage: ShuffleMapStage 340 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:47.165+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:47.165+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:47.166+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting ShuffleMapStage 340 (MapPartitionsRDD[468] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:47.168+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 8.0 in stage 309.0 (TID 513) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.169+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 7.0 in stage 309.0 (TID 512) in 31 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:47.170+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 31.7 KiB, free 415.7 MiB)
[2025-05-07T02:44:47.173+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 415.6 MiB)
[2025-05-07T02:44:47.174+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 5c5d1775d94e:37761 (size: 14.9 KiB, free: 433.4 MiB)
[2025-05-07T02:44:47.175+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:47.176+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 340 (MapPartitionsRDD[468] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:47.177+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSchedulerImpl: Adding task set 340.0 with 1 tasks resource profile 0
[2025-05-07T02:44:47.190+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 8.0 in stage 309.0 (TID 513) in 22 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:47.192+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 9.0 in stage 309.0 (TID 514) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.231+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 0.0 in stage 332.0 (TID 515) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.231+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 9.0 in stage 309.0 (TID 514) in 37 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:47.232+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool
[2025-05-07T02:44:47.232+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: ShuffleMapStage 309 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.643 s
[2025-05-07T02:44:47.233+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:47.233+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ShuffleMapStage 332, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ShuffleMapStage 333, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T02:44:47.234+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:47.234+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:47.245+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.20.0.5:40657 (size: 11.8 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.253+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_0 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.276+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 1.0 in stage 332.0 (TID 516) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 0.0 in stage 332.0 (TID 515) in 50 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T02:44:47.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_1 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.300+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO CodeGenerator: Code generated in 26.041188 ms
[2025-05-07T02:44:47.301+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Registering RDD 474 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 63
[2025-05-07T02:44:47.302+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Got map stage job 59 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:47.302+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Final stage: ShuffleMapStage 341 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:47.303+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:47.303+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:47.304+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting ShuffleMapStage 341 (MapPartitionsRDD[474] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:47.310+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 2.0 in stage 332.0 (TID 517) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.311+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 1.0 in stage 332.0 (TID 516) in 32 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T02:44:47.317+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 16.6 KiB, free 415.6 MiB)
[2025-05-07T02:44:47.336+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 415.6 MiB)
[2025-05-07T02:44:47.337+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 5c5d1775d94e:37761 (size: 8.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:47.340+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 5c5d1775d94e:37761 in memory (size: 9.9 KiB, free: 433.4 MiB)
[2025-05-07T02:44:47.345+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:47.346+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 341 (MapPartitionsRDD[474] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:47.347+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSchedulerImpl: Adding task set 341.0 with 1 tasks resource profile 0
[2025-05-07T02:44:47.347+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO CodeGenerator: Code generated in 31.205772 ms
[2025-05-07T02:44:47.348+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_2 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.348+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.20.0.5:40657 in memory (size: 9.9 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Registering RDD 476 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 64
[2025-05-07T02:44:47.357+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Got map stage job 60 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:47.358+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Final stage: ShuffleMapStage 342 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:47.359+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T02:44:47.359+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:47.360+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting ShuffleMapStage 342 (MapPartitionsRDD[476] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:47.360+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 15.0 KiB, free 415.6 MiB)
[2025-05-07T02:44:47.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 415.6 MiB)
[2025-05-07T02:44:47.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 5c5d1775d94e:37761 (size: 7.7 KiB, free: 433.4 MiB)
[2025-05-07T02:44:47.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 3.0 in stage 332.0 (TID 518) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.364+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:47.364+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 342 (MapPartitionsRDD[476] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:47.366+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSchedulerImpl: Adding task set 342.0 with 1 tasks resource profile 0
[2025-05-07T02:44:47.374+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 2.0 in stage 332.0 (TID 517) in 53 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T02:44:47.375+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_3 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.385+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 4.0 in stage 332.0 (TID 519) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.387+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 3.0 in stage 332.0 (TID 518) in 31 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T02:44:47.402+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_4 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.409+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 5.0 in stage 332.0 (TID 520) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.414+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 4.0 in stage 332.0 (TID 519) in 29 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T02:44:47.422+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:47.423+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:47.437+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_5 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.454+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 6.0 in stage 332.0 (TID 521) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.455+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 5.0 in stage 332.0 (TID 520) in 44 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T02:44:47.467+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:47.469+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Got job 61 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:47.472+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Final stage: ResultStage 344 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:47.473+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 343)
[2025-05-07T02:44:47.476+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:47.478+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting ResultStage 344 (MapPartitionsRDD[479] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:47.508+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-07T02:44:47.511+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_6 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.514+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-07T02:44:47.517+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T02:44:47.518+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:47.519+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 344 (MapPartitionsRDD[479] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:47.520+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSchedulerImpl: Adding task set 344.0 with 1 tasks resource profile 0
[2025-05-07T02:44:47.528+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 7.0 in stage 332.0 (TID 522) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.529+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 6.0 in stage 332.0 (TID 521) in 67 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T02:44:47.535+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_7 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T02:44:47.547+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 8.0 in stage 332.0 (TID 523) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.549+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 7.0 in stage 332.0 (TID 522) in 32 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T02:44:47.596+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_8 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:47.606+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 8.0 in stage 332.0 (TID 523) in 59 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T02:44:47.607+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 9.0 in stage 332.0 (TID 524) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.631+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added rdd_402_9 in memory on 172.20.0.5:40657 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:47.652+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 0.0 in stage 333.0 (TID 525) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.656+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 9.0 in stage 332.0 (TID 524) in 45 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T02:44:47.661+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSchedulerImpl: Removed TaskSet 332.0, whose tasks have all completed, from pool
[2025-05-07T02:44:47.672+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: ShuffleMapStage 332 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.037 s
[2025-05-07T02:44:47.673+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:47.675+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 333, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T02:44:47.676+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:47.679+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:47.699+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO ShufflePartitionsUtil: For shuffle(54), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:47.710+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.20.0.5:40657 (size: 11.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:47.731+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:47.736+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Got job 62 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:47.736+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Final stage: ResultStage 368 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:47.736+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 367)
[2025-05-07T02:44:47.736+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:47.736+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting ResultStage 368 (MapPartitionsRDD[482] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:47.738+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-07T02:44:47.779+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-07T02:44:47.780+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 1.0 in stage 333.0 (TID 526) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.787+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 0.0 in stage 333.0 (TID 525) in 130 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T02:44:47.788+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T02:44:47.791+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:47.792+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 368 (MapPartitionsRDD[482] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:47.792+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSchedulerImpl: Adding task set 368.0 with 1 tasks resource profile 0
[2025-05-07T02:44:47.792+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 5c5d1775d94e:37761 in memory (size: 11.8 KiB, free: 433.4 MiB)
[2025-05-07T02:44:47.792+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.20.0.5:40657 in memory (size: 11.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:47.851+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 2.0 in stage 333.0 (TID 527) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.851+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 1.0 in stage 333.0 (TID 526) in 69 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T02:44:47.896+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 3.0 in stage 333.0 (TID 528) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.902+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 2.0 in stage 333.0 (TID 527) in 54 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T02:44:47.937+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 4.0 in stage 333.0 (TID 529) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.937+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 3.0 in stage 333.0 (TID 528) in 41 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T02:44:47.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Starting task 5.0 in stage 333.0 (TID 530) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:47.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:47 INFO TaskSetManager: Finished task 4.0 in stage 333.0 (TID 529) in 30 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T02:44:48.013+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 334.0 (TID 531) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.013+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 5.0 in stage 333.0 (TID 530) in 47 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T02:44:48.013+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.014+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 333 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.230 s
[2025-05-07T02:44:48.014+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.014+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T02:44:48.014+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.014+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.031+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.20.0.5:40657 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.032+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:48.033+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:48.043+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:48.045+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Got job 63 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:48.046+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Final stage: ResultStage 370 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:48.046+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 369)
[2025-05-07T02:44:48.046+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:48.047+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting ResultStage 370 (MapPartitionsRDD[485] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:48.047+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-07T02:44:48.058+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-07T02:44:48.059+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T02:44:48.060+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:48.061+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 370 (MapPartitionsRDD[485] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:48.061+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Adding task set 370.0 with 1 tasks resource profile 0
[2025-05-07T02:44:48.063+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.20.0.5:40657 in memory (size: 11.2 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.064+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 5c5d1775d94e:37761 in memory (size: 11.2 KiB, free: 433.4 MiB)
[2025-05-07T02:44:48.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 335.0 (TID 532) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 334.0 (TID 531) in 56 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 334.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.068+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 334 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.275 s
[2025-05-07T02:44:48.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ResultStage 370)
[2025-05-07T02:44:48.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.069+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.073+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.20.0.5:40657 (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.088+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO ShufflePartitionsUtil: For shuffle(56), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:48.101+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:48.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Got job 64 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:48.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Final stage: ResultStage 372 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:48.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 371)
[2025-05-07T02:44:48.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:48.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting ResultStage 372 (MapPartitionsRDD[488] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:48.103+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 7.2 KiB, free 415.7 MiB)
[2025-05-07T02:44:48.104+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.7 MiB)
[2025-05-07T02:44:48.104+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T02:44:48.105+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:48.105+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 372 (MapPartitionsRDD[488] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:48.105+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Adding task set 372.0 with 1 tasks resource profile 0
[2025-05-07T02:44:48.136+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 336.0 (TID 533) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.136+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 335.0 (TID 532) in 67 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.136+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 335.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.137+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 335 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.290 s
[2025-05-07T02:44:48.138+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.138+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ResultStage 370)
[2025-05-07T02:44:48.139+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.139+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.173+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.20.0.5:40657 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 337.0 (TID 534) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 336.0 (TID 533) in 80 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 336.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.214+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 336 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.333 s
[2025-05-07T02:44:48.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ResultStage 370)
[2025-05-07T02:44:48.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.215+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.219+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.20.0.5:40657 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.253+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 338.0 (TID 535) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.254+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 337.0 (TID 534) in 40 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.256+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.256+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 337 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.304 s
[2025-05-07T02:44:48.257+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.257+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-07T02:44:48.258+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.258+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.262+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.20.0.5:40657 (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.297+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 339.0 (TID 536) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.297+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 338.0 (TID 535) in 44 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 338.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.298+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 338 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.310 s
[2025-05-07T02:44:48.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-07T02:44:48.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.303+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.20.0.5:40657 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.348+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 340.0 (TID 537) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 339.0 (TID 536) in 52 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 339.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 339 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.284 s
[2025-05-07T02:44:48.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-07T02:44:48.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.350+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.355+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.20.0.5:40657 (size: 14.9 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.399+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 341.0 (TID 538) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.399+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 340.0 (TID 537) in 51 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.400+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 340.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.400+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 340 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.238 s
[2025-05-07T02:44:48.400+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.400+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ResultStage 372, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-07T02:44:48.400+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.400+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.404+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.20.0.5:40657 (size: 8.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.418+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO ShufflePartitionsUtil: For shuffle(57, 58, 59, 60, 61, 62), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:48.443+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.20.0.5:40657 (size: 27.5 KiB, free: 432.8 MiB)
[2025-05-07T02:44:48.446+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 7.959775 ms
[2025-05-07T02:44:48.448+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:48.460+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 8.404586 ms
[2025-05-07T02:44:48.472+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:48.489+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 14.023778 ms
[2025-05-07T02:44:48.497+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 342.0 (TID 539) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.502+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 341.0 (TID 538) in 103 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.503+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 341.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.503+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 341 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.201 s
[2025-05-07T02:44:48.503+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.503+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ResultStage 372, ResultStage 344, ResultStage 370)
[2025-05-07T02:44:48.503+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.504+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.508+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:48.530+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.20.0.5:40657 (size: 7.7 KiB, free: 432.8 MiB)
[2025-05-07T02:44:48.531+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 16.982305 ms
[2025-05-07T02:44:48.536+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:48.569+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 344.0 (TID 540) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.570+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 342.0 (TID 539) in 73 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.572+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 342.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.572+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ShuffleMapStage 342 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.219 s
[2025-05-07T02:44:48.572+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:48.573+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: running: Set(ResultStage 368, ResultStage 372, ResultStage 344, ResultStage 370)
[2025-05-07T02:44:48.573+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:48.573+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:48.577+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 5c5d1775d94e:37761 in memory (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-07T02:44:48.579+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.20.0.5:40657 in memory (size: 13.4 KiB, free: 432.8 MiB)
[2025-05-07T02:44:48.585+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 5c5d1775d94e:37761 in memory (size: 13.0 KiB, free: 433.4 MiB)
[2025-05-07T02:44:48.587+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.20.0.5:40657 in memory (size: 13.0 KiB, free: 432.8 MiB)
[2025-05-07T02:44:48.591+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T02:44:48.593+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 51.867409 ms
[2025-05-07T02:44:48.597+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 5c5d1775d94e:37761 in memory (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T02:44:48.613+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:52776
[2025-05-07T02:44:48.614+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:48.617+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.20.0.5:40657 in memory (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.629+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 5c5d1775d94e:37761 in memory (size: 8.3 KiB, free: 433.5 MiB)
[2025-05-07T02:44:48.630+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 368.0 (TID 541) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.631+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 344.0 (TID 540) in 62 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.633+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.634+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 16.460732 ms
[2025-05-07T02:44:48.636+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ResultStage 344 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.160 s
[2025-05-07T02:44:48.637+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:48.637+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 344: Stage finished
[2025-05-07T02:44:48.638+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.20.0.5:40657 in memory (size: 8.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.638+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Job 61 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.166766 s
[2025-05-07T02:44:48.643+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 5c5d1775d94e:37761 in memory (size: 14.9 KiB, free: 433.5 MiB)
[2025-05-07T02:44:48.652+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.20.0.5:40657 in memory (size: 14.9 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.653+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:48.665+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 15.36816 ms
[2025-05-07T02:44:48.669+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.670+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 14.385598 ms
[2025-05-07T02:44:48.673+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.20.0.5:40657 in memory (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.675+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.20.0.5:52776
[2025-05-07T02:44:48.686+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 5c5d1775d94e:37761 in memory (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T02:44:48.689+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 1088.0 KiB, free 414.8 MiB)
[2025-05-07T02:44:48.689+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 370.0 (TID 542) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.690+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 368.0 (TID 541) in 60 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.690+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 368.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.693+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ResultStage 368 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.954 s
[2025-05-07T02:44:48.694+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 5c5d1775d94e:37761 in memory (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T02:44:48.694+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:48.695+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 368: Stage finished
[2025-05-07T02:44:48.696+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Job 62 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.960198 s
[2025-05-07T02:44:48.699+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 414.8 MiB)
[2025-05-07T02:44:48.700+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 5c5d1775d94e:37761 (size: 32.6 KiB, free: 433.5 MiB)
[2025-05-07T02:44:48.701+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.20.0.5:40657 in memory (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.702+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 104 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:48.712+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 1088.0 KiB, free 413.8 MiB)
[2025-05-07T02:44:48.717+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 5c5d1775d94e:37761 in memory (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T02:44:48.718+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.718+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 413.8 MiB)
[2025-05-07T02:44:48.719+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 5c5d1775d94e:37761 (size: 23.7 KiB, free: 433.5 MiB)
[2025-05-07T02:44:48.720+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 105 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:48.722+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.20.0.5:40657 in memory (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.723+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:52776
[2025-05-07T02:44:48.728+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:48.731+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO ShufflePartitionsUtil: For shuffle(64), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:48.734+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:48.737+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Got job 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T02:44:48.737+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Final stage: ResultStage 379 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:48.738+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 374, ShuffleMapStage 375, ShuffleMapStage 376, ShuffleMapStage 373, ShuffleMapStage 377, ShuffleMapStage 378)
[2025-05-07T02:44:48.739+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:48.740+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting ResultStage 379 (MapPartitionsRDD[511] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:48.748+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 91.7 KiB, free 413.7 MiB)
[2025-05-07T02:44:48.749+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 413.7 MiB)
[2025-05-07T02:44:48.749+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 5c5d1775d94e:37761 (size: 30.3 KiB, free: 433.4 MiB)
[2025-05-07T02:44:48.749+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:48.749+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 379 (MapPartitionsRDD[511] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T02:44:48.749+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Adding task set 379.0 with 6 tasks resource profile 0
[2025-05-07T02:44:48.757+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 372.0 (TID 543) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 370.0 (TID 542) in 66 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 370.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ResultStage 370 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.709 s
[2025-05-07T02:44:48.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:48.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 370: Stage finished
[2025-05-07T02:44:48.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Job 63 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.712480 s
[2025-05-07T02:44:48.758+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 9.53663 ms
[2025-05-07T02:44:48.769+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Registering RDD 515 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 65
[2025-05-07T02:44:48.770+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Got map stage job 66 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:48.770+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Final stage: ShuffleMapStage 381 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:48.770+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 380)
[2025-05-07T02:44:48.770+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:48.770+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting ShuffleMapStage 381 (MapPartitionsRDD[515] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:48.771+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 13.4 KiB, free 413.7 MiB)
[2025-05-07T02:44:48.775+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 413.6 MiB)
[2025-05-07T02:44:48.780+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 5c5d1775d94e:37761 (size: 6.8 KiB, free: 433.4 MiB)
[2025-05-07T02:44:48.781+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:48.781+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 381 (MapPartitionsRDD[515] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:48.781+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Adding task set 381.0 with 1 tasks resource profile 0
[2025-05-07T02:44:48.785+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.788+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:52776
[2025-05-07T02:44:48.794+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 5.0 MiB, free 408.6 MiB)
[2025-05-07T02:44:48.797+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 0.0 in stage 379.0 (TID 544) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.801+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 372.0 (TID 543) in 45 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:48.802+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Removed TaskSet 372.0, whose tasks have all completed, from pool
[2025-05-07T02:44:48.803+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: ResultStage 372 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.699 s
[2025-05-07T02:44:48.805+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:48.806+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 372: Stage finished
[2025-05-07T02:44:48.806+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Job 64 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.701642 s
[2025-05-07T02:44:48.808+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 33.262926 ms
[2025-05-07T02:44:48.811+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 408.2 MiB)
[2025-05-07T02:44:48.812+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 5c5d1775d94e:37761 (size: 502.1 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.813+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 108 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:48.815+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 2.1 MiB, free 406.1 MiB)
[2025-05-07T02:44:48.817+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 406.1 MiB)
[2025-05-07T02:44:48.818+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.20.0.5:40657 (size: 30.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.818+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 5c5d1775d94e:37761 (size: 20.6 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.818+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 109 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:48.830+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 172.20.0.5:52776
[2025-05-07T02:44:48.832+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 5c5d1775d94e:37761 in memory (size: 7.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.835+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.20.0.5:40657 in memory (size: 7.7 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.836+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.840+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.845+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.845+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Registering RDD 518 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 66
[2025-05-07T02:44:48.846+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Got map stage job 67 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:48.846+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Final stage: ShuffleMapStage 383 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:48.846+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 382)
[2025-05-07T02:44:48.846+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:48.846+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.846+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting ShuffleMapStage 383 (MapPartitionsRDD[518] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:48.852+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.853+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 78.0 KiB, free 406.0 MiB)
[2025-05-07T02:44:48.857+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 406.0 MiB)
[2025-05-07T02:44:48.857+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 5c5d1775d94e:37761 (size: 34.5 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.858+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:48.859+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 383 (MapPartitionsRDD[518] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:48.861+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Adding task set 383.0 with 1 tasks resource profile 0
[2025-05-07T02:44:48.863+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:48.865+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.873+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.881+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO CodeGenerator: Code generated in 10.202258 ms
[2025-05-07T02:44:48.885+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Registering RDD 522 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 67
[2025-05-07T02:44:48.886+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Got map stage job 68 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:48.886+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Final stage: ShuffleMapStage 384 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:48.886+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 380)
[2025-05-07T02:44:48.886+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:48.886+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting ShuffleMapStage 384 (MapPartitionsRDD[522] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:48.890+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 13.8 KiB, free 406.0 MiB)
[2025-05-07T02:44:48.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 406.0 MiB)
[2025-05-07T02:44:48.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 5c5d1775d94e:37761 (size: 6.9 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:48.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 384 (MapPartitionsRDD[522] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:48.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSchedulerImpl: Adding task set 384.0 with 1 tasks resource profile 0
[2025-05-07T02:44:48.892+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:48.904+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 1.0 in stage 379.0 (TID 545) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.905+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 0.0 in stage 379.0 (TID 544) in 109 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T02:44:48.913+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.20.0.5:52776
[2025-05-07T02:44:48.947+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 2.0 in stage 379.0 (TID 546) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.947+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 1.0 in stage 379.0 (TID 545) in 44 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T02:44:48.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.20.0.5:52776
[2025-05-07T02:44:48.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 3.0 in stage 379.0 (TID 547) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 2.0 in stage 379.0 (TID 546) in 19 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T02:44:48.972+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 172.20.0.5:52776
[2025-05-07T02:44:48.993+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Starting task 4.0 in stage 379.0 (TID 548) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:48.994+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO TaskSetManager: Finished task 3.0 in stage 379.0 (TID 547) in 28 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T02:44:48.998+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.20.0.5:52776
[2025-05-07T02:44:49.011+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 5.0 in stage 379.0 (TID 549) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.011+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 4.0 in stage 379.0 (TID 548) in 18 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T02:44:49.016+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.20.0.5:52776
[2025-05-07T02:44:49.032+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 0.0 in stage 381.0 (TID 550) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.032+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 5.0 in stage 379.0 (TID 549) in 22 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T02:44:49.033+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Removed TaskSet 379.0, whose tasks have all completed, from pool
[2025-05-07T02:44:49.033+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: ResultStage 379 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.294 s
[2025-05-07T02:44:49.033+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:49.033+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 379: Stage finished
[2025-05-07T02:44:49.033+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Job 65 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.299168 s
[2025-05-07T02:44:49.037+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.20.0.5:40657 (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-07T02:44:49.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 2.3 MiB, free 403.8 MiB)
[2025-05-07T02:44:49.040+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 63 to 172.20.0.5:52776
[2025-05-07T02:44:49.044+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 403.6 MiB)
[2025-05-07T02:44:49.044+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 5c5d1775d94e:37761 (size: 114.2 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.044+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO SparkContext: Created broadcast 112 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:49.058+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.20.0.5:40657 (size: 32.6 KiB, free: 432.9 MiB)
[2025-05-07T02:44:49.079+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 0.0 in stage 383.0 (TID 551) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.080+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 0.0 in stage 381.0 (TID 550) in 47 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:49.080+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Removed TaskSet 381.0, whose tasks have all completed, from pool
[2025-05-07T02:44:49.081+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: ShuffleMapStage 381 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.311 s
[2025-05-07T02:44:49.083+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:49.084+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: running: Set(ShuffleMapStage 383, ShuffleMapStage 384)
[2025-05-07T02:44:49.084+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:49.085+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:49.085+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO CodeGenerator: Code generated in 24.186817 ms
[2025-05-07T02:44:49.085+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:49.094+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.20.0.5:40657 (size: 34.5 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.143+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.20.0.5:52776
[2025-05-07T02:44:49.161+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO CodeGenerator: Code generated in 50.366111 ms
[2025-05-07T02:44:49.199+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO CodeGenerator: Code generated in 12.345538 ms
[2025-05-07T02:44:49.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Registering RDD 529 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 68
[2025-05-07T02:44:49.221+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Got map stage job 69 (jdbc at NativeMethodAccessorImpl.java:0) with 11 output partitions
[2025-05-07T02:44:49.222+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Final stage: ShuffleMapStage 386 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:49.223+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 385)
[2025-05-07T02:44:49.224+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:49.226+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Submitting ShuffleMapStage 386 (MapPartitionsRDD[529] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:49.235+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 141.2 KiB, free 403.5 MiB)
[2025-05-07T02:44:49.237+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 49.6 KiB, free 403.5 MiB)
[2025-05-07T02:44:49.239+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 5c5d1775d94e:37761 (size: 49.6 KiB, free: 432.7 MiB)
[2025-05-07T02:44:49.241+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:49.244+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 386 (MapPartitionsRDD[529] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T02:44:49.245+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Adding task set 386.0 with 11 tasks resource profile 0
[2025-05-07T02:44:49.255+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 0.0 in stage 384.0 (TID 552) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.255+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 0.0 in stage 383.0 (TID 551) in 176 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:49.256+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Removed TaskSet 383.0, whose tasks have all completed, from pool
[2025-05-07T02:44:49.260+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: ShuffleMapStage 383 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.413 s
[2025-05-07T02:44:49.261+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:49.261+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: running: Set(ShuffleMapStage 386, ShuffleMapStage 384)
[2025-05-07T02:44:49.261+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:49.261+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:49.267+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO ShufflePartitionsUtil: For shuffle(66), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:49.284+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:49.299+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.20.0.5:40657 (size: 6.9 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.301+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO CodeGenerator: Code generated in 14.369639 ms
[2025-05-07T02:44:49.345+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 5c5d1775d94e:37761 in memory (size: 34.5 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.349+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:49.350+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Got job 70 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:49.350+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.20.0.5:40657 in memory (size: 34.5 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.350+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Final stage: ResultStage 389 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:49.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 388)
[2025-05-07T02:44:49.352+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:49.353+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.20.0.5:40657 (size: 23.7 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.353+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Submitting ResultStage 389 (MapPartitionsRDD[532] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:49.354+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 5c5d1775d94e:37761 in memory (size: 6.8 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.359+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 75.2 KiB, free 403.5 MiB)
[2025-05-07T02:44:49.359+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 33.2 KiB, free 403.5 MiB)
[2025-05-07T02:44:49.360+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 5c5d1775d94e:37761 (size: 33.2 KiB, free: 432.7 MiB)
[2025-05-07T02:44:49.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:49.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 389 (MapPartitionsRDD[532] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:49.361+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Adding task set 389.0 with 1 tasks resource profile 0
[2025-05-07T02:44:49.367+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 172.20.0.5:40657 in memory (size: 6.8 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.371+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 5c5d1775d94e:37761 in memory (size: 30.3 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.372+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.20.0.5:40657 in memory (size: 30.3 KiB, free: 432.9 MiB)
[2025-05-07T02:44:49.382+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 0.0 in stage 386.0 (TID 553) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.383+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 0.0 in stage 384.0 (TID 552) in 127 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:49.383+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Removed TaskSet 384.0, whose tasks have all completed, from pool
[2025-05-07T02:44:49.383+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: ShuffleMapStage 384 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.496 s
[2025-05-07T02:44:49.383+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:49.383+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: running: Set(ResultStage 389, ShuffleMapStage 386)
[2025-05-07T02:44:49.383+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:49.383+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:49.394+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO ShufflePartitionsUtil: For shuffle(67), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:49.399+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.20.0.5:40657 (size: 49.6 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.403+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:49.404+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Got job 71 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:49.404+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Final stage: ResultStage 392 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:49.404+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 391)
[2025-05-07T02:44:49.405+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:49.405+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Submitting ResultStage 392 (MapPartitionsRDD[534] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:49.409+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 7.2 KiB, free 403.6 MiB)
[2025-05-07T02:44:49.409+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 403.6 MiB)
[2025-05-07T02:44:49.409+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 5c5d1775d94e:37761 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T02:44:49.409+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:49.412+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 392 (MapPartitionsRDD[534] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:49.412+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Adding task set 392.0 with 1 tasks resource profile 0
[2025-05-07T02:44:49.433+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:52776
[2025-05-07T02:44:49.473+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.20.0.5:40657 (size: 502.1 KiB, free: 432.3 MiB)
[2025-05-07T02:44:49.487+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.20.0.5:40657 (size: 114.2 KiB, free: 432.2 MiB)
[2025-05-07T02:44:49.499+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.20.0.5:40657 (size: 20.6 KiB, free: 432.2 MiB)
[2025-05-07T02:44:49.584+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 1.0 in stage 386.0 (TID 554) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.585+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 0.0 in stage 386.0 (TID 553) in 203 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T02:44:49.619+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 2.0 in stage 386.0 (TID 555) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.620+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 1.0 in stage 386.0 (TID 554) in 34 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T02:44:49.664+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 3.0 in stage 386.0 (TID 556) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.665+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 2.0 in stage 386.0 (TID 555) in 47 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T02:44:49.700+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 4.0 in stage 386.0 (TID 557) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.702+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 3.0 in stage 386.0 (TID 556) in 37 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T02:44:49.736+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 5.0 in stage 386.0 (TID 558) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.737+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 4.0 in stage 386.0 (TID 557) in 38 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T02:44:49.754+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 6.0 in stage 386.0 (TID 559) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.754+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 5.0 in stage 386.0 (TID 558) in 18 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-07T02:44:49.776+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 7.0 in stage 386.0 (TID 560) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.776+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 6.0 in stage 386.0 (TID 559) in 23 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-07T02:44:49.792+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 8.0 in stage 386.0 (TID 561) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.792+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 7.0 in stage 386.0 (TID 560) in 17 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-07T02:44:49.823+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 9.0 in stage 386.0 (TID 562) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.823+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 8.0 in stage 386.0 (TID 561) in 31 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-07T02:44:49.837+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 10.0 in stage 386.0 (TID 563) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.838+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 9.0 in stage 386.0 (TID 562) in 15 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-07T02:44:49.890+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 0.0 in stage 389.0 (TID 564) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.891+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 10.0 in stage 386.0 (TID 563) in 53 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-07T02:44:49.892+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool
[2025-05-07T02:44:49.892+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: ShuffleMapStage 386 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.663 s
[2025-05-07T02:44:49.892+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:49.893+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: running: Set(ResultStage 389, ResultStage 392)
[2025-05-07T02:44:49.893+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:49.895+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:49.901+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO ShufflePartitionsUtil: For shuffle(68), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:49.903+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:49.933+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.20.0.5:40657 (size: 33.2 KiB, free: 432.2 MiB)
[2025-05-07T02:44:49.936+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO CodeGenerator: Code generated in 28.39971 ms
[2025-05-07T02:44:49.937+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 66 to 172.20.0.5:52776
[2025-05-07T02:44:49.947+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Registering RDD 537 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 69
[2025-05-07T02:44:49.949+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Got map stage job 72 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:49.949+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Final stage: ShuffleMapStage 395 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:49.950+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 394)
[2025-05-07T02:44:49.950+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:49.951+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Submitting ShuffleMapStage 395 (MapPartitionsRDD[537] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:49.953+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 130.2 KiB, free 403.5 MiB)
[2025-05-07T02:44:49.954+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 44.6 KiB, free 403.4 MiB)
[2025-05-07T02:44:49.954+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 5c5d1775d94e:37761 (size: 44.6 KiB, free: 432.7 MiB)
[2025-05-07T02:44:49.954+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:49.954+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 395 (MapPartitionsRDD[537] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:49.955+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Adding task set 395.0 with 1 tasks resource profile 0
[2025-05-07T02:44:49.960+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 0.0 in stage 392.0 (TID 565) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.960+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 0.0 in stage 389.0 (TID 564) in 70 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:49.960+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Removed TaskSet 389.0, whose tasks have all completed, from pool
[2025-05-07T02:44:49.961+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: ResultStage 389 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.608 s
[2025-05-07T02:44:49.961+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:49.961+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 389: Stage finished
[2025-05-07T02:44:49.961+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Job 70 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.611862 s
[2025-05-07T02:44:49.966+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.20.0.5:40657 (size: 3.8 KiB, free: 432.2 MiB)
[2025-05-07T02:44:49.967+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO CodeGenerator: Code generated in 4.159529 ms
[2025-05-07T02:44:49.968+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 67 to 172.20.0.5:52776
[2025-05-07T02:44:49.970+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 1088.0 KiB, free 402.4 MiB)
[2025-05-07T02:44:49.971+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 22.4 KiB, free 402.3 MiB)
[2025-05-07T02:44:49.972+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 5c5d1775d94e:37761 (size: 22.4 KiB, free: 432.7 MiB)
[2025-05-07T02:44:49.972+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO SparkContext: Created broadcast 117 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:49.972+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Starting task 0.0 in stage 395.0 (TID 566) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:49.973+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSetManager: Finished task 0.0 in stage 392.0 (TID 565) in 13 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:49.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Removed TaskSet 392.0, whose tasks have all completed, from pool
[2025-05-07T02:44:49.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: ResultStage 392 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.569 s
[2025-05-07T02:44:49.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:49.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 392: Stage finished
[2025-05-07T02:44:49.974+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO DAGScheduler: Job 71 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.570759 s
[2025-05-07T02:44:49.979+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 2.1 MiB, free 400.3 MiB)
[2025-05-07T02:44:49.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 400.3 MiB)
[2025-05-07T02:44:49.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 5c5d1775d94e:37761 (size: 20.3 KiB, free: 432.7 MiB)
[2025-05-07T02:44:49.981+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO SparkContext: Created broadcast 118 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:49.983+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.20.0.5:40657 (size: 44.6 KiB, free: 432.1 MiB)
[2025-05-07T02:44:49.988+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 68 to 172.20.0.5:52776
[2025-05-07T02:44:50.049+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSetManager: Finished task 0.0 in stage 395.0 (TID 566) in 77 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:50.049+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSchedulerImpl: Removed TaskSet 395.0, whose tasks have all completed, from pool
[2025-05-07T02:44:50.050+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: ShuffleMapStage 395 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.100 s
[2025-05-07T02:44:50.050+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T02:44:50.050+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: running: Set()
[2025-05-07T02:44:50.050+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: waiting: Set()
[2025-05-07T02:44:50.050+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: failed: Set()
[2025-05-07T02:44:50.052+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO ShufflePartitionsUtil: For shuffle(69), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:50.056+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T02:44:50.080+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO CodeGenerator: Code generated in 11.78572 ms
[2025-05-07T02:44:50.101+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:50.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Got job 73 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T02:44:50.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Final stage: ResultStage 399 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T02:44:50.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 398)
[2025-05-07T02:44:50.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:50.102+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Submitting ResultStage 399 (MapPartitionsRDD[540] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T02:44:50.108+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 122.7 KiB, free 400.1 MiB)
[2025-05-07T02:44:50.110+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 42.0 KiB, free 400.1 MiB)
[2025-05-07T02:44:50.111+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 5c5d1775d94e:37761 (size: 42.0 KiB, free: 432.6 MiB)
[2025-05-07T02:44:50.111+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:50.112+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 399 (MapPartitionsRDD[540] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:50.112+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSchedulerImpl: Adding task set 399.0 with 1 tasks resource profile 0
[2025-05-07T02:44:50.112+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSetManager: Starting task 0.0 in stage 399.0 (TID 567) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:50.120+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.20.0.5:40657 (size: 42.0 KiB, free: 432.1 MiB)
[2025-05-07T02:44:50.134+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 69 to 172.20.0.5:52776
[2025-05-07T02:44:50.197+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSetManager: Finished task 0.0 in stage 399.0 (TID 567) in 83 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:50.197+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool
[2025-05-07T02:44:50.197+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: ResultStage 399 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.094 s
[2025-05-07T02:44:50.198+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:50.199+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 399: Stage finished
[2025-05-07T02:44:50.199+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Job 73 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.097033 s
[2025-05-07T02:44:50.206+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 2.1 MiB, free 398.0 MiB)
[2025-05-07T02:44:50.208+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 82.5 KiB, free 398.0 MiB)
[2025-05-07T02:44:50.209+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 5c5d1775d94e:37761 (size: 82.5 KiB, free: 432.6 MiB)
[2025-05-07T02:44:50.209+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO SparkContext: Created broadcast 120 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T02:44:50.216+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO ShufflePartitionsUtil: For shuffle(65), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T02:44:50.236+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO CodeGenerator: Code generated in 7.159271 ms
[2025-05-07T02:44:50.268+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 5c5d1775d94e:37761 in memory (size: 42.0 KiB, free: 432.6 MiB)
[2025-05-07T02:44:50.269+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.20.0.5:40657 in memory (size: 42.0 KiB, free: 432.1 MiB)
[2025-05-07T02:44:50.274+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 5c5d1775d94e:37761 in memory (size: 44.6 KiB, free: 432.6 MiB)
[2025-05-07T02:44:50.275+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 172.20.0.5:40657 in memory (size: 44.6 KiB, free: 432.2 MiB)
[2025-05-07T02:44:50.276+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 5c5d1775d94e:37761 in memory (size: 3.8 KiB, free: 432.6 MiB)
[2025-05-07T02:44:50.277+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.20.0.5:40657 in memory (size: 3.8 KiB, free: 432.2 MiB)
[2025-05-07T02:44:50.280+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 5c5d1775d94e:37761 in memory (size: 33.2 KiB, free: 432.7 MiB)
[2025-05-07T02:44:50.281+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.20.0.5:40657 in memory (size: 33.2 KiB, free: 432.2 MiB)
[2025-05-07T02:44:50.283+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 5c5d1775d94e:37761 in memory (size: 6.9 KiB, free: 432.7 MiB)
[2025-05-07T02:44:50.283+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.20.0.5:40657 in memory (size: 6.9 KiB, free: 432.2 MiB)
[2025-05-07T02:44:50.285+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 5c5d1775d94e:37761 in memory (size: 49.6 KiB, free: 432.7 MiB)
[2025-05-07T02:44:50.286+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.20.0.5:40657 in memory (size: 49.6 KiB, free: 432.2 MiB)
[2025-05-07T02:44:50.289+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-05-07T02:44:50.289+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Got job 74 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T02:44:50.290+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Final stage: ResultStage 402 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T02:44:50.290+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 401)
[2025-05-07T02:44:50.290+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Missing parents: List()
[2025-05-07T02:44:50.290+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Submitting ResultStage 402 (MapPartitionsRDD[545] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T02:44:50.318+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 203.9 KiB, free 398.4 MiB)
[2025-05-07T02:44:50.319+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 71.9 KiB, free 398.3 MiB)
[2025-05-07T02:44:50.319+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 5c5d1775d94e:37761 (size: 71.9 KiB, free: 432.7 MiB)
[2025-05-07T02:44:50.320+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1474
[2025-05-07T02:44:50.320+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 402 (MapPartitionsRDD[545] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T02:44:50.320+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSchedulerImpl: Adding task set 402.0 with 1 tasks resource profile 0
[2025-05-07T02:44:50.321+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSetManager: Starting task 0.0 in stage 402.0 (TID 568) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T02:44:50.328+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.20.0.5:40657 (size: 71.9 KiB, free: 432.2 MiB)
[2025-05-07T02:44:50.346+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 65 to 172.20.0.5:52776
[2025-05-07T02:44:50.358+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.20.0.5:40657 (size: 20.3 KiB, free: 432.2 MiB)
[2025-05-07T02:44:50.364+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.20.0.5:40657 (size: 82.5 KiB, free: 432.1 MiB)
[2025-05-07T02:44:50.368+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.20.0.5:40657 (size: 22.4 KiB, free: 432.1 MiB)
[2025-05-07T02:44:50.515+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSetManager: Finished task 0.0 in stage 402.0 (TID 568) in 194 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T02:44:50.515+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool
[2025-05-07T02:44:50.515+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: ResultStage 402 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.225 s
[2025-05-07T02:44:50.515+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T02:44:50.515+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 402: Stage finished
[2025-05-07T02:44:50.516+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO DAGScheduler: Job 74 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.226676 s
[2025-05-07T02:44:50.535+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:50,535 [INFO] Анализ графа успешно завершен
[2025-05-07T02:44:50.545+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO SparkUI: Stopped Spark web UI at http://5c5d1775d94e:4040
[2025-05-07T02:44:50.548+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-05-07T02:44:50.548+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2025-05-07T02:44:50.572+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-07T02:44:50.608+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO MemoryStore: MemoryStore cleared
[2025-05-07T02:44:50.609+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManager: BlockManager stopped
[2025-05-07T02:44:50.612+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-07T02:44:50.615+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-07T02:44:50.632+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:50 INFO SparkContext: Successfully stopped SparkContext
[2025-05-07T02:44:51.014+0000] {spark_submit.py:571} INFO - 2025-05-07 02:44:51,013 [INFO] SparkSession остановлена
[2025-05-07T02:44:51.103+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:51 INFO ShutdownHookManager: Shutdown hook called
[2025-05-07T02:44:51.103+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-992f3ae9-878e-4bb7-a636-6ed043c1a517
[2025-05-07T02:44:51.106+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-6f513a46-cc9c-4cc1-a2d9-6dcfe6a5c1c2
[2025-05-07T02:44:51.108+0000] {spark_submit.py:571} INFO - 25/05/07 02:44:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-992f3ae9-878e-4bb7-a636-6ed043c1a517/pyspark-39912651-07d8-4fae-ae9a-cc12eeaa622d
[2025-05-07T02:44:51.198+0000] {taskinstance.py:1345} INFO - Marking task as SUCCESS. dag_id=graph_analysis, task_id=build_graph, execution_date=20250507T024407, start_date=20250507T024415, end_date=20250507T024451
[2025-05-07T02:44:51.238+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2025-05-07T02:44:51.272+0000] {taskinstance.py:2653} INFO - 1 downstream tasks scheduled from follow-on schedule check
