[2025-05-07T21:34:46.648+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-07T21:29:46.443501+00:00 [queued]>
[2025-05-07T21:34:46.654+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-07T21:29:46.443501+00:00 [queued]>
[2025-05-07T21:34:46.655+0000] {taskinstance.py:1308} INFO - Starting attempt 2 of 2
[2025-05-07T21:34:46.668+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): build_graph> on 2025-05-07 21:29:46.443501+00:00
[2025-05-07T21:34:46.673+0000] {standard_task_runner.py:57} INFO - Started process 10283 to run task
[2025-05-07T21:34:46.677+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'graph_analysis', 'build_graph', 'manual__2025-05-07T21:29:46.443501+00:00', '--job-id', '283', '--raw', '--subdir', 'DAGS_FOLDER/graph_analysis.py', '--cfg-path', '/tmp/tmp4kk_86yd']
[2025-05-07T21:34:46.678+0000] {standard_task_runner.py:85} INFO - Job 283: Subtask build_graph
[2025-05-07T21:34:46.693+0000] {logging_mixin.py:150} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-07T21:34:46.730+0000] {task_command.py:410} INFO - Running <TaskInstance: graph_analysis.build_graph manual__2025-05-07T21:29:46.443501+00:00 [running]> on host 3530b0b864fd
[2025-05-07T21:34:46.814+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='finbest' AIRFLOW_CTX_DAG_ID='graph_analysis' AIRFLOW_CTX_TASK_ID='build_graph' AIRFLOW_CTX_EXECUTION_DATE='2025-05-07T21:29:46.443501+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-07T21:29:46.443501+00:00'
[2025-05-07T21:34:46.826+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-05-07T21:34:46.827+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******
[2025-05-07T21:34:46.844+0000] {spark_submit.py:571} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-05-07T21:34:47.803+0000] {spark_submit.py:571} INFO - Using properties file: null
[2025-05-07T21:34:47.868+0000] {spark_submit.py:571} INFO - WARNING: An illegal reflective access operation has occurred
[2025-05-07T21:34:47.869+0000] {spark_submit.py:571} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2025-05-07T21:34:47.869+0000] {spark_submit.py:571} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2025-05-07T21:34:47.869+0000] {spark_submit.py:571} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-05-07T21:34:47.869+0000] {spark_submit.py:571} INFO - WARNING: All illegal access operations will be denied in a future release
[2025-05-07T21:34:47.903+0000] {spark_submit.py:571} INFO - Parsed arguments:
[2025-05-07T21:34:47.903+0000] {spark_submit.py:571} INFO - master                  spark://spark-master:7077
[2025-05-07T21:34:47.903+0000] {spark_submit.py:571} INFO - deployMode              null
[2025-05-07T21:34:47.903+0000] {spark_submit.py:571} INFO - executorMemory          1g
[2025-05-07T21:34:47.903+0000] {spark_submit.py:571} INFO - executorCores           1
[2025-05-07T21:34:47.903+0000] {spark_submit.py:571} INFO - totalExecutorCores      null
[2025-05-07T21:34:47.903+0000] {spark_submit.py:571} INFO - propertiesFile          null
[2025-05-07T21:34:47.903+0000] {spark_submit.py:571} INFO - driverMemory            1g
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - driverCores             null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - driverExtraClassPath    null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - driverExtraLibraryPath  null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - driverExtraJavaOptions  null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - supervise               false
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - queue                   null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - numExecutors            null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - files                   null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - pyFiles                 null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - archives                null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - mainClass               null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - primaryResource         file:/opt/airflow/spark/build_graph.py
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - name                    arrow-spark
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - childArgs               [--jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ***]
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - jars                    null
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - packages                org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12
[2025-05-07T21:34:47.904+0000] {spark_submit.py:571} INFO - packagesExclusions      null
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - repositories            null
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - verbose                 true
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - Spark properties used, including those specified through
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - --conf and those from the properties file null:
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:34:47.905+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:34:48.005+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-07T21:34:48.075+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-05-07T21:34:48.076+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-05-07T21:34:48.082+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql added as a dependency
[2025-05-07T21:34:48.083+0000] {spark_submit.py:571} INFO - graphframes#graphframes added as a dependency
[2025-05-07T21:34:48.084+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-4fc9d348-dad6-4823-b46f-901aeb0aa73b;1.0
[2025-05-07T21:34:48.084+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-07T21:34:48.237+0000] {spark_submit.py:571} INFO - found org.postgresql#postgresql;42.6.0 in central
[2025-05-07T21:34:48.255+0000] {spark_submit.py:571} INFO - found org.checkerframework#checker-qual;3.31.0 in central
[2025-05-07T21:34:48.277+0000] {spark_submit.py:571} INFO - found graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages
[2025-05-07T21:34:48.302+0000] {spark_submit.py:571} INFO - found org.slf4j#slf4j-api;1.7.16 in central
[2025-05-07T21:34:48.321+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 231ms :: artifacts dl 6ms
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - graphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - org.checkerframework#checker-qual;3.31.0 from central in [default]
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql;42.6.0 from central in [default]
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - org.slf4j#slf4j-api;1.7.16 from central in [default]
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
[2025-05-07T21:34:48.322+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T21:34:48.328+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-4fc9d348-dad6-4823-b46f-901aeb0aa73b
[2025-05-07T21:34:48.328+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-07T21:34:48.334+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 4 already retrieved (0kB/7ms)
[2025-05-07T21:34:48.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-07T21:34:48.695+0000] {spark_submit.py:571} INFO - Main class:
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - org.apache.spark.deploy.PythonRunner
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - Arguments:
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - file:/opt/airflow/spark/build_graph.py
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - --jdbc
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - jdbc:postgresql://postgres:5432/finbest
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - --user
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - finbest
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - --password
[2025-05-07T21:34:48.696+0000] {spark_submit.py:571} INFO - ***
[2025-05-07T21:34:48.698+0000] {spark_submit.py:571} INFO - Spark config:
[2025-05-07T21:34:48.698+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-07T21:34:48.698+0000] {spark_submit.py:571} INFO - (spark.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T21:34:48.698+0000] {spark_submit.py:571} INFO - (spark.app.name,arrow-spark)
[2025-05-07T21:34:48.698+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-07T21:34:48.698+0000] {spark_submit.py:571} INFO - (spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,/home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,/home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,/home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T21:34:48.698+0000] {spark_submit.py:571} INFO - (spark.files,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T21:34:48.698+0000] {spark_submit.py:571} INFO - (spark.submit.deployMode,client)
[2025-05-07T21:34:48.698+0000] {spark_submit.py:571} INFO - (spark.master,spark://spark-master:7077)
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - (spark.executor.memory,1g)
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - (spark.executor.cores,1)
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - (spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - Classpath elements:
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:34:48.699+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:34:49.886+0000] {spark_submit.py:571} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2025-05-07T21:34:49.891+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO SparkContext: Running Spark version 3.2.4
[2025-05-07T21:34:49.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO ResourceUtils: ==============================================================
[2025-05-07T21:34:49.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-07T21:34:49.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO ResourceUtils: ==============================================================
[2025-05-07T21:34:49.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO SparkContext: Submitted application: FinBestGraphAnalysis
[2025-05-07T21:34:49.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-07T21:34:49.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-05-07T21:34:49.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-07T21:34:49.991+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO SecurityManager: Changing view acls to: airflow
[2025-05-07T21:34:49.991+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO SecurityManager: Changing modify acls to: airflow
[2025-05-07T21:34:49.991+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO SecurityManager: Changing view acls groups to:
[2025-05-07T21:34:49.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO SecurityManager: Changing modify acls groups to:
[2025-05-07T21:34:49.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(airflow); groups with view permissions: Set(); users  with modify permissions: Set(airflow); groups with modify permissions: Set()
[2025-05-07T21:34:50.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO Utils: Successfully started service 'sparkDriver' on port 45715.
[2025-05-07T21:34:50.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkEnv: Registering MapOutputTracker
[2025-05-07T21:34:50.279+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-07T21:34:50.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-07T21:34:50.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-07T21:34:50.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-07T21:34:50.322+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9307724f-0274-42a9-837e-2d69deb35d02
[2025-05-07T21:34:50.341+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-07T21:34:50.355+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-07T21:34:50.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-07T21:34:50.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://3530b0b864fd:4040
[2025-05-07T21:34:50.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://3530b0b864fd:45715/jars/org.postgresql_postgresql-42.6.0.jar with timestamp 1746653689884
[2025-05-07T21:34:50.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://3530b0b864fd:45715/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746653689884
[2025-05-07T21:34:50.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://3530b0b864fd:45715/jars/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746653689884
[2025-05-07T21:34:50.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://3530b0b864fd:45715/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746653689884
[2025-05-07T21:34:50.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://3530b0b864fd:45715/files/org.postgresql_postgresql-42.6.0.jar with timestamp 1746653689884
[2025-05-07T21:34:50.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO Utils: Copying /home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar to /tmp/spark-f267d2b8-753f-4e5d-a947-43ac110363f1/userFiles-dcc8b2c2-ced8-4c1b-ba96-1d190fdb11dc/org.postgresql_postgresql-42.6.0.jar
[2025-05-07T21:34:50.595+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://3530b0b864fd:45715/files/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746653689884
[2025-05-07T21:34:50.596+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO Utils: Copying /home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar to /tmp/spark-f267d2b8-753f-4e5d-a947-43ac110363f1/userFiles-dcc8b2c2-ced8-4c1b-ba96-1d190fdb11dc/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-07T21:34:50.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://3530b0b864fd:45715/files/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746653689884
[2025-05-07T21:34:50.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO Utils: Copying /home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar to /tmp/spark-f267d2b8-753f-4e5d-a947-43ac110363f1/userFiles-dcc8b2c2-ced8-4c1b-ba96-1d190fdb11dc/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-07T21:34:50.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://3530b0b864fd:45715/files/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746653689884
[2025-05-07T21:34:50.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO Utils: Copying /home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-f267d2b8-753f-4e5d-a947-43ac110363f1/userFiles-dcc8b2c2-ced8-4c1b-ba96-1d190fdb11dc/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T21:34:50.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-05-07T21:34:50.769+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.2:7077 after 22 ms (0 ms spent in bootstraps)
[2025-05-07T21:34:50.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250507213450-0005
[2025-05-07T21:34:50.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36239.
[2025-05-07T21:34:50.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO NettyBlockTransferService: Server created on 3530b0b864fd:36239
[2025-05-07T21:34:50.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250507213450-0005/0 on worker-20250507121535-172.20.0.5-41865 (172.20.0.5:41865) with 1 core(s)
[2025-05-07T21:34:50.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-07T21:34:50.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO StandaloneSchedulerBackend: Granted executor ID app-20250507213450-0005/0 on hostPort 172.20.0.5:41865 with 1 core(s), 1024.0 MiB RAM
[2025-05-07T21:34:50.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 3530b0b864fd, 36239, None)
[2025-05-07T21:34:50.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO BlockManagerMasterEndpoint: Registering block manager 3530b0b864fd:36239 with 434.4 MiB RAM, BlockManagerId(driver, 3530b0b864fd, 36239, None)
[2025-05-07T21:34:50.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 3530b0b864fd, 36239, None)
[2025-05-07T21:34:50.865+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 3530b0b864fd, 36239, None)
[2025-05-07T21:34:50.888+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:50 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507213450-0005/0 is now RUNNING
[2025-05-07T21:34:51.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:51 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-05-07T21:34:51.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:51 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-07T21:34:51.219+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:51 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-05-07T21:34:51.910+0000] {spark_submit.py:571} INFO - 2025-05-07 21:34:51,910 [INFO] SparkSession создана
[2025-05-07T21:34:51.910+0000] {spark_submit.py:571} INFO - 2025-05-07 21:34:51,910 [INFO] Загружаем клиентов и транзакции
[2025-05-07T21:34:53.324+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:53 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:52056) with ID 0,  ResourceProfileId 0
[2025-05-07T21:34:54.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:54 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:34941 with 434.4 MiB RAM, BlockManagerId(0, 172.20.0.5, 34941, None)
[2025-05-07T21:34:55.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:55 INFO CodeGenerator: Code generated in 91.694828 ms
[2025-05-07T21:34:56.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-05-07T21:34:56.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:34:56.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:34:56.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:34:56.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:34:56.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:34:56.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-07T21:34:56.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-07T21:34:56.150+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 3530b0b864fd:36239 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:56.152+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:34:56.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:34:56.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-07T21:34:56.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:34:56.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.5:34941 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1020 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:34:57.202+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-07T21:34:57.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.155 s
[2025-05-07T21:34:57.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:34:57.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: running: Set()
[2025-05-07T21:34:57.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:34:57.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: failed: Set()
[2025-05-07T21:34:57.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO CodeGenerator: Code generated in 8.383043 ms
[2025-05-07T21:34:57.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-07T21:34:57.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:34:57.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:34:57.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-07T21:34:57.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:34:57.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:34:57.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-07T21:34:57.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-07T21:34:57.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 3530b0b864fd:36239 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:34:57.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:34:57.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-07T21:34:57.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:34:57.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.20.0.5:52056
[2025-05-07T21:34:57.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 249 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:34:57.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-07T21:34:57.562+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.264 s
[2025-05-07T21:34:57.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:34:57.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-07T21:34:57.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.286501 s
[2025-05-07T21:34:57.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Registering RDD 8 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-05-07T21:34:57.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:34:57.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:34:57.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:34:57.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:34:57.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:34:57.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-07T21:34:57.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.3 MiB)
[2025-05-07T21:34:57.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 3530b0b864fd:36239 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:34:57.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:34:57.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-05-07T21:34:57.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:34:57.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.0.5:34941 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 42 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:34:57.669+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-07T21:34:57.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.051 s
[2025-05-07T21:34:57.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:34:57.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: running: Set()
[2025-05-07T21:34:57.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:34:57.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: failed: Set()
[2025-05-07T21:34:57.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-07T21:34:57.692+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:34:57.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:34:57.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-07T21:34:57.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:34:57.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:34:57.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-07T21:34:57.700+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.3 MiB)
[2025-05-07T21:34:57.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 3530b0b864fd:36239 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:34:57.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:34:57.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-07T21:34:57.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:34:57.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.20.0.5:52056
[2025-05-07T21:34:57.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 31 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:34:57.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-07T21:34:57.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.039 s
[2025-05-07T21:34:57.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:34:57.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-05-07T21:34:57.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.044983 s
[2025-05-07T21:34:57.737+0000] {spark_submit.py:571} INFO - 2025-05-07 21:34:57,737 [INFO] Загружено 4652 транзакций и 1200 клиентов
[2025-05-07T21:34:57.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 3530b0b864fd:36239 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.5:34941 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 3530b0b864fd:36239 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.0.5:34941 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 3530b0b864fd:36239 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.5:34941 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 3530b0b864fd:36239 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.0.5:34941 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:57.920+0000] {spark_submit.py:571} INFO - 2025-05-07 21:34:57,920 [INFO] Создаем вершины двудольного графа
[2025-05-07T21:34:58.281+0000] {spark_submit.py:571} INFO - 2025-05-07 21:34:58,281 [INFO] Создаем ATM-хабы
[2025-05-07T21:34:58.476+0000] {spark_submit.py:571} INFO - 2025-05-07 21:34:58,476 [INFO] Объединяем ребра двудольного графа
[2025-05-07T21:34:58.568+0000] {spark_submit.py:571} INFO - 2025-05-07 21:34:58,567 [INFO] Создаем P2P-слой
[2025-05-07T21:34:58.603+0000] {spark_submit.py:571} INFO - 2025-05-07 21:34:58,602 [INFO] Создаем проекцию клиент-клиент
[2025-05-07T21:34:59.151+0000] {spark_submit.py:571} INFO - 2025-05-07 21:34:59,151 [INFO] Вычисляем метрики графа
[2025-05-07T21:34:59.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO CodeGenerator: Code generated in 14.530268 ms
[2025-05-07T21:34:59.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Registering RDD 15 (rdd at GraphFrame.scala:187) as input to shuffle 2
[2025-05-07T21:34:59.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Got map stage job 4 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-07T21:34:59.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (rdd at GraphFrame.scala:187)
[2025-05-07T21:34:59.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:34:59.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:34:59.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:34:59.476+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
[2025-05-07T21:34:59.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.4 MiB)
[2025-05-07T21:34:59.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 3530b0b864fd:36239 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T21:34:59.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:34:59.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:34:59.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-05-07T21:34:59.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:34:59.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.5:34941 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T21:34:59.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 230 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:34:59.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-05-07T21:34:59.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: ShuffleMapStage 6 (rdd at GraphFrame.scala:187) finished in 0.243 s
[2025-05-07T21:34:59.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:34:59.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: running: Set()
[2025-05-07T21:34:59.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:34:59.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: failed: Set()
[2025-05-07T21:34:59.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:34:59.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:34:59.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:34:59.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:34:59.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-07T21:34:59.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:34:59.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:34:59.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-07T21:34:59.759+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-07T21:34:59.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:59.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:34:59.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:34:59.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-07T21:34:59.762+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:34:59.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.5:34941 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:59.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.20.0.5:52056
[2025-05-07T21:34:59.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 35 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:34:59.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-07T21:34:59.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.041 s
[2025-05-07T21:34:59.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:34:59.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-07T21:34:59.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.044126 s
[2025-05-07T21:34:59.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 3530b0b864fd:36239 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T21:34:59.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.5:34941 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T21:34:59.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:59.827+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.0.5:34941 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:59.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO CodeGenerator: Code generated in 11.41886 ms
[2025-05-07T21:34:59.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-07T21:34:59.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.8 KiB, free 432.3 MiB)
[2025-05-07T21:34:59.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 3530b0b864fd:36239 (size: 28.8 KiB, free: 434.4 MiB)
[2025-05-07T21:34:59.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO SparkContext: Created broadcast 6 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:34:59.887+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO CodeGenerator: Code generated in 11.552838 ms
[2025-05-07T21:34:59.890+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:34:59.891+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:34:59.933+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO CodeGenerator: Code generated in 33.918295 ms
[2025-05-07T21:34:59.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO CodeGenerator: Code generated in 7.578419 ms
[2025-05-07T21:34:59.977+0000] {spark_submit.py:571} INFO - 25/05/07 21:34:59 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#995 - id.nullCount#994) > 0)
[2025-05-07T21:35:00.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 6.753822 ms
[2025-05-07T21:35:00.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 5.525381 ms
[2025-05-07T21:35:00.516+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 5.924908 ms
[2025-05-07T21:35:00.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 14.411527 ms
[2025-05-07T21:35:00.546+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 4.904322 ms
[2025-05-07T21:35:00.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 9.174501 ms
[2025-05-07T21:35:00.762+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 8.117677 ms
[2025-05-07T21:35:00.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 8.149989 ms
[2025-05-07T21:35:00.788+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 6.78014 ms
[2025-05-07T21:35:00.800+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 8.268286 ms
[2025-05-07T21:35:00.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 11.473152 ms
[2025-05-07T21:35:00.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Registering RDD 60 (collect at GraphFrame.scala:574) as input to shuffle 4
[2025-05-07T21:35:00.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Got map stage job 6 (collect at GraphFrame.scala:574) with 6 output partitions
[2025-05-07T21:35:00.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:00.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:00.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:00.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:00.848+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 36.4 KiB, free 432.3 MiB)
[2025-05-07T21:35:00.849+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 11.337914 ms
[2025-05-07T21:35:00.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 432.3 MiB)
[2025-05-07T21:35:00.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 3530b0b864fd:36239 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T21:35:00.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:00.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:35:00.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO TaskSchedulerImpl: Adding task set 9.0 with 6 tasks resource profile 0
[2025-05-07T21:35:00.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Registering RDD 62 (collect at GraphFrame.scala:574) as input to shuffle 5
[2025-05-07T21:35:00.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Got map stage job 7 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:35:00.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:00.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:00.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:00.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:00.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:00.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:00.861+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.6 KiB, free 432.3 MiB)
[2025-05-07T21:35:00.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 432.2 MiB)
[2025-05-07T21:35:00.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:35:00.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:00.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:00.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2025-05-07T21:35:00.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.5:34941 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T21:35:00.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 33.740044 ms
[2025-05-07T21:35:00.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Registering RDD 64 (collect at GraphFrame.scala:574) as input to shuffle 6
[2025-05-07T21:35:00.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Got map stage job 8 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:35:00.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:00.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:00.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:00.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:00.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:00.938+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 27.3 KiB, free 432.2 MiB)
[2025-05-07T21:35:00.939+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.2 MiB)
[2025-05-07T21:35:00.940+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T21:35:00.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:00.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:00.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-05-07T21:35:00.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO CodeGenerator: Code generated in 33.117437 ms
[2025-05-07T21:35:00.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:00.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Registering RDD 66 (collect at GraphFrame.scala:574) as input to shuffle 7
[2025-05-07T21:35:00.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Got map stage job 9 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:35:00.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:00.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:00.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:00.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:00 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:01.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 28.5 KiB, free 432.2 MiB)
[2025-05-07T21:35:01.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 432.2 MiB)
[2025-05-07T21:35:01.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 3530b0b864fd:36239 (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-07T21:35:01.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:01.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 7) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:01.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:01.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-05-07T21:35:01.045+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 191 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:35:01.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO CodeGenerator: Code generated in 72.087328 ms
[2025-05-07T21:35:01.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Registering RDD 68 (collect at GraphFrame.scala:574) as input to shuffle 8
[2025-05-07T21:35:01.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Got map stage job 10 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:35:01.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:01.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:01.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:01.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:01.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:01.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-07T21:35:01.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 432.1 MiB)
[2025-05-07T21:35:01.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:35:01.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:01.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:01.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-05-07T21:35:01.119+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO CodeGenerator: Code generated in 42.642008 ms
[2025-05-07T21:35:01.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:01.138+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Registering RDD 70 (collect at GraphFrame.scala:574) as input to shuffle 9
[2025-05-07T21:35:01.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Got map stage job 11 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:35:01.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:01.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:01.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:01.150+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:01.156+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 27.4 KiB, free 432.1 MiB)
[2025-05-07T21:35:01.156+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 8) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:01.157+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 7) in 117 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:35:01.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.1 MiB)
[2025-05-07T21:35:01.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T21:35:01.191+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:01.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:01.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-05-07T21:35:01.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO CodeGenerator: Code generated in 84.173661 ms
[2025-05-07T21:35:01.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Registering RDD 72 (collect at GraphFrame.scala:574) as input to shuffle 10
[2025-05-07T21:35:01.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Got map stage job 12 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:35:01.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:01.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:01.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:01.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:01.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:01.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-07T21:35:01.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 9) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:01.283+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 8) in 129 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:35:01.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 432.0 MiB)
[2025-05-07T21:35:01.304+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:35:01.304+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:01.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:01.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-05-07T21:35:01.324+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO CodeGenerator: Code generated in 50.283116 ms
[2025-05-07T21:35:01.341+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Registering RDD 74 (collect at GraphFrame.scala:574) as input to shuffle 11
[2025-05-07T21:35:01.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Got map stage job 13 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:35:01.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:01.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:01.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:01.347+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:01.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.7 KiB, free 432.0 MiB)
[2025-05-07T21:35:01.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 432.0 MiB)
[2025-05-07T21:35:01.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 3530b0b864fd:36239 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:01.381+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:01.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:01.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-05-07T21:35:01.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 10) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:01.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 9) in 112 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:35:01.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 11) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:01.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 10) in 112 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:35:01.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 12) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:01.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 11) in 477 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:35:01.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-05-07T21:35:01.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: ShuffleMapStage 9 (collect at GraphFrame.scala:574) finished in 1.133 s
[2025-05-07T21:35:01.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:01.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 10, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-07T21:35:01.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:01.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:01.990+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.5:34941 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:35:01.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:01 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:02.001+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:02.037+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 13) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:02.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 12) in 70 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:02.045+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-05-07T21:35:02.045+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: ShuffleMapStage 10 (collect at GraphFrame.scala:574) finished in 1.185 s
[2025-05-07T21:35:02.046+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:02.046+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-07T21:35:02.046+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:02.046+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:02.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:02.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:35:02.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Final stage: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:35:02.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-05-07T21:35:02.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:02.075+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:35:02.076+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T21:35:02.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.5:34941 (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:35:02.095+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-07T21:35:02.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:35:02.099+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:02.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 3530b0b864fd:36239 in memory (size: 11.2 KiB, free: 434.3 MiB)
[2025-05-07T21:35:02.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:02.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-05-07T21:35:02.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.20.0.5:34941 in memory (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T21:35:02.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:02.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-07T21:35:02.141+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.20.0.5:34941 in memory (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:35:02.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:02.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:35:02.168+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Final stage: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:35:02.168+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2025-05-07T21:35:02.168+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:02.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:35:02.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T21:35:02.185+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-07T21:35:02.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:35:02.191+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:02.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:02.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2025-05-07T21:35:02.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 14) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:02.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 13) in 333 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:02.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-05-07T21:35:02.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: ShuffleMapStage 11 (collect at GraphFrame.scala:574) finished in 1.444 s
[2025-05-07T21:35:02.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:02.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T21:35:02.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:02.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:02.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.5:34941 (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T21:35:02.489+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 15) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:02.493+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 14) in 122 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:02.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-05-07T21:35:02.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: ShuffleMapStage 12 (collect at GraphFrame.scala:574) finished in 1.503 s
[2025-05-07T21:35:02.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:02.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T21:35:02.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:02.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:02.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.5:34941 (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T21:35:02.577+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 16) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:02.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 15) in 90 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:02.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-05-07T21:35:02.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: ShuffleMapStage 13 (collect at GraphFrame.scala:574) finished in 1.512 s
[2025-05-07T21:35:02.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:02.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T21:35:02.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:02.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:02.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.5:34941 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T21:35:02.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 17) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:02.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 16) in 109 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:02.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-05-07T21:35:02.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: ShuffleMapStage 14 (collect at GraphFrame.scala:574) finished in 1.539 s
[2025-05-07T21:35:02.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:02.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-07T21:35:02.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:02.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:02.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.5:34941 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:35:02.790+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:02.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 17) in 106 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:02.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-07T21:35:02.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: ShuffleMapStage 15 (collect at GraphFrame.scala:574) finished in 1.528 s
[2025-05-07T21:35:02.792+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:02.792+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: running: Set(ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-07T21:35:02.792+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:02.792+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:02.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:34941 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:02.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 19) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:02.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 132 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:02.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-05-07T21:35:02.922+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: ShuffleMapStage 16 (collect at GraphFrame.scala:574) finished in 1.578 s
[2025-05-07T21:35:02.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:02.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: running: Set(ResultStage 20, ResultStage 18)
[2025-05-07T21:35:02.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:02.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:02.937+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.20.0.5:34941 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:35:02.940+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO ShufflePartitionsUtil: For shuffle(6, 7, 8, 9, 10, 11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:02.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.20.0.5:52056
[2025-05-07T21:35:02.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO CodeGenerator: Code generated in 5.013952 ms
[2025-05-07T21:35:02.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:02.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:02.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 19) in 77 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:02.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-05-07T21:35:02.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.927 s
[2025-05-07T21:35:03.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:03.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-05-07T21:35:03.003+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.933769 s
[2025-05-07T21:35:03.010+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO CodeGenerator: Code generated in 17.474021 ms
[2025-05-07T21:35:03.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO CodeGenerator: Code generated in 13.356356 ms
[2025-05-07T21:35:03.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.20.0.5:34941 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:35:03.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:03.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:52056
[2025-05-07T21:35:03.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 59 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:03.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-05-07T21:35:03.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO CodeGenerator: Code generated in 17.205015 ms
[2025-05-07T21:35:03.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.885 s
[2025-05-07T21:35:03.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:03.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2025-05-07T21:35:03.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.890210 s
[2025-05-07T21:35:03.059+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:03.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 2.1 MiB, free 430.0 MiB)
[2025-05-07T21:35:03.076+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.20.0.5:34941 in memory (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-07T21:35:03.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 3530b0b864fd:36239 in memory (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-07T21:35:03.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 430.0 MiB)
[2025-05-07T21:35:03.080+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 3530b0b864fd:36239 (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-07T21:35:03.080+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:03.080+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 5.0 MiB, free 425.0 MiB)
[2025-05-07T21:35:03.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO CodeGenerator: Code generated in 28.21253 ms
[2025-05-07T21:35:03.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 3530b0b864fd:36239 in memory (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:03.102+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:03.103+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.20.0.5:34941 in memory (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:03.112+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 424.6 MiB)
[2025-05-07T21:35:03.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 3530b0b864fd:36239 (size: 502.1 KiB, free: 433.8 MiB)
[2025-05-07T21:35:03.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO SparkContext: Created broadcast 18 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:03.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO CodeGenerator: Code generated in 13.495721 ms
[2025-05-07T21:35:03.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.20.0.5:34941 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:35:03.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T21:35:03.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 433.8 MiB)
[2025-05-07T21:35:03.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:03.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.20.0.5:34941 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T21:35:03.157+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO CodeGenerator: Code generated in 12.276474 ms
[2025-05-07T21:35:03.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T21:35:03.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.20.0.5:34941 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:35:03.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:03.170+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 433.8 MiB)
[2025-05-07T21:35:03.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.20.0.5:34941 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:35:03.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO CodeGenerator: Code generated in 10.938061 ms
[2025-05-07T21:35:03.180+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 433.8 MiB)
[2025-05-07T21:35:03.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.20.0.5:34941 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:35:03.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 433.9 MiB)
[2025-05-07T21:35:03.199+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.20.0.5:34941 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T21:35:03.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:03.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Got job 16 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T21:35:03.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Final stage: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:35:03.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24, ShuffleMapStage 21, ShuffleMapStage 25, ShuffleMapStage 22, ShuffleMapStage 26, ShuffleMapStage 23)
[2025-05-07T21:35:03.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:03.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[105] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:35:03.209+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 91.7 KiB, free 424.6 MiB)
[2025-05-07T21:35:03.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 424.6 MiB)
[2025-05-07T21:35:03.219+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 3530b0b864fd:36239 (size: 30.3 KiB, free: 433.8 MiB)
[2025-05-07T21:35:03.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:03.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 27 (MapPartitionsRDD[105] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:35:03.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSchedulerImpl: Adding task set 27.0 with 6 tasks resource profile 0
[2025-05-07T21:35:03.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:03.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.20.0.5:34941 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T21:35:03.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.20.0.5:52056
[2025-05-07T21:35:03.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 22) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:03.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 68 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:35:03.304+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.20.0.5:52056
[2025-05-07T21:35:03.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 23) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:03.341+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 22) in 53 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:35:03.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.20.0.5:52056
[2025-05-07T21:35:03.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 24) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:03.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 23) in 52 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:35:03.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.20.0.5:52056
[2025-05-07T21:35:03.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 25) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:03.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 24) in 65 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:35:03.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.20.0.5:52056
[2025-05-07T21:35:03.578+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 26) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:03.578+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 25) in 130 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:35:03.608+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:52056
[2025-05-07T21:35:03.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 26) in 80 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:35:03.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-05-07T21:35:03.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.452 s
[2025-05-07T21:35:03.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:03.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-05-07T21:35:03.661+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO DAGScheduler: Job 16 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.456953 s
[2025-05-07T21:35:03.714+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 3530b0b864fd:36239 in memory (size: 30.3 KiB, free: 433.9 MiB)
[2025-05-07T21:35:03.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 2.3 MiB, free 422.4 MiB)
[2025-05-07T21:35:03.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.20.0.5:34941 in memory (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T21:35:03.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 422.4 MiB)
[2025-05-07T21:35:03.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 3530b0b864fd:36239 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T21:35:03.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO SparkContext: Created broadcast 20 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:03.925+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO CodeGenerator: Code generated in 59.42417 ms
[2025-05-07T21:35:03.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:03.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:03 INFO CodeGenerator: Code generated in 33.622639 ms
[2025-05-07T21:35:04.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO CodeGenerator: Code generated in 4.160253 ms
[2025-05-07T21:35:04.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Registering RDD 112 (collect at GraphFrame.scala:574) as input to shuffle 12
[2025-05-07T21:35:04.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Got map stage job 17 (collect at GraphFrame.scala:574) with 11 output partitions
[2025-05-07T21:35:04.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:04.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
[2025-05-07T21:35:04.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:04.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:04.060+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 141.0 KiB, free 422.2 MiB)
[2025-05-07T21:35:04.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 49.7 KiB, free 422.2 MiB)
[2025-05-07T21:35:04.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 3530b0b864fd:36239 (size: 49.7 KiB, free: 433.7 MiB)
[2025-05-07T21:35:04.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:04.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T21:35:04.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSchedulerImpl: Adding task set 29.0 with 11 tasks resource profile 0
[2025-05-07T21:35:04.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 27) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.20.0.5:34941 (size: 49.7 KiB, free: 434.4 MiB)
[2025-05-07T21:35:04.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:52056
[2025-05-07T21:35:04.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.20.0.5:34941 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-07T21:35:04.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.20.0.5:34941 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T21:35:04.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.20.0.5:34941 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T21:35:04.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 28) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 27) in 349 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T21:35:04.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 29) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 28) in 60 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T21:35:04.517+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 30) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 29) in 37 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T21:35:04.577+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 31) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.577+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 30) in 62 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T21:35:04.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 32) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 31) in 42 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T21:35:04.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 6.0 in stage 29.0 (TID 33) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 32) in 39 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-07T21:35:04.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 7.0 in stage 29.0 (TID 34) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.697+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 6.0 in stage 29.0 (TID 33) in 43 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-07T21:35:04.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 8.0 in stage 29.0 (TID 35) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 7.0 in stage 29.0 (TID 34) in 34 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-07T21:35:04.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 9.0 in stage 29.0 (TID 36) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 8.0 in stage 29.0 (TID 35) in 36 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-07T21:35:04.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 10.0 in stage 29.0 (TID 37) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 9.0 in stage 29.0 (TID 36) in 39 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-07T21:35:04.887+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Finished task 10.0 in stage 29.0 (TID 37) in 84 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-07T21:35:04.888+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-05-07T21:35:04.888+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: ShuffleMapStage 29 (collect at GraphFrame.scala:574) finished in 0.833 s
[2025-05-07T21:35:04.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:04.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:04.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:04.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:04.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:04.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:04.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO CodeGenerator: Code generated in 27.518489 ms
[2025-05-07T21:35:04.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Registering RDD 115 (collect at GraphFrame.scala:574) as input to shuffle 13
[2025-05-07T21:35:04.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Got map stage job 18 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:35:04.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:04.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
[2025-05-07T21:35:04.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:04.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[115] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:04.982+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 129.7 KiB, free 422.1 MiB)
[2025-05-07T21:35:04.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 44.3 KiB, free 422.0 MiB)
[2025-05-07T21:35:04.994+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 3530b0b864fd:36239 (size: 44.3 KiB, free: 433.7 MiB)
[2025-05-07T21:35:04.994+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:04.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[115] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:04.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-05-07T21:35:04.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 38) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:04.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 3530b0b864fd:36239 in memory (size: 49.7 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.20.0.5:34941 in memory (size: 49.7 KiB, free: 433.8 MiB)
[2025-05-07T21:35:05.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.20.0.5:34941 (size: 44.3 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:52056
[2025-05-07T21:35:05.158+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 38) in 162 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:05.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-05-07T21:35:05.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: ShuffleMapStage 32 (collect at GraphFrame.scala:574) finished in 0.182 s
[2025-05-07T21:35:05.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:05.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:05.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:05.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:05.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:05.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:05.197+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO CodeGenerator: Code generated in 11.13976 ms
[2025-05-07T21:35:05.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO SparkContext: Starting job: collect at GraphFrame.scala:574
[2025-05-07T21:35:05.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Got job 19 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:35:05.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Final stage: ResultStage 36 (collect at GraphFrame.scala:574)
[2025-05-07T21:35:05.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-05-07T21:35:05.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:05.222+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[118] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:35:05.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 122.6 KiB, free 422.1 MiB)
[2025-05-07T21:35:05.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 422.0 MiB)
[2025-05-07T21:35:05.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 3530b0b864fd:36239 (size: 41.8 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 3530b0b864fd:36239 in memory (size: 44.3 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:05.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.20.0.5:34941 in memory (size: 44.3 KiB, free: 433.8 MiB)
[2025-05-07T21:35:05.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[118] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:05.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-05-07T21:35:05.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 39) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:05.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.20.0.5:34941 (size: 41.8 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:52056
[2025-05-07T21:35:05.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 39) in 90 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:05.338+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-05-07T21:35:05.338+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: ResultStage 36 (collect at GraphFrame.scala:574) finished in 0.115 s
[2025-05-07T21:35:05.338+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:05.338+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-05-07T21:35:05.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Job 19 finished: collect at GraphFrame.scala:574, took 0.118876 s
[2025-05-07T21:35:05.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 3530b0b864fd:36239 in memory (size: 41.8 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.556+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.20.0.5:34941 in memory (size: 41.8 KiB, free: 433.8 MiB)
[2025-05-07T21:35:05.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Registering RDD 149 (rdd at GraphFrame.scala:188) as input to shuffle 14
[2025-05-07T21:35:05.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Got map stage job 20 (rdd at GraphFrame.scala:188) with 6 output partitions
[2025-05-07T21:35:05.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:05.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:05.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:05.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:05.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 36.4 KiB, free 422.3 MiB)
[2025-05-07T21:35:05.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:05.905+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 422.3 MiB)
[2025-05-07T21:35:05.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 3530b0b864fd:36239 (size: 11.2 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:05.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:35:05.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSchedulerImpl: Adding task set 37.0 with 6 tasks resource profile 0
[2025-05-07T21:35:05.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Registering RDD 151 (rdd at GraphFrame.scala:188) as input to shuffle 15
[2025-05-07T21:35:05.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Got map stage job 21 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:35:05.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:05.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:05.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:05.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 40) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:05.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:05.916+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:05.918+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 12.6 KiB, free 422.3 MiB)
[2025-05-07T21:35:05.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 422.3 MiB)
[2025-05-07T21:35:05.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:05.925+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:05.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
[2025-05-07T21:35:05.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.20.0.5:34941 (size: 11.2 KiB, free: 433.8 MiB)
[2025-05-07T21:35:05.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Registering RDD 153 (rdd at GraphFrame.scala:188) as input to shuffle 16
[2025-05-07T21:35:05.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Got map stage job 22 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:35:05.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:05.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:05.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:05.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:05.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:05.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 27.3 KiB, free 422.3 MiB)
[2025-05-07T21:35:05.937+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 422.3 MiB)
[2025-05-07T21:35:05.939+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:05.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:05.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-05-07T21:35:05.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Registering RDD 155 (rdd at GraphFrame.scala:188) as input to shuffle 17
[2025-05-07T21:35:05.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Got map stage job 23 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:35:05.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:05.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:05.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:05.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[155] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:05.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:05.948+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-07T21:35:05.949+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 422.2 MiB)
[2025-05-07T21:35:05.949+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 3530b0b864fd:36239 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.949+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:05.949+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[155] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:05.949+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-05-07T21:35:05.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Registering RDD 157 (rdd at GraphFrame.scala:188) as input to shuffle 18
[2025-05-07T21:35:05.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Got map stage job 24 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:35:05.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:05.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:05.955+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:05.955+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:05.959+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[157] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:05.963+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-07T21:35:05.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 422.2 MiB)
[2025-05-07T21:35:05.965+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 3530b0b864fd:36239 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:35:05.965+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:05.966+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[157] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:05.967+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-05-07T21:35:05.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:05.986+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Registering RDD 159 (rdd at GraphFrame.scala:188) as input to shuffle 19
[2025-05-07T21:35:05.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Got map stage job 25 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:35:05.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:05.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:05.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:05.990+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 41) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:05.994+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[159] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:05.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 40) in 89 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:35:05.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:05 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 3530b0b864fd:36239 in memory (size: 502.1 KiB, free: 434.2 MiB)
[2025-05-07T21:35:06.006+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 27.4 KiB, free 427.7 MiB)
[2025-05-07T21:35:06.006+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 427.6 MiB)
[2025-05-07T21:35:06.006+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.20.0.5:34941 in memory (size: 502.1 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.006+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 434.2 MiB)
[2025-05-07T21:35:06.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:06.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[159] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:06.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-05-07T21:35:06.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Registering RDD 161 (rdd at GraphFrame.scala:188) as input to shuffle 20
[2025-05-07T21:35:06.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Got map stage job 26 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:35:06.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:06.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:06.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:06.013+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[161] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:06.015+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 28.5 KiB, free 427.6 MiB)
[2025-05-07T21:35:06.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 427.6 MiB)
[2025-05-07T21:35:06.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 434.2 MiB)
[2025-05-07T21:35:06.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:06.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[161] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:06.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
[2025-05-07T21:35:06.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Registering RDD 163 (rdd at GraphFrame.scala:188) as input to shuffle 21
[2025-05-07T21:35:06.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Got map stage job 27 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:35:06.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Final stage: ShuffleMapStage 44 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:06.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:06.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:06.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[163] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:06.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 31.7 KiB, free 429.6 MiB)
[2025-05-07T21:35:06.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 3530b0b864fd:36239 in memory (size: 20.6 KiB, free: 434.2 MiB)
[2025-05-07T21:35:06.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.20.0.5:34941 in memory (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 429.6 MiB)
[2025-05-07T21:35:06.029+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 3530b0b864fd:36239 (size: 14.9 KiB, free: 434.2 MiB)
[2025-05-07T21:35:06.029+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:06.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[163] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:06.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-05-07T21:35:06.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 3530b0b864fd:36239 in memory (size: 114.2 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.046+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.20.0.5:34941 in memory (size: 114.2 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.051+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 42) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 41) in 63 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:35:06.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 43) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 42) in 37 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:35:06.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 44) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 43) in 37 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:35:06.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 45) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 44) in 36 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:35:06.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 46) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.211+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 45) in 51 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:35:06.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.213+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ShuffleMapStage 37 (rdd at GraphFrame.scala:188) finished in 0.315 s
[2025-05-07T21:35:06.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:06.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: running: Set(ShuffleMapStage 38, ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T21:35:06.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:06.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:06.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.20.0.5:34941 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:06.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:06.262+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 47) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 46) in 53 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:06.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ShuffleMapStage 38 (rdd at GraphFrame.scala:188) finished in 0.351 s
[2025-05-07T21:35:06.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:06.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: running: Set(ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T21:35:06.268+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:06.269+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:06.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:06.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:35:06.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Final stage: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:35:06.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
[2025-05-07T21:35:06.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:06.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[166] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:35:06.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T21:35:06.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 432.0 MiB)
[2025-05-07T21:35:06.281+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 3530b0b864fd:36239 (size: 3.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:06.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[166] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:06.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-05-07T21:35:06.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.291+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.20.0.5:34941 in memory (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.20.0.5:34941 (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 3530b0b864fd:36239 in memory (size: 11.2 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.20.0.5:34941 in memory (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:06.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:06.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:06.323+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:06.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:35:06.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:35:06.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-05-07T21:35:06.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:06.343+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[169] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:35:06.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 48) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 47) in 85 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:06.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T21:35:06.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-07T21:35:06.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.347+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:06.347+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[169] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:06.347+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-05-07T21:35:06.350+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ShuffleMapStage 39 (rdd at GraphFrame.scala:188) finished in 0.418 s
[2025-05-07T21:35:06.350+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:06.350+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T21:35:06.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:06.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:06.356+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.20.0.5:34941 (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 49) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 48) in 44 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:06.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ShuffleMapStage 40 (rdd at GraphFrame.scala:188) finished in 0.442 s
[2025-05-07T21:35:06.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:06.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T21:35:06.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:06.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:06.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.20.0.5:34941 (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.419+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 50) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 49) in 34 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:06.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ShuffleMapStage 41 (rdd at GraphFrame.scala:188) finished in 0.464 s
[2025-05-07T21:35:06.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:06.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-07T21:35:06.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:06.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:06.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.20.0.5:34941 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 51) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 50) in 45 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:06.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ShuffleMapStage 42 (rdd at GraphFrame.scala:188) finished in 0.471 s
[2025-05-07T21:35:06.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:06.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-07T21:35:06.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:06.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:06.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.20.0.5:34941 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 52) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 51) in 56 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:06.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ShuffleMapStage 43 (rdd at GraphFrame.scala:188) finished in 0.509 s
[2025-05-07T21:35:06.522+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:06.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 44)
[2025-05-07T21:35:06.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:06.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:06.538+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.20.0.5:34941 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 53) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 52) in 66 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:06.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ShuffleMapStage 44 (rdd at GraphFrame.scala:188) finished in 0.562 s
[2025-05-07T21:35:06.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:06.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46)
[2025-05-07T21:35:06.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:06.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:06.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.20.0.5:34941 (size: 3.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO ShufflePartitionsUtil: For shuffle(16, 17, 18, 19, 20, 21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:06.608+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:52056
[2025-05-07T21:35:06.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO CodeGenerator: Code generated in 4.149329 ms
[2025-05-07T21:35:06.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:06.635+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 54) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO CodeGenerator: Code generated in 9.066673 ms
[2025-05-07T21:35:06.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 53) in 52 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:06.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.369 s
[2025-05-07T21:35:06.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:06.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
[2025-05-07T21:35:06.639+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.372337 s
[2025-05-07T21:35:06.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:06.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 3530b0b864fd:36239 in memory (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.20.0.5:34941 in memory (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.20.0.5:34941 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:52056
[2025-05-07T21:35:06.667+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO CodeGenerator: Code generated in 11.345258 ms
[2025-05-07T21:35:06.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 3530b0b864fd:36239 in memory (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.20.0.5:34941 in memory (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 54) in 40 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:06.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-05-07T21:35:06.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.333 s
[2025-05-07T21:35:06.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:06.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-05-07T21:35:06.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.20.0.5:34941 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:06.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.359172 s
[2025-05-07T21:35:06.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 5.0 MiB, free 427.2 MiB)
[2025-05-07T21:35:06.689+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 2.1 MiB, free 425.1 MiB)
[2025-05-07T21:35:06.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 3530b0b864fd:36239 in memory (size: 3.9 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 425.1 MiB)
[2025-05-07T21:35:06.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.20.0.5:34941 in memory (size: 3.9 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 3530b0b864fd:36239 (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-07T21:35:06.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:06.704+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:06.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 424.6 MiB)
[2025-05-07T21:35:06.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 3530b0b864fd:36239 (size: 502.1 KiB, free: 433.8 MiB)
[2025-05-07T21:35:06.712+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Created broadcast 34 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:06.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 3530b0b864fd:36239 in memory (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-07T21:35:06.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.20.0.5:34941 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO CodeGenerator: Code generated in 23.635369 ms
[2025-05-07T21:35:06.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.20.0.5:34941 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 433.8 MiB)
[2025-05-07T21:35:06.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 433.9 MiB)
[2025-05-07T21:35:06.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.20.0.5:34941 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:06.771+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO CodeGenerator: Code generated in 14.090425 ms
[2025-05-07T21:35:06.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:06.785+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO CodeGenerator: Code generated in 9.266291 ms
[2025-05-07T21:35:06.802+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:06.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T21:35:06.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:35:06.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 49, ShuffleMapStage 53, ShuffleMapStage 50, ShuffleMapStage 54)
[2025-05-07T21:35:06.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:06.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[192] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:35:06.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 91.7 KiB, free 424.6 MiB)
[2025-05-07T21:35:06.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 424.6 MiB)
[2025-05-07T21:35:06.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 3530b0b864fd:36239 (size: 30.3 KiB, free: 433.8 MiB)
[2025-05-07T21:35:06.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:06.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 55 (MapPartitionsRDD[192] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:35:06.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSchedulerImpl: Adding task set 55.0 with 6 tasks resource profile 0
[2025-05-07T21:35:06.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T21:35:06.823+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.20.0.5:34941 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.20.0.5:34941 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T21:35:06.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:52056
[2025-05-07T21:35:06.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 56) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 52 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:35:06.891+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:52056
[2025-05-07T21:35:06.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 57) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 56) in 40 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:35:06.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:52056
[2025-05-07T21:35:06.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 58) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 57) in 23 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:35:06.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.20.0.5:52056
[2025-05-07T21:35:06.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Starting task 4.0 in stage 55.0 (TID 59) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:06.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 58) in 41 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:35:06.983+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.20.0.5:52056
[2025-05-07T21:35:07.005+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 5.0 in stage 55.0 (TID 60) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.006+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 4.0 in stage 55.0 (TID 59) in 32 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:35:07.015+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.20.0.5:52056
[2025-05-07T21:35:07.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 5.0 in stage 55.0 (TID 60) in 46 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:35:07.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-05-07T21:35:07.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.244 s
[2025-05-07T21:35:07.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:07.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-05-07T21:35:07.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.250904 s
[2025-05-07T21:35:07.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 2.3 MiB, free 422.4 MiB)
[2025-05-07T21:35:07.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 422.3 MiB)
[2025-05-07T21:35:07.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 3530b0b864fd:36239 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T21:35:07.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO SparkContext: Created broadcast 37 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:07.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:07.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO CodeGenerator: Code generated in 35.064199 ms
[2025-05-07T21:35:07.202+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO CodeGenerator: Code generated in 8.982666 ms
[2025-05-07T21:35:07.209+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: Registering RDD 199 (rdd at GraphFrame.scala:188) as input to shuffle 22
[2025-05-07T21:35:07.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: Got map stage job 31 (rdd at GraphFrame.scala:188) with 11 output partitions
[2025-05-07T21:35:07.211+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: Final stage: ShuffleMapStage 57 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:07.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-05-07T21:35:07.213+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:07.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[199] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:07.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 129.6 KiB, free 422.1 MiB)
[2025-05-07T21:35:07.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 45.0 KiB, free 422.1 MiB)
[2025-05-07T21:35:07.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 3530b0b864fd:36239 (size: 45.0 KiB, free: 433.7 MiB)
[2025-05-07T21:35:07.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:07.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[199] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T21:35:07.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSchedulerImpl: Adding task set 57.0 with 11 tasks resource profile 0
[2025-05-07T21:35:07.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 61) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 3530b0b864fd:36239 in memory (size: 30.3 KiB, free: 433.7 MiB)
[2025-05-07T21:35:07.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.20.0.5:34941 in memory (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T21:35:07.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.20.0.5:34941 (size: 45.0 KiB, free: 434.4 MiB)
[2025-05-07T21:35:07.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:52056
[2025-05-07T21:35:07.356+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.20.0.5:34941 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-07T21:35:07.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.20.0.5:34941 (size: 114.2 KiB, free: 433.8 MiB)
[2025-05-07T21:35:07.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:34941 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T21:35:07.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 62) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.431+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 61) in 187 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T21:35:07.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 63) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 62) in 49 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T21:35:07.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 64) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.536+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 63) in 59 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T21:35:07.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 4.0 in stage 57.0 (TID 65) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 64) in 39 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T21:35:07.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 5.0 in stage 57.0 (TID 66) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 4.0 in stage 57.0 (TID 65) in 32 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T21:35:07.641+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 6.0 in stage 57.0 (TID 67) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.642+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 5.0 in stage 57.0 (TID 66) in 36 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-07T21:35:07.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 7.0 in stage 57.0 (TID 68) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.661+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 6.0 in stage 57.0 (TID 67) in 20 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-07T21:35:07.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 8.0 in stage 57.0 (TID 69) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 7.0 in stage 57.0 (TID 68) in 24 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-07T21:35:07.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 9.0 in stage 57.0 (TID 70) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.704+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 8.0 in stage 57.0 (TID 69) in 20 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-07T21:35:07.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Starting task 10.0 in stage 57.0 (TID 71) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:07.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:07 INFO TaskSetManager: Finished task 9.0 in stage 57.0 (TID 70) in 29 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-07T21:35:08.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 10.0 in stage 57.0 (TID 71) in 270 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-07T21:35:08.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-05-07T21:35:08.003+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: ShuffleMapStage 57 (rdd at GraphFrame.scala:188) finished in 0.785 s
[2025-05-07T21:35:08.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:08.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:08.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:08.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:08.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:08.047+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO CodeGenerator: Code generated in 11.449978 ms
[2025-05-07T21:35:08.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:08.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Got job 32 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:35:08.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Final stage: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:35:08.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
[2025-05-07T21:35:08.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:08.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[203] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:35:08.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 116.0 KiB, free 422.1 MiB)
[2025-05-07T21:35:08.094+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 422.1 MiB)
[2025-05-07T21:35:08.095+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 3530b0b864fd:36239 (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.096+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 3530b0b864fd:36239 in memory (size: 45.0 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.098+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:08.099+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[203] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:08.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
[2025-05-07T21:35:08.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.20.0.5:34941 in memory (size: 45.0 KiB, free: 433.8 MiB)
[2025-05-07T21:35:08.104+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 72) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.120+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.20.0.5:34941 (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.20.0.5:52056
[2025-05-07T21:35:08.213+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 72) in 112 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:08.213+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-07T21:35:08.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.139 s
[2025-05-07T21:35:08.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:08.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
[2025-05-07T21:35:08.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Job 32 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.141528 s
[2025-05-07T21:35:08.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 2.0 MiB, free 420.2 MiB)
[2025-05-07T21:35:08.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 3530b0b864fd:36239 in memory (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 96.0 KiB, free 420.2 MiB)
[2025-05-07T21:35:08.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 3530b0b864fd:36239 (size: 96.0 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.20.0.5:34941 in memory (size: 39.3 KiB, free: 433.8 MiB)
[2025-05-07T21:35:08.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO SparkContext: Created broadcast 40 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:08.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO CodeGenerator: Code generated in 33.838394 ms
[2025-05-07T21:35:08.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1534 - id.nullCount#1533) > 0)
[2025-05-07T21:35:08.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Registering RDD 19 (rdd at GraphFrame.scala:187) as input to shuffle 3
[2025-05-07T21:35:08.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Registering RDD 208 (rdd at GraphFrame.scala:188) as input to shuffle 23
[2025-05-07T21:35:08.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Got map stage job 33 (rdd at GraphFrame.scala:188) with 10 output partitions
[2025-05-07T21:35:08.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (rdd at GraphFrame.scala:188)
[2025-05-07T21:35:08.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
[2025-05-07T21:35:08.316+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
[2025-05-07T21:35:08.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:35:08.322+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.6 KiB, free 420.2 MiB)
[2025-05-07T21:35:08.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 420.2 MiB)
[2025-05-07T21:35:08.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:08.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:08.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
[2025-05-07T21:35:08.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 73) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.352+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.20.0.5:34941 (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-07T21:35:08.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 73) in 67 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:08.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool
[2025-05-07T21:35:08.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: ShuffleMapStage 61 (rdd at GraphFrame.scala:187) finished in 0.084 s
[2025-05-07T21:35:08.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:08.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:08.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 62)
[2025-05-07T21:35:08.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:08.407+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[208] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:35:08.425+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 51.0 KiB, free 420.2 MiB)
[2025-05-07T21:35:08.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 420.2 MiB)
[2025-05-07T21:35:08.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 3530b0b864fd:36239 (size: 21.7 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:08.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[208] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:08.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Adding task set 62.0 with 10 tasks resource profile 0
[2025-05-07T21:35:08.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 74) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.20.0.5:34941 (size: 21.7 KiB, free: 433.8 MiB)
[2025-05-07T21:35:08.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:52056
[2025-05-07T21:35:08.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.20.0.5:34941 (size: 2.0 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.20.0.5:34941 (size: 96.0 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 75) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 74) in 188 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:08.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.20.0.5:34941 (size: 2.5 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 76) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 75) in 48 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:08.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 77) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.706+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 76) in 35 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:08.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.20.0.5:34941 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 4.0 in stage 62.0 (TID 78) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.738+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 77) in 33 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:08.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.20.0.5:34941 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.769+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 5.0 in stage 62.0 (TID 79) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.770+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 4.0 in stage 62.0 (TID 78) in 33 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:08.786+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.20.0.5:34941 (size: 2.0 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 6.0 in stage 62.0 (TID 80) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 5.0 in stage 62.0 (TID 79) in 29 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:08.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.20.0.5:34941 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 7.0 in stage 62.0 (TID 81) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.823+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 6.0 in stage 62.0 (TID 80) in 26 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:08.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.20.0.5:34941 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 8.0 in stage 62.0 (TID 82) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 7.0 in stage 62.0 (TID 81) in 34 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:08.887+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.20.0.5:34941 (size: 2.4 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 9.0 in stage 62.0 (TID 83) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 8.0 in stage 62.0 (TID 82) in 42 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:08.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.20.0.5:34941 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.922+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 9.0 in stage 62.0 (TID 83) in 27 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:08.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-05-07T21:35:08.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: ShuffleMapStage 62 (rdd at GraphFrame.scala:188) finished in 0.513 s
[2025-05-07T21:35:08.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:08.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:08.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:08.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:08.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:08.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:08.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Got job 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:35:08.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Final stage: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:35:08.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
[2025-05-07T21:35:08.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:08.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[210] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:35:08.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.2 KiB, free 420.2 MiB)
[2025-05-07T21:35:08.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 420.1 MiB)
[2025-05-07T21:35:08.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:08.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[210] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:08.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
[2025-05-07T21:35:08.955+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.20.0.5:34941 in memory (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.955+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 84) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:08.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 3530b0b864fd:36239 in memory (size: 21.7 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.959+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.20.0.5:34941 in memory (size: 21.7 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.962+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.20.0.5:34941 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T21:35:08.965+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.20.0.5:52056
[2025-05-07T21:35:08.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 84) in 17 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:08.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool
[2025-05-07T21:35:08.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.030 s
[2025-05-07T21:35:08.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:08.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
[2025-05-07T21:35:08.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO DAGScheduler: Job 34 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.031748 s
[2025-05-07T21:35:08.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 2.0 MiB, free 418.2 MiB)
[2025-05-07T21:35:08.978+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 98.0 KiB, free 418.1 MiB)
[2025-05-07T21:35:08.978+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 3530b0b864fd:36239 (size: 98.0 KiB, free: 433.6 MiB)
[2025-05-07T21:35:08.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:08 INFO SparkContext: Created broadcast 44 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:35:09.006+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO CodeGenerator: Code generated in 8.718878 ms
[2025-05-07T21:35:09.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1544 - id.nullCount#1543) > 0)
[2025-05-07T21:35:09.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-07T21:35:09.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Registering RDD 31 (map at GraphFrame.scala:187) as input to shuffle 25
[2025-05-07T21:35:09.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Registering RDD 223 (mapPartitions at VertexRDD.scala:356) as input to shuffle 28
[2025-05-07T21:35:09.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Registering RDD 249 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 26
[2025-05-07T21:35:09.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Registering RDD 245 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 24
[2025-05-07T21:35:09.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Registering RDD 253 (mapPartitions at GraphImpl.scala:208) as input to shuffle 27
[2025-05-07T21:35:09.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Got job 35 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-07T21:35:09.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Final stage: ResultStage 72 (fold at VertexRDDImpl.scala:90)
[2025-05-07T21:35:09.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-07T21:35:09.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-07T21:35:09.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[31] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:35:09.122+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 59.1 KiB, free 418.1 MiB)
[2025-05-07T21:35:09.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 418.0 MiB)
[2025-05-07T21:35:09.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 3530b0b864fd:36239 (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:09.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 433.5 MiB)
[2025-05-07T21:35:09.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:09.129+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[31] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:09.129+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO TaskSchedulerImpl: Adding task set 67.0 with 10 tasks resource profile 0
[2025-05-07T21:35:09.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.20.0.5:34941 in memory (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T21:35:09.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Submitting ShuffleMapStage 68 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[223] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-07T21:35:09.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 85) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:09.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.20.0.5:34941 (size: 26.0 KiB, free: 433.6 MiB)
[2025-05-07T21:35:09.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 158.2 KiB, free 417.9 MiB)
[2025-05-07T21:35:09.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 55.6 KiB, free 417.8 MiB)
[2025-05-07T21:35:09.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 3530b0b864fd:36239 (size: 55.6 KiB, free: 433.5 MiB)
[2025-05-07T21:35:09.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:09.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 68 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[223] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:09.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO TaskSchedulerImpl: Adding task set 68.0 with 10 tasks resource profile 0
[2025-05-07T21:35:09.273+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.5:34941 (size: 28.8 KiB, free: 433.6 MiB)
[2025-05-07T21:35:10.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 86) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 85) in 967 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:10.120+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 87) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.121+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 86) in 23 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:10.138+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 88) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.138+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 2.0 in stage 67.0 (TID 87) in 18 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:10.156+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 4.0 in stage 67.0 (TID 89) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.156+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 3.0 in stage 67.0 (TID 88) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:10.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 5.0 in stage 67.0 (TID 90) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 4.0 in stage 67.0 (TID 89) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:10.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 6.0 in stage 67.0 (TID 91) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 5.0 in stage 67.0 (TID 90) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:10.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 7.0 in stage 67.0 (TID 92) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 6.0 in stage 67.0 (TID 91) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:10.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 8.0 in stage 67.0 (TID 93) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 7.0 in stage 67.0 (TID 92) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:10.239+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 9.0 in stage 67.0 (TID 94) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 8.0 in stage 67.0 (TID 93) in 20 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:10.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 95) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 9.0 in stage 67.0 (TID 94) in 23 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:10.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool
[2025-05-07T21:35:10.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: ShuffleMapStage 67 (map at GraphFrame.scala:187) finished in 1.151 s
[2025-05-07T21:35:10.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:10.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: running: Set(ShuffleMapStage 68)
[2025-05-07T21:35:10.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-07T21:35:10.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:10.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:34941 (size: 55.6 KiB, free: 433.6 MiB)
[2025-05-07T21:35:10.375+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.20.0.5:34941 (size: 98.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:10.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 96) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 95) in 206 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:10.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 97) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 96) in 30 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:10.522+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 98) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 97) in 26 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:10.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 4.0 in stage 68.0 (TID 99) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.550+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 98) in 27 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:10.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 5.0 in stage 68.0 (TID 100) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 4.0 in stage 68.0 (TID 99) in 19 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:10.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 6.0 in stage 68.0 (TID 101) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 5.0 in stage 68.0 (TID 100) in 18 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:10.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 7.0 in stage 68.0 (TID 102) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.604+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 6.0 in stage 68.0 (TID 101) in 19 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:10.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 8.0 in stage 68.0 (TID 103) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 7.0 in stage 68.0 (TID 102) in 26 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:10.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 9.0 in stage 68.0 (TID 104) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 8.0 in stage 68.0 (TID 103) in 31 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:10.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Finished task 9.0 in stage 68.0 (TID 104) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:10.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool
[2025-05-07T21:35:10.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: ShuffleMapStage 68 (mapPartitions at VertexRDD.scala:356) finished in 1.543 s
[2025-05-07T21:35:10.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:10.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:10.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-07T21:35:10.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:10.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: Submitting ShuffleMapStage 70 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[245] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:10.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 10.3 KiB, free 417.8 MiB)
[2025-05-07T21:35:10.700+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.8 MiB)
[2025-05-07T21:35:10.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 3530b0b864fd:36239 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:10.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:10.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 3530b0b864fd:36239 in memory (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:10.704+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 70 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[245] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:10.704+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSchedulerImpl: Adding task set 70.0 with 10 tasks resource profile 0
[2025-05-07T21:35:10.704+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: Submitting ShuffleMapStage 69 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[249] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:10.706+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 9.9 KiB, free 417.9 MiB)
[2025-05-07T21:35:10.706+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 105) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:10.708+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 417.9 MiB)
[2025-05-07T21:35:10.708+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.20.0.5:34941 in memory (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:10.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 3530b0b864fd:36239 (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-07T21:35:10.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:10.721+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 69 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[249] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:10.721+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO TaskSchedulerImpl: Adding task set 69.0 with 10 tasks resource profile 0
[2025-05-07T21:35:10.724+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.20.0.5:34941 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:10.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.20.0.5:52056
[2025-05-07T21:35:10.810+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 3530b0b864fd:36239 in memory (size: 55.6 KiB, free: 433.6 MiB)
[2025-05-07T21:35:10.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.20.0.5:34941 in memory (size: 55.6 KiB, free: 433.5 MiB)
[2025-05-07T21:35:10.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.20.0.5:52056
[2025-05-07T21:35:11.012+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_0 in memory on 172.20.0.5:34941 (size: 18.6 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_0 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 106) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 105) in 335 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:11.047+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.20.0.5:34941 (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 107) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 106) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:11.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_1 in memory on 172.20.0.5:34941 (size: 18.6 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_1 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.093+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 108) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.093+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 107) in 36 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:11.115+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_2 in memory on 172.20.0.5:34941 (size: 18.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.119+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_2 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.121+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.129+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 109) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 108) in 37 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:11.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_3 in memory on 172.20.0.5:34941 (size: 18.2 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.150+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_3 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.153+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 110) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 109) in 30 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:11.176+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_4 in memory on 172.20.0.5:34941 (size: 18.8 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_4 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.180+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.183+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:11.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 111) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.190+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 110) in 30 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:11.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_5 in memory on 172.20.0.5:34941 (size: 18.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.209+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_5 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 6.0 in stage 69.0 (TID 112) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.222+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 111) in 33 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:11.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_6 in memory on 172.20.0.5:34941 (size: 18.4 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_6 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 7.0 in stage 69.0 (TID 113) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 6.0 in stage 69.0 (TID 112) in 29 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:11.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_7 in memory on 172.20.0.5:34941 (size: 18.4 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_7 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.276+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:35:11.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 8.0 in stage 69.0 (TID 114) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 7.0 in stage 69.0 (TID 113) in 46 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:11.311+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_8 in memory on 172.20.0.5:34941 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-07T21:35:11.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_8 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T21:35:11.317+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:35:11.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:35:11.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 9.0 in stage 69.0 (TID 115) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 8.0 in stage 69.0 (TID 114) in 32 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:11.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_226_9 in memory on 172.20.0.5:34941 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-07T21:35:11.347+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_231_9 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T21:35:11.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_237_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:35:11.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_241_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:35:11.358+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 116) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 9.0 in stage 69.0 (TID 115) in 32 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:11.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-07T21:35:11.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: ShuffleMapStage 69 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.654 s
[2025-05-07T21:35:11.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:11.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: running: Set(ShuffleMapStage 70)
[2025-05-07T21:35:11.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-07T21:35:11.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:11.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 117) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 116) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:11.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 118) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.377+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 117) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:11.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 119) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 118) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:11.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 5.0 in stage 70.0 (TID 120) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 119) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:11.407+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 6.0 in stage 70.0 (TID 121) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.408+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 5.0 in stage 70.0 (TID 120) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:11.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 7.0 in stage 70.0 (TID 122) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 6.0 in stage 70.0 (TID 121) in 6 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:11.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 8.0 in stage 70.0 (TID 123) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 7.0 in stage 70.0 (TID 122) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:11.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 9.0 in stage 70.0 (TID 124) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 8.0 in stage 70.0 (TID 123) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:11.438+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 9.0 in stage 70.0 (TID 124) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:11.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-05-07T21:35:11.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: ShuffleMapStage 70 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.762 s
[2025-05-07T21:35:11.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:11.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:11.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-07T21:35:11.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:11.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: Submitting ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[253] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:11.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 162.8 KiB, free 417.9 MiB)
[2025-05-07T21:35:11.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 57.6 KiB, free 417.9 MiB)
[2025-05-07T21:35:11.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 3530b0b864fd:36239 in memory (size: 4.9 KiB, free: 433.6 MiB)
[2025-05-07T21:35:11.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 3530b0b864fd:36239 (size: 57.6 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:11.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[253] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:11.455+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSchedulerImpl: Adding task set 71.0 with 10 tasks resource profile 0
[2025-05-07T21:35:11.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.20.0.5:34941 in memory (size: 4.9 KiB, free: 433.2 MiB)
[2025-05-07T21:35:11.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 125) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.463+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.20.0.5:34941 (size: 57.6 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.517+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.522+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.20.0.5:52056
[2025-05-07T21:35:11.538+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.20.0.5:52056
[2025-05-07T21:35:11.552+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 3530b0b864fd:36239 in memory (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.553+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.20.0.5:34941 in memory (size: 5.0 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 126) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 125) in 105 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:11.577+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.581+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 127) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 126) in 42 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:11.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.620+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 128) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 127) in 28 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:11.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 129) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 128) in 35 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:11.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.692+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.697+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 130) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 129) in 34 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:11.713+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.720+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 6.0 in stage 71.0 (TID 131) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 130) in 30 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:11.749+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.754+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 7.0 in stage 71.0 (TID 132) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.765+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 6.0 in stage 71.0 (TID 131) in 37 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:11.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.795+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 8.0 in stage 71.0 (TID 133) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 7.0 in stage 71.0 (TID 132) in 40 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:11.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.823+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.827+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 9.0 in stage 71.0 (TID 134) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.827+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 8.0 in stage 71.0 (TID 133) in 24 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:11.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_229_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.843+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_233_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_239_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_247_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 9.0 in stage 71.0 (TID 134) in 28 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:11.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-05-07T21:35:11.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: ShuffleMapStage 71 (mapPartitions at GraphImpl.scala:208) finished in 0.415 s
[2025-05-07T21:35:11.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:11.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:11.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: waiting: Set(ResultStage 72)
[2025-05-07T21:35:11.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:11.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[257] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-07T21:35:11.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 11.2 KiB, free 417.9 MiB)
[2025-05-07T21:35:11.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.9 MiB)
[2025-05-07T21:35:11.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 3530b0b864fd:36239 (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T21:35:11.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:11.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 72 (MapPartitionsRDD[257] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:11.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSchedulerImpl: Adding task set 72.0 with 10 tasks resource profile 0
[2025-05-07T21:35:11.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 135) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.20.0.5:34941 (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.20.0.5:52056
[2025-05-07T21:35:11.879+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_0 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 136) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 135) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:11.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_1 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.1 MiB)
[2025-05-07T21:35:11.891+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 137) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 136) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:11.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_2 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:35:11.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 138) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 137) in 7 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:11.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_3 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:35:11.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 4.0 in stage 72.0 (TID 139) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 138) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:11.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_4 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:35:11.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 5.0 in stage 72.0 (TID 140) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 4.0 in stage 72.0 (TID 139) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:11.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_5 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:35:11.931+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 6.0 in stage 72.0 (TID 141) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.932+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 5.0 in stage 72.0 (TID 140) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:11.939+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_6 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:35:11.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 7.0 in stage 72.0 (TID 142) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 6.0 in stage 72.0 (TID 141) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:11.947+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_7 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:35:11.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 8.0 in stage 72.0 (TID 143) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 7.0 in stage 72.0 (TID 142) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:11.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_8 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:35:11.959+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Starting task 9.0 in stage 72.0 (TID 144) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:11.960+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 8.0 in stage 72.0 (TID 143) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:11.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManagerInfo: Added rdd_255_9 in memory on 172.20.0.5:34941 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:35:11.967+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSetManager: Finished task 9.0 in stage 72.0 (TID 144) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:11.968+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-05-07T21:35:11.968+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: ResultStage 72 (fold at VertexRDDImpl.scala:90) finished in 0.111 s
[2025-05-07T21:35:11.968+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:11.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-05-07T21:35:11.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO DAGScheduler: Job 35 finished: fold at VertexRDDImpl.scala:90, took 2.861071 s
[2025-05-07T21:35:11.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO ZippedPartitionsRDD2: Removing RDD 255 from persistence list
[2025-05-07T21:35:11.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:11 INFO BlockManager: Removing RDD 255
[2025-05-07T21:35:12.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManager: Removing RDD 247
[2025-05-07T21:35:12.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManager: Removing RDD 255
[2025-05-07T21:35:12.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 3530b0b864fd:36239 in memory (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T21:35:12.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:12.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.20.0.5:34941 in memory (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Registering RDD 260 (mapPartitions at GraphImpl.scala:208) as input to shuffle 30
[2025-05-07T21:35:12.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Registering RDD 278 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 31
[2025-05-07T21:35:12.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Registering RDD 268 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 29
[2025-05-07T21:35:12.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Registering RDD 282 (mapPartitions at GraphImpl.scala:208) as input to shuffle 33
[2025-05-07T21:35:12.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Registering RDD 290 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 32
[2025-05-07T21:35:12.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Got job 36 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:12.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Final stage: ResultStage 81 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:12.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78, ShuffleMapStage 73, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T21:35:12.219+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 3530b0b864fd:36239 in memory (size: 57.6 KiB, free: 433.6 MiB)
[2025-05-07T21:35:12.219+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T21:35:12.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Submitting ShuffleMapStage 75 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[260] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:12.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.20.0.5:34941 in memory (size: 57.6 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.224+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 161.1 KiB, free 418.0 MiB)
[2025-05-07T21:35:12.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 56.8 KiB, free 417.9 MiB)
[2025-05-07T21:35:12.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 3530b0b864fd:36239 (size: 56.8 KiB, free: 433.5 MiB)
[2025-05-07T21:35:12.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:12.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 75 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[260] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:12.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSchedulerImpl: Adding task set 75.0 with 10 tasks resource profile 0
[2025-05-07T21:35:12.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 145) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.20.0.5:34941 (size: 56.8 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 146) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 145) in 23 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:12.271+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 147) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 146) in 19 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:12.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 148) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 147) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:12.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 149) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 148) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:12.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 5.0 in stage 75.0 (TID 150) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 4.0 in stage 75.0 (TID 149) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:12.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 6.0 in stage 75.0 (TID 151) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 5.0 in stage 75.0 (TID 150) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:12.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 7.0 in stage 75.0 (TID 152) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 6.0 in stage 75.0 (TID 151) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:12.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 8.0 in stage 75.0 (TID 153) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 7.0 in stage 75.0 (TID 152) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:12.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 9.0 in stage 75.0 (TID 154) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 8.0 in stage 75.0 (TID 153) in 25 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:12.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 9.0 in stage 75.0 (TID 154) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:12.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool
[2025-05-07T21:35:12.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: ShuffleMapStage 75 (mapPartitions at GraphImpl.scala:208) finished in 0.179 s
[2025-05-07T21:35:12.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:12.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:12.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 78, ShuffleMapStage 79, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T21:35:12.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:12.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Submitting ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[268] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:12.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 10.1 KiB, free 417.9 MiB)
[2025-05-07T21:35:12.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.9 MiB)
[2025-05-07T21:35:12.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 3530b0b864fd:36239 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:12.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:12.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[268] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:12.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSchedulerImpl: Adding task set 78.0 with 10 tasks resource profile 0
[2025-05-07T21:35:12.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 155) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Submitting ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[278] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:12.419+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 10.7 KiB, free 417.9 MiB)
[2025-05-07T21:35:12.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.9 MiB)
[2025-05-07T21:35:12.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 3530b0b864fd:36239 (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T21:35:12.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:12.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[278] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:12.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSchedulerImpl: Adding task set 77.0 with 10 tasks resource profile 0
[2025-05-07T21:35:12.426+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.20.0.5:34941 (size: 5.0 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.20.0.5:52056
[2025-05-07T21:35:12.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_0 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 156) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 155) in 50 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:12.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.20.0.5:34941 (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.486+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 157) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.486+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 156) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:12.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_1 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 158) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 157) in 20 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:12.524+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_2 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:35:12.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.530+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 159) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.531+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 158) in 27 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:12.540+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_3 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.546+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 4.0 in stage 77.0 (TID 160) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.546+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 159) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:12.556+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_4 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.558+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.562+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 5.0 in stage 77.0 (TID 161) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 4.0 in stage 77.0 (TID 160) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:12.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_5 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 6.0 in stage 77.0 (TID 162) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 5.0 in stage 77.0 (TID 161) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:12.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_6 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.597+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 7.0 in stage 77.0 (TID 163) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 6.0 in stage 77.0 (TID 162) in 19 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:12.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_7 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 8.0 in stage 77.0 (TID 164) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 7.0 in stage 77.0 (TID 163) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:12.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_8 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.631+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 9.0 in stage 77.0 (TID 165) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 8.0 in stage 77.0 (TID 164) in 19 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:12.645+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_264_9 in memory on 172.20.0.5:34941 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.646+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_274_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 166) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 9.0 in stage 77.0 (TID 165) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:12.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool
[2025-05-07T21:35:12.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: ShuffleMapStage 77 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.238 s
[2025-05-07T21:35:12.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:12.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: running: Set(ShuffleMapStage 78)
[2025-05-07T21:35:12.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-07T21:35:12.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:12.661+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 167) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.661+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 166) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:12.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 168) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 167) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:12.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 169) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 168) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:12.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 5.0 in stage 78.0 (TID 170) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 169) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:12.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 6.0 in stage 78.0 (TID 171) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 5.0 in stage 78.0 (TID 170) in 6 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:12.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 7.0 in stage 78.0 (TID 172) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 6.0 in stage 78.0 (TID 171) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:12.708+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 8.0 in stage 78.0 (TID 173) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 7.0 in stage 78.0 (TID 172) in 7 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:12.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 9.0 in stage 78.0 (TID 174) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 8.0 in stage 78.0 (TID 173) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:12.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 9.0 in stage 78.0 (TID 174) in 18 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:12.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-05-07T21:35:12.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: ShuffleMapStage 78 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.329 s
[2025-05-07T21:35:12.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:12.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:12.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-07T21:35:12.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:12.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Submitting ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[282] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:12.741+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 163.7 KiB, free 417.7 MiB)
[2025-05-07T21:35:12.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.7 MiB)
[2025-05-07T21:35:12.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 3530b0b864fd:36239 in memory (size: 56.8 KiB, free: 433.6 MiB)
[2025-05-07T21:35:12.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 3530b0b864fd:36239 (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:12.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:12.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[282] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:12.754+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSchedulerImpl: Adding task set 79.0 with 10 tasks resource profile 0
[2025-05-07T21:35:12.754+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.20.0.5:34941 in memory (size: 56.8 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.754+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 175) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 3530b0b864fd:36239 in memory (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T21:35:12.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.20.0.5:34941 in memory (size: 5.3 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.20.0.5:34941 (size: 58.0 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_266_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:52056
[2025-05-07T21:35:12.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_276_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:52056
[2025-05-07T21:35:12.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 176) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.812+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 175) in 39 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:12.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_266_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_276_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.824+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 177) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.824+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 176) in 35 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:12.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_266_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_276_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 178) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 177) in 28 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:12.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_266_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_276_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 4.0 in stage 79.0 (TID 179) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 178) in 26 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:12.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_266_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_276_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 5.0 in stage 79.0 (TID 180) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 4.0 in stage 79.0 (TID 179) in 20 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:12.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_266_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_276_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 6.0 in stage 79.0 (TID 181) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 5.0 in stage 79.0 (TID 180) in 23 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:12.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_266_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_276_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 7.0 in stage 79.0 (TID 182) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 6.0 in stage 79.0 (TID 181) in 23 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:12.955+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_266_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.959+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_276_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:35:12.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 8.0 in stage 79.0 (TID 183) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 7.0 in stage 79.0 (TID 182) in 34 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:12.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_266_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:12.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO BlockManagerInfo: Added rdd_276_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:12.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Starting task 9.0 in stage 79.0 (TID 184) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:12.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:12 INFO TaskSetManager: Finished task 8.0 in stage 79.0 (TID 183) in 21 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:13.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_266_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.015+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_276_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 9.0 in stage 79.0 (TID 184) in 27 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:13.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-05-07T21:35:13.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: ShuffleMapStage 79 (mapPartitions at GraphImpl.scala:208) finished in 0.286 s
[2025-05-07T21:35:13.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:13.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:13.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 80)
[2025-05-07T21:35:13.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:13.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[290] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:13.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 12.0 KiB, free 417.9 MiB)
[2025-05-07T21:35:13.034+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 417.9 MiB)
[2025-05-07T21:35:13.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 3530b0b864fd:36239 (size: 5.7 KiB, free: 433.5 MiB)
[2025-05-07T21:35:13.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 3530b0b864fd:36239 in memory (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:13.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:13.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[290] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:13.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Adding task set 80.0 with 10 tasks resource profile 0
[2025-05-07T21:35:13.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 185) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.20.0.5:34941 in memory (size: 5.0 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.051+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.20.0.5:34941 (size: 5.7 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:52056
[2025-05-07T21:35:13.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 186) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.080+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 185) in 41 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:13.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.117+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 187) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 186) in 39 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:13.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 188) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 187) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:13.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.146+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 4.0 in stage 80.0 (TID 189) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.146+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 188) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:13.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 5.0 in stage 80.0 (TID 190) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 4.0 in stage 80.0 (TID 189) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:13.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 6.0 in stage 80.0 (TID 191) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 5.0 in stage 80.0 (TID 190) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:13.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 7.0 in stage 80.0 (TID 192) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.195+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 6.0 in stage 80.0 (TID 191) in 21 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:13.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 8.0 in stage 80.0 (TID 193) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.222+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 7.0 in stage 80.0 (TID 192) in 28 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:13.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 9.0 in stage 80.0 (TID 194) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 8.0 in stage 80.0 (TID 193) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:13.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_286_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 9.0 in stage 80.0 (TID 194) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:13.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool
[2025-05-07T21:35:13.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: ShuffleMapStage 80 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.220 s
[2025-05-07T21:35:13.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:13.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:13.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: waiting: Set(ResultStage 81)
[2025-05-07T21:35:13.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:13.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting ResultStage 81 (EdgeRDDImpl[293] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:13.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 163.5 KiB, free 417.7 MiB)
[2025-05-07T21:35:13.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 57.5 KiB, free 417.8 MiB)
[2025-05-07T21:35:13.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 3530b0b864fd:36239 in memory (size: 58.0 KiB, free: 433.6 MiB)
[2025-05-07T21:35:13.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 3530b0b864fd:36239 (size: 57.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:13.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:13.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 81 (EdgeRDDImpl[293] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:13.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Adding task set 81.0 with 10 tasks resource profile 0
[2025-05-07T21:35:13.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.20.0.5:34941 in memory (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 195) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.265+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.20.0.5:34941 (size: 57.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:52056
[2025-05-07T21:35:13.276+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:52056
[2025-05-07T21:35:13.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 196) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 195) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:13.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 197) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 196) in 26 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:13.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.324+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 198) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.324+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 197) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:13.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 199) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 198) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:13.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 200) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 199) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:13.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 6.0 in stage 81.0 (TID 201) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 200) in 18 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:13.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 7.0 in stage 81.0 (TID 202) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.387+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 6.0 in stage 81.0 (TID 201) in 17 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:13.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 8.0 in stage 81.0 (TID 203) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 7.0 in stage 81.0 (TID 202) in 26 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:13.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.425+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 9.0 in stage 81.0 (TID 204) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.426+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 8.0 in stage 81.0 (TID 203) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:13.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_292_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 9.0 in stage 81.0 (TID 204) in 19 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:13.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-05-07T21:35:13.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: ResultStage 81 (foreachPartition at PageRank.scala:199) finished in 0.199 s
[2025-05-07T21:35:13.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:13.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
[2025-05-07T21:35:13.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Job 36 finished: foreachPartition at PageRank.scala:199, took 1.230707 s
[2025-05-07T21:35:13.446+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO PageRank: PageRank finished iteration 0.
[2025-05-07T21:35:13.446+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MapPartitionsRDD: Removing RDD 274 from persistence list
[2025-05-07T21:35:13.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MapPartitionsRDD: Removing RDD 276 from persistence list
[2025-05-07T21:35:13.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManager: Removing RDD 274
[2025-05-07T21:35:13.450+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManager: Removing RDD 276
[2025-05-07T21:35:13.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:13.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Registering RDD 294 (mapPartitions at GraphImpl.scala:208) as input to shuffle 35
[2025-05-07T21:35:13.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Registering RDD 302 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 34
[2025-05-07T21:35:13.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Got job 37 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:13.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Final stage: ResultStage 92 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:13.471+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82, ShuffleMapStage 89, ShuffleMapStage 86, ShuffleMapStage 87, ShuffleMapStage 91)
[2025-05-07T21:35:13.471+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
[2025-05-07T21:35:13.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[294] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:13.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 164.0 KiB, free 417.7 MiB)
[2025-05-07T21:35:13.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-07T21:35:13.488+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 3530b0b864fd:36239 in memory (size: 57.5 KiB, free: 433.6 MiB)
[2025-05-07T21:35:13.488+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:13.489+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:13.489+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.20.0.5:34941 in memory (size: 57.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:13.489+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[294] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:13.489+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Adding task set 90.0 with 10 tasks resource profile 0
[2025-05-07T21:35:13.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 205) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 3530b0b864fd:36239 in memory (size: 5.7 KiB, free: 433.5 MiB)
[2025-05-07T21:35:13.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.20.0.5:34941 in memory (size: 5.7 KiB, free: 433.0 MiB)
[2025-05-07T21:35:13.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.20.0.5:34941 (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 206) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.516+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 205) in 25 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:13.530+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 207) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 206) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:13.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 208) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 207) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:13.571+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 4.0 in stage 90.0 (TID 209) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 208) in 22 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:13.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 5.0 in stage 90.0 (TID 210) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 4.0 in stage 90.0 (TID 209) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:13.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 6.0 in stage 90.0 (TID 211) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 5.0 in stage 90.0 (TID 210) in 20 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:13.639+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 7.0 in stage 90.0 (TID 212) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 6.0 in stage 90.0 (TID 211) in 34 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:13.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 8.0 in stage 90.0 (TID 213) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 7.0 in stage 90.0 (TID 212) in 19 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:13.674+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 9.0 in stage 90.0 (TID 214) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.674+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 8.0 in stage 90.0 (TID 213) in 17 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:13.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 9.0 in stage 90.0 (TID 214) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:13.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-05-07T21:35:13.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: ShuffleMapStage 90 (mapPartitions at GraphImpl.scala:208) finished in 0.217 s
[2025-05-07T21:35:13.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:13.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:13.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 91, ResultStage 92)
[2025-05-07T21:35:13.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:13.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[302] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:13.689+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.8 KiB, free 417.9 MiB)
[2025-05-07T21:35:13.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 417.9 MiB)
[2025-05-07T21:35:13.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 3530b0b864fd:36239 (size: 5.9 KiB, free: 433.5 MiB)
[2025-05-07T21:35:13.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:13.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[302] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:13.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Adding task set 91.0 with 10 tasks resource profile 0
[2025-05-07T21:35:13.700+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 215) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.20.0.5:34941 (size: 5.9 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:52056
[2025-05-07T21:35:13.719+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 216) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 215) in 25 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:13.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 217) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 216) in 33 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:13.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 218) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 217) in 25 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:13.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.801+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 219) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.801+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 218) in 21 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:13.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.815+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 220) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.815+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 219) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:13.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.829+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 221) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 220) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:13.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 222) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 221) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:13.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 8.0 in stage 91.0 (TID 223) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 222) in 23 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:13.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 9.0 in stage 91.0 (TID 224) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 8.0 in stage 91.0 (TID 223) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:13.888+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_298_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 9.0 in stage 91.0 (TID 224) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:13.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-05-07T21:35:13.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: ShuffleMapStage 91 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.204 s
[2025-05-07T21:35:13.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:13.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:13.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: waiting: Set(ResultStage 92)
[2025-05-07T21:35:13.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:13.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting ResultStage 92 (EdgeRDDImpl[305] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:13.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 163.8 KiB, free 417.7 MiB)
[2025-05-07T21:35:13.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 57.7 KiB, free 417.8 MiB)
[2025-05-07T21:35:13.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 433.6 MiB)
[2025-05-07T21:35:13.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 3530b0b864fd:36239 (size: 57.7 KiB, free: 433.5 MiB)
[2025-05-07T21:35:13.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:13.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 92 (EdgeRDDImpl[305] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:13.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSchedulerImpl: Adding task set 92.0 with 10 tasks resource profile 0
[2025-05-07T21:35:13.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.20.0.5:34941 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 225) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.20.0.5:34941 (size: 57.7 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:52056
[2025-05-07T21:35:13.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_304_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 226) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 225) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:13.956+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_304_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.959+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 227) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.959+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 226) in 29 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:13.968+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_304_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 228) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 227) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:13.982+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_304_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.984+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 229) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 228) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:13.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO BlockManagerInfo: Added rdd_304_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:13.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Starting task 5.0 in stage 92.0 (TID 230) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:13.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:13 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 229) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:14.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_304_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.010+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 6.0 in stage 92.0 (TID 231) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.010+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 5.0 in stage 92.0 (TID 230) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:14.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_304_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 7.0 in stage 92.0 (TID 232) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 6.0 in stage 92.0 (TID 231) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:14.033+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_304_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 8.0 in stage 92.0 (TID 233) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.045+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 7.0 in stage 92.0 (TID 232) in 20 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:14.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_304_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 9.0 in stage 92.0 (TID 234) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 8.0 in stage 92.0 (TID 233) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:14.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_304_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 9.0 in stage 92.0 (TID 234) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:14.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool
[2025-05-07T21:35:14.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: ResultStage 92 (foreachPartition at PageRank.scala:199) finished in 0.178 s
[2025-05-07T21:35:14.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:14.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
[2025-05-07T21:35:14.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Job 37 finished: foreachPartition at PageRank.scala:199, took 0.606971 s
[2025-05-07T21:35:14.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO PageRank: PageRank finished iteration 1.
[2025-05-07T21:35:14.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO ZippedPartitionsRDD2: Removing RDD 286 from persistence list
[2025-05-07T21:35:14.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManager: Removing RDD 286
[2025-05-07T21:35:14.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO ZippedPartitionsRDD2: Removing RDD 292 from persistence list
[2025-05-07T21:35:14.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManager: Removing RDD 292
[2025-05-07T21:35:14.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:14.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Registering RDD 306 (mapPartitions at GraphImpl.scala:208) as input to shuffle 37
[2025-05-07T21:35:14.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Registering RDD 314 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 36
[2025-05-07T21:35:14.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Got job 38 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:14.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Final stage: ResultStage 105 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:14.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 100, ShuffleMapStage 104, ShuffleMapStage 93, ShuffleMapStage 97, ShuffleMapStage 98)
[2025-05-07T21:35:14.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
[2025-05-07T21:35:14.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[306] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:14.096+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 164.3 KiB, free 417.7 MiB)
[2025-05-07T21:35:14.103+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-07T21:35:14.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 3530b0b864fd:36239 in memory (size: 57.7 KiB, free: 433.6 MiB)
[2025-05-07T21:35:14.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:14.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:14.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[306] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:14.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Adding task set 103.0 with 10 tasks resource profile 0
[2025-05-07T21:35:14.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.20.0.5:34941 in memory (size: 57.7 KiB, free: 433.0 MiB)
[2025-05-07T21:35:14.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 235) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 3530b0b864fd:36239 in memory (size: 5.9 KiB, free: 433.5 MiB)
[2025-05-07T21:35:14.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.20.0.5:34941 in memory (size: 5.9 KiB, free: 433.0 MiB)
[2025-05-07T21:35:14.113+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.20.0.5:34941 (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 236) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 235) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:14.146+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 237) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.146+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 236) in 19 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:14.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 238) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 237) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:14.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 239) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 238) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:14.177+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 240) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 239) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:14.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 6.0 in stage 103.0 (TID 241) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 240) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:14.198+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 7.0 in stage 103.0 (TID 242) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.198+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 6.0 in stage 103.0 (TID 241) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:14.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 8.0 in stage 103.0 (TID 243) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 7.0 in stage 103.0 (TID 242) in 18 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:14.224+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 9.0 in stage 103.0 (TID 244) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 8.0 in stage 103.0 (TID 243) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:14.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 9.0 in stage 103.0 (TID 244) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:14.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-05-07T21:35:14.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: ShuffleMapStage 103 (mapPartitions at GraphImpl.scala:208) finished in 0.140 s
[2025-05-07T21:35:14.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:14.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:14.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: waiting: Set(ShuffleMapStage 104, ResultStage 105)
[2025-05-07T21:35:14.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:14.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[314] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:14.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 13.5 KiB, free 417.9 MiB)
[2025-05-07T21:35:14.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.9 MiB)
[2025-05-07T21:35:14.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 3530b0b864fd:36239 (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:14.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:14.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[314] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:14.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Adding task set 104.0 with 10 tasks resource profile 0
[2025-05-07T21:35:14.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 245) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.20.0.5:34941 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.252+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:52056
[2025-05-07T21:35:14.262+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 246) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 245) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:14.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 247) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 246) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:14.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 248) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 247) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:14.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 4.0 in stage 104.0 (TID 249) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 248) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:14.318+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.322+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 5.0 in stage 104.0 (TID 250) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.323+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 4.0 in stage 104.0 (TID 249) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:14.329+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 6.0 in stage 104.0 (TID 251) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 5.0 in stage 104.0 (TID 250) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:14.343+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 7.0 in stage 104.0 (TID 252) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 6.0 in stage 104.0 (TID 251) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:14.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 8.0 in stage 104.0 (TID 253) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 7.0 in stage 104.0 (TID 252) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:14.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 9.0 in stage 104.0 (TID 254) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 8.0 in stage 104.0 (TID 253) in 23 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:14.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_310_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 9.0 in stage 104.0 (TID 254) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:14.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool
[2025-05-07T21:35:14.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: ShuffleMapStage 104 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.161 s
[2025-05-07T21:35:14.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:14.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:14.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: waiting: Set(ResultStage 105)
[2025-05-07T21:35:14.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:14.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting ResultStage 105 (EdgeRDDImpl[317] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:14.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 164.1 KiB, free 417.7 MiB)
[2025-05-07T21:35:14.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 433.6 MiB)
[2025-05-07T21:35:14.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 57.9 KiB, free 417.9 MiB)
[2025-05-07T21:35:14.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 3530b0b864fd:36239 (size: 57.9 KiB, free: 433.5 MiB)
[2025-05-07T21:35:14.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:14.410+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 105 (EdgeRDDImpl[317] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:14.410+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Adding task set 105.0 with 10 tasks resource profile 0
[2025-05-07T21:35:14.411+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.20.0.5:34941 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.411+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 255) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.20.0.5:34941 (size: 57.9 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:52056
[2025-05-07T21:35:14.426+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 256) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 255) in 18 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:14.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 257) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 256) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:14.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 258) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 257) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:14.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 4.0 in stage 105.0 (TID 259) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 258) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:14.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 5.0 in stage 105.0 (TID 260) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 4.0 in stage 105.0 (TID 259) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:14.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 6.0 in stage 105.0 (TID 261) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 5.0 in stage 105.0 (TID 260) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:14.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 7.0 in stage 105.0 (TID 262) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 6.0 in stage 105.0 (TID 261) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:14.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 8.0 in stage 105.0 (TID 263) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 7.0 in stage 105.0 (TID 262) in 20 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:14.556+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.558+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 9.0 in stage 105.0 (TID 264) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.558+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 8.0 in stage 105.0 (TID 263) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:14.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_316_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 9.0 in stage 105.0 (TID 264) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:14.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool
[2025-05-07T21:35:14.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: ResultStage 105 (foreachPartition at PageRank.scala:199) finished in 0.174 s
[2025-05-07T21:35:14.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:14.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
[2025-05-07T21:35:14.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Job 38 finished: foreachPartition at PageRank.scala:199, took 0.481178 s
[2025-05-07T21:35:14.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO PageRank: PageRank finished iteration 2.
[2025-05-07T21:35:14.570+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO ZippedPartitionsRDD2: Removing RDD 298 from persistence list
[2025-05-07T21:35:14.571+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManager: Removing RDD 298
[2025-05-07T21:35:14.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO ZippedPartitionsRDD2: Removing RDD 304 from persistence list
[2025-05-07T21:35:14.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManager: Removing RDD 304
[2025-05-07T21:35:14.581+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:14.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Registering RDD 318 (mapPartitions at GraphImpl.scala:208) as input to shuffle 39
[2025-05-07T21:35:14.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Registering RDD 326 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 38
[2025-05-07T21:35:14.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Got job 39 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:14.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Final stage: ResultStage 120 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:14.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 115, ShuffleMapStage 119, ShuffleMapStage 111, ShuffleMapStage 106, ShuffleMapStage 113, ShuffleMapStage 110)
[2025-05-07T21:35:14.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
[2025-05-07T21:35:14.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[318] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:14.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 164.6 KiB, free 417.7 MiB)
[2025-05-07T21:35:14.597+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 3530b0b864fd:36239 in memory (size: 57.9 KiB, free: 433.6 MiB)
[2025-05-07T21:35:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-07T21:35:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[318] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Adding task set 118.0 with 10 tasks resource profile 0
[2025-05-07T21:35:14.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.20.0.5:34941 in memory (size: 57.9 KiB, free: 433.0 MiB)
[2025-05-07T21:35:14.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 265) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 3530b0b864fd:36239 in memory (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:14.604+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.20.0.5:34941 in memory (size: 6.1 KiB, free: 433.0 MiB)
[2025-05-07T21:35:14.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.20.0.5:34941 (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 266) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.620+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 265) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:14.642+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 267) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.642+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 266) in 24 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:14.649+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 268) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.649+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 267) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:14.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 269) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 268) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:14.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 270) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 269) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:14.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 271) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 270) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:14.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 272) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 271) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:14.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 8.0 in stage 118.0 (TID 273) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 272) in 25 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:14.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 9.0 in stage 118.0 (TID 274) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 8.0 in stage 118.0 (TID 273) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:14.724+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 9.0 in stage 118.0 (TID 274) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:14.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-05-07T21:35:14.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: ShuffleMapStage 118 (mapPartitions at GraphImpl.scala:208) finished in 0.140 s
[2025-05-07T21:35:14.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:14.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:14.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: waiting: Set(ShuffleMapStage 119, ResultStage 120)
[2025-05-07T21:35:14.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:14.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[326] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:14.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 14.2 KiB, free 417.9 MiB)
[2025-05-07T21:35:14.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.9 MiB)
[2025-05-07T21:35:14.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 3530b0b864fd:36239 (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:14.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:14.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[326] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:14.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Adding task set 119.0 with 10 tasks resource profile 0
[2025-05-07T21:35:14.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 275) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.20.0.5:34941 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.739+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:52056
[2025-05-07T21:35:14.743+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.747+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 276) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.747+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 275) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:14.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.759+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 277) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 276) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:14.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 278) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 277) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:14.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 4.0 in stage 119.0 (TID 279) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 278) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:14.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.788+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 5.0 in stage 119.0 (TID 280) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.788+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 4.0 in stage 119.0 (TID 279) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:14.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 6.0 in stage 119.0 (TID 281) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 5.0 in stage 119.0 (TID 280) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:14.810+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.815+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 7.0 in stage 119.0 (TID 282) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.815+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 6.0 in stage 119.0 (TID 281) in 17 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:14.823+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 8.0 in stage 119.0 (TID 283) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 7.0 in stage 119.0 (TID 282) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:14.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 9.0 in stage 119.0 (TID 284) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 8.0 in stage 119.0 (TID 283) in 22 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:14.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_322_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 9.0 in stage 119.0 (TID 284) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:14.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-05-07T21:35:14.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: ShuffleMapStage 119 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.138 s
[2025-05-07T21:35:14.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:14.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:14.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: waiting: Set(ResultStage 120)
[2025-05-07T21:35:14.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:14.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting ResultStage 120 (EdgeRDDImpl[329] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:14.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 164.4 KiB, free 417.7 MiB)
[2025-05-07T21:35:14.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 433.6 MiB)
[2025-05-07T21:35:14.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 57.8 KiB, free 417.9 MiB)
[2025-05-07T21:35:14.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 3530b0b864fd:36239 (size: 57.8 KiB, free: 433.5 MiB)
[2025-05-07T21:35:14.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:14.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 120 (EdgeRDDImpl[329] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:14.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSchedulerImpl: Adding task set 120.0 with 10 tasks resource profile 0
[2025-05-07T21:35:14.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.20.0.5:34941 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 285) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.20.0.5:34941 (size: 57.8 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.890+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:52056
[2025-05-07T21:35:14.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_328_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 286) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 285) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:14.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_328_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 287) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 286) in 21 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:14.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_328_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 288) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 287) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:14.939+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_328_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 4.0 in stage 120.0 (TID 289) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 288) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:14.949+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_328_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 5.0 in stage 120.0 (TID 290) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 4.0 in stage 120.0 (TID 289) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:14.960+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_328_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.962+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 6.0 in stage 120.0 (TID 291) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.962+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 5.0 in stage 120.0 (TID 290) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:14.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_328_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 7.0 in stage 120.0 (TID 292) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 6.0 in stage 120.0 (TID 291) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:14.984+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO BlockManagerInfo: Added rdd_328_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:14.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Starting task 8.0 in stage 120.0 (TID 293) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:14.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:14 INFO TaskSetManager: Finished task 7.0 in stage 120.0 (TID 292) in 21 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:15.008+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_328_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.010+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 9.0 in stage 120.0 (TID 294) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 8.0 in stage 120.0 (TID 293) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:15.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_328_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 9.0 in stage 120.0 (TID 294) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:15.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool
[2025-05-07T21:35:15.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: ResultStage 120 (foreachPartition at PageRank.scala:199) finished in 0.157 s
[2025-05-07T21:35:15.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:15.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished
[2025-05-07T21:35:15.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Job 39 finished: foreachPartition at PageRank.scala:199, took 0.440559 s
[2025-05-07T21:35:15.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO PageRank: PageRank finished iteration 3.
[2025-05-07T21:35:15.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO ZippedPartitionsRDD2: Removing RDD 310 from persistence list
[2025-05-07T21:35:15.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManager: Removing RDD 310
[2025-05-07T21:35:15.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO ZippedPartitionsRDD2: Removing RDD 316 from persistence list
[2025-05-07T21:35:15.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManager: Removing RDD 316
[2025-05-07T21:35:15.034+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:15.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Registering RDD 330 (mapPartitions at GraphImpl.scala:208) as input to shuffle 41
[2025-05-07T21:35:15.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Registering RDD 338 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 40
[2025-05-07T21:35:15.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Got job 40 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:15.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Final stage: ResultStage 137 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:15.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132, ShuffleMapStage 121, ShuffleMapStage 136, ShuffleMapStage 125, ShuffleMapStage 126, ShuffleMapStage 130, ShuffleMapStage 134, ShuffleMapStage 128)
[2025-05-07T21:35:15.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
[2025-05-07T21:35:15.037+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[330] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:15.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 164.9 KiB, free 417.7 MiB)
[2025-05-07T21:35:15.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.7 MiB)
[2025-05-07T21:35:15.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 3530b0b864fd:36239 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T21:35:15.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:15.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[330] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:15.045+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Adding task set 135.0 with 10 tasks resource profile 0
[2025-05-07T21:35:15.045+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 295) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.049+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.20.0.5:34941 (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 296) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.059+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 295) in 13 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:15.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 297) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 296) in 7 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:15.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 298) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 297) in 7 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:15.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 4.0 in stage 135.0 (TID 299) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 298) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:15.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 5.0 in stage 135.0 (TID 300) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 4.0 in stage 135.0 (TID 299) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:15.098+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 6.0 in stage 135.0 (TID 301) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.099+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 5.0 in stage 135.0 (TID 300) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:15.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 7.0 in stage 135.0 (TID 302) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 6.0 in stage 135.0 (TID 301) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:15.123+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 8.0 in stage 135.0 (TID 303) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 7.0 in stage 135.0 (TID 302) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:15.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 9.0 in stage 135.0 (TID 304) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 8.0 in stage 135.0 (TID 303) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:15.139+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 9.0 in stage 135.0 (TID 304) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:15.139+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool
[2025-05-07T21:35:15.139+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: ShuffleMapStage 135 (mapPartitions at GraphImpl.scala:208) finished in 0.101 s
[2025-05-07T21:35:15.139+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:15.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:15.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: waiting: Set(ShuffleMapStage 136, ResultStage 137)
[2025-05-07T21:35:15.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:15.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:15.141+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 14.9 KiB, free 417.7 MiB)
[2025-05-07T21:35:15.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 417.6 MiB)
[2025-05-07T21:35:15.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 3530b0b864fd:36239 (size: 6.3 KiB, free: 433.4 MiB)
[2025-05-07T21:35:15.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 3530b0b864fd:36239 in memory (size: 57.8 KiB, free: 433.5 MiB)
[2025-05-07T21:35:15.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:15.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:15.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Adding task set 136.0 with 10 tasks resource profile 0
[2025-05-07T21:35:15.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.20.0.5:34941 in memory (size: 57.8 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.149+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 305) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.151+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 3530b0b864fd:36239 in memory (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:15.151+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.20.0.5:34941 in memory (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.20.0.5:34941 (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:52056
[2025-05-07T21:35:15.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 306) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 305) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:15.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 2.0 in stage 136.0 (TID 307) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 306) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:15.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.199+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 3.0 in stage 136.0 (TID 308) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.199+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 2.0 in stage 136.0 (TID 307) in 21 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:15.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.211+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 4.0 in stage 136.0 (TID 309) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 3.0 in stage 136.0 (TID 308) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:15.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 5.0 in stage 136.0 (TID 310) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 4.0 in stage 136.0 (TID 309) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:15.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 6.0 in stage 136.0 (TID 311) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 5.0 in stage 136.0 (TID 310) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:15.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 7.0 in stage 136.0 (TID 312) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 6.0 in stage 136.0 (TID 311) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:15.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.256+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 8.0 in stage 136.0 (TID 313) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 7.0 in stage 136.0 (TID 312) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:15.273+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.278+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 9.0 in stage 136.0 (TID 314) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.279+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 8.0 in stage 136.0 (TID 313) in 22 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:15.285+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_334_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 9.0 in stage 136.0 (TID 314) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:15.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-05-07T21:35:15.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: ShuffleMapStage 136 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.149 s
[2025-05-07T21:35:15.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:15.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:15.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: waiting: Set(ResultStage 137)
[2025-05-07T21:35:15.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:15.291+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting ResultStage 137 (EdgeRDDImpl[341] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:15.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 164.7 KiB, free 417.7 MiB)
[2025-05-07T21:35:15.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-07T21:35:15.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-07T21:35:15.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:15.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 137 (EdgeRDDImpl[341] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:15.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Adding task set 137.0 with 10 tasks resource profile 0
[2025-05-07T21:35:15.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 315) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.20.0.5:34941 (size: 58.1 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:52056
[2025-05-07T21:35:15.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 316) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 315) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:15.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 2.0 in stage 137.0 (TID 317) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 316) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:15.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 3.0 in stage 137.0 (TID 318) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.338+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 2.0 in stage 137.0 (TID 317) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:15.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 4.0 in stage 137.0 (TID 319) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 3.0 in stage 137.0 (TID 318) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:15.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 5.0 in stage 137.0 (TID 320) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 4.0 in stage 137.0 (TID 319) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:15.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 6.0 in stage 137.0 (TID 321) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 5.0 in stage 137.0 (TID 320) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:15.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 7.0 in stage 137.0 (TID 322) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 6.0 in stage 137.0 (TID 321) in 19 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:15.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 8.0 in stage 137.0 (TID 323) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 7.0 in stage 137.0 (TID 322) in 23 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:15.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 9.0 in stage 137.0 (TID 324) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 8.0 in stage 137.0 (TID 323) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:15.438+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_340_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:15.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 9.0 in stage 137.0 (TID 324) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:15.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool
[2025-05-07T21:35:15.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: ResultStage 137 (foreachPartition at PageRank.scala:199) finished in 0.149 s
[2025-05-07T21:35:15.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:15.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
[2025-05-07T21:35:15.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Job 40 finished: foreachPartition at PageRank.scala:199, took 0.407389 s
[2025-05-07T21:35:15.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO PageRank: PageRank finished iteration 4.
[2025-05-07T21:35:15.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO ZippedPartitionsRDD2: Removing RDD 322 from persistence list
[2025-05-07T21:35:15.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManager: Removing RDD 322
[2025-05-07T21:35:15.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO ZippedPartitionsRDD2: Removing RDD 328 from persistence list
[2025-05-07T21:35:15.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManager: Removing RDD 328
[2025-05-07T21:35:15.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:15.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Registering RDD 342 (mapPartitions at GraphImpl.scala:208) as input to shuffle 43
[2025-05-07T21:35:15.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Registering RDD 350 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 42
[2025-05-07T21:35:15.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Got job 41 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:15.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Final stage: ResultStage 156 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:15.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143, ShuffleMapStage 153, ShuffleMapStage 147, ShuffleMapStage 151, ShuffleMapStage 155, ShuffleMapStage 138, ShuffleMapStage 145, ShuffleMapStage 142, ShuffleMapStage 149)
[2025-05-07T21:35:15.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 155)
[2025-05-07T21:35:15.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[342] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:15.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 165.2 KiB, free 417.5 MiB)
[2025-05-07T21:35:15.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:15.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.5 MiB)
[2025-05-07T21:35:15.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 3530b0b864fd:36239 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T21:35:15.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.20.0.5:34941 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.476+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:15.476+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[342] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:15.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Adding task set 154.0 with 10 tasks resource profile 0
[2025-05-07T21:35:15.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 325) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 3530b0b864fd:36239 in memory (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-07T21:35:15.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.20.0.5:34941 in memory (size: 58.3 KiB, free: 433.0 MiB)
[2025-05-07T21:35:15.485+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 3530b0b864fd:36239 in memory (size: 6.3 KiB, free: 433.5 MiB)
[2025-05-07T21:35:15.486+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.20.0.5:34941 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.20.0.5:34941 in memory (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 326) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 325) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:15.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 327) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 326) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:15.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 328) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 327) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:15.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 329) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 328) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:15.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 5.0 in stage 154.0 (TID 330) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 329) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:15.554+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 6.0 in stage 154.0 (TID 331) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.554+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 5.0 in stage 154.0 (TID 330) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:15.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 7.0 in stage 154.0 (TID 332) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 6.0 in stage 154.0 (TID 331) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:15.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 8.0 in stage 154.0 (TID 333) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 7.0 in stage 154.0 (TID 332) in 21 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:15.595+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 9.0 in stage 154.0 (TID 334) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.596+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 8.0 in stage 154.0 (TID 333) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:15.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 9.0 in stage 154.0 (TID 334) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:15.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool
[2025-05-07T21:35:15.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: ShuffleMapStage 154 (mapPartitions at GraphImpl.scala:208) finished in 0.142 s
[2025-05-07T21:35:15.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:15.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:15.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: waiting: Set(ShuffleMapStage 155, ResultStage 156)
[2025-05-07T21:35:15.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:15.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[350] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:15.604+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 15.6 KiB, free 417.9 MiB)
[2025-05-07T21:35:15.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 417.9 MiB)
[2025-05-07T21:35:15.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 3530b0b864fd:36239 (size: 6.4 KiB, free: 433.5 MiB)
[2025-05-07T21:35:15.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:15.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[350] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:15.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Adding task set 155.0 with 10 tasks resource profile 0
[2025-05-07T21:35:15.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 335) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.20.0.5:34941 (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:52056
[2025-05-07T21:35:15.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 336) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 335) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:15.628+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 337) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 336) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:15.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 338) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.641+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 337) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:15.646+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 4.0 in stage 155.0 (TID 339) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 338) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:15.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 5.0 in stage 155.0 (TID 340) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 4.0 in stage 155.0 (TID 339) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:15.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 6.0 in stage 155.0 (TID 341) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 5.0 in stage 155.0 (TID 340) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:15.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.689+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 7.0 in stage 155.0 (TID 342) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 6.0 in stage 155.0 (TID 341) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:15.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 8.0 in stage 155.0 (TID 343) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 7.0 in stage 155.0 (TID 342) in 26 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:15.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 9.0 in stage 155.0 (TID 344) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 8.0 in stage 155.0 (TID 343) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:15.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_346_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.739+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 9.0 in stage 155.0 (TID 344) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:15.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool
[2025-05-07T21:35:15.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: ShuffleMapStage 155 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.136 s
[2025-05-07T21:35:15.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:15.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:15.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: waiting: Set(ResultStage 156)
[2025-05-07T21:35:15.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:15.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting ResultStage 156 (EdgeRDDImpl[353] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:15.745+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 165.0 KiB, free 417.7 MiB)
[2025-05-07T21:35:15.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 3530b0b864fd:36239 in memory (size: 58.2 KiB, free: 433.6 MiB)
[2025-05-07T21:35:15.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.9 MiB)
[2025-05-07T21:35:15.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 3530b0b864fd:36239 (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T21:35:15.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:15.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 156 (EdgeRDDImpl[353] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:15.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Adding task set 156.0 with 10 tasks resource profile 0
[2025-05-07T21:35:15.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.20.0.5:34941 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 345) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.20.0.5:34941 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:52056
[2025-05-07T21:35:15.772+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 346) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 345) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:15.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 347) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 346) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:15.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 348) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.810+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 347) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:15.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 4.0 in stage 156.0 (TID 349) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 348) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:15.829+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.831+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 5.0 in stage 156.0 (TID 350) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.831+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 4.0 in stage 156.0 (TID 349) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:15.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 6.0 in stage 156.0 (TID 351) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 5.0 in stage 156.0 (TID 350) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:15.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 7.0 in stage 156.0 (TID 352) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 6.0 in stage 156.0 (TID 351) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:15.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 8.0 in stage 156.0 (TID 353) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 7.0 in stage 156.0 (TID 352) in 21 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:15.884+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 9.0 in stage 156.0 (TID 354) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 8.0 in stage 156.0 (TID 353) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:15.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added rdd_352_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 9.0 in stage 156.0 (TID 354) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:15.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool
[2025-05-07T21:35:15.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: ResultStage 156 (foreachPartition at PageRank.scala:199) finished in 0.157 s
[2025-05-07T21:35:15.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:15.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished
[2025-05-07T21:35:15.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Job 41 finished: foreachPartition at PageRank.scala:199, took 0.444452 s
[2025-05-07T21:35:15.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO PageRank: PageRank finished iteration 5.
[2025-05-07T21:35:15.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO ZippedPartitionsRDD2: Removing RDD 334 from persistence list
[2025-05-07T21:35:15.900+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManager: Removing RDD 334
[2025-05-07T21:35:15.900+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO ZippedPartitionsRDD2: Removing RDD 340 from persistence list
[2025-05-07T21:35:15.900+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManager: Removing RDD 340
[2025-05-07T21:35:15.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:15.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Registering RDD 354 (mapPartitions at GraphImpl.scala:208) as input to shuffle 45
[2025-05-07T21:35:15.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Registering RDD 362 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 44
[2025-05-07T21:35:15.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Got job 42 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:15.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Final stage: ResultStage 177 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:15.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 161, ShuffleMapStage 168, ShuffleMapStage 157, ShuffleMapStage 172, ShuffleMapStage 166, ShuffleMapStage 176, ShuffleMapStage 170, ShuffleMapStage 162, ShuffleMapStage 174, ShuffleMapStage 164)
[2025-05-07T21:35:15.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 176)
[2025-05-07T21:35:15.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[354] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:15.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 165.5 KiB, free 417.7 MiB)
[2025-05-07T21:35:15.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.7 MiB)
[2025-05-07T21:35:15.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 3530b0b864fd:36239 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:15.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:15.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[354] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:15.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSchedulerImpl: Adding task set 175.0 with 10 tasks resource profile 0
[2025-05-07T21:35:15.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 355) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.20.0.5:34941 (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:15.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 1.0 in stage 175.0 (TID 356) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 355) in 14 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:15.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 2.0 in stage 175.0 (TID 357) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 1.0 in stage 175.0 (TID 356) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:15.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 3.0 in stage 175.0 (TID 358) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 2.0 in stage 175.0 (TID 357) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:15.960+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 4.0 in stage 175.0 (TID 359) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.961+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 3.0 in stage 175.0 (TID 358) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:15.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 5.0 in stage 175.0 (TID 360) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 4.0 in stage 175.0 (TID 359) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:15.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 6.0 in stage 175.0 (TID 361) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 5.0 in stage 175.0 (TID 360) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:15.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Starting task 7.0 in stage 175.0 (TID 362) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:15.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:15 INFO TaskSetManager: Finished task 6.0 in stage 175.0 (TID 361) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:16.010+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 8.0 in stage 175.0 (TID 363) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 7.0 in stage 175.0 (TID 362) in 24 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:16.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 9.0 in stage 175.0 (TID 364) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 8.0 in stage 175.0 (TID 363) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:16.031+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 9.0 in stage 175.0 (TID 364) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:16.031+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool
[2025-05-07T21:35:16.031+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: ShuffleMapStage 175 (mapPartitions at GraphImpl.scala:208) finished in 0.116 s
[2025-05-07T21:35:16.031+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:16.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:16.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: waiting: Set(ShuffleMapStage 176, ResultStage 177)
[2025-05-07T21:35:16.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:16.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[362] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:16.033+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 16.4 KiB, free 417.6 MiB)
[2025-05-07T21:35:16.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 417.6 MiB)
[2025-05-07T21:35:16.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 3530b0b864fd:36239 in memory (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T21:35:16.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 3530b0b864fd:36239 (size: 6.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:16.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:16.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[362] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:16.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Adding task set 176.0 with 10 tasks resource profile 0
[2025-05-07T21:35:16.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 365) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.20.0.5:34941 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.047+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 3530b0b864fd:36239 in memory (size: 6.4 KiB, free: 433.5 MiB)
[2025-05-07T21:35:16.051+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.20.0.5:34941 in memory (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.051+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.20.0.5:34941 (size: 6.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:52056
[2025-05-07T21:35:16.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 1.0 in stage 176.0 (TID 366) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 365) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:16.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 2.0 in stage 176.0 (TID 367) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.076+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 1.0 in stage 176.0 (TID 366) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:16.095+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.099+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 3.0 in stage 176.0 (TID 368) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 2.0 in stage 176.0 (TID 367) in 26 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:16.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 4.0 in stage 176.0 (TID 369) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.112+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 3.0 in stage 176.0 (TID 368) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:16.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 5.0 in stage 176.0 (TID 370) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 4.0 in stage 176.0 (TID 369) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:16.136+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.141+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 6.0 in stage 176.0 (TID 371) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.141+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 5.0 in stage 176.0 (TID 370) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:16.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 7.0 in stage 176.0 (TID 372) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 6.0 in stage 176.0 (TID 371) in 26 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:16.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.180+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 8.0 in stage 176.0 (TID 373) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.180+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 7.0 in stage 176.0 (TID 372) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:16.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.191+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 9.0 in stage 176.0 (TID 374) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 8.0 in stage 176.0 (TID 373) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:16.199+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_358_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 9.0 in stage 176.0 (TID 374) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:16.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool
[2025-05-07T21:35:16.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: ShuffleMapStage 176 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.172 s
[2025-05-07T21:35:16.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:16.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:16.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: waiting: Set(ResultStage 177)
[2025-05-07T21:35:16.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:16.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting ResultStage 177 (EdgeRDDImpl[365] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:16.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 165.3 KiB, free 417.7 MiB)
[2025-05-07T21:35:16.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.7 MiB)
[2025-05-07T21:35:16.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 3530b0b864fd:36239 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T21:35:16.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:16.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 177 (EdgeRDDImpl[365] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:16.213+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Adding task set 177.0 with 10 tasks resource profile 0
[2025-05-07T21:35:16.213+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 375) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.20.0.5:34941 (size: 58.3 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:52056
[2025-05-07T21:35:16.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 376) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 375) in 25 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:16.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 2.0 in stage 177.0 (TID 377) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 376) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:16.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.262+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 3.0 in stage 177.0 (TID 378) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 2.0 in stage 177.0 (TID 377) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:16.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 4.0 in stage 177.0 (TID 379) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 3.0 in stage 177.0 (TID 378) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:16.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 5.0 in stage 177.0 (TID 380) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 4.0 in stage 177.0 (TID 379) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:16.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 6.0 in stage 177.0 (TID 381) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.304+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 5.0 in stage 177.0 (TID 380) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:16.323+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 7.0 in stage 177.0 (TID 382) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 6.0 in stage 177.0 (TID 381) in 22 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:16.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 8.0 in stage 177.0 (TID 383) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 7.0 in stage 177.0 (TID 382) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:16.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 9.0 in stage 177.0 (TID 384) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 8.0 in stage 177.0 (TID 383) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:16.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_364_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:16.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 9.0 in stage 177.0 (TID 384) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:16.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool
[2025-05-07T21:35:16.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: ResultStage 177 (foreachPartition at PageRank.scala:199) finished in 0.159 s
[2025-05-07T21:35:16.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:16.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished
[2025-05-07T21:35:16.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Job 42 finished: foreachPartition at PageRank.scala:199, took 0.453167 s
[2025-05-07T21:35:16.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO PageRank: PageRank finished iteration 6.
[2025-05-07T21:35:16.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO ZippedPartitionsRDD2: Removing RDD 346 from persistence list
[2025-05-07T21:35:16.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManager: Removing RDD 346
[2025-05-07T21:35:16.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO ZippedPartitionsRDD2: Removing RDD 352 from persistence list
[2025-05-07T21:35:16.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManager: Removing RDD 352
[2025-05-07T21:35:16.374+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:16.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Registering RDD 366 (mapPartitions at GraphImpl.scala:208) as input to shuffle 47
[2025-05-07T21:35:16.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Registering RDD 374 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 46
[2025-05-07T21:35:16.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Got job 43 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:16.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Final stage: ResultStage 200 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:16.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 197, ShuffleMapStage 183, ShuffleMapStage 187, ShuffleMapStage 191, ShuffleMapStage 195, ShuffleMapStage 189, ShuffleMapStage 199, ShuffleMapStage 178, ShuffleMapStage 193, ShuffleMapStage 185, ShuffleMapStage 182)
[2025-05-07T21:35:16.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 199)
[2025-05-07T21:35:16.377+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[366] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:16.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 165.8 KiB, free 417.5 MiB)
[2025-05-07T21:35:16.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 3530b0b864fd:36239 in memory (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-07T21:35:16.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.7 MiB)
[2025-05-07T21:35:16.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 3530b0b864fd:36239 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:16.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:16.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[366] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:16.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Adding task set 198.0 with 10 tasks resource profile 0
[2025-05-07T21:35:16.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.20.0.5:34941 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.391+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 385) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.392+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 3530b0b864fd:36239 in memory (size: 6.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:16.393+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.20.0.5:34941 in memory (size: 6.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 3530b0b864fd:36239 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:16.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.20.0.5:34941 in memory (size: 58.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:16.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.20.0.5:34941 (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 1.0 in stage 198.0 (TID 386) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 385) in 15 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:16.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 2.0 in stage 198.0 (TID 387) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 1.0 in stage 198.0 (TID 386) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:16.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 3.0 in stage 198.0 (TID 388) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 2.0 in stage 198.0 (TID 387) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:16.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 4.0 in stage 198.0 (TID 389) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 3.0 in stage 198.0 (TID 388) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:16.449+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 5.0 in stage 198.0 (TID 390) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.449+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 4.0 in stage 198.0 (TID 389) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:16.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 6.0 in stage 198.0 (TID 391) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 5.0 in stage 198.0 (TID 390) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:16.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 7.0 in stage 198.0 (TID 392) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 6.0 in stage 198.0 (TID 391) in 16 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:16.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 8.0 in stage 198.0 (TID 393) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 7.0 in stage 198.0 (TID 392) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:16.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 9.0 in stage 198.0 (TID 394) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 8.0 in stage 198.0 (TID 393) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:16.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 9.0 in stage 198.0 (TID 394) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:16.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool
[2025-05-07T21:35:16.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: ShuffleMapStage 198 (mapPartitions at GraphImpl.scala:208) finished in 0.120 s
[2025-05-07T21:35:16.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:16.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:16.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: waiting: Set(ShuffleMapStage 199, ResultStage 200)
[2025-05-07T21:35:16.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:16.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[374] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:16.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 17.1 KiB, free 417.9 MiB)
[2025-05-07T21:35:16.500+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 417.9 MiB)
[2025-05-07T21:35:16.500+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 3530b0b864fd:36239 (size: 6.6 KiB, free: 433.5 MiB)
[2025-05-07T21:35:16.500+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:16.500+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[374] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:16.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Adding task set 199.0 with 10 tasks resource profile 0
[2025-05-07T21:35:16.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 395) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.20.0.5:34941 (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:52056
[2025-05-07T21:35:16.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.516+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 1.0 in stage 199.0 (TID 396) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.516+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 395) in 15 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:16.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 2.0 in stage 199.0 (TID 397) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 1.0 in stage 199.0 (TID 396) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:16.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 3.0 in stage 199.0 (TID 398) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 2.0 in stage 199.0 (TID 397) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:16.540+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 4.0 in stage 199.0 (TID 399) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.544+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 3.0 in stage 199.0 (TID 398) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:16.553+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.556+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 5.0 in stage 199.0 (TID 400) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.557+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 4.0 in stage 199.0 (TID 399) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:16.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 6.0 in stage 199.0 (TID 401) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 5.0 in stage 199.0 (TID 400) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:16.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 7.0 in stage 199.0 (TID 402) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.589+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 6.0 in stage 199.0 (TID 401) in 20 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:16.595+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.601+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 8.0 in stage 199.0 (TID 403) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.601+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 7.0 in stage 199.0 (TID 402) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:16.608+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 9.0 in stage 199.0 (TID 404) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 8.0 in stage 199.0 (TID 403) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:16.620+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_370_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 9.0 in stage 199.0 (TID 404) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:16.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool
[2025-05-07T21:35:16.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: ShuffleMapStage 199 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.126 s
[2025-05-07T21:35:16.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:16.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:16.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: waiting: Set(ResultStage 200)
[2025-05-07T21:35:16.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:16.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting ResultStage 200 (EdgeRDDImpl[377] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:16.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 165.6 KiB, free 417.7 MiB)
[2025-05-07T21:35:16.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 3530b0b864fd:36239 in memory (size: 58.5 KiB, free: 433.6 MiB)
[2025-05-07T21:35:16.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.9 MiB)
[2025-05-07T21:35:16.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:16.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:16.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 200 (EdgeRDDImpl[377] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:16.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Adding task set 200.0 with 10 tasks resource profile 0
[2025-05-07T21:35:16.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.20.0.5:34941 in memory (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 405) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.641+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.20.0.5:34941 (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.649+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:52056
[2025-05-07T21:35:16.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 406) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 405) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:16.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.673+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 2.0 in stage 200.0 (TID 407) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.673+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 406) in 19 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:16.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 3.0 in stage 200.0 (TID 408) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 2.0 in stage 200.0 (TID 407) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:16.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 4.0 in stage 200.0 (TID 409) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 3.0 in stage 200.0 (TID 408) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:16.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.713+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 5.0 in stage 200.0 (TID 410) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.714+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 4.0 in stage 200.0 (TID 409) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:16.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 6.0 in stage 200.0 (TID 411) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 5.0 in stage 200.0 (TID 410) in 22 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:16.742+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.744+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 7.0 in stage 200.0 (TID 412) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.744+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 6.0 in stage 200.0 (TID 411) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:16.754+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 8.0 in stage 200.0 (TID 413) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 7.0 in stage 200.0 (TID 412) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:16.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.765+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 9.0 in stage 200.0 (TID 414) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 8.0 in stage 200.0 (TID 413) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:16.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_376_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 9.0 in stage 200.0 (TID 414) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:16.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool
[2025-05-07T21:35:16.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: ResultStage 200 (foreachPartition at PageRank.scala:199) finished in 0.149 s
[2025-05-07T21:35:16.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:16.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished
[2025-05-07T21:35:16.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Job 43 finished: foreachPartition at PageRank.scala:199, took 0.401258 s
[2025-05-07T21:35:16.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO PageRank: PageRank finished iteration 7.
[2025-05-07T21:35:16.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO ZippedPartitionsRDD2: Removing RDD 358 from persistence list
[2025-05-07T21:35:16.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManager: Removing RDD 358
[2025-05-07T21:35:16.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO ZippedPartitionsRDD2: Removing RDD 364 from persistence list
[2025-05-07T21:35:16.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManager: Removing RDD 364
[2025-05-07T21:35:16.787+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:16.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Registering RDD 378 (mapPartitions at GraphImpl.scala:208) as input to shuffle 49
[2025-05-07T21:35:16.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Registering RDD 386 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 48
[2025-05-07T21:35:16.790+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Got job 44 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:16.790+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Final stage: ResultStage 225 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:16.790+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 212, ShuffleMapStage 222, ShuffleMapStage 201, ShuffleMapStage 216, ShuffleMapStage 208, ShuffleMapStage 205, ShuffleMapStage 220, ShuffleMapStage 224, ShuffleMapStage 206, ShuffleMapStage 210, ShuffleMapStage 214, ShuffleMapStage 218)
[2025-05-07T21:35:16.790+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 224)
[2025-05-07T21:35:16.790+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[378] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:16.795+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 166.0 KiB, free 417.7 MiB)
[2025-05-07T21:35:16.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.7 MiB)
[2025-05-07T21:35:16.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 3530b0b864fd:36239 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:16.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:16.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[378] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:16.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Adding task set 223.0 with 10 tasks resource profile 0
[2025-05-07T21:35:16.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 415) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.20.0.5:34941 (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.810+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 1.0 in stage 223.0 (TID 416) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.811+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 415) in 12 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:16.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 2.0 in stage 223.0 (TID 417) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 1.0 in stage 223.0 (TID 416) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:16.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 3.0 in stage 223.0 (TID 418) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 2.0 in stage 223.0 (TID 417) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:16.849+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 4.0 in stage 223.0 (TID 419) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 3.0 in stage 223.0 (TID 418) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:16.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 5.0 in stage 223.0 (TID 420) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 4.0 in stage 223.0 (TID 419) in 7 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:16.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 6.0 in stage 223.0 (TID 421) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 5.0 in stage 223.0 (TID 420) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:16.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 7.0 in stage 223.0 (TID 422) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 6.0 in stage 223.0 (TID 421) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:16.879+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 8.0 in stage 223.0 (TID 423) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.879+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 7.0 in stage 223.0 (TID 422) in 7 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:16.888+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 9.0 in stage 223.0 (TID 424) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.888+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 8.0 in stage 223.0 (TID 423) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:16.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 9.0 in stage 223.0 (TID 424) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:16.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool
[2025-05-07T21:35:16.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: ShuffleMapStage 223 (mapPartitions at GraphImpl.scala:208) finished in 0.106 s
[2025-05-07T21:35:16.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:16.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:16.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: waiting: Set(ShuffleMapStage 224, ResultStage 225)
[2025-05-07T21:35:16.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:16.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[386] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:16.900+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 17.8 KiB, free 417.6 MiB)
[2025-05-07T21:35:16.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.6 MiB)
[2025-05-07T21:35:16.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T21:35:16.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:16.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:16.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[386] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:16.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSchedulerImpl: Adding task set 224.0 with 10 tasks resource profile 0
[2025-05-07T21:35:16.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.20.0.5:34941 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 425) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 3530b0b864fd:36239 in memory (size: 6.6 KiB, free: 433.5 MiB)
[2025-05-07T21:35:16.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.20.0.5:34941 in memory (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.918+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.20.0.5:34941 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.922+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:52056
[2025-05-07T21:35:16.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_382_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 1.0 in stage 224.0 (TID 426) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 425) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:16.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_382_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 2.0 in stage 224.0 (TID 427) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 1.0 in stage 224.0 (TID 426) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:16.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_382_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:16.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Starting task 3.0 in stage 224.0 (TID 428) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:16.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO TaskSetManager: Finished task 2.0 in stage 224.0 (TID 427) in 44 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:16.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:16 INFO BlockManagerInfo: Added rdd_382_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 4.0 in stage 224.0 (TID 429) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.003+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 3.0 in stage 224.0 (TID 428) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:17.009+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_382_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.014+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 5.0 in stage 224.0 (TID 430) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.015+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 4.0 in stage 224.0 (TID 429) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:17.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_382_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 6.0 in stage 224.0 (TID 431) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.029+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 5.0 in stage 224.0 (TID 430) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:17.037+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_382_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 7.0 in stage 224.0 (TID 432) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 6.0 in stage 224.0 (TID 431) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:17.051+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_382_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 8.0 in stage 224.0 (TID 433) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 7.0 in stage 224.0 (TID 432) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:17.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_382_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 9.0 in stage 224.0 (TID 434) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 8.0 in stage 224.0 (TID 433) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:17.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_382_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 9.0 in stage 224.0 (TID 434) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:17.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool
[2025-05-07T21:35:17.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: ShuffleMapStage 224 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.186 s
[2025-05-07T21:35:17.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:17.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:17.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: waiting: Set(ResultStage 225)
[2025-05-07T21:35:17.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:17.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting ResultStage 225 (EdgeRDDImpl[389] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:17.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 165.8 KiB, free 417.7 MiB)
[2025-05-07T21:35:17.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.7 MiB)
[2025-05-07T21:35:17.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 3530b0b864fd:36239 (size: 58.0 KiB, free: 433.4 MiB)
[2025-05-07T21:35:17.093+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:17.093+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 225 (EdgeRDDImpl[389] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:17.093+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Adding task set 225.0 with 10 tasks resource profile 0
[2025-05-07T21:35:17.093+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 435) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.20.0.5:34941 (size: 58.0 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.20.0.5:52056
[2025-05-07T21:35:17.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.119+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 1.0 in stage 225.0 (TID 436) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.119+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 435) in 25 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:17.141+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 2.0 in stage 225.0 (TID 437) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 1.0 in stage 225.0 (TID 436) in 26 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:17.157+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 3.0 in stage 225.0 (TID 438) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 2.0 in stage 225.0 (TID 437) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:17.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 4.0 in stage 225.0 (TID 439) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 3.0 in stage 225.0 (TID 438) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:17.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 5.0 in stage 225.0 (TID 440) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 4.0 in stage 225.0 (TID 439) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:17.191+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 6.0 in stage 225.0 (TID 441) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 5.0 in stage 225.0 (TID 440) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:17.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 7.0 in stage 225.0 (TID 442) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 6.0 in stage 225.0 (TID 441) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:17.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 8.0 in stage 225.0 (TID 443) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 7.0 in stage 225.0 (TID 442) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:17.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 9.0 in stage 225.0 (TID 444) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 8.0 in stage 225.0 (TID 443) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:17.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_388_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.8 MiB)
[2025-05-07T21:35:17.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 9.0 in stage 225.0 (TID 444) in 18 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:17.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool
[2025-05-07T21:35:17.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: ResultStage 225 (foreachPartition at PageRank.scala:199) finished in 0.160 s
[2025-05-07T21:35:17.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:17.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished
[2025-05-07T21:35:17.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Job 44 finished: foreachPartition at PageRank.scala:199, took 0.461795 s
[2025-05-07T21:35:17.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO PageRank: PageRank finished iteration 8.
[2025-05-07T21:35:17.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO ZippedPartitionsRDD2: Removing RDD 370 from persistence list
[2025-05-07T21:35:17.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManager: Removing RDD 370
[2025-05-07T21:35:17.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO ZippedPartitionsRDD2: Removing RDD 376 from persistence list
[2025-05-07T21:35:17.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManager: Removing RDD 376
[2025-05-07T21:35:17.271+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:35:17.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Registering RDD 390 (mapPartitions at GraphImpl.scala:208) as input to shuffle 51
[2025-05-07T21:35:17.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Registering RDD 398 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 50
[2025-05-07T21:35:17.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Got job 45 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:35:17.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Final stage: ResultStage 252 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:35:17.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 233, ShuffleMapStage 230, ShuffleMapStage 251, ShuffleMapStage 237, ShuffleMapStage 249, ShuffleMapStage 241, ShuffleMapStage 235, ShuffleMapStage 245, ShuffleMapStage 239, ShuffleMapStage 231, ShuffleMapStage 243, ShuffleMapStage 247, ShuffleMapStage 226)
[2025-05-07T21:35:17.275+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 251)
[2025-05-07T21:35:17.275+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[390] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:35:17.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 166.3 KiB, free 417.5 MiB)
[2025-05-07T21:35:17.291+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.4 MiB)
[2025-05-07T21:35:17.291+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T21:35:17.291+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 3530b0b864fd:36239 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:17.291+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:17.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[390] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:17.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Adding task set 250.0 with 10 tasks resource profile 0
[2025-05-07T21:35:17.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 0.0 in stage 250.0 (TID 445) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.20.0.5:34941 in memory (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 3530b0b864fd:36239 in memory (size: 58.0 KiB, free: 433.4 MiB)
[2025-05-07T21:35:17.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.20.0.5:34941 in memory (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.20.0.5:34941 (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.304+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 3530b0b864fd:36239 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:17.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.20.0.5:34941 in memory (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.311+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 1.0 in stage 250.0 (TID 446) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 0.0 in stage 250.0 (TID 445) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:17.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 2.0 in stage 250.0 (TID 447) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.322+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 1.0 in stage 250.0 (TID 446) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:17.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 3.0 in stage 250.0 (TID 448) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 2.0 in stage 250.0 (TID 447) in 26 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:17.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 4.0 in stage 250.0 (TID 449) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 3.0 in stage 250.0 (TID 448) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:17.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 5.0 in stage 250.0 (TID 450) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 4.0 in stage 250.0 (TID 449) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:17.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 6.0 in stage 250.0 (TID 451) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 5.0 in stage 250.0 (TID 450) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:17.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 7.0 in stage 250.0 (TID 452) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 6.0 in stage 250.0 (TID 451) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:17.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 8.0 in stage 250.0 (TID 453) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 7.0 in stage 250.0 (TID 452) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:17.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 9.0 in stage 250.0 (TID 454) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 8.0 in stage 250.0 (TID 453) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:17.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 9.0 in stage 250.0 (TID 454) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:17.425+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool
[2025-05-07T21:35:17.426+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: ShuffleMapStage 250 (mapPartitions at GraphImpl.scala:208) finished in 0.148 s
[2025-05-07T21:35:17.426+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:17.426+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:17.427+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: waiting: Set(ShuffleMapStage 251, ResultStage 252)
[2025-05-07T21:35:17.427+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:17.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[398] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:35:17.432+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 18.5 KiB, free 417.9 MiB)
[2025-05-07T21:35:17.433+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 417.9 MiB)
[2025-05-07T21:35:17.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 3530b0b864fd:36239 (size: 6.8 KiB, free: 433.5 MiB)
[2025-05-07T21:35:17.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:17.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[398] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:17.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Adding task set 251.0 with 10 tasks resource profile 0
[2025-05-07T21:35:17.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 455) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.20.0.5:34941 (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.20.0.5:52056
[2025-05-07T21:35:17.452+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 1.0 in stage 251.0 (TID 456) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 455) in 23 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:17.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 2.0 in stage 251.0 (TID 457) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.471+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 1.0 in stage 251.0 (TID 456) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:17.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 3.0 in stage 251.0 (TID 458) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 2.0 in stage 251.0 (TID 457) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:17.490+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 4.0 in stage 251.0 (TID 459) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 3.0 in stage 251.0 (TID 458) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:17.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 5.0 in stage 251.0 (TID 460) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 4.0 in stage 251.0 (TID 459) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:17.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 6.0 in stage 251.0 (TID 461) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 5.0 in stage 251.0 (TID 460) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:17.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 7.0 in stage 251.0 (TID 462) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 6.0 in stage 251.0 (TID 461) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:17.552+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.557+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 8.0 in stage 251.0 (TID 463) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.557+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 7.0 in stage 251.0 (TID 462) in 25 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:17.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.571+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 9.0 in stage 251.0 (TID 464) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.571+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 8.0 in stage 251.0 (TID 463) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:17.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_394_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 9.0 in stage 251.0 (TID 464) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:17.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool
[2025-05-07T21:35:17.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: ShuffleMapStage 251 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.155 s
[2025-05-07T21:35:17.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:17.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: running: Set()
[2025-05-07T21:35:17.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: waiting: Set(ResultStage 252)
[2025-05-07T21:35:17.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:17.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting ResultStage 252 (EdgeRDDImpl[401] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:35:17.593+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 166.1 KiB, free 417.7 MiB)
[2025-05-07T21:35:17.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.7 MiB)
[2025-05-07T21:35:17.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-07T21:35:17.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.20.0.5:34941 in memory (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:17.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 252 (EdgeRDDImpl[401] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:17.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Adding task set 252.0 with 10 tasks resource profile 0
[2025-05-07T21:35:17.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 3530b0b864fd:36239 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-07T21:35:17.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 0.0 in stage 252.0 (TID 465) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.633+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.20.0.5:34941 (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.641+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:52056
[2025-05-07T21:35:17.645+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_0 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.649+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 1.0 in stage 252.0 (TID 466) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 0.0 in stage 252.0 (TID 465) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:17.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_1 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 2.0 in stage 252.0 (TID 467) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 1.0 in stage 252.0 (TID 466) in 36 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:17.697+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_2 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 3.0 in stage 252.0 (TID 468) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 2.0 in stage 252.0 (TID 467) in 19 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:17.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_3 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 4.0 in stage 252.0 (TID 469) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 3.0 in stage 252.0 (TID 468) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:17.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_4 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 5.0 in stage 252.0 (TID 470) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 4.0 in stage 252.0 (TID 469) in 19 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:17.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_5 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 6.0 in stage 252.0 (TID 471) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 5.0 in stage 252.0 (TID 470) in 19 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:17.762+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_6 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 7.0 in stage 252.0 (TID 472) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.765+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 6.0 in stage 252.0 (TID 471) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:17.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_7 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 8.0 in stage 252.0 (TID 473) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 7.0 in stage 252.0 (TID 472) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:17.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_8 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 9.0 in stage 252.0 (TID 474) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 8.0 in stage 252.0 (TID 473) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:17.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added rdd_400_9 in memory on 172.20.0.5:34941 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:17.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Finished task 9.0 in stage 252.0 (TID 474) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:17.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool
[2025-05-07T21:35:17.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: ResultStage 252 (foreachPartition at PageRank.scala:199) finished in 0.218 s
[2025-05-07T21:35:17.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:17.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished
[2025-05-07T21:35:17.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Job 45 finished: foreachPartition at PageRank.scala:199, took 0.535138 s
[2025-05-07T21:35:17.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO PageRank: PageRank finished iteration 9.
[2025-05-07T21:35:17.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO ZippedPartitionsRDD2: Removing RDD 382 from persistence list
[2025-05-07T21:35:17.807+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManager: Removing RDD 382
[2025-05-07T21:35:17.807+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO ZippedPartitionsRDD2: Removing RDD 388 from persistence list
[2025-05-07T21:35:17.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManager: Removing RDD 388
[2025-05-07T21:35:17.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO SparkContext: Starting job: sum at PageRank.scala:503
[2025-05-07T21:35:17.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Got job 46 (sum at PageRank.scala:503) with 10 output partitions
[2025-05-07T21:35:17.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Final stage: ResultStage 278 (sum at PageRank.scala:503)
[2025-05-07T21:35:17.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 269, ShuffleMapStage 263, ShuffleMapStage 255, ShuffleMapStage 273, ShuffleMapStage 267, ShuffleMapStage 277, ShuffleMapStage 256, ShuffleMapStage 271, ShuffleMapStage 259, ShuffleMapStage 275, ShuffleMapStage 261, ShuffleMapStage 265, ShuffleMapStage 254)
[2025-05-07T21:35:17.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:17.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting ResultStage 278 (MapPartitionsRDD[402] at values at PageRank.scala:503), which has no missing parents
[2025-05-07T21:35:17.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 18.9 KiB, free 417.9 MiB)
[2025-05-07T21:35:17.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 417.9 MiB)
[2025-05-07T21:35:17.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 3530b0b864fd:36239 (size: 7.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:17.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:17.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 278 (MapPartitionsRDD[402] at values at PageRank.scala:503) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:17.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSchedulerImpl: Adding task set 278.0 with 10 tasks resource profile 0
[2025-05-07T21:35:17.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 475) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:17.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:17 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.20.0.5:34941 (size: 7.0 KiB, free: 432.9 MiB)
[2025-05-07T21:35:18.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 1.0 in stage 278.0 (TID 476) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 475) in 323 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:18.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 2.0 in stage 278.0 (TID 477) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 1.0 in stage 278.0 (TID 476) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:18.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 3.0 in stage 278.0 (TID 478) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 2.0 in stage 278.0 (TID 477) in 5 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:18.195+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 4.0 in stage 278.0 (TID 479) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 3.0 in stage 278.0 (TID 478) in 6 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:18.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 5.0 in stage 278.0 (TID 480) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 4.0 in stage 278.0 (TID 479) in 6 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:18.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 6.0 in stage 278.0 (TID 481) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 5.0 in stage 278.0 (TID 480) in 5 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:18.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 7.0 in stage 278.0 (TID 482) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 6.0 in stage 278.0 (TID 481) in 5 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:18.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 8.0 in stage 278.0 (TID 483) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 7.0 in stage 278.0 (TID 482) in 6 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:18.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 9.0 in stage 278.0 (TID 484) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.222+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 8.0 in stage 278.0 (TID 483) in 6 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:18.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 9.0 in stage 278.0 (TID 484) in 6 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:18.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool
[2025-05-07T21:35:18.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: ResultStage 278 (sum at PageRank.scala:503) finished in 0.372 s
[2025-05-07T21:35:18.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:18.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 278: Stage finished
[2025-05-07T21:35:18.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Job 46 finished: sum at PageRank.scala:503, took 0.380778 s
[2025-05-07T21:35:18.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-07T21:35:18.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Got job 47 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-07T21:35:18.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Final stage: ResultStage 304 (fold at VertexRDDImpl.scala:90)
[2025-05-07T21:35:18.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 287, ShuffleMapStage 281, ShuffleMapStage 299, ShuffleMapStage 291, ShuffleMapStage 303, ShuffleMapStage 285, ShuffleMapStage 289, ShuffleMapStage 293, ShuffleMapStage 282, ShuffleMapStage 297, ShuffleMapStage 301, ShuffleMapStage 280, ShuffleMapStage 295)
[2025-05-07T21:35:18.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:18.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Submitting ResultStage 304 (MapPartitionsRDD[403] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-07T21:35:18.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 18.7 KiB, free 417.8 MiB)
[2025-05-07T21:35:18.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 417.8 MiB)
[2025-05-07T21:35:18.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 3530b0b864fd:36239 (size: 6.9 KiB, free: 433.5 MiB)
[2025-05-07T21:35:18.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 3530b0b864fd:36239 in memory (size: 7.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:18.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:18.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 304 (MapPartitionsRDD[403] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:18.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSchedulerImpl: Adding task set 304.0 with 10 tasks resource profile 0
[2025-05-07T21:35:18.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 485) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.20.0.5:34941 in memory (size: 7.0 KiB, free: 432.9 MiB)
[2025-05-07T21:35:18.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T21:35:18.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.20.0.5:34941 in memory (size: 58.1 KiB, free: 433.0 MiB)
[2025-05-07T21:35:18.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.20.0.5:34941 (size: 6.9 KiB, free: 433.0 MiB)
[2025-05-07T21:35:18.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.20.0.5:34941 in memory (size: 6.8 KiB, free: 433.0 MiB)
[2025-05-07T21:35:18.304+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 3530b0b864fd:36239 in memory (size: 6.8 KiB, free: 433.6 MiB)
[2025-05-07T21:35:18.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 1.0 in stage 304.0 (TID 486) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 485) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:18.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 2.0 in stage 304.0 (TID 487) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 1.0 in stage 304.0 (TID 486) in 7 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:18.317+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 3.0 in stage 304.0 (TID 488) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.317+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 2.0 in stage 304.0 (TID 487) in 6 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:18.322+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 4.0 in stage 304.0 (TID 489) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.323+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 3.0 in stage 304.0 (TID 488) in 6 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:18.338+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 5.0 in stage 304.0 (TID 490) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.338+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 4.0 in stage 304.0 (TID 489) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:18.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 6.0 in stage 304.0 (TID 491) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 5.0 in stage 304.0 (TID 490) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:18.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 7.0 in stage 304.0 (TID 492) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 6.0 in stage 304.0 (TID 491) in 7 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:18.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 8.0 in stage 304.0 (TID 493) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 7.0 in stage 304.0 (TID 492) in 5 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:18.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Starting task 9.0 in stage 304.0 (TID 494) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:18.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 8.0 in stage 304.0 (TID 493) in 5 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:18.375+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSetManager: Finished task 9.0 in stage 304.0 (TID 494) in 6 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:18.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool
[2025-05-07T21:35:18.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: ResultStage 304 (fold at VertexRDDImpl.scala:90) finished in 0.120 s
[2025-05-07T21:35:18.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:18.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 304: Stage finished
[2025-05-07T21:35:18.377+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO DAGScheduler: Job 47 finished: fold at VertexRDDImpl.scala:90, took 0.125701 s
[2025-05-07T21:35:18.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 3530b0b864fd:36239 in memory (size: 6.9 KiB, free: 433.6 MiB)
[2025-05-07T21:35:18.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:18 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.20.0.5:34941 in memory (size: 6.9 KiB, free: 433.0 MiB)
[2025-05-07T21:35:18.758+0000] {spark_submit.py:571} INFO - 2025-05-07 21:35:18,753 [INFO] Экспортируем граф в GraphML
[2025-05-07T21:35:22.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 6.837188 ms
[2025-05-07T21:35:22.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#2031 - id.nullCount#2030) > 0)
[2025-05-07T21:35:22.075+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 10.946823 ms
[2025-05-07T21:35:22.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 445 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 53
[2025-05-07T21:35:22.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 48 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-07T21:35:22.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 308 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.083+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 306, ShuffleMapStage 307)
[2025-05-07T21:35:22.083+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:35:22.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 308 (MapPartitionsRDD[445] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 23.3 KiB, free 418.1 MiB)
[2025-05-07T21:35:22.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 418.1 MiB)
[2025-05-07T21:35:22.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 3530b0b864fd:36239 (size: 9.9 KiB, free: 433.6 MiB)
[2025-05-07T21:35:22.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 308 (MapPartitionsRDD[445] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:22.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 308.0 with 10 tasks resource profile 0
[2025-05-07T21:35:22.112+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 0.0 in stage 308.0 (TID 495) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got job 49 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-07T21:35:22.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ResultStage 309 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 305)
[2025-05-07T21:35:22.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.117+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ResultStage 309 (MapPartitionsRDD[442] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 15.15282 ms
[2025-05-07T21:35:22.119+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 43.9 KiB, free 418.0 MiB)
[2025-05-07T21:35:22.123+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 418.0 MiB)
[2025-05-07T21:35:22.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 3530b0b864fd:36239 (size: 19.4 KiB, free: 433.5 MiB)
[2025-05-07T21:35:22.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 309 (MapPartitionsRDD[442] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:22.129+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 309.0 with 10 tasks resource profile 0
[2025-05-07T21:35:22.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 448 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 54
[2025-05-07T21:35:22.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 50 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-07T21:35:22.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 332 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 317, ShuffleMapStage 306, ShuffleMapStage 321, ShuffleMapStage 310, ShuffleMapStage 307, ShuffleMapStage 325, ShuffleMapStage 329, ShuffleMapStage 323, ShuffleMapStage 315, ShuffleMapStage 327, ShuffleMapStage 319, ShuffleMapStage 331, ShuffleMapStage 313)
[2025-05-07T21:35:22.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 332 (MapPartitionsRDD[448] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 8.933118 ms
[2025-05-07T21:35:22.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 31.6 KiB, free 418.0 MiB)
[2025-05-07T21:35:22.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 418.0 MiB)
[2025-05-07T21:35:22.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 3530b0b864fd:36239 (size: 11.8 KiB, free: 433.5 MiB)
[2025-05-07T21:35:22.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 332 (MapPartitionsRDD[448] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:35:22.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 332.0 with 10 tasks resource profile 0
[2025-05-07T21:35:22.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 27.725088 ms
[2025-05-07T21:35:22.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.20.0.5:34941 (size: 9.9 KiB, free: 433.0 MiB)
[2025-05-07T21:35:22.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 13.731752 ms
[2025-05-07T21:35:22.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 8.778655 ms
[2025-05-07T21:35:22.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 9.717691 ms
[2025-05-07T21:35:22.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 27.216874 ms
[2025-05-07T21:35:22.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 456 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 55
[2025-05-07T21:35:22.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 5.408627 ms
[2025-05-07T21:35:22.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 51 (toPandas at /opt/airflow/spark/build_graph.py:207) with 6 output partitions
[2025-05-07T21:35:22.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 333 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:22.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 333 (MapPartitionsRDD[456] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.311+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:22.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 36.4 KiB, free 418.0 MiB)
[2025-05-07T21:35:22.316+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 417.9 MiB)
[2025-05-07T21:35:22.319+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 3530b0b864fd:36239 (size: 11.2 KiB, free: 433.5 MiB)
[2025-05-07T21:35:22.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 333 (MapPartitionsRDD[456] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:35:22.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 333.0 with 6 tasks resource profile 0
[2025-05-07T21:35:22.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 458 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 56
[2025-05-07T21:35:22.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 52 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:22.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 334 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:22.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.323+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 334 (MapPartitionsRDD[458] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.324+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 12.7 KiB, free 417.9 MiB)
[2025-05-07T21:35:22.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.9 MiB)
[2025-05-07T21:35:22.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 1.0 in stage 308.0 (TID 496) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.350+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 35.502009 ms
[2025-05-07T21:35:22.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T21:35:22.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 0.0 in stage 308.0 (TID 495) in 238 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:22.352+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.352+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 334 (MapPartitionsRDD[458] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:22.352+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 334.0 with 1 tasks resource profile 0
[2025-05-07T21:35:22.357+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:22.358+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 460 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 57
[2025-05-07T21:35:22.358+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 53 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:22.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 335 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:22.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 335 (MapPartitionsRDD[460] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 2.0 in stage 308.0 (TID 497) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 1.0 in stage 308.0 (TID 496) in 17 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:22.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 27.3 KiB, free 417.9 MiB)
[2025-05-07T21:35:22.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 417.9 MiB)
[2025-05-07T21:35:22.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 3.0 in stage 308.0 (TID 498) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.381+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:22.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 2.0 in stage 308.0 (TID 497) in 18 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:22.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 335 (MapPartitionsRDD[460] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:22.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 335.0 with 1 tasks resource profile 0
[2025-05-07T21:35:22.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 18.141078 ms
[2025-05-07T21:35:22.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:22.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 462 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 58
[2025-05-07T21:35:22.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 54 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:22.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 336 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:22.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 336 (MapPartitionsRDD[462] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 28.5 KiB, free 417.9 MiB)
[2025-05-07T21:35:22.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 417.8 MiB)
[2025-05-07T21:35:22.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T21:35:22.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 4.0 in stage 308.0 (TID 499) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 336 (MapPartitionsRDD[462] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:22.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 336.0 with 1 tasks resource profile 0
[2025-05-07T21:35:22.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 3.0 in stage 308.0 (TID 498) in 24 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:22.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 5.0 in stage 308.0 (TID 500) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 4.0 in stage 308.0 (TID 499) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:22.418+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 17.258309 ms
[2025-05-07T21:35:22.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 5.0 in stage 308.0 (TID 500) in 18 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:22.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 6.0 in stage 308.0 (TID 501) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 464 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 59
[2025-05-07T21:35:22.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 55 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:22.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 337 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:22.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.446+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 337 (MapPartitionsRDD[464] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.449+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:22.452+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 28.5 KiB, free 417.8 MiB)
[2025-05-07T21:35:22.463+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 7.0 in stage 308.0 (TID 502) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 417.8 MiB)
[2025-05-07T21:35:22.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 6.0 in stage 308.0 (TID 501) in 18 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:22.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T21:35:22.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 337 (MapPartitionsRDD[464] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:22.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 337.0 with 1 tasks resource profile 0
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 11.721996 ms
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 466 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 60
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 56 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 338 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 338 (MapPartitionsRDD[466] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 27.4 KiB, free 417.8 MiB)
[2025-05-07T21:35:22.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 8.0 in stage 308.0 (TID 503) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 7.0 in stage 308.0 (TID 502) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:22.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 417.8 MiB)
[2025-05-07T21:35:22.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T21:35:22.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 338 (MapPartitionsRDD[466] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:22.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 338.0 with 1 tasks resource profile 0
[2025-05-07T21:35:22.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 9.0 in stage 308.0 (TID 504) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 8.0 in stage 308.0 (TID 503) in 18 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:22.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 20.374801 ms
[2025-05-07T21:35:22.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 468 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 61
[2025-05-07T21:35:22.490+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:35:22.490+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 57 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:22.490+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 339 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.490+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:22.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.493+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 339 (MapPartitionsRDD[468] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 28.5 KiB, free 417.7 MiB)
[2025-05-07T21:35:22.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 417.7 MiB)
[2025-05-07T21:35:22.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 505) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-07T21:35:22.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 339 (MapPartitionsRDD[468] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:22.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 339.0 with 1 tasks resource profile 0
[2025-05-07T21:35:22.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 9.0 in stage 308.0 (TID 504) in 42 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:22.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Removed TaskSet 308.0, whose tasks have all completed, from pool
[2025-05-07T21:35:22.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: ShuffleMapStage 308 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.439 s
[2025-05-07T21:35:22.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:22.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ShuffleMapStage 332, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 333, ResultStage 309, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T21:35:22.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:22.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:22.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.20.0.5:34941 (size: 19.4 KiB, free: 433.0 MiB)
[2025-05-07T21:35:22.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 49.009601 ms
[2025-05-07T21:35:22.553+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 1.0 in stage 309.0 (TID 506) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Registering RDD 470 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 62
[2025-05-07T21:35:22.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 505) in 35 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:22.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got map stage job 58 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:22.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ShuffleMapStage 340 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:22.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 340 (MapPartitionsRDD[470] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.556+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 31.7 KiB, free 417.7 MiB)
[2025-05-07T21:35:22.562+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 417.7 MiB)
[2025-05-07T21:35:22.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 2.0 in stage 309.0 (TID 507) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 1.0 in stage 309.0 (TID 506) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:22.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 3530b0b864fd:36239 (size: 14.9 KiB, free: 433.4 MiB)
[2025-05-07T21:35:22.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 340 (MapPartitionsRDD[470] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:22.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 340.0 with 1 tasks resource profile 0
[2025-05-07T21:35:22.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 3.0 in stage 309.0 (TID 508) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 2.0 in stage 309.0 (TID 507) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:22.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 4.0 in stage 309.0 (TID 509) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 3.0 in stage 309.0 (TID 508) in 30 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:22.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 5.0 in stage 309.0 (TID 510) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 4.0 in stage 309.0 (TID 509) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:22.645+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 6.0 in stage 309.0 (TID 511) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 5.0 in stage 309.0 (TID 510) in 26 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:22.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:22.661+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 7.0 in stage 309.0 (TID 512) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:22.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 6.0 in stage 309.0 (TID 511) in 23 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:22.674+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 8.0 in stage 309.0 (TID 513) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 7.0 in stage 309.0 (TID 512) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:22.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 9.0 in stage 309.0 (TID 514) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 8.0 in stage 309.0 (TID 513) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:22.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 0.0 in stage 332.0 (TID 515) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 9.0 in stage 309.0 (TID 514) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:22.700+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: ResultStage 309 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.582 s
[2025-05-07T21:35:22.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:35:22.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool
[2025-05-07T21:35:22.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 309: Stage finished
[2025-05-07T21:35:22.706+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Job 49 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.621081 s
[2025-05-07T21:35:22.747+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.20.0.5:34941 (size: 11.8 KiB, free: 433.0 MiB)
[2025-05-07T21:35:22.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:35:22.795+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO CodeGenerator: Code generated in 54.165228 ms
[2025-05-07T21:35:22.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Got job 59 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:22.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Final stage: ResultStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:22.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 341)
[2025-05-07T21:35:22.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:22.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting ResultStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:22.801+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 7.2 KiB, free 417.7 MiB)
[2025-05-07T21:35:22.848+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added rdd_404_0 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:22.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.7 MiB)
[2025-05-07T21:35:22.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 3530b0b864fd:36239 in memory (size: 9.9 KiB, free: 433.4 MiB)
[2025-05-07T21:35:22.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 2.1 MiB, free 415.6 MiB)
[2025-05-07T21:35:22.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:35:22.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:22.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:22.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSchedulerImpl: Adding task set 342.0 with 1 tasks resource profile 0
[2025-05-07T21:35:22.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 415.6 MiB)
[2025-05-07T21:35:22.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 3530b0b864fd:36239 (size: 27.5 KiB, free: 433.4 MiB)
[2025-05-07T21:35:22.861+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO SparkContext: Created broadcast 98 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:35:22.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.20.0.5:34941 in memory (size: 9.9 KiB, free: 433.0 MiB)
[2025-05-07T21:35:22.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.20.0.5:34941 in memory (size: 19.4 KiB, free: 433.0 MiB)
[2025-05-07T21:35:22.871+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 3530b0b864fd:36239 in memory (size: 19.4 KiB, free: 433.4 MiB)
[2025-05-07T21:35:22.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 1.0 in stage 332.0 (TID 516) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 0.0 in stage 332.0 (TID 515) in 214 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:35:22.938+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added rdd_404_1 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:22.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 2.0 in stage 332.0 (TID 517) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.961+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 1.0 in stage 332.0 (TID 516) in 55 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:35:22.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added rdd_404_2 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:22.990+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Starting task 3.0 in stage 332.0 (TID 518) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:22.991+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO TaskSetManager: Finished task 2.0 in stage 332.0 (TID 517) in 32 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:35:22.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:22 INFO BlockManagerInfo: Added rdd_404_3 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:23.003+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 4.0 in stage 332.0 (TID 519) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 3.0 in stage 332.0 (TID 518) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:35:23.010+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added rdd_404_4 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:23.010+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO CodeGenerator: Code generated in 31.331463 ms
[2025-05-07T21:35:23.016+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 5.0 in stage 332.0 (TID 520) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.016+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 4.0 in stage 332.0 (TID 519) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:35:23.016+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Registering RDD 486 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 63
[2025-05-07T21:35:23.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Got map stage job 60 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:23.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Final stage: ShuffleMapStage 343 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:23.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:35:23.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:23.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Submitting ShuffleMapStage 343 (MapPartitionsRDD[486] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:23.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 16.6 KiB, free 415.7 MiB)
[2025-05-07T21:35:23.034+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 415.6 MiB)
[2025-05-07T21:35:23.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 3530b0b864fd:36239 (size: 8.3 KiB, free: 433.4 MiB)
[2025-05-07T21:35:23.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:23.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 343 (MapPartitionsRDD[486] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:23.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSchedulerImpl: Adding task set 343.0 with 1 tasks resource profile 0
[2025-05-07T21:35:23.037+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added rdd_404_5 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:23.046+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 6.0 in stage 332.0 (TID 521) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.047+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 5.0 in stage 332.0 (TID 520) in 32 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:35:23.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added rdd_404_6 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:23.060+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 7.0 in stage 332.0 (TID 522) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 6.0 in stage 332.0 (TID 521) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:35:23.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added rdd_404_7 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:35:23.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 8.0 in stage 332.0 (TID 523) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.080+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 7.0 in stage 332.0 (TID 522) in 19 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:35:23.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added rdd_404_8 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:23.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 9.0 in stage 332.0 (TID 524) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.115+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 8.0 in stage 332.0 (TID 523) in 38 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:35:23.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added rdd_404_9 in memory on 172.20.0.5:34941 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:35:23.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 0.0 in stage 333.0 (TID 525) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 9.0 in stage 332.0 (TID 524) in 25 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:35:23.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSchedulerImpl: Removed TaskSet 332.0, whose tasks have all completed, from pool
[2025-05-07T21:35:23.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: ShuffleMapStage 332 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.003 s
[2025-05-07T21:35:23.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:23.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 333, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T21:35:23.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:23.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:23.146+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.20.0.5:34941 (size: 11.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:23.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO ShufflePartitionsUtil: For shuffle(54), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:23.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:35:23.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Got job 61 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:23.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Final stage: ResultStage 367 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:23.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 366)
[2025-05-07T21:35:23.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:23.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Submitting ResultStage 367 (MapPartitionsRDD[491] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:23.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-07T21:35:23.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 1.0 in stage 333.0 (TID 526) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-07T21:35:23.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 0.0 in stage 333.0 (TID 525) in 114 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:35:23.252+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:35:23.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:23.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 367 (MapPartitionsRDD[491] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:23.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSchedulerImpl: Adding task set 367.0 with 1 tasks resource profile 0
[2025-05-07T21:35:23.254+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 3530b0b864fd:36239 in memory (size: 11.8 KiB, free: 433.4 MiB)
[2025-05-07T21:35:23.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.20.0.5:34941 in memory (size: 11.8 KiB, free: 432.9 MiB)
[2025-05-07T21:35:23.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 2.0 in stage 333.0 (TID 527) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 1.0 in stage 333.0 (TID 526) in 72 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:35:23.357+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 3.0 in stage 333.0 (TID 528) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 2.0 in stage 333.0 (TID 527) in 57 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:35:23.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 4.0 in stage 333.0 (TID 529) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 3.0 in stage 333.0 (TID 528) in 41 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:35:23.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 5.0 in stage 333.0 (TID 530) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 4.0 in stage 333.0 (TID 529) in 42 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:35:23.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 0.0 in stage 334.0 (TID 531) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 5.0 in stage 333.0 (TID 530) in 89 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:35:23.536+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool
[2025-05-07T21:35:23.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: ShuffleMapStage 333 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.232 s
[2025-05-07T21:35:23.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:23.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 337, ShuffleMapStage 334, ResultStage 367)
[2025-05-07T21:35:23.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:23.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:23.578+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.20.0.5:34941 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:35:23.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:23.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:23.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:35:23.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Got job 62 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:23.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Final stage: ResultStage 369 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:23.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 368)
[2025-05-07T21:35:23.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:23.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Submitting ResultStage 369 (MapPartitionsRDD[497] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:23.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 7.2 KiB, free 415.7 MiB)
[2025-05-07T21:35:23.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.7 MiB)
[2025-05-07T21:35:23.934+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Starting task 0.0 in stage 335.0 (TID 532) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:23.940+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.20.0.5:34941 in memory (size: 11.2 KiB, free: 432.9 MiB)
[2025-05-07T21:35:23.940+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSetManager: Finished task 0.0 in stage 334.0 (TID 531) in 420 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:23.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:35:23.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 3530b0b864fd:36239 in memory (size: 11.2 KiB, free: 433.4 MiB)
[2025-05-07T21:35:23.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSchedulerImpl: Removed TaskSet 334.0, whose tasks have all completed, from pool
[2025-05-07T21:35:23.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.20.0.5:34941 (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-07T21:35:23.948+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:23.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 369 (MapPartitionsRDD[497] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:23.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO TaskSchedulerImpl: Adding task set 369.0 with 1 tasks resource profile 0
[2025-05-07T21:35:23.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: ShuffleMapStage 334 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.628 s
[2025-05-07T21:35:23.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:23.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 337, ResultStage 367)
[2025-05-07T21:35:23.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:23.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:35:23.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:23 INFO ShufflePartitionsUtil: For shuffle(56), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:35:25.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:25 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:35:26.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:25 INFO DAGScheduler: Got job 63 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:35:26.252+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:25 INFO DAGScheduler: Final stage: ResultStage 371 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:35:26.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 370)
[2025-05-07T21:35:26.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:25 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:35:26.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:25 INFO DAGScheduler: Submitting ResultStage 371 (MapPartitionsRDD[504] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:35:26.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:25 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 7.2 KiB, free 415.7 MiB)
[2025-05-07T21:35:28.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:28 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.7 MiB)
[2025-05-07T21:35:28.713+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:28 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:35:28.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:28 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T21:35:28.771+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:28 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:35:28.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:28 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.20.0.5:34941 in memory (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:35:29.121+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 371 (MapPartitionsRDD[504] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:35:29.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:28 INFO TaskSchedulerImpl: Adding task set 371.0 with 1 tasks resource profile 0
[2025-05-07T21:35:45.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:45 INFO TaskSetManager: Starting task 0.0 in stage 336.0 (TID 533) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:35:45.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:45 INFO TaskSetManager: Finished task 0.0 in stage 335.0 (TID 532) in 21302 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:35:45.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:45 INFO TaskSchedulerImpl: Removed TaskSet 335.0, whose tasks have all completed, from pool
[2025-05-07T21:35:46.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:45 INFO DAGScheduler: ShuffleMapStage 335 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 22.886 s
[2025-05-07T21:35:46.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:35:46.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:45 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 371, ResultStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 337, ResultStage 367)
[2025-05-07T21:35:46.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:45 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:35:46.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:35:45 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:15.276+0000] {job.py:213} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.20.0.3), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 184, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3056, in merge
    return self._merge(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3136, in _merge
    merged = self.get(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2853, in get
    return self._get_impl(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2975, in _get_impl
    return db_load_fn(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.20.0.3), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-05-07T21:37:16.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(0,WrappedArray((532,335,0,Vector(AccumulableInfo(4637,Some(internal.metrics.jvmGCTime),Some(1185),None,true,true,None), AccumulableInfo(4641,Some(internal.metrics.peakExecutionMemory),Some(17039360),None,true,true,None), AccumulableInfo(4650,Some(internal.metrics.shuffle.write.bytesWritten),Some(618),None,true,true,None), AccumulableInfo(4651,Some(internal.metrics.shuffle.write.recordsWritten),Some(14),None,true,true,None), AccumulableInfo(4652,Some(internal.metrics.shuffle.write.writeTime),Some(251757690),None,true,true,None), AccumulableInfo(4654,Some(internal.metrics.input.recordsRead),Some(4652),None,true,true,None), AccumulableInfo(3825,Some(number of output rows),Some(4652),None,true,true,Some(sql)), AccumulableInfo(3822,Some(time in aggregation build),Some(4850),None,true,true,Some(sql)), AccumulableInfo(3820,Some(peak memory),Some(17039360),None,true,true,Some(sql)), AccumulableInfo(3819,Some(number of output rows),Some(14),None,true,true,Some(sql)), AccumulableInfo(3823,Some(avg hash probe bucket list iters),Some(10),None,true,true,Some(sql)), AccumulableInfo(4358,Some(duration),Some(8821),None,true,true,Some(sql)), AccumulableInfo(4346,Some(data size),Some(392),None,true,true,Some(sql)), AccumulableInfo(4355,Some(shuffle bytes written),Some(618),None,true,true,Some(sql)), AccumulableInfo(4356,Some(shuffle records written),Some(14),None,true,true,Some(sql)), AccumulableInfo(4357,Some(shuffle write time),Some(251757690),None,true,true,Some(sql))))),Map((335,0) -> org.apache.spark.executor.ExecutorMetrics@f98ea0a)) by listener AppStatusListener took 1.288240927s.
[2025-05-07T21:37:16.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.20.0.5:34941 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T21:37:16.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO TaskSetManager: Starting task 0.0 in stage 337.0 (TID 534) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:16.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO TaskSetManager: Finished task 0.0 in stage 336.0 (TID 533) in 91088 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:37:16.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO TaskSchedulerImpl: Removed TaskSet 336.0, whose tasks have all completed, from pool
[2025-05-07T21:37:16.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: ShuffleMapStage 336 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 113.895 s
[2025-05-07T21:37:16.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:16.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 371, ResultStage 342, ShuffleMapStage 339, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 337, ResultStage 367)
[2025-05-07T21:37:16.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:37:16.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:16.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.20.0.5:34941 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T21:37:16.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO TaskSetManager: Starting task 0.0 in stage 338.0 (TID 535) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:16.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO TaskSetManager: Finished task 0.0 in stage 337.0 (TID 534) in 168 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:37:16.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool
[2025-05-07T21:37:16.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: ShuffleMapStage 337 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 114.015 s
[2025-05-07T21:37:16.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:16.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 371, ResultStage 342, ShuffleMapStage 339, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ResultStage 367)
[2025-05-07T21:37:16.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:37:16.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:16.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.20.0.5:34941 (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-07T21:37:16.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507213450-0005/0 is now LOST (worker lost)
[2025-05-07T21:37:16.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO StandaloneSchedulerBackend: Executor app-20250507213450-0005/0 removed: worker lost
[2025-05-07T21:37:16.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 ERROR TaskSchedulerImpl: Lost executor 0 on 172.20.0.5: worker lost
[2025-05-07T21:37:16.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN TaskSetManager: Lost task 0.0 in stage 338.0 (TID 535) (172.20.0.5 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: worker lost
[2025-05-07T21:37:16.601+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: Executor lost: 0 (epoch 59)
[2025-05-07T21:37:16.608+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
[2025-05-07T21:37:16.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_7 !
[2025-05-07T21:37:16.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_5 !
[2025-05-07T21:37:16.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_7 !
[2025-05-07T21:37:16.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_6 !
[2025-05-07T21:37:16.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_5 !
[2025-05-07T21:37:16.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_7 !
[2025-05-07T21:37:16.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_3 !
[2025-05-07T21:37:16.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_8 !
[2025-05-07T21:37:16.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_4 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_9 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_0 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_7 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_0 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_3 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_4 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_2 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_6 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_4 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_1 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_0 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_0 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_8 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_4 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_6 !
[2025-05-07T21:37:16.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_3 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_5 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_2 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_6 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_7 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_5 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_3 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_9 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_4 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_7 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_9 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_4 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_4 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_3 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_9 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_6 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_2 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_4 !
[2025-05-07T21:37:16.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_1 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_1 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_5 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_2 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_6 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_3 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_9 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_3 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_8 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_5 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_6 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_2 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_6 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_2 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_0 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_2 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_0 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_8 !
[2025-05-07T21:37:16.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_8 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_5 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_0 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_3 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_8 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_1 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_3 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_7 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_7 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_1 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_6 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_1 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_3 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_1 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_6 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_2 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_5 !
[2025-05-07T21:37:16.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_7 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_2 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_4 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_3 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_0 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_8 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_4 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_4 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_9 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_0 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_7 !
[2025-05-07T21:37:16.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_0 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_9 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_8 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_5 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_6 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_9 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_8 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_5 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_0 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_8 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_2 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_7 !
[2025-05-07T21:37:16.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_5 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_2 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_9 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_2 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_9 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_0 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_3 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_3 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_0 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_6 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_9 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_1 !
[2025-05-07T21:37:16.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_8 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_6 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_9 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_7 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_8 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_5 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_9 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_400_1 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_1 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_4 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_1 !
[2025-05-07T21:37:16.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_239_4 !
[2025-05-07T21:37:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_2 !
[2025-05-07T21:37:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_5 !
[2025-05-07T21:37:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_7 !
[2025-05-07T21:37:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_8 !
[2025-05-07T21:37:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_1 !
[2025-05-07T21:37:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_1 !
[2025-05-07T21:37:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.20.0.5, 34941, None)
[2025-05-07T21:37:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor
[2025-05-07T21:37:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:16 INFO DAGScheduler: Shuffle files lost for host: 172.20.0.5 (epoch 59)
[2025-05-07T21:37:17.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:17 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 535 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
[2025-05-07T21:37:18.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:18 WARN CoarseGrainedSchedulerBackend$DriverEndpoint: Ignored task status update (535 state FINISHED) from unknown executor with ID 0
[2025-05-07T21:37:18.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:18 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20250507121535-172.20.0.5-41865: Not receiving heartbeat for 60 seconds
[2025-05-07T21:37:18.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:18 INFO StandaloneSchedulerBackend: Worker worker-20250507121535-172.20.0.5-41865 removed: Not receiving heartbeat for 60 seconds
[2025-05-07T21:37:18.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:18 INFO TaskSchedulerImpl: Handle removed worker worker-20250507121535-172.20.0.5-41865: Not receiving heartbeat for 60 seconds
[2025-05-07T21:37:18.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:18 INFO DAGScheduler: Shuffle files lost for worker worker-20250507121535-172.20.0.5-41865 on host 172.20.0.5
[2025-05-07T21:37:19.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:19 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250507213450-0005/1 on worker-20250507121535-172.20.0.5-41865 (172.20.0.5:41865) with 1 core(s)
[2025-05-07T21:37:19.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:19 INFO StandaloneSchedulerBackend: Granted executor ID app-20250507213450-0005/1 on hostPort 172.20.0.5:41865 with 1 core(s), 1024.0 MiB RAM
[2025-05-07T21:37:19.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507213450-0005/1 is now RUNNING
[2025-05-07T21:37:21.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:58132) with ID 1,  ResourceProfileId 0
[2025-05-07T21:37:21.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:37555 with 434.4 MiB RAM, BlockManagerId(1, 172.20.0.5, 37555, None)
[2025-05-07T21:37:22.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:22 INFO TaskSetManager: Starting task 0.1 in stage 338.0 (TID 536) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:22.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:22 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.20.0.5:37555 (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:37:22.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:22 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 433.4 MiB)
[2025-05-07T21:37:22.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:22 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T21:37:22.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:22 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T21:37:23.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO TaskSetManager: Starting task 0.0 in stage 339.0 (TID 537) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:23.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO TaskSetManager: Finished task 0.1 in stage 338.0 (TID 536) in 1276 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:23.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO TaskSchedulerImpl: Removed TaskSet 338.0, whose tasks have all completed, from pool
[2025-05-07T21:37:23.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: ShuffleMapStage 338 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 120.838 s
[2025-05-07T21:37:23.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:23.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: running: Set(ResultStage 371, ResultStage 342, ShuffleMapStage 339, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ResultStage 367)
[2025-05-07T21:37:23.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:37:23.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:23.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.20.0.5:37555 (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T21:37:23.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO TaskSetManager: Starting task 0.0 in stage 340.0 (TID 538) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:23.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO TaskSetManager: Finished task 0.0 in stage 339.0 (TID 537) in 99 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:23.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO TaskSchedulerImpl: Removed TaskSet 339.0, whose tasks have all completed, from pool
[2025-05-07T21:37:23.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: ShuffleMapStage 339 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 120.906 s
[2025-05-07T21:37:23.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:23.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: running: Set(ResultStage 371, ResultStage 342, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ResultStage 367)
[2025-05-07T21:37:23.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:37:23.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:23.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.20.0.5:37555 (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-07T21:37:23.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO TaskSetManager: Starting task 0.0 in stage 342.0 (TID 539) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:23.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO TaskSetManager: Finished task 0.0 in stage 340.0 (TID 538) in 460 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:23.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO TaskSchedulerImpl: Removed TaskSet 340.0, whose tasks have all completed, from pool
[2025-05-07T21:37:23.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: ShuffleMapStage 340 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 121.303 s
[2025-05-07T21:37:23.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:23.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: running: Set(ResultStage 371, ResultStage 342, ResultStage 369, ShuffleMapStage 343, ResultStage 367)
[2025-05-07T21:37:23.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:37:23.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:23.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO ShufflePartitionsUtil: For shuffle(57, 58, 59, 60, 61, 62), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:37:23.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.20.0.5:37555 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:37:23.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO CodeGenerator: Code generated in 3.82366 ms
[2025-05-07T21:37:23.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:23.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO CodeGenerator: Code generated in 16.582327 ms
[2025-05-07T21:37:23.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:23.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO CodeGenerator: Code generated in 9.656528 ms
[2025-05-07T21:37:23.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:23.961+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO CodeGenerator: Code generated in 8.385532 ms
[2025-05-07T21:37:23.965+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:58132
[2025-05-07T21:37:23.968+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:23.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO CodeGenerator: Code generated in 21.25738 ms
[2025-05-07T21:37:23.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T21:37:23.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:23.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:23 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.20.0.5:37555 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.009+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO CodeGenerator: Code generated in 14.437372 ms
[2025-05-07T21:37:24.010+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 3530b0b864fd:36239 in memory (size: 14.9 KiB, free: 433.5 MiB)
[2025-05-07T21:37:24.012+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Starting task 0.0 in stage 343.0 (TID 540) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:24.013+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:24.015+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.20.0.5:37555 in memory (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 WARN TaskSetManager: Lost task 0.0 in stage 342.0 (TID 539) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=53, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 53 partition 0
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T21:37:24.018+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:238)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:37:24.019+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - )
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: task 0.0 in stage 342.0 (TID 539) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Removed TaskSet 342.0, whose tasks have all completed, from pool
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Marking ResultStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207) as failed due to a fetch failure from ShuffleMapStage 341 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: ResultStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207) failed in 121.224 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 53 partition 0
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T21:37:24.020+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:238)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.021+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:37:24.022+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:37:24.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Resubmitting ShuffleMapStage 341 (toPandas at /opt/airflow/spark/build_graph.py:207) and ResultStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207) due to fetch failure
[2025-05-07T21:37:24.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO CodeGenerator: Code generated in 8.806291 ms
[2025-05-07T21:37:24.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T21:37:24.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.20.0.5:37555 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.20.0.5:37555 (size: 8.3 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:24.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Got job 64 (toPandas at /opt/airflow/spark/build_graph.py:207) with 6 output partitions
[2025-05-07T21:37:24.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Final stage: ResultStage 378 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:24.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 374, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 376, ShuffleMapStage 373, ShuffleMapStage 377)
[2025-05-07T21:37:24.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 377)
[2025-05-07T21:37:24.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 372 (MapPartitionsRDD[462] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:24.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 28.5 KiB, free 415.9 MiB)
[2025-05-07T21:37:24.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 415.9 MiB)
[2025-05-07T21:37:24.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 3530b0b864fd:36239 (size: 13.5 KiB, free: 433.5 MiB)
[2025-05-07T21:37:24.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:24.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 372 (MapPartitionsRDD[462] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:24.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Adding task set 372.0 with 1 tasks resource profile 0
[2025-05-07T21:37:24.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 375 (MapPartitionsRDD[460] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:24.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 27.3 KiB, free 415.9 MiB)
[2025-05-07T21:37:24.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 415.9 MiB)
[2025-05-07T21:37:24.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T21:37:24.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:24.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 375 (MapPartitionsRDD[460] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:24.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Adding task set 375.0 with 1 tasks resource profile 0
[2025-05-07T21:37:24.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 377 (MapPartitionsRDD[464] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:24.060+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 28.5 KiB, free 415.9 MiB)
[2025-05-07T21:37:24.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 415.8 MiB)
[2025-05-07T21:37:24.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 3530b0b864fd:36239 (size: 13.5 KiB, free: 433.5 MiB)
[2025-05-07T21:37:24.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:24.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 377 (MapPartitionsRDD[464] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:24.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Adding task set 377.0 with 1 tasks resource profile 0
[2025-05-07T21:37:24.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.20.0.5:37555 (size: 27.5 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 433.5 MiB)
[2025-05-07T21:37:24.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.20.0.5:37555 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.138+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Starting task 0.0 in stage 367.0 (TID 541) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:24.139+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Finished task 0.0 in stage 343.0 (TID 540) in 127 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:24.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Removed TaskSet 343.0, whose tasks have all completed, from pool
[2025-05-07T21:37:24.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: ShuffleMapStage 343 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 121.123 s
[2025-05-07T21:37:24.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:24.141+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: running: Set(ResultStage 371, ShuffleMapStage 375, ShuffleMapStage 372, ResultStage 369, ShuffleMapStage 377, ResultStage 367)
[2025-05-07T21:37:24.141+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: waiting: Set(ResultStage 378)
[2025-05-07T21:37:24.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: failed: Set(ResultStage 342, ShuffleMapStage 341)
[2025-05-07T21:37:24.157+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.20.0.5:37555 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.20.0.5:58132
[2025-05-07T21:37:24.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Starting task 0.0 in stage 369.0 (TID 542) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:24.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 WARN TaskSetManager: Lost task 0.0 in stage 367.0 (TID 541) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=54, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-07T21:37:24.174+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 54 partition 0
[2025-05-07T21:37:24.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T21:37:24.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T21:37:24.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.176+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T21:37:24.176+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T21:37:24.177+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T21:37:24.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T21:37:24.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T21:37:24.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T21:37:24.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:238)
[2025-05-07T21:37:24.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:37:24.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2025-05-07T21:37:24.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:37:24.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:37:24.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:37:24.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:37:24.182+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:37:24.183+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:37:24.183+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:37:24.183+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:37:24.183+0000] {spark_submit.py:571} INFO - )
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: task 0.0 in stage 367.0 (TID 541) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Removed TaskSet 367.0, whose tasks have all completed, from pool
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Marking ResultStage 367 (toPandas at /opt/airflow/spark/build_graph.py:207) as failed due to a fetch failure from ShuffleMapStage 366 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: ResultStage 367 (toPandas at /opt/airflow/spark/build_graph.py:207) failed in 120.950 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 54 partition 0
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T21:37:24.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:238)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2025-05-07T21:37:24.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:37:24.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:37:24.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:37:24.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:37:24.186+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:37:24.186+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:37:24.186+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:37:24.186+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:37:24.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Resubmitting ShuffleMapStage 366 (toPandas at /opt/airflow/spark/build_graph.py:207) and ResultStage 367 (toPandas at /opt/airflow/spark/build_graph.py:207) due to fetch failure
[2025-05-07T21:37:24.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.20.0.5:37555 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.190+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:58132
[2025-05-07T21:37:24.199+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Starting task 0.0 in stage 371.0 (TID 543) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 WARN TaskSetManager: Lost task 0.0 in stage 369.0 (TID 542) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=55, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 55 partition 0
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.200+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T21:37:24.201+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T21:37:24.201+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T21:37:24.201+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:238)
[2025-05-07T21:37:24.201+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.201+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.201+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:37:24.202+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - )
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: task 0.0 in stage 369.0 (TID 542) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Marking ResultStage 369 (toPandas at /opt/airflow/spark/build_graph.py:207) as failed due to a fetch failure from ShuffleMapStage 368 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Removed TaskSet 369.0, whose tasks have all completed, from pool
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: ResultStage 369 (toPandas at /opt/airflow/spark/build_graph.py:207) failed in 120.449 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 55 partition 0
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.203+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T21:37:24.204+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T21:37:24.204+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T21:37:24.204+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.204+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T21:37:24.204+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T21:37:24.204+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T21:37:24.204+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:238)
[2025-05-07T21:37:24.204+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.204+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:37:24.205+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:37:24.206+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:37:24.206+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:37:24.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Resubmitting ShuffleMapStage 368 (toPandas at /opt/airflow/spark/build_graph.py:207) and ResultStage 369 (toPandas at /opt/airflow/spark/build_graph.py:207) due to fetch failure
[2025-05-07T21:37:24.222+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.20.0.5:37555 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.224+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 3530b0b864fd:36239 in memory (size: 8.3 KiB, free: 433.5 MiB)
[2025-05-07T21:37:24.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Resubmitting failed stages
[2025-05-07T21:37:24.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.20.0.5:37555 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 305 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:37:24.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:58132
[2025-05-07T21:37:24.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 12.6 KiB, free 415.9 MiB)
[2025-05-07T21:37:24.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 415.9 MiB)
[2025-05-07T21:37:24.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T21:37:24.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:24.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 305 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:24.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Adding task set 305.0 with 1 tasks resource profile 0
[2025-05-07T21:37:24.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Starting task 0.0 in stage 305.0 (TID 544) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:24.239+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 368 (MapPartitionsRDD[456] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:24.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 WARN TaskSetManager: Lost task 0.0 in stage 371.0 (TID 543) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=56, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-07T21:37:24.240+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 56 partition 0
[2025-05-07T21:37:24.241+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T21:37:24.241+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T21:37:24.241+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.242+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T21:37:24.242+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T21:37:24.242+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T21:37:24.242+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.242+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T21:37:24.242+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:228)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:37:24.243+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:37:24.244+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:37:24.244+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:37:24.244+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:37:24.244+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:37:24.244+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:37:24.244+0000] {spark_submit.py:571} INFO - )
[2025-05-07T21:37:24.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: task 0.0 in stage 371.0 (TID 543) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T21:37:24.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Removed TaskSet 371.0, whose tasks have all completed, from pool
[2025-05-07T21:37:24.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 36.4 KiB, free 415.8 MiB)
[2025-05-07T21:37:24.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 415.8 MiB)
[2025-05-07T21:37:24.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 3530b0b864fd:36239 (size: 11.3 KiB, free: 433.5 MiB)
[2025-05-07T21:37:24.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:24.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 368 (MapPartitionsRDD[456] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:37:24.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Adding task set 368.1 with 6 tasks resource profile 0
[2025-05-07T21:37:24.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Marking ResultStage 371 (toPandas at /opt/airflow/spark/build_graph.py:207) as failed due to a fetch failure from ShuffleMapStage 370 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:24.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: ResultStage 371 (toPandas at /opt/airflow/spark/build_graph.py:207) failed in 118.679 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 56 partition 0
[2025-05-07T21:37:24.247+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T21:37:24.247+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T21:37:24.247+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.247+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T21:37:24.247+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:228)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:37:24.248+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:37:24.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Resubmitting ShuffleMapStage 370 (toPandas at /opt/airflow/spark/build_graph.py:207) and ResultStage 371 (toPandas at /opt/airflow/spark/build_graph.py:207) due to fetch failure
[2025-05-07T21:37:24.254+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.20.0.5:37555 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Starting task 0.0 in stage 368.1 (TID 545) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:24.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Finished task 0.0 in stage 305.0 (TID 544) in 60 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:24.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Removed TaskSet 305.0, whose tasks have all completed, from pool
[2025-05-07T21:37:24.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: ShuffleMapStage 305 (rdd at GraphFrame.scala:187) finished in 0.070 s
[2025-05-07T21:37:24.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:24.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 377)
[2025-05-07T21:37:24.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 306, ShuffleMapStage 357, ShuffleMapStage 307, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ShuffleMapStage 347, ShuffleMapStage 348, ResultStage 378, ShuffleMapStage 349, ShuffleMapStage 350, ResultStage 342, ShuffleMapStage 365, ShuffleMapStage 344, ShuffleMapStage 366, ShuffleMapStage 345, ResultStage 367, ShuffleMapStage 346, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 341, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:24.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: failed: Set(ResultStage 371, ShuffleMapStage 370)
[2025-05-07T21:37:24.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 306 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[223] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-07T21:37:24.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 158.2 KiB, free 415.7 MiB)
[2025-05-07T21:37:24.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 55.6 KiB, free 415.6 MiB)
[2025-05-07T21:37:24.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 3530b0b864fd:36239 (size: 55.6 KiB, free: 433.4 MiB)
[2025-05-07T21:37:24.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:24.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 306 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[223] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:24.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Adding task set 306.0 with 10 tasks resource profile 0
[2025-05-07T21:37:24.316+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 307 (MapPartitionsRDD[31] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:37:24.317+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.20.0.5:37555 (size: 11.3 KiB, free: 434.3 MiB)
[2025-05-07T21:37:24.319+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 59.1 KiB, free 415.5 MiB)
[2025-05-07T21:37:24.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 415.5 MiB)
[2025-05-07T21:37:24.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 3530b0b864fd:36239 (size: 26.0 KiB, free: 433.4 MiB)
[2025-05-07T21:37:24.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:24.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 307 (MapPartitionsRDD[31] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:24.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Adding task set 307.0 with 10 tasks resource profile 0
[2025-05-07T21:37:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 344 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[260] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:24.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 161.1 KiB, free 415.4 MiB)
[2025-05-07T21:37:24.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 56.8 KiB, free 415.3 MiB)
[2025-05-07T21:37:24.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 3530b0b864fd:36239 (size: 56.8 KiB, free: 433.3 MiB)
[2025-05-07T21:37:24.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:24.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 344 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[260] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:24.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Adding task set 344.0 with 10 tasks resource profile 0
[2025-05-07T21:37:24.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Resubmitting failed stages
[2025-05-07T21:37:24.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 370 (MapPartitionsRDD[458] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:24.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 12.7 KiB, free 415.3 MiB)
[2025-05-07T21:37:24.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 415.3 MiB)
[2025-05-07T21:37:24.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 3530b0b864fd:36239 (size: 6.8 KiB, free: 433.3 MiB)
[2025-05-07T21:37:24.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:24.387+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 370 (MapPartitionsRDD[458] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:24.387+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSchedulerImpl: Adding task set 370.1 with 1 tasks resource profile 0
[2025-05-07T21:37:24.388+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 433.3 MiB)
[2025-05-07T21:37:24.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.20.0.5:37555 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:37:24.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 433.3 MiB)
[2025-05-07T21:37:24.408+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Starting task 0.0 in stage 306.0 (TID 546) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:24.410+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.20.0.5:37555 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO TaskSetManager: Finished task 0.0 in stage 368.1 (TID 545) in 115 ms on 172.20.0.5 (executor 1) (1/6)
[2025-05-07T21:37:24.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 433.3 MiB)
[2025-05-07T21:37:24.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.20.0.5:37555 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:37:24.425+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.20.0.5:37555 (size: 55.6 KiB, free: 434.3 MiB)
[2025-05-07T21:37:24.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:58132
[2025-05-07T21:37:24.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 433.3 MiB)
[2025-05-07T21:37:24.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.20.0.5:37555 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-07T21:37:24.925+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.20.0.5:37555 (size: 2.0 KiB, free: 434.3 MiB)
[2025-05-07T21:37:24.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:37555 (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-07T21:37:24.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:24 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.20.0.5:37555 (size: 98.0 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 1.0 in stage 306.0 (TID 547) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 0.0 in stage 306.0 (TID 546) in 1636 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:26.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.20.0.5:37555 (size: 2.5 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 2.0 in stage 306.0 (TID 548) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 1.0 in stage 306.0 (TID 547) in 91 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:26.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 3.0 in stage 306.0 (TID 549) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 2.0 in stage 306.0 (TID 548) in 45 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:26.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.20.0.5:37555 (size: 2.3 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 4.0 in stage 306.0 (TID 550) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 3.0 in stage 306.0 (TID 549) in 57 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:26.265+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.20.0.5:37555 (size: 2.1 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 5.0 in stage 306.0 (TID 551) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 4.0 in stage 306.0 (TID 550) in 45 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:26.318+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.20.0.5:37555 (size: 2.0 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 6.0 in stage 306.0 (TID 552) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.341+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 5.0 in stage 306.0 (TID 551) in 62 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:26.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.20.0.5:37555 (size: 2.1 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 7.0 in stage 306.0 (TID 553) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.380+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 6.0 in stage 306.0 (TID 552) in 40 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:26.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.20.0.5:37555 (size: 2.3 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 8.0 in stage 306.0 (TID 554) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 7.0 in stage 306.0 (TID 553) in 60 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:26.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.20.0.5:37555 (size: 2.4 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 9.0 in stage 306.0 (TID 555) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 8.0 in stage 306.0 (TID 554) in 43 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:26.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.20.0.5:37555 (size: 2.3 KiB, free: 434.2 MiB)
[2025-05-07T21:37:26.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 0.0 in stage 307.0 (TID 556) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 9.0 in stage 306.0 (TID 555) in 43 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:26.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool
[2025-05-07T21:37:26.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: ShuffleMapStage 306 (mapPartitions at VertexRDD.scala:356) finished in 2.225 s
[2025-05-07T21:37:26.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:26.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 307, ShuffleMapStage 344, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:26.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ShuffleMapStage 347, ShuffleMapStage 348, ResultStage 378, ShuffleMapStage 349, ResultStage 371, ShuffleMapStage 350, ResultStage 342, ShuffleMapStage 365, ShuffleMapStage 366, ShuffleMapStage 345, ResultStage 367, ShuffleMapStage 346, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 341, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:26.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:26.536+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.20.0.5:37555 (size: 26.0 KiB, free: 434.1 MiB)
[2025-05-07T21:37:26.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.5:37555 (size: 28.8 KiB, free: 434.1 MiB)
[2025-05-07T21:37:26.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 1.0 in stage 307.0 (TID 557) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 0.0 in stage 307.0 (TID 556) in 59 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:26.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 2.0 in stage 307.0 (TID 558) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 1.0 in stage 307.0 (TID 557) in 23 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:26.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 3.0 in stage 307.0 (TID 559) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 2.0 in stage 307.0 (TID 558) in 20 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:26.648+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 4.0 in stage 307.0 (TID 560) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.649+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 3.0 in stage 307.0 (TID 559) in 23 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:26.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 5.0 in stage 307.0 (TID 561) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 4.0 in stage 307.0 (TID 560) in 17 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:26.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 6.0 in stage 307.0 (TID 562) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 5.0 in stage 307.0 (TID 561) in 17 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:26.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 7.0 in stage 307.0 (TID 563) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 6.0 in stage 307.0 (TID 562) in 17 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:26.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 8.0 in stage 307.0 (TID 564) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 7.0 in stage 307.0 (TID 563) in 18 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:26.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 9.0 in stage 307.0 (TID 565) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 8.0 in stage 307.0 (TID 564) in 16 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:26.747+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 0.0 in stage 344.0 (TID 566) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 9.0 in stage 307.0 (TID 565) in 15 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:26.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSchedulerImpl: Removed TaskSet 307.0, whose tasks have all completed, from pool
[2025-05-07T21:37:26.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: ShuffleMapStage 307 (map at GraphFrame.scala:187) finished in 2.432 s
[2025-05-07T21:37:26.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:26.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 344, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:26.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ShuffleMapStage 347, ShuffleMapStage 348, ResultStage 378, ShuffleMapStage 349, ResultStage 371, ShuffleMapStage 350, ResultStage 342, ShuffleMapStage 365, ShuffleMapStage 366, ShuffleMapStage 345, ResultStage 367, ShuffleMapStage 346, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 341, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:26.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:26.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: Submitting ShuffleMapStage 341 (MapPartitionsRDD[445] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:26.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 23.3 KiB, free 415.3 MiB)
[2025-05-07T21:37:26.754+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 415.3 MiB)
[2025-05-07T21:37:26.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 3530b0b864fd:36239 (size: 9.9 KiB, free: 433.3 MiB)
[2025-05-07T21:37:26.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:26.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 341 (MapPartitionsRDD[445] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:26.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSchedulerImpl: Adding task set 341.1 with 10 tasks resource profile 0
[2025-05-07T21:37:26.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.20.0.5:37555 (size: 56.8 KiB, free: 434.1 MiB)
[2025-05-07T21:37:26.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 3530b0b864fd:36239 in memory (size: 55.6 KiB, free: 433.4 MiB)
[2025-05-07T21:37:26.770+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.20.0.5:37555 in memory (size: 55.6 KiB, free: 434.1 MiB)
[2025-05-07T21:37:26.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_229_0 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 434.1 MiB)
[2025-05-07T21:37:26.843+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added rdd_233_0 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 434.1 MiB)
[2025-05-07T21:37:26.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Starting task 0.0 in stage 341.1 (TID 567) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:26.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO TaskSetManager: Finished task 0.0 in stage 344.0 (TID 566) in 112 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:26.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.20.0.5:37555 (size: 9.9 KiB, free: 434.1 MiB)
[2025-05-07T21:37:26.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.20.0.5:58132
[2025-05-07T21:37:26.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.20.0.5:58132
[2025-05-07T21:37:27.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_0 in memory on 172.20.0.5:37555 (size: 18.6 KiB, free: 434.1 MiB)
[2025-05-07T21:37:27.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_0 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 434.1 MiB)
[2025-05-07T21:37:27.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_0 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 434.1 MiB)
[2025-05-07T21:37:27.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_0 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 434.1 MiB)
[2025-05-07T21:37:27.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 1.0 in stage 341.1 (TID 568) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.222+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 0.0 in stage 341.1 (TID 567) in 363 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:27.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_1 in memory on 172.20.0.5:37555 (size: 18.6 KiB, free: 434.1 MiB)
[2025-05-07T21:37:27.254+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_1 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_1 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_1 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 2.0 in stage 341.1 (TID 569) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 1.0 in stage 341.1 (TID 568) in 49 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:27.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_2 in memory on 172.20.0.5:37555 (size: 18.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_2 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_2 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_2 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 3.0 in stage 341.1 (TID 570) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 2.0 in stage 341.1 (TID 569) in 43 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:27.331+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_3 in memory on 172.20.0.5:37555 (size: 18.2 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_3 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_3 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_3 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 4.0 in stage 341.1 (TID 571) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 3.0 in stage 341.1 (TID 570) in 33 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:27.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_4 in memory on 172.20.0.5:37555 (size: 18.8 KiB, free: 434.0 MiB)
[2025-05-07T21:37:27.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_4 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_4 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_4 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 5.0 in stage 341.1 (TID 572) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 4.0 in stage 341.1 (TID 571) in 35 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:27.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_5 in memory on 172.20.0.5:37555 (size: 18.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_5 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_5 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_5 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 6.0 in stage 341.1 (TID 573) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 5.0 in stage 341.1 (TID 572) in 35 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:27.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_6 in memory on 172.20.0.5:37555 (size: 18.4 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_6 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_6 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.446+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_6 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 7.0 in stage 341.1 (TID 574) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 6.0 in stage 341.1 (TID 573) in 43 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:27.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_7 in memory on 172.20.0.5:37555 (size: 18.4 KiB, free: 433.9 MiB)
[2025-05-07T21:37:27.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_7 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.485+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_7 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.488+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_7 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 8.0 in stage 341.1 (TID 575) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 7.0 in stage 341.1 (TID 574) in 40 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:27.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_8 in memory on 172.20.0.5:37555 (size: 18.0 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.517+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_8 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_8 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.522+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_8 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 9.0 in stage 341.1 (TID 576) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 8.0 in stage 341.1 (TID 575) in 38 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:27.556+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_226_9 in memory on 172.20.0.5:37555 (size: 18.0 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.559+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_231_9 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_237_9 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_241_9 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 1.0 in stage 344.0 (TID 577) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 9.0 in stage 341.1 (TID 576) in 41 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:27.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSchedulerImpl: Removed TaskSet 341.1, whose tasks have all completed, from pool
[2025-05-07T21:37:27.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: ShuffleMapStage 341 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.823 s
[2025-05-07T21:37:27.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:27.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 344, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:27.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ShuffleMapStage 347, ShuffleMapStage 348, ResultStage 378, ShuffleMapStage 349, ResultStage 371, ShuffleMapStage 350, ResultStage 342, ShuffleMapStage 365, ShuffleMapStage 366, ShuffleMapStage 345, ResultStage 367, ShuffleMapStage 346, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:27.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:27.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Submitting ResultStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:27.578+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 342.
[2025-05-07T21:37:27.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 7.2 KiB, free 415.5 MiB)
[2025-05-07T21:37:27.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.5 MiB)
[2025-05-07T21:37:27.581+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:37:27.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:27.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:27.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSchedulerImpl: Adding task set 342.1 with 1 tasks resource profile 0
[2025-05-07T21:37:27.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_229_1 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.600+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_233_1 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 0.0 in stage 342.1 (TID 578) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 1.0 in stage 344.0 (TID 577) in 33 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:27.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.20.0.5:37555 (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:58132
[2025-05-07T21:37:27.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 2.0 in stage 344.0 (TID 579) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 0.0 in stage 342.1 (TID 578) in 22 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:27.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSchedulerImpl: Removed TaskSet 342.1, whose tasks have all completed, from pool
[2025-05-07T21:37:27.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: ResultStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.049 s
[2025-05-07T21:37:27.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:37:27.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 342: Stage finished
[2025-05-07T21:37:27.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Job 59 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 124.834507 s
[2025-05-07T21:37:27.643+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO CodeGenerator: Code generated in 6.208494 ms
[2025-05-07T21:37:27.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 1088.0 KiB, free 414.4 MiB)
[2025-05-07T21:37:27.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_229_2 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_233_2 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 414.4 MiB)
[2025-05-07T21:37:27.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 3530b0b864fd:36239 (size: 32.6 KiB, free: 433.4 MiB)
[2025-05-07T21:37:27.661+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO SparkContext: Created broadcast 114 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:27.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 3.0 in stage 344.0 (TID 580) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 2.0 in stage 344.0 (TID 579) in 37 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:27.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:37:27.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.20.0.5:37555 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.704+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 3530b0b864fd:36239 in memory (size: 26.0 KiB, free: 433.4 MiB)
[2025-05-07T21:37:27.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.20.0.5:37555 in memory (size: 26.0 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 3530b0b864fd:36239 in memory (size: 9.9 KiB, free: 433.4 MiB)
[2025-05-07T21:37:27.719+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 172.20.0.5:37555 in memory (size: 9.9 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_229_3 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.724+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_233_3 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.731+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 4.0 in stage 344.0 (TID 581) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 3.0 in stage 344.0 (TID 580) in 72 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:27.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_229_4 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_233_4 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 5.0 in stage 344.0 (TID 582) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.785+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 4.0 in stage 344.0 (TID 581) in 54 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:27.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO CodeGenerator: Code generated in 28.566568 ms
[2025-05-07T21:37:27.815+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Registering RDD 545 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 64
[2025-05-07T21:37:27.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Got map stage job 65 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:37:27.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Final stage: ShuffleMapStage 379 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:27.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:37:27.823+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:27.824+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Submitting ShuffleMapStage 379 (MapPartitionsRDD[545] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:27.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 17.6 KiB, free 414.5 MiB)
[2025-05-07T21:37:27.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 414.5 MiB)
[2025-05-07T21:37:27.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 3530b0b864fd:36239 (size: 8.3 KiB, free: 433.4 MiB)
[2025-05-07T21:37:27.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:27.829+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 379 (MapPartitionsRDD[545] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:27.829+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSchedulerImpl: Adding task set 379.0 with 1 tasks resource profile 0
[2025-05-07T21:37:27.832+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_229_5 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_233_5 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 6.0 in stage 344.0 (TID 583) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 5.0 in stage 344.0 (TID 582) in 85 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:27.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO CodeGenerator: Code generated in 73.609805 ms
[2025-05-07T21:37:27.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_229_6 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_233_6 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 7.0 in stage 344.0 (TID 584) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 6.0 in stage 344.0 (TID 583) in 54 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:27.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Registering RDD 547 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 65
[2025-05-07T21:37:27.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Got map stage job 66 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:37:27.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Final stage: ShuffleMapStage 380 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:27.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:37:27.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:27.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Submitting ShuffleMapStage 380 (MapPartitionsRDD[547] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:27.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 77.9 KiB, free 414.4 MiB)
[2025-05-07T21:37:27.968+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 414.4 MiB)
[2025-05-07T21:37:27.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_229_7 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 3530b0b864fd:36239 (size: 33.9 KiB, free: 433.3 MiB)
[2025-05-07T21:37:27.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:27.978+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 380 (MapPartitionsRDD[547] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:27.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSchedulerImpl: Adding task set 380.0 with 1 tasks resource profile 0
[2025-05-07T21:37:27.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO BlockManagerInfo: Added rdd_233_7 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:27.982+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Starting task 8.0 in stage 344.0 (TID 585) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:27.983+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:27 INFO TaskSetManager: Finished task 7.0 in stage 344.0 (TID 584) in 64 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:28.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_229_8 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:28.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_233_8 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:28.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 9.0 in stage 344.0 (TID 586) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.029+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 8.0 in stage 344.0 (TID 585) in 47 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:28.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_229_9 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:28.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_233_9 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.8 MiB)
[2025-05-07T21:37:28.094+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 1.0 in stage 368.1 (TID 587) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.096+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 9.0 in stage 344.0 (TID 586) in 67 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:28.096+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool
[2025-05-07T21:37:28.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: ShuffleMapStage 344 (mapPartitions at GraphImpl.scala:208) finished in 3.770 s
[2025-05-07T21:37:28.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:28.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:28.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ShuffleMapStage 347, ShuffleMapStage 348, ResultStage 378, ShuffleMapStage 349, ResultStage 371, ShuffleMapStage 350, ShuffleMapStage 365, ShuffleMapStage 366, ShuffleMapStage 345, ResultStage 367, ShuffleMapStage 346, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:28.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:28.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting ShuffleMapStage 345 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[278] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:28.102+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 10.7 KiB, free 414.4 MiB)
[2025-05-07T21:37:28.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 414.4 MiB)
[2025-05-07T21:37:28.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 3530b0b864fd:36239 (size: 5.3 KiB, free: 433.3 MiB)
[2025-05-07T21:37:28.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:28.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 345 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[278] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:28.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Adding task set 345.0 with 10 tasks resource profile 0
[2025-05-07T21:37:28.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting ShuffleMapStage 346 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[268] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:28.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 10.1 KiB, free 414.4 MiB)
[2025-05-07T21:37:28.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 414.4 MiB)
[2025-05-07T21:37:28.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 3530b0b864fd:36239 (size: 5.0 KiB, free: 433.3 MiB)
[2025-05-07T21:37:28.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:28.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 346 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[268] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:28.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Adding task set 346.0 with 10 tasks resource profile 0
[2025-05-07T21:37:28.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 0.0 in stage 345.0 (TID 588) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 1.0 in stage 368.1 (TID 587) in 61 ms on 172.20.0.5 (executor 1) (2/6)
[2025-05-07T21:37:28.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.20.0.5:37555 (size: 5.3 KiB, free: 433.8 MiB)
[2025-05-07T21:37:28.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.20.0.5:58132
[2025-05-07T21:37:28.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_0 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:28.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 1.0 in stage 345.0 (TID 589) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 0.0 in stage 345.0 (TID 588) in 60 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:28.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_1 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:28.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 2.0 in stage 345.0 (TID 590) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 1.0 in stage 345.0 (TID 589) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:28.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_2 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.252+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 3.0 in stage 345.0 (TID 591) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.252+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 2.0 in stage 345.0 (TID 590) in 21 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:28.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_3 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.281+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 4.0 in stage 345.0 (TID 592) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 3.0 in stage 345.0 (TID 591) in 30 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:28.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_4 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 5.0 in stage 345.0 (TID 593) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 4.0 in stage 345.0 (TID 592) in 21 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:28.317+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_5 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.324+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 6.0 in stage 345.0 (TID 594) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 5.0 in stage 345.0 (TID 593) in 23 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:28.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_6 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 7.0 in stage 345.0 (TID 595) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 6.0 in stage 345.0 (TID 594) in 21 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:28.358+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_7 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 8.0 in stage 345.0 (TID 596) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 7.0 in stage 345.0 (TID 595) in 22 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:28.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_8 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 9.0 in stage 345.0 (TID 597) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 8.0 in stage 345.0 (TID 596) in 19 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:28.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_264_9 in memory on 172.20.0.5:37555 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 0.0 in stage 346.0 (TID 598) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 9.0 in stage 345.0 (TID 597) in 20 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:28.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Removed TaskSet 345.0, whose tasks have all completed, from pool
[2025-05-07T21:37:28.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: ShuffleMapStage 345 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.306 s
[2025-05-07T21:37:28.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:28.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 370, ShuffleMapStage 346)
[2025-05-07T21:37:28.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ShuffleMapStage 347, ShuffleMapStage 348, ResultStage 378, ShuffleMapStage 349, ResultStage 371, ShuffleMapStage 350, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:28.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:28.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.20.0.5:37555 (size: 5.0 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.425+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 1.0 in stage 346.0 (TID 599) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.426+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 0.0 in stage 346.0 (TID 598) in 21 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:28.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 2.0 in stage 346.0 (TID 600) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 1.0 in stage 346.0 (TID 599) in 12 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:28.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 3.0 in stage 346.0 (TID 601) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 2.0 in stage 346.0 (TID 600) in 11 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:28.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 4.0 in stage 346.0 (TID 602) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 3.0 in stage 346.0 (TID 601) in 11 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:28.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 5.0 in stage 346.0 (TID 603) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 4.0 in stage 346.0 (TID 602) in 10 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:28.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 6.0 in stage 346.0 (TID 604) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 5.0 in stage 346.0 (TID 603) in 10 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:28.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 7.0 in stage 346.0 (TID 605) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.488+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 6.0 in stage 346.0 (TID 604) in 11 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:28.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 8.0 in stage 346.0 (TID 606) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 7.0 in stage 346.0 (TID 605) in 11 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:28.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 9.0 in stage 346.0 (TID 607) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 8.0 in stage 346.0 (TID 606) in 10 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:28.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 2.0 in stage 368.1 (TID 608) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 9.0 in stage 346.0 (TID 607) in 11 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:28.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool
[2025-05-07T21:37:28.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: ShuffleMapStage 346 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.411 s
[2025-05-07T21:37:28.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:28.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:28.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ShuffleMapStage 347, ShuffleMapStage 348, ResultStage 378, ShuffleMapStage 349, ResultStage 371, ShuffleMapStage 350, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:28.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:28.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting ShuffleMapStage 347 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[282] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:28.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 163.7 KiB, free 414.2 MiB)
[2025-05-07T21:37:28.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 414.2 MiB)
[2025-05-07T21:37:28.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 3530b0b864fd:36239 (size: 58.0 KiB, free: 433.3 MiB)
[2025-05-07T21:37:28.528+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:28.528+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 347 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[282] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:28.529+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Adding task set 347.0 with 10 tasks resource profile 0
[2025-05-07T21:37:28.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 0.0 in stage 347.0 (TID 609) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 2.0 in stage 368.1 (TID 608) in 44 ms on 172.20.0.5 (executor 1) (3/6)
[2025-05-07T21:37:28.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.20.0.5:37555 (size: 58.0 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_0 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.581+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:28.589+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:28.596+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 1.0 in stage 347.0 (TID 610) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.597+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 0.0 in stage 347.0 (TID 609) in 37 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:28.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_1 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 2.0 in stage 347.0 (TID 611) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 1.0 in stage 347.0 (TID 610) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:28.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_2 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.639+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 3.0 in stage 347.0 (TID 612) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 2.0 in stage 347.0 (TID 611) in 26 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:28.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_3 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:37:28.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 4.0 in stage 347.0 (TID 613) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 3.0 in stage 347.0 (TID 612) in 24 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:28.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_4 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:37:28.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 5.0 in stage 347.0 (TID 614) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 4.0 in stage 347.0 (TID 613) in 18 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:28.692+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_5 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:37:28.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 6.0 in stage 347.0 (TID 615) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 5.0 in stage 347.0 (TID 614) in 20 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:28.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_6 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:37:28.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 7.0 in stage 347.0 (TID 616) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 6.0 in stage 347.0 (TID 615) in 17 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:28.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 3530b0b864fd:36239 in memory (size: 5.3 KiB, free: 433.3 MiB)
[2025-05-07T21:37:28.731+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 172.20.0.5:37555 in memory (size: 5.3 KiB, free: 433.6 MiB)
[2025-05-07T21:37:28.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_7 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:37:28.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 3530b0b864fd:36239 in memory (size: 5.0 KiB, free: 433.3 MiB)
[2025-05-07T21:37:28.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 172.20.0.5:37555 in memory (size: 5.0 KiB, free: 433.7 MiB)
[2025-05-07T21:37:28.743+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 8.0 in stage 347.0 (TID 617) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.744+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 7.0 in stage 347.0 (TID 616) in 26 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:28.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_8 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:37:28.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 9.0 in stage 347.0 (TID 618) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 8.0 in stage 347.0 (TID 617) in 21 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:28.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added rdd_266_9 in memory on 172.20.0.5:37555 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:37:28.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 3.0 in stage 368.1 (TID 619) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 9.0 in stage 347.0 (TID 618) in 17 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:28.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Removed TaskSet 347.0, whose tasks have all completed, from pool
[2025-05-07T21:37:28.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: ShuffleMapStage 347 (mapPartitions at GraphImpl.scala:208) finished in 0.259 s
[2025-05-07T21:37:28.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:28.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:28.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ShuffleMapStage 348, ResultStage 378, ShuffleMapStage 349, ResultStage 371, ShuffleMapStage 350, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:28.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:28.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting ShuffleMapStage 348 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[290] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:28.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 12.0 KiB, free 414.2 MiB)
[2025-05-07T21:37:28.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 414.2 MiB)
[2025-05-07T21:37:28.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 3530b0b864fd:36239 (size: 5.7 KiB, free: 433.3 MiB)
[2025-05-07T21:37:28.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:28.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 348 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[290] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:28.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Adding task set 348.0 with 10 tasks resource profile 0
[2025-05-07T21:37:28.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 0.0 in stage 348.0 (TID 620) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 3.0 in stage 368.1 (TID 619) in 34 ms on 172.20.0.5 (executor 1) (4/6)
[2025-05-07T21:37:28.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.20.0.5:37555 (size: 5.7 KiB, free: 433.6 MiB)
[2025-05-07T21:37:28.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:28.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 1.0 in stage 348.0 (TID 621) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 0.0 in stage 348.0 (TID 620) in 25 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:28.849+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 2.0 in stage 348.0 (TID 622) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 1.0 in stage 348.0 (TID 621) in 11 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:28.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 3.0 in stage 348.0 (TID 623) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 2.0 in stage 348.0 (TID 622) in 15 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:28.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 4.0 in stage 348.0 (TID 624) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 3.0 in stage 348.0 (TID 623) in 13 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:28.887+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 5.0 in stage 348.0 (TID 625) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.887+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 4.0 in stage 348.0 (TID 624) in 11 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:28.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 6.0 in stage 348.0 (TID 626) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 5.0 in stage 348.0 (TID 625) in 12 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:28.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 7.0 in stage 348.0 (TID 627) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 6.0 in stage 348.0 (TID 626) in 11 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:28.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 8.0 in stage 348.0 (TID 628) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 7.0 in stage 348.0 (TID 627) in 10 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:28.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 9.0 in stage 348.0 (TID 629) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 8.0 in stage 348.0 (TID 628) in 15 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:28.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 4.0 in stage 368.1 (TID 630) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 9.0 in stage 348.0 (TID 629) in 11 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:28.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Removed TaskSet 348.0, whose tasks have all completed, from pool
[2025-05-07T21:37:28.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: ShuffleMapStage 348 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.165 s
[2025-05-07T21:37:28.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:28.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:28.947+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ResultStage 378, ShuffleMapStage 349, ResultStage 371, ShuffleMapStage 350, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:28.947+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:28.947+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting ShuffleMapStage 349 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[294] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:28.956+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 164.0 KiB, free 414.0 MiB)
[2025-05-07T21:37:28.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 414.0 MiB)
[2025-05-07T21:37:28.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 3530b0b864fd:36239 (size: 58.2 KiB, free: 433.2 MiB)
[2025-05-07T21:37:28.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:28.961+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 349 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[294] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:28.961+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSchedulerImpl: Adding task set 349.0 with 10 tasks resource profile 0
[2025-05-07T21:37:28.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Starting task 0.0 in stage 349.0 (TID 631) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:28.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO TaskSetManager: Finished task 4.0 in stage 368.1 (TID 630) in 47 ms on 172.20.0.5 (executor 1) (5/6)
[2025-05-07T21:37:28.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:28 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.20.0.5:37555 (size: 58.2 KiB, free: 433.6 MiB)
[2025-05-07T21:37:29.008+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:29.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:29.013+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:58132
[2025-05-07T21:37:29.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 1.0 in stage 349.0 (TID 632) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 0.0 in stage 349.0 (TID 631) in 28 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:29.034+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 2.0 in stage 349.0 (TID 633) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 1.0 in stage 349.0 (TID 632) in 15 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:29.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 3.0 in stage 349.0 (TID 634) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 2.0 in stage 349.0 (TID 633) in 17 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:29.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 4.0 in stage 349.0 (TID 635) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 3.0 in stage 349.0 (TID 634) in 15 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:29.078+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 5.0 in stage 349.0 (TID 636) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 4.0 in stage 349.0 (TID 635) in 15 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:29.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 6.0 in stage 349.0 (TID 637) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 5.0 in stage 349.0 (TID 636) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:29.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 7.0 in stage 349.0 (TID 638) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 6.0 in stage 349.0 (TID 637) in 15 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:29.129+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 8.0 in stage 349.0 (TID 639) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 7.0 in stage 349.0 (TID 638) in 19 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:29.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 3530b0b864fd:36239 in memory (size: 5.7 KiB, free: 433.2 MiB)
[2025-05-07T21:37:29.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 172.20.0.5:37555 in memory (size: 5.7 KiB, free: 433.6 MiB)
[2025-05-07T21:37:29.137+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 3530b0b864fd:36239 in memory (size: 58.0 KiB, free: 433.3 MiB)
[2025-05-07T21:37:29.138+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.20.0.5:37555 in memory (size: 58.0 KiB, free: 433.6 MiB)
[2025-05-07T21:37:29.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 9.0 in stage 349.0 (TID 640) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 8.0 in stage 349.0 (TID 639) in 18 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:29.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 5.0 in stage 368.1 (TID 641) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 9.0 in stage 349.0 (TID 640) in 14 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:29.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Removed TaskSet 349.0, whose tasks have all completed, from pool
[2025-05-07T21:37:29.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: ShuffleMapStage 349 (mapPartitions at GraphImpl.scala:208) finished in 0.213 s
[2025-05-07T21:37:29.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:29.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: running: Set(ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:29.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ResultStage 378, ResultStage 371, ShuffleMapStage 350, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:29.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:29.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting ShuffleMapStage 350 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[302] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:29.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 12.8 KiB, free 414.2 MiB)
[2025-05-07T21:37:29.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 414.2 MiB)
[2025-05-07T21:37:29.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 3530b0b864fd:36239 (size: 5.9 KiB, free: 433.3 MiB)
[2025-05-07T21:37:29.176+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:29.176+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 350 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[302] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:29.176+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Adding task set 350.0 with 10 tasks resource profile 0
[2025-05-07T21:37:29.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 0.0 in stage 350.0 (TID 642) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.254+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 3530b0b864fd:36239 in memory (size: 56.8 KiB, free: 433.3 MiB)
[2025-05-07T21:37:29.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 5.0 in stage 368.1 (TID 641) in 94 ms on 172.20.0.5 (executor 1) (6/6)
[2025-05-07T21:37:29.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Removed TaskSet 368.1, whose tasks have all completed, from pool
[2025-05-07T21:37:29.256+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: ShuffleMapStage 368 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 5.015 s
[2025-05-07T21:37:29.256+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:29.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: running: Set(ShuffleMapStage 350, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:29.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ResultStage 378, ResultStage 371, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ResultStage 369, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:29.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:29.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting ResultStage 369 (MapPartitionsRDD[497] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:29.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 369.
[2025-05-07T21:37:29.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 7.2 KiB, free 414.4 MiB)
[2025-05-07T21:37:29.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.20.0.5:37555 in memory (size: 56.8 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 414.4 MiB)
[2025-05-07T21:37:29.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 433.3 MiB)
[2025-05-07T21:37:29.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:29.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 369 (MapPartitionsRDD[497] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:29.262+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Adding task set 369.1 with 1 tasks resource profile 0
[2025-05-07T21:37:29.265+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.20.0.5:37555 (size: 5.9 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.268+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:29.276+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:58132
[2025-05-07T21:37:29.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 1.0 in stage 350.0 (TID 643) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 0.0 in stage 350.0 (TID 642) in 34 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:29.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 2.0 in stage 350.0 (TID 644) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 1.0 in stage 350.0 (TID 643) in 14 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:29.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 3.0 in stage 350.0 (TID 645) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 2.0 in stage 350.0 (TID 644) in 13 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:29.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 4.0 in stage 350.0 (TID 646) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 3.0 in stage 350.0 (TID 645) in 12 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:29.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 5.0 in stage 350.0 (TID 647) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 4.0 in stage 350.0 (TID 646) in 14 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:29.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 6.0 in stage 350.0 (TID 648) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 5.0 in stage 350.0 (TID 647) in 14 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:29.367+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 7.0 in stage 350.0 (TID 649) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.367+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 6.0 in stage 350.0 (TID 648) in 14 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:29.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 8.0 in stage 350.0 (TID 650) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 7.0 in stage 350.0 (TID 649) in 11 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:29.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 9.0 in stage 350.0 (TID 651) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 8.0 in stage 350.0 (TID 650) in 12 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:29.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 0.0 in stage 369.1 (TID 652) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 9.0 in stage 350.0 (TID 651) in 10 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:29.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Removed TaskSet 350.0, whose tasks have all completed, from pool
[2025-05-07T21:37:29.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: ShuffleMapStage 350 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.237 s
[2025-05-07T21:37:29.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:29.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: running: Set(ShuffleMapStage 375, ShuffleMapStage 372, ResultStage 369, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:29.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 351, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ResultStage 378, ResultStage 371, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:29.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:29.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting ShuffleMapStage 351 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[306] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:29.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.20.0.5:37555 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 164.3 KiB, free 414.2 MiB)
[2025-05-07T21:37:29.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:58132
[2025-05-07T21:37:29.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 414.2 MiB)
[2025-05-07T21:37:29.419+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 433.3 MiB)
[2025-05-07T21:37:29.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:29.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 351 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[306] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:29.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Adding task set 351.0 with 10 tasks resource profile 0
[2025-05-07T21:37:29.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 3530b0b864fd:36239 in memory (size: 58.2 KiB, free: 433.3 MiB)
[2025-05-07T21:37:29.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.20.0.5:37555 in memory (size: 58.2 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 0.0 in stage 351.0 (TID 653) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 0.0 in stage 369.1 (TID 652) in 53 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:29.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Removed TaskSet 369.1, whose tasks have all completed, from pool
[2025-05-07T21:37:29.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: ResultStage 369 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.198 s
[2025-05-07T21:37:29.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:37:29.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 369: Stage finished
[2025-05-07T21:37:29.455+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Job 62 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 125.714139 s
[2025-05-07T21:37:29.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 172.20.0.5:37555 (size: 58.1 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:29.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:29.492+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 3530b0b864fd:36239 in memory (size: 11.3 KiB, free: 433.3 MiB)
[2025-05-07T21:37:29.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 172.20.0.5:37555 in memory (size: 11.3 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:58132
[2025-05-07T21:37:29.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 5.0 MiB, free 409.4 MiB)
[2025-05-07T21:37:29.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:58132
[2025-05-07T21:37:29.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 1.0 in stage 351.0 (TID 654) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 0.0 in stage 351.0 (TID 653) in 52 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:29.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 408.9 MiB)
[2025-05-07T21:37:29.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 3530b0b864fd:36239 (size: 502.1 KiB, free: 432.9 MiB)
[2025-05-07T21:37:29.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO SparkContext: Created broadcast 125 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:29.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 2.0 in stage 351.0 (TID 655) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.524+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 1.0 in stage 351.0 (TID 654) in 20 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:29.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 3.0 in stage 351.0 (TID 656) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 2.0 in stage 351.0 (TID 655) in 19 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:29.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 4.0 in stage 351.0 (TID 657) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 3.0 in stage 351.0 (TID 656) in 23 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:29.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 5.0 in stage 351.0 (TID 658) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 4.0 in stage 351.0 (TID 657) in 20 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:29.600+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 6.0 in stage 351.0 (TID 659) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.600+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 5.0 in stage 351.0 (TID 658) in 16 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:29.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 7.0 in stage 351.0 (TID 660) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 6.0 in stage 351.0 (TID 659) in 13 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:29.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 8.0 in stage 351.0 (TID 661) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 7.0 in stage 351.0 (TID 660) in 14 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:29.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 9.0 in stage 351.0 (TID 662) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 8.0 in stage 351.0 (TID 661) in 13 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:29.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 0.0 in stage 370.1 (TID 663) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 9.0 in stage 351.0 (TID 662) in 12 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:29.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Removed TaskSet 351.0, whose tasks have all completed, from pool
[2025-05-07T21:37:29.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: ShuffleMapStage 351 (mapPartitions at GraphImpl.scala:208) finished in 0.251 s
[2025-05-07T21:37:29.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:29.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: running: Set(ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 370)
[2025-05-07T21:37:29.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ShuffleMapStage 352, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ResultStage 378, ResultStage 371, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:29.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:29.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting ShuffleMapStage 352 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[314] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:29.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 13.5 KiB, free 408.9 MiB)
[2025-05-07T21:37:29.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 408.9 MiB)
[2025-05-07T21:37:29.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 3530b0b864fd:36239 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T21:37:29.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 3530b0b864fd:36239 in memory (size: 5.9 KiB, free: 432.9 MiB)
[2025-05-07T21:37:29.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:29.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 352 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[314] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:29.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Adding task set 352.0 with 10 tasks resource profile 0
[2025-05-07T21:37:29.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.20.0.5:37555 (size: 6.8 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 172.20.0.5:37555 in memory (size: 5.9 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.669+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:37:29.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 172.20.0.5:37555 in memory (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 0.0 in stage 352.0 (TID 664) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 0.0 in stage 370.1 (TID 663) in 38 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:29.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Removed TaskSet 370.1, whose tasks have all completed, from pool
[2025-05-07T21:37:29.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: ShuffleMapStage 370 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 5.309 s
[2025-05-07T21:37:29.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:29.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: running: Set(ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377, ShuffleMapStage 352)
[2025-05-07T21:37:29.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ResultStage 378, ResultStage 371, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:29.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:29.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting ResultStage 371 (MapPartitionsRDD[504] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:29.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 371.
[2025-05-07T21:37:29.692+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 7.2 KiB, free 408.9 MiB)
[2025-05-07T21:37:29.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 408.9 MiB)
[2025-05-07T21:37:29.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:37:29.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:29.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 371 (MapPartitionsRDD[504] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:29.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Adding task set 371.1 with 1 tasks resource profile 0
[2025-05-07T21:37:29.697+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 172.20.0.5:37555 (size: 6.1 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:29.707+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:58132
[2025-05-07T21:37:29.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:58132
[2025-05-07T21:37:29.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 1.0 in stage 352.0 (TID 665) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 0.0 in stage 352.0 (TID 664) in 44 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:29.749+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 2.0 in stage 352.0 (TID 666) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 1.0 in stage 352.0 (TID 665) in 16 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:29.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 3.0 in stage 352.0 (TID 667) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 2.0 in stage 352.0 (TID 666) in 14 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:29.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 4.0 in stage 352.0 (TID 668) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 3.0 in stage 352.0 (TID 667) in 11 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:29.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 5.0 in stage 352.0 (TID 669) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.785+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 4.0 in stage 352.0 (TID 668) in 10 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:29.795+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 6.0 in stage 352.0 (TID 670) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.795+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 5.0 in stage 352.0 (TID 669) in 11 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:29.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 7.0 in stage 352.0 (TID 671) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 6.0 in stage 352.0 (TID 670) in 10 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:29.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 8.0 in stage 352.0 (TID 672) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 7.0 in stage 352.0 (TID 671) in 11 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:29.829+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 9.0 in stage 352.0 (TID 673) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 8.0 in stage 352.0 (TID 672) in 13 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:29.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 0.0 in stage 371.1 (TID 674) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 9.0 in stage 352.0 (TID 673) in 11 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:29.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Removed TaskSet 352.0, whose tasks have all completed, from pool
[2025-05-07T21:37:29.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: ShuffleMapStage 352 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.185 s
[2025-05-07T21:37:29.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:29.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: running: Set(ResultStage 371, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377)
[2025-05-07T21:37:29.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ShuffleMapStage 353, ShuffleMapStage 354, ShuffleMapStage 355, ResultStage 378, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:29.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:29.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting ShuffleMapStage 353 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[318] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:29.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 172.20.0.5:37555 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.847+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 164.6 KiB, free 408.8 MiB)
[2025-05-07T21:37:29.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:58132
[2025-05-07T21:37:29.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 408.7 MiB)
[2025-05-07T21:37:29.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 432.8 MiB)
[2025-05-07T21:37:29.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:37:29.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:29.865+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 353 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[318] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:29.865+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Adding task set 353.0 with 10 tasks resource profile 0
[2025-05-07T21:37:29.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 172.20.0.5:37555 in memory (size: 58.1 KiB, free: 433.8 MiB)
[2025-05-07T21:37:29.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 0.0 in stage 353.0 (TID 675) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 0.0 in stage 371.1 (TID 674) in 26 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:29.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Removed TaskSet 371.1, whose tasks have all completed, from pool
[2025-05-07T21:37:29.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: ResultStage 371 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.174 s
[2025-05-07T21:37:29.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:37:29.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 371: Stage finished
[2025-05-07T21:37:29.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO DAGScheduler: Job 63 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 124.505102 s
[2025-05-07T21:37:29.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 2.1 MiB, free 406.9 MiB)
[2025-05-07T21:37:29.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 406.8 MiB)
[2025-05-07T21:37:29.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 3530b0b864fd:36239 (size: 20.6 KiB, free: 432.8 MiB)
[2025-05-07T21:37:29.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO SparkContext: Created broadcast 129 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:29.879+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 172.20.0.5:37555 (size: 58.1 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.891+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:29.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:29.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:58132
[2025-05-07T21:37:29.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:58132
[2025-05-07T21:37:29.901+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:58132
[2025-05-07T21:37:29.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 1.0 in stage 353.0 (TID 676) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 0.0 in stage 353.0 (TID 675) in 44 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:29.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 3530b0b864fd:36239 in memory (size: 6.8 KiB, free: 432.8 MiB)
[2025-05-07T21:37:29.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 2.0 in stage 353.0 (TID 677) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.20.0.5:37555 in memory (size: 6.8 KiB, free: 433.7 MiB)
[2025-05-07T21:37:29.931+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 1.0 in stage 353.0 (TID 676) in 22 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:29.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 3.0 in stage 353.0 (TID 678) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 2.0 in stage 353.0 (TID 677) in 23 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:29.966+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 4.0 in stage 353.0 (TID 679) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.967+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 3.0 in stage 353.0 (TID 678) in 13 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:29.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 5.0 in stage 353.0 (TID 680) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 4.0 in stage 353.0 (TID 679) in 13 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:29.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Starting task 6.0 in stage 353.0 (TID 681) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:29.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:29 INFO TaskSetManager: Finished task 5.0 in stage 353.0 (TID 680) in 13 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:30.005+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 7.0 in stage 353.0 (TID 682) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.005+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 6.0 in stage 353.0 (TID 681) in 13 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:30.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 8.0 in stage 353.0 (TID 683) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 7.0 in stage 353.0 (TID 682) in 17 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:30.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 9.0 in stage 353.0 (TID 684) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 8.0 in stage 353.0 (TID 683) in 14 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:30.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 0.0 in stage 372.0 (TID 685) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 9.0 in stage 353.0 (TID 684) in 17 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:30.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Removed TaskSet 353.0, whose tasks have all completed, from pool
[2025-05-07T21:37:30.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: ShuffleMapStage 353 (mapPartitions at GraphImpl.scala:208) finished in 0.212 s
[2025-05-07T21:37:30.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:30.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: running: Set(ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377)
[2025-05-07T21:37:30.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ShuffleMapStage 354, ShuffleMapStage 355, ResultStage 378, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:30.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:30.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting ShuffleMapStage 354 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[326] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:30.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 14.2 KiB, free 406.8 MiB)
[2025-05-07T21:37:30.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 406.8 MiB)
[2025-05-07T21:37:30.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 3530b0b864fd:36239 (size: 6.1 KiB, free: 432.8 MiB)
[2025-05-07T21:37:30.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T21:37:30.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:30.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 354 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[326] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:30.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Adding task set 354.0 with 10 tasks resource profile 0
[2025-05-07T21:37:30.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.20.0.5:37555 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.076+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 172.20.0.5:37555 in memory (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 3530b0b864fd:36239 in memory (size: 6.1 KiB, free: 432.8 MiB)
[2025-05-07T21:37:30.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 172.20.0.5:37555 in memory (size: 6.1 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.149+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 0.0 in stage 354.0 (TID 686) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.153+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 0.0 in stage 372.0 (TID 685) in 99 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:30.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Removed TaskSet 372.0, whose tasks have all completed, from pool
[2025-05-07T21:37:30.156+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: ShuffleMapStage 372 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 6.115 s
[2025-05-07T21:37:30.158+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:30.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: running: Set(ShuffleMapStage 375, ShuffleMapStage 354, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377)
[2025-05-07T21:37:30.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ShuffleMapStage 355, ResultStage 378, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:30.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:30.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 172.20.0.5:37555 (size: 6.1 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:30.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:58132
[2025-05-07T21:37:30.181+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:58132
[2025-05-07T21:37:30.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:58132
[2025-05-07T21:37:30.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 1.0 in stage 354.0 (TID 687) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 0.0 in stage 354.0 (TID 686) in 47 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:30.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 2.0 in stage 354.0 (TID 688) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 1.0 in stage 354.0 (TID 687) in 17 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:30.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 3.0 in stage 354.0 (TID 689) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 2.0 in stage 354.0 (TID 688) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:30.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 4.0 in stage 354.0 (TID 690) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 3.0 in stage 354.0 (TID 689) in 15 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:30.256+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 5.0 in stage 354.0 (TID 691) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.256+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 4.0 in stage 354.0 (TID 690) in 13 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:30.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 6.0 in stage 354.0 (TID 692) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.271+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 5.0 in stage 354.0 (TID 691) in 14 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:30.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 7.0 in stage 354.0 (TID 693) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 6.0 in stage 354.0 (TID 692) in 17 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:30.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 8.0 in stage 354.0 (TID 694) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 7.0 in stage 354.0 (TID 693) in 13 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:30.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 9.0 in stage 354.0 (TID 695) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 8.0 in stage 354.0 (TID 694) in 13 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:30.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 0.0 in stage 375.0 (TID 696) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 9.0 in stage 354.0 (TID 695) in 12 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:30.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Removed TaskSet 354.0, whose tasks have all completed, from pool
[2025-05-07T21:37:30.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: ShuffleMapStage 354 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.270 s
[2025-05-07T21:37:30.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:30.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: running: Set(ShuffleMapStage 375, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377)
[2025-05-07T21:37:30.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ShuffleMapStage 355, ResultStage 378, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:30.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:30.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting ShuffleMapStage 355 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[330] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:30.331+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.20.0.5:37555 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.331+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 164.9 KiB, free 406.7 MiB)
[2025-05-07T21:37:30.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 406.7 MiB)
[2025-05-07T21:37:30.343+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:37:30.343+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 3530b0b864fd:36239 (size: 58.3 KiB, free: 432.8 MiB)
[2025-05-07T21:37:30.343+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:30.343+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 355 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[330] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:30.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Adding task set 355.0 with 10 tasks resource profile 0
[2025-05-07T21:37:30.347+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 172.20.0.5:37555 in memory (size: 58.1 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 0.0 in stage 355.0 (TID 697) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 0.0 in stage 375.0 (TID 696) in 47 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:30.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Removed TaskSet 375.0, whose tasks have all completed, from pool
[2025-05-07T21:37:30.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: ShuffleMapStage 375 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 6.320 s
[2025-05-07T21:37:30.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:30.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: running: Set(ShuffleMapStage 379, ShuffleMapStage 355, ShuffleMapStage 380, ShuffleMapStage 377)
[2025-05-07T21:37:30.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ResultStage 378, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:30.374+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:30.380+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 172.20.0.5:37555 (size: 58.3 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.387+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:30.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:30.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:58132
[2025-05-07T21:37:30.407+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:58132
[2025-05-07T21:37:30.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 3530b0b864fd:36239 in memory (size: 13.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:30.410+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.20.0.5:37555 in memory (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.410+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:58132
[2025-05-07T21:37:30.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:58132
[2025-05-07T21:37:30.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 1.0 in stage 355.0 (TID 698) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 0.0 in stage 355.0 (TID 697) in 51 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:30.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 2.0 in stage 355.0 (TID 699) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 1.0 in stage 355.0 (TID 698) in 21 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:30.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 3.0 in stage 355.0 (TID 700) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 2.0 in stage 355.0 (TID 699) in 25 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:30.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 4.0 in stage 355.0 (TID 701) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 3.0 in stage 355.0 (TID 700) in 27 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:30.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 5.0 in stage 355.0 (TID 702) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 4.0 in stage 355.0 (TID 701) in 20 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:30.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 6.0 in stage 355.0 (TID 703) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 5.0 in stage 355.0 (TID 702) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:30.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 7.0 in stage 355.0 (TID 704) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 6.0 in stage 355.0 (TID 703) in 15 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:30.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 8.0 in stage 355.0 (TID 705) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.562+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 7.0 in stage 355.0 (TID 704) in 13 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:30.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 9.0 in stage 355.0 (TID 706) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 8.0 in stage 355.0 (TID 705) in 15 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:30.589+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 0.0 in stage 377.0 (TID 707) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 9.0 in stage 355.0 (TID 706) in 14 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:30.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Removed TaskSet 355.0, whose tasks have all completed, from pool
[2025-05-07T21:37:30.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: ShuffleMapStage 355 (mapPartitions at GraphImpl.scala:208) finished in 0.263 s
[2025-05-07T21:37:30.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:30.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: running: Set(ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 377)
[2025-05-07T21:37:30.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 356, ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ResultStage 378, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:30.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:30.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting ShuffleMapStage 356 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:30.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 14.9 KiB, free 406.9 MiB)
[2025-05-07T21:37:30.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 406.9 MiB)
[2025-05-07T21:37:30.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 3530b0b864fd:36239 (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-07T21:37:30.604+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:30.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 356 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:30.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Adding task set 356.0 with 10 tasks resource profile 0
[2025-05-07T21:37:30.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 3530b0b864fd:36239 in memory (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T21:37:30.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.20.0.5:37555 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 172.20.0.5:37555 in memory (size: 6.1 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 0.0 in stage 356.0 (TID 708) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 0.0 in stage 377.0 (TID 707) in 70 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:30.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Removed TaskSet 377.0, whose tasks have all completed, from pool
[2025-05-07T21:37:30.661+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: ShuffleMapStage 377 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 6.602 s
[2025-05-07T21:37:30.661+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:30.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: running: Set(ShuffleMapStage 356, ShuffleMapStage 379, ShuffleMapStage 380)
[2025-05-07T21:37:30.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ResultStage 378, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:30.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:30.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting ResultStage 378 (MapPartitionsRDD[537] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:30.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 91.7 KiB, free 406.8 MiB)
[2025-05-07T21:37:30.667+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 30.4 KiB, free 406.8 MiB)
[2025-05-07T21:37:30.667+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 3530b0b864fd:36239 (size: 30.4 KiB, free: 432.8 MiB)
[2025-05-07T21:37:30.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:30.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 378 (MapPartitionsRDD[537] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:37:30.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Adding task set 378.0 with 6 tasks resource profile 0
[2025-05-07T21:37:30.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 172.20.0.5:37555 (size: 6.3 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 432.8 MiB)
[2025-05-07T21:37:30.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.20.0.5:37555 in memory (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:30.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:58132
[2025-05-07T21:37:30.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:58132
[2025-05-07T21:37:30.692+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:58132
[2025-05-07T21:37:30.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:58132
[2025-05-07T21:37:30.713+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 1.0 in stage 356.0 (TID 709) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.714+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 0.0 in stage 356.0 (TID 708) in 55 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:30.731+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 2.0 in stage 356.0 (TID 710) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 1.0 in stage 356.0 (TID 709) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:30.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 3.0 in stage 356.0 (TID 711) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 2.0 in stage 356.0 (TID 710) in 22 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:30.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 4.0 in stage 356.0 (TID 712) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 3.0 in stage 356.0 (TID 711) in 20 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:30.807+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 5.0 in stage 356.0 (TID 713) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.807+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 4.0 in stage 356.0 (TID 712) in 34 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:30.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 6.0 in stage 356.0 (TID 714) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 5.0 in stage 356.0 (TID 713) in 32 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:30.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 7.0 in stage 356.0 (TID 715) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 6.0 in stage 356.0 (TID 714) in 22 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:30.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 8.0 in stage 356.0 (TID 716) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 7.0 in stage 356.0 (TID 715) in 20 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:30.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 9.0 in stage 356.0 (TID 717) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 8.0 in stage 356.0 (TID 716) in 15 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:30.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Starting task 0.0 in stage 378.0 (TID 718) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:30.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSetManager: Finished task 9.0 in stage 356.0 (TID 717) in 14 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:30.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Removed TaskSet 356.0, whose tasks have all completed, from pool
[2025-05-07T21:37:30.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: ShuffleMapStage 356 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.316 s
[2025-05-07T21:37:30.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:30.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: running: Set(ShuffleMapStage 379, ShuffleMapStage 380, ResultStage 378)
[2025-05-07T21:37:30.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 357, ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:30.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:30.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting ShuffleMapStage 357 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[342] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:30.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 165.2 KiB, free 406.7 MiB)
[2025-05-07T21:37:30.931+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 406.6 MiB)
[2025-05-07T21:37:30.932+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 3530b0b864fd:36239 (size: 58.2 KiB, free: 432.8 MiB)
[2025-05-07T21:37:30.934+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 3530b0b864fd:36239 in memory (size: 58.3 KiB, free: 432.8 MiB)
[2025-05-07T21:37:30.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:30.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 357 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[342] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:30.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO TaskSchedulerImpl: Adding task set 357.0 with 10 tasks resource profile 0
[2025-05-07T21:37:30.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 172.20.0.5:37555 in memory (size: 58.3 KiB, free: 433.8 MiB)
[2025-05-07T21:37:30.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 172.20.0.5:37555 (size: 30.4 KiB, free: 433.7 MiB)
[2025-05-07T21:37:30.967+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 172.20.0.5:58132
[2025-05-07T21:37:31.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 0.0 in stage 357.0 (TID 719) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 0.0 in stage 378.0 (TID 718) in 118 ms on 172.20.0.5 (executor 1) (1/6)
[2025-05-07T21:37:31.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 172.20.0.5:37555 in memory (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:31.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 3530b0b864fd:36239 in memory (size: 13.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:31.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 172.20.0.5:37555 (size: 58.2 KiB, free: 433.7 MiB)
[2025-05-07T21:37:31.049+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:31.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:31.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:58132
[2025-05-07T21:37:31.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:58132
[2025-05-07T21:37:31.060+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:58132
[2025-05-07T21:37:31.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:58132
[2025-05-07T21:37:31.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:58132
[2025-05-07T21:37:31.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 1.0 in stage 357.0 (TID 720) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 0.0 in stage 357.0 (TID 719) in 53 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:31.099+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 2.0 in stage 357.0 (TID 721) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 1.0 in stage 357.0 (TID 720) in 23 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:31.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 3.0 in stage 357.0 (TID 722) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 2.0 in stage 357.0 (TID 721) in 19 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:31.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 4.0 in stage 357.0 (TID 723) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 3.0 in stage 357.0 (TID 722) in 15 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:31.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 5.0 in stage 357.0 (TID 724) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 4.0 in stage 357.0 (TID 723) in 30 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:31.177+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 6.0 in stage 357.0 (TID 725) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 5.0 in stage 357.0 (TID 724) in 15 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:31.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 7.0 in stage 357.0 (TID 726) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 6.0 in stage 357.0 (TID 725) in 16 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:31.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 8.0 in stage 357.0 (TID 727) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 7.0 in stage 357.0 (TID 726) in 14 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:31.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 9.0 in stage 357.0 (TID 728) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 8.0 in stage 357.0 (TID 727) in 14 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:31.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 1.0 in stage 378.0 (TID 729) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.236+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 9.0 in stage 357.0 (TID 728) in 15 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:31.236+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSchedulerImpl: Removed TaskSet 357.0, whose tasks have all completed, from pool
[2025-05-07T21:37:31.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: ShuffleMapStage 357 (mapPartitions at GraphImpl.scala:208) finished in 0.328 s
[2025-05-07T21:37:31.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:31.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: running: Set(ShuffleMapStage 379, ShuffleMapStage 380, ResultStage 378)
[2025-05-07T21:37:31.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 358, ShuffleMapStage 359, ShuffleMapStage 360, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:31.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:31.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: Submitting ShuffleMapStage 358 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[350] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:31.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 15.6 KiB, free 406.9 MiB)
[2025-05-07T21:37:31.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 406.9 MiB)
[2025-05-07T21:37:31.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.20.0.5:58132
[2025-05-07T21:37:31.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 3530b0b864fd:36239 (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-07T21:37:31.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:31.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 358 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[350] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:31.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSchedulerImpl: Adding task set 358.0 with 10 tasks resource profile 0
[2025-05-07T21:37:31.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 0.0 in stage 358.0 (TID 730) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 1.0 in stage 378.0 (TID 729) in 28 ms on 172.20.0.5 (executor 1) (2/6)
[2025-05-07T21:37:31.269+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 172.20.0.5:37555 (size: 6.4 KiB, free: 433.7 MiB)
[2025-05-07T21:37:31.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:31.275+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:58132
[2025-05-07T21:37:31.277+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:58132
[2025-05-07T21:37:31.279+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:58132
[2025-05-07T21:37:31.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:58132
[2025-05-07T21:37:31.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:58132
[2025-05-07T21:37:31.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 1.0 in stage 358.0 (TID 731) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 0.0 in stage 358.0 (TID 730) in 30 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:31.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 2.0 in stage 358.0 (TID 732) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.311+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 1.0 in stage 358.0 (TID 731) in 17 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:31.328+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 3.0 in stage 358.0 (TID 733) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.328+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 2.0 in stage 358.0 (TID 732) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:31.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 4.0 in stage 358.0 (TID 734) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.350+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 3.0 in stage 358.0 (TID 733) in 22 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:31.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 5.0 in stage 358.0 (TID 735) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 4.0 in stage 358.0 (TID 734) in 19 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:31.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 6.0 in stage 358.0 (TID 736) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 5.0 in stage 358.0 (TID 735) in 29 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:31.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 7.0 in stage 358.0 (TID 737) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 6.0 in stage 358.0 (TID 736) in 17 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:31.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 8.0 in stage 358.0 (TID 738) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 7.0 in stage 358.0 (TID 737) in 16 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:31.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 9.0 in stage 358.0 (TID 739) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 8.0 in stage 358.0 (TID 738) in 16 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:31.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 2.0 in stage 378.0 (TID 740) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 9.0 in stage 358.0 (TID 739) in 19 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:31.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSchedulerImpl: Removed TaskSet 358.0, whose tasks have all completed, from pool
[2025-05-07T21:37:31.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: ShuffleMapStage 358 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.225 s
[2025-05-07T21:37:31.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:31.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: running: Set(ShuffleMapStage 379, ShuffleMapStage 380, ResultStage 378)
[2025-05-07T21:37:31.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 359, ShuffleMapStage 360, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:31.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:31.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: Submitting ShuffleMapStage 359 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[354] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:31.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.20.0.5:58132
[2025-05-07T21:37:31.471+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 165.5 KiB, free 406.7 MiB)
[2025-05-07T21:37:31.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 406.6 MiB)
[2025-05-07T21:37:31.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 3530b0b864fd:36239 (size: 58.4 KiB, free: 432.8 MiB)
[2025-05-07T21:37:31.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:31.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 359 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[354] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:31.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSchedulerImpl: Adding task set 359.0 with 10 tasks resource profile 0
[2025-05-07T21:37:31.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 0.0 in stage 359.0 (TID 741) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.488+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 2.0 in stage 378.0 (TID 740) in 24 ms on 172.20.0.5 (executor 1) (3/6)
[2025-05-07T21:37:31.493+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 172.20.0.5:37555 (size: 58.4 KiB, free: 433.6 MiB)
[2025-05-07T21:37:31.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:31.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:31.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:58132
[2025-05-07T21:37:31.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:58132
[2025-05-07T21:37:31.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:58132
[2025-05-07T21:37:31.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:58132
[2025-05-07T21:37:31.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:58132
[2025-05-07T21:37:31.516+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:58132
[2025-05-07T21:37:31.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 1.0 in stage 359.0 (TID 742) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 0.0 in stage 359.0 (TID 741) in 86 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:31.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 2.0 in stage 359.0 (TID 743) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 1.0 in stage 359.0 (TID 742) in 44 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:31.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 3.0 in stage 359.0 (TID 744) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 2.0 in stage 359.0 (TID 743) in 33 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:31.634+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 4.0 in stage 359.0 (TID 745) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.634+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 3.0 in stage 359.0 (TID 744) in 16 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:31.648+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 5.0 in stage 359.0 (TID 746) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.648+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 4.0 in stage 359.0 (TID 745) in 14 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:31.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 6.0 in stage 359.0 (TID 747) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 5.0 in stage 359.0 (TID 746) in 20 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:31.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 7.0 in stage 359.0 (TID 748) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 6.0 in stage 359.0 (TID 747) in 20 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:31.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 8.0 in stage 359.0 (TID 749) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 7.0 in stage 359.0 (TID 748) in 18 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:31.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 9.0 in stage 359.0 (TID 750) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 8.0 in stage 359.0 (TID 749) in 21 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:31.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 3530b0b864fd:36239 in memory (size: 6.3 KiB, free: 432.8 MiB)
[2025-05-07T21:37:31.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 172.20.0.5:37555 in memory (size: 6.3 KiB, free: 433.6 MiB)
[2025-05-07T21:37:31.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 3530b0b864fd:36239 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:37:31.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 172.20.0.5:37555 in memory (size: 58.2 KiB, free: 433.7 MiB)
[2025-05-07T21:37:31.731+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 3530b0b864fd:36239 in memory (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-07T21:37:31.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 172.20.0.5:37555 in memory (size: 6.4 KiB, free: 433.7 MiB)
[2025-05-07T21:37:31.745+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 3.0 in stage 378.0 (TID 751) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 9.0 in stage 359.0 (TID 750) in 20 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:31.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSchedulerImpl: Removed TaskSet 359.0, whose tasks have all completed, from pool
[2025-05-07T21:37:31.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: ShuffleMapStage 359 (mapPartitions at GraphImpl.scala:208) finished in 0.280 s
[2025-05-07T21:37:31.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:31.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: running: Set(ShuffleMapStage 379, ShuffleMapStage 380, ResultStage 378)
[2025-05-07T21:37:31.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 360, ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:31.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:31.747+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: Submitting ShuffleMapStage 360 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[362] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:31.749+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 16.4 KiB, free 406.9 MiB)
[2025-05-07T21:37:31.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 172.20.0.5:58132
[2025-05-07T21:37:31.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 406.9 MiB)
[2025-05-07T21:37:31.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 3530b0b864fd:36239 (size: 6.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:31.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:31.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 360 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[362] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:31.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSchedulerImpl: Adding task set 360.0 with 10 tasks resource profile 0
[2025-05-07T21:37:31.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 0.0 in stage 360.0 (TID 752) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 3.0 in stage 378.0 (TID 751) in 22 ms on 172.20.0.5 (executor 1) (4/6)
[2025-05-07T21:37:31.772+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 172.20.0.5:37555 (size: 6.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:31.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:31.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:58132
[2025-05-07T21:37:31.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:58132
[2025-05-07T21:37:31.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:58132
[2025-05-07T21:37:31.786+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:58132
[2025-05-07T21:37:31.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:58132
[2025-05-07T21:37:31.802+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:58132
[2025-05-07T21:37:31.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 1.0 in stage 360.0 (TID 753) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 0.0 in stage 360.0 (TID 752) in 47 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:31.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 2.0 in stage 360.0 (TID 754) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 1.0 in stage 360.0 (TID 753) in 41 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:31.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 3.0 in stage 360.0 (TID 755) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 2.0 in stage 360.0 (TID 754) in 21 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:31.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 4.0 in stage 360.0 (TID 756) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 3.0 in stage 360.0 (TID 755) in 17 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:31.918+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 5.0 in stage 360.0 (TID 757) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 4.0 in stage 360.0 (TID 756) in 26 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:31.938+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 6.0 in stage 360.0 (TID 758) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.939+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 5.0 in stage 360.0 (TID 757) in 20 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:31.956+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 7.0 in stage 360.0 (TID 759) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.956+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 6.0 in stage 360.0 (TID 758) in 18 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:31.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 8.0 in stage 360.0 (TID 760) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 7.0 in stage 360.0 (TID 759) in 19 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:31.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Starting task 9.0 in stage 360.0 (TID 761) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:31.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:31 INFO TaskSetManager: Finished task 8.0 in stage 360.0 (TID 760) in 18 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:32.014+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 4.0 in stage 378.0 (TID 762) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.015+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 9.0 in stage 360.0 (TID 761) in 22 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:32.015+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Removed TaskSet 360.0, whose tasks have all completed, from pool
[2025-05-07T21:37:32.016+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: ShuffleMapStage 360 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.267 s
[2025-05-07T21:37:32.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:32.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: running: Set(ShuffleMapStage 379, ShuffleMapStage 380, ResultStage 378)
[2025-05-07T21:37:32.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 361, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:32.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:32.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Submitting ShuffleMapStage 361 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[366] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:32.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.20.0.5:58132
[2025-05-07T21:37:32.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 165.8 KiB, free 406.7 MiB)
[2025-05-07T21:37:32.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 406.7 MiB)
[2025-05-07T21:37:32.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 3530b0b864fd:36239 (size: 58.5 KiB, free: 432.8 MiB)
[2025-05-07T21:37:32.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:32.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 361 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[366] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:32.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Adding task set 361.0 with 10 tasks resource profile 0
[2025-05-07T21:37:32.045+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 0.0 in stage 361.0 (TID 763) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.046+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 4.0 in stage 378.0 (TID 762) in 31 ms on 172.20.0.5 (executor 1) (5/6)
[2025-05-07T21:37:32.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 172.20.0.5:37555 (size: 58.5 KiB, free: 433.6 MiB)
[2025-05-07T21:37:32.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:32.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:32.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:58132
[2025-05-07T21:37:32.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:58132
[2025-05-07T21:37:32.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:58132
[2025-05-07T21:37:32.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:58132
[2025-05-07T21:37:32.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:58132
[2025-05-07T21:37:32.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:58132
[2025-05-07T21:37:32.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:58132
[2025-05-07T21:37:32.080+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 1.0 in stage 361.0 (TID 764) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.080+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 0.0 in stage 361.0 (TID 763) in 35 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:32.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 2.0 in stage 361.0 (TID 765) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 1.0 in stage 361.0 (TID 764) in 21 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:32.120+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 3.0 in stage 361.0 (TID 766) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.121+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 2.0 in stage 361.0 (TID 765) in 20 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:32.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 4.0 in stage 361.0 (TID 767) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 3.0 in stage 361.0 (TID 766) in 15 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:32.151+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 5.0 in stage 361.0 (TID 768) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.152+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 4.0 in stage 361.0 (TID 767) in 18 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:32.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 6.0 in stage 361.0 (TID 769) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 5.0 in stage 361.0 (TID 768) in 14 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:32.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 7.0 in stage 361.0 (TID 770) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 6.0 in stage 361.0 (TID 769) in 13 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:32.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 8.0 in stage 361.0 (TID 771) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 7.0 in stage 361.0 (TID 770) in 19 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:32.197+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 3530b0b864fd:36239 in memory (size: 6.5 KiB, free: 432.8 MiB)
[2025-05-07T21:37:32.198+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 172.20.0.5:37555 in memory (size: 6.5 KiB, free: 433.6 MiB)
[2025-05-07T21:37:32.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 3530b0b864fd:36239 in memory (size: 58.4 KiB, free: 432.9 MiB)
[2025-05-07T21:37:32.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 172.20.0.5:37555 in memory (size: 58.4 KiB, free: 433.7 MiB)
[2025-05-07T21:37:32.211+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 9.0 in stage 361.0 (TID 772) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.212+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 8.0 in stage 361.0 (TID 771) in 20 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:32.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 5.0 in stage 378.0 (TID 773) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 9.0 in stage 361.0 (TID 772) in 14 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:32.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Removed TaskSet 361.0, whose tasks have all completed, from pool
[2025-05-07T21:37:32.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: ShuffleMapStage 361 (mapPartitions at GraphImpl.scala:208) finished in 0.208 s
[2025-05-07T21:37:32.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:32.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: running: Set(ShuffleMapStage 379, ShuffleMapStage 380, ResultStage 378)
[2025-05-07T21:37:32.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 362, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:32.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:32.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Submitting ShuffleMapStage 362 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[374] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:32.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 17.1 KiB, free 406.9 MiB)
[2025-05-07T21:37:32.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 406.9 MiB)
[2025-05-07T21:37:32.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 3530b0b864fd:36239 (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-07T21:37:32.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:32.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 362 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[374] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:32.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Adding task set 362.0 with 10 tasks resource profile 0
[2025-05-07T21:37:32.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.20.0.5:58132
[2025-05-07T21:37:32.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 0.0 in stage 362.0 (TID 774) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 5.0 in stage 378.0 (TID 773) in 33 ms on 172.20.0.5 (executor 1) (6/6)
[2025-05-07T21:37:32.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: ResultStage 378 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.597 s
[2025-05-07T21:37:32.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:37:32.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Removed TaskSet 378.0, whose tasks have all completed, from pool
[2025-05-07T21:37:32.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 378: Stage finished
[2025-05-07T21:37:32.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Job 64 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 8.222012 s
[2025-05-07T21:37:32.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 172.20.0.5:37555 (size: 6.6 KiB, free: 433.7 MiB)
[2025-05-07T21:37:32.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:32.271+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:58132
[2025-05-07T21:37:32.271+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 2.3 MiB, free 404.6 MiB)
[2025-05-07T21:37:32.273+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:58132
[2025-05-07T21:37:32.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 404.5 MiB)
[2025-05-07T21:37:32.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 3530b0b864fd:36239 (size: 114.2 KiB, free: 432.7 MiB)
[2025-05-07T21:37:32.275+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO SparkContext: Created broadcast 140 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:32.275+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:58132
[2025-05-07T21:37:32.278+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:58132
[2025-05-07T21:37:32.283+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:58132
[2025-05-07T21:37:32.291+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:58132
[2025-05-07T21:37:32.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:58132
[2025-05-07T21:37:32.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 1.0 in stage 362.0 (TID 775) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.324+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 0.0 in stage 362.0 (TID 774) in 66 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:32.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 3530b0b864fd:36239 in memory (size: 30.4 KiB, free: 432.8 MiB)
[2025-05-07T21:37:32.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 172.20.0.5:37555 in memory (size: 30.4 KiB, free: 433.7 MiB)
[2025-05-07T21:37:32.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 3530b0b864fd:36239 in memory (size: 58.5 KiB, free: 432.8 MiB)
[2025-05-07T21:37:32.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO CodeGenerator: Code generated in 42.594118 ms
[2025-05-07T21:37:32.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 172.20.0.5:37555 in memory (size: 58.5 KiB, free: 433.8 MiB)
[2025-05-07T21:37:32.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:32.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 2.0 in stage 362.0 (TID 776) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 1.0 in stage 362.0 (TID 775) in 51 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:32.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO CodeGenerator: Code generated in 37.83808 ms
[2025-05-07T21:37:32.455+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 3.0 in stage 362.0 (TID 777) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 2.0 in stage 362.0 (TID 776) in 84 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:32.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO CodeGenerator: Code generated in 6.21481 ms
[2025-05-07T21:37:32.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Registering RDD 558 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 66
[2025-05-07T21:37:32.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Got map stage job 67 (toPandas at /opt/airflow/spark/build_graph.py:207) with 11 output partitions
[2025-05-07T21:37:32.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Final stage: ShuffleMapStage 382 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:32.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 381)
[2025-05-07T21:37:32.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:32.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Submitting ShuffleMapStage 382 (MapPartitionsRDD[558] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:32.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 141.2 KiB, free 404.7 MiB)
[2025-05-07T21:37:32.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 49.7 KiB, free 404.7 MiB)
[2025-05-07T21:37:32.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 3530b0b864fd:36239 (size: 49.7 KiB, free: 432.8 MiB)
[2025-05-07T21:37:32.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:32.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 382 (MapPartitionsRDD[558] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T21:37:32.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Adding task set 382.0 with 11 tasks resource profile 0
[2025-05-07T21:37:32.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 4.0 in stage 362.0 (TID 778) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 3.0 in stage 362.0 (TID 777) in 94 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:32.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 5.0 in stage 362.0 (TID 779) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 4.0 in stage 362.0 (TID 778) in 50 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:32.645+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 6.0 in stage 362.0 (TID 780) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.645+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 5.0 in stage 362.0 (TID 779) in 47 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:32.689+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 7.0 in stage 362.0 (TID 781) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 6.0 in stage 362.0 (TID 780) in 44 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:32.739+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 8.0 in stage 362.0 (TID 782) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.739+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 7.0 in stage 362.0 (TID 781) in 50 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:32.765+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 9.0 in stage 362.0 (TID 783) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 8.0 in stage 362.0 (TID 782) in 27 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:32.795+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 0.0 in stage 379.0 (TID 784) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 9.0 in stage 362.0 (TID 783) in 30 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:32.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Removed TaskSet 362.0, whose tasks have all completed, from pool
[2025-05-07T21:37:32.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: ShuffleMapStage 362 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.570 s
[2025-05-07T21:37:32.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:32.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: running: Set(ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 382)
[2025-05-07T21:37:32.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 363, ShuffleMapStage 364)
[2025-05-07T21:37:32.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:32.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Submitting ShuffleMapStage 363 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[378] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:32.802+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.20.0.5:37555 (size: 8.3 KiB, free: 433.8 MiB)
[2025-05-07T21:37:32.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 166.0 KiB, free 404.5 MiB)
[2025-05-07T21:37:32.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 404.4 MiB)
[2025-05-07T21:37:32.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 3530b0b864fd:36239 (size: 58.5 KiB, free: 432.7 MiB)
[2025-05-07T21:37:32.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:32.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 363 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[378] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:32.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Adding task set 363.0 with 10 tasks resource profile 0
[2025-05-07T21:37:32.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.20.0.5:37555 (size: 32.6 KiB, free: 433.7 MiB)
[2025-05-07T21:37:32.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 0.0 in stage 363.0 (TID 785) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 0.0 in stage 379.0 (TID 784) in 81 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:32.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSchedulerImpl: Removed TaskSet 379.0, whose tasks have all completed, from pool
[2025-05-07T21:37:32.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: ShuffleMapStage 379 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 5.061 s
[2025-05-07T21:37:32.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:32.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: running: Set(ShuffleMapStage 380, ShuffleMapStage 363, ShuffleMapStage 382)
[2025-05-07T21:37:32.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 364)
[2025-05-07T21:37:32.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:32.888+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 172.20.0.5:37555 (size: 58.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:32.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:32.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:32.916+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:58132
[2025-05-07T21:37:32.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:58132
[2025-05-07T21:37:32.922+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:58132
[2025-05-07T21:37:32.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:58132
[2025-05-07T21:37:32.925+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:58132
[2025-05-07T21:37:32.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:58132
[2025-05-07T21:37:32.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:58132
[2025-05-07T21:37:32.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:58132
[2025-05-07T21:37:32.937+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 1.0 in stage 363.0 (TID 786) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.937+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 0.0 in stage 363.0 (TID 785) in 62 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:32.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 2.0 in stage 363.0 (TID 787) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 1.0 in stage 363.0 (TID 786) in 15 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:32.966+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 3.0 in stage 363.0 (TID 788) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.966+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 2.0 in stage 363.0 (TID 787) in 15 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:32.984+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 4.0 in stage 363.0 (TID 789) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.984+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 3.0 in stage 363.0 (TID 788) in 19 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:32.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Starting task 5.0 in stage 363.0 (TID 790) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:32.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:32 INFO TaskSetManager: Finished task 4.0 in stage 363.0 (TID 789) in 15 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:33.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 6.0 in stage 363.0 (TID 791) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 5.0 in stage 363.0 (TID 790) in 22 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:33.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 7.0 in stage 363.0 (TID 792) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 6.0 in stage 363.0 (TID 791) in 21 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:33.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 8.0 in stage 363.0 (TID 793) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 7.0 in stage 363.0 (TID 792) in 21 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:33.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 9.0 in stage 363.0 (TID 794) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 8.0 in stage 363.0 (TID 793) in 20 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:33.104+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 0.0 in stage 380.0 (TID 795) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.104+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 9.0 in stage 363.0 (TID 794) in 24 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:33.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSchedulerImpl: Removed TaskSet 363.0, whose tasks have all completed, from pool
[2025-05-07T21:37:33.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: ShuffleMapStage 363 (mapPartitions at GraphImpl.scala:208) finished in 0.306 s
[2025-05-07T21:37:33.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:33.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: running: Set(ShuffleMapStage 380, ShuffleMapStage 382)
[2025-05-07T21:37:33.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367, ShuffleMapStage 364)
[2025-05-07T21:37:33.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:33.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Submitting ShuffleMapStage 364 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[386] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:37:33.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 17.8 KiB, free 404.4 MiB)
[2025-05-07T21:37:33.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 404.4 MiB)
[2025-05-07T21:37:33.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 432.7 MiB)
[2025-05-07T21:37:33.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:33.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 364 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[386] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:33.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSchedulerImpl: Adding task set 364.0 with 10 tasks resource profile 0
[2025-05-07T21:37:33.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.20.0.5:37555 (size: 33.9 KiB, free: 433.6 MiB)
[2025-05-07T21:37:33.236+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 0.0 in stage 364.0 (TID 796) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 0.0 in stage 380.0 (TID 795) in 133 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:33.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSchedulerImpl: Removed TaskSet 380.0, whose tasks have all completed, from pool
[2025-05-07T21:37:33.239+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: ShuffleMapStage 380 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 5.305 s
[2025-05-07T21:37:33.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:33.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: running: Set(ShuffleMapStage 382, ShuffleMapStage 364)
[2025-05-07T21:37:33.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367)
[2025-05-07T21:37:33.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:33.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO ShufflePartitionsUtil: For shuffle(65), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:37:33.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 172.20.0.5:37555 (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T21:37:33.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:33.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:33.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:58132
[2025-05-07T21:37:33.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:58132
[2025-05-07T21:37:33.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:58132
[2025-05-07T21:37:33.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO CodeGenerator: Code generated in 10.746683 ms
[2025-05-07T21:37:33.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:58132
[2025-05-07T21:37:33.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:58132
[2025-05-07T21:37:33.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:58132
[2025-05-07T21:37:33.331+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:58132
[2025-05-07T21:37:33.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 3530b0b864fd:36239 in memory (size: 58.5 KiB, free: 432.8 MiB)
[2025-05-07T21:37:33.334+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:33.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Got job 68 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:37:33.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Final stage: ResultStage 384 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:33.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 383)
[2025-05-07T21:37:33.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:33.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 172.20.0.5:37555 in memory (size: 58.5 KiB, free: 433.7 MiB)
[2025-05-07T21:37:33.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Submitting ResultStage 384 (MapPartitionsRDD[561] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:33.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 73.5 KiB, free 404.6 MiB)
[2025-05-07T21:37:33.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 404.5 MiB)
[2025-05-07T21:37:33.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 3530b0b864fd:36239 (size: 32.5 KiB, free: 432.7 MiB)
[2025-05-07T21:37:33.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:33.341+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 384 (MapPartitionsRDD[561] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:33.341+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSchedulerImpl: Adding task set 384.0 with 1 tasks resource profile 0
[2025-05-07T21:37:33.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:58132
[2025-05-07T21:37:33.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 1.0 in stage 364.0 (TID 797) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 0.0 in stage 364.0 (TID 796) in 137 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:33.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 2.0 in stage 364.0 (TID 798) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 1.0 in stage 364.0 (TID 797) in 49 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:33.485+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 3.0 in stage 364.0 (TID 799) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.485+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 2.0 in stage 364.0 (TID 798) in 65 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:33.537+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 4.0 in stage 364.0 (TID 800) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.537+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 3.0 in stage 364.0 (TID 799) in 52 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:33.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 5.0 in stage 364.0 (TID 801) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 4.0 in stage 364.0 (TID 800) in 71 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:33.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 6.0 in stage 364.0 (TID 802) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 5.0 in stage 364.0 (TID 801) in 50 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:33.706+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 7.0 in stage 364.0 (TID 803) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.707+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 6.0 in stage 364.0 (TID 802) in 50 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:33.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 8.0 in stage 364.0 (TID 804) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 7.0 in stage 364.0 (TID 803) in 77 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:33.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 9.0 in stage 364.0 (TID 805) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 8.0 in stage 364.0 (TID 804) in 56 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:33.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Starting task 0.0 in stage 382.0 (TID 806) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:33.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSetManager: Finished task 9.0 in stage 364.0 (TID 805) in 71 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:33.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSchedulerImpl: Removed TaskSet 364.0, whose tasks have all completed, from pool
[2025-05-07T21:37:33.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: ShuffleMapStage 364 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.804 s
[2025-05-07T21:37:33.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:33.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: running: Set(ResultStage 384, ShuffleMapStage 382)
[2025-05-07T21:37:33.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 365, ShuffleMapStage 366, ResultStage 367)
[2025-05-07T21:37:33.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:33.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Submitting ShuffleMapStage 365 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[390] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:37:33.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 172.20.0.5:37555 (size: 49.7 KiB, free: 433.6 MiB)
[2025-05-07T21:37:33.918+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 166.3 KiB, free 404.4 MiB)
[2025-05-07T21:37:33.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 404.3 MiB)
[2025-05-07T21:37:33.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 3530b0b864fd:36239 (size: 58.4 KiB, free: 432.7 MiB)
[2025-05-07T21:37:33.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:33.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 365 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[390] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:33.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO TaskSchedulerImpl: Adding task set 365.0 with 10 tasks resource profile 0
[2025-05-07T21:37:33.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:58132
[2025-05-07T21:37:33.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 172.20.0.5:37555 (size: 502.1 KiB, free: 433.1 MiB)
[2025-05-07T21:37:33.982+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 172.20.0.5:37555 (size: 114.2 KiB, free: 433.0 MiB)
[2025-05-07T21:37:33.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:33 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 172.20.0.5:37555 (size: 20.6 KiB, free: 433.0 MiB)
[2025-05-07T21:37:34.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 0.0 in stage 365.0 (TID 807) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 0.0 in stage 382.0 (TID 806) in 199 ms on 172.20.0.5 (executor 1) (1/11)
[2025-05-07T21:37:34.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 172.20.0.5:37555 (size: 58.4 KiB, free: 433.0 MiB)
[2025-05-07T21:37:34.123+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:58132
[2025-05-07T21:37:34.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:58132
[2025-05-07T21:37:34.129+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:58132
[2025-05-07T21:37:34.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:58132
[2025-05-07T21:37:34.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:58132
[2025-05-07T21:37:34.136+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:58132
[2025-05-07T21:37:34.138+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:58132
[2025-05-07T21:37:34.141+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:58132
[2025-05-07T21:37:34.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:58132
[2025-05-07T21:37:34.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:58132
[2025-05-07T21:37:34.146+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.20.0.5:58132
[2025-05-07T21:37:34.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 1.0 in stage 365.0 (TID 808) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 0.0 in stage 365.0 (TID 807) in 53 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:34.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 2.0 in stage 365.0 (TID 809) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 1.0 in stage 365.0 (TID 808) in 27 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:34.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 3.0 in stage 365.0 (TID 810) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 2.0 in stage 365.0 (TID 809) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:34.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 4.0 in stage 365.0 (TID 811) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 3.0 in stage 365.0 (TID 810) in 17 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:34.236+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 5.0 in stage 365.0 (TID 812) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.236+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 4.0 in stage 365.0 (TID 811) in 17 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:34.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 6.0 in stage 365.0 (TID 813) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 5.0 in stage 365.0 (TID 812) in 24 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:34.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 7.0 in stage 365.0 (TID 814) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 6.0 in stage 365.0 (TID 813) in 36 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:34.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 8.0 in stage 365.0 (TID 815) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 7.0 in stage 365.0 (TID 814) in 24 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:34.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 9.0 in stage 365.0 (TID 816) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 8.0 in stage 365.0 (TID 815) in 21 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:34.355+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 1.0 in stage 382.0 (TID 817) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.356+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 9.0 in stage 365.0 (TID 816) in 22 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:34.356+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSchedulerImpl: Removed TaskSet 365.0, whose tasks have all completed, from pool
[2025-05-07T21:37:34.357+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO DAGScheduler: ShuffleMapStage 365 (mapPartitions at GraphImpl.scala:208) finished in 0.444 s
[2025-05-07T21:37:34.357+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:34.357+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO DAGScheduler: running: Set(ResultStage 384, ShuffleMapStage 382)
[2025-05-07T21:37:34.357+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 366, ResultStage 367)
[2025-05-07T21:37:34.357+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:34.357+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO DAGScheduler: Submitting ShuffleMapStage 366 (MapPartitionsRDD[448] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:34.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 31.6 KiB, free 404.3 MiB)
[2025-05-07T21:37:34.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 11.9 KiB, free 404.3 MiB)
[2025-05-07T21:37:34.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 3530b0b864fd:36239 (size: 11.9 KiB, free: 432.7 MiB)
[2025-05-07T21:37:34.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:34.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 366 (MapPartitionsRDD[448] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:37:34.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSchedulerImpl: Adding task set 366.1 with 10 tasks resource profile 0
[2025-05-07T21:37:34.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:58132
[2025-05-07T21:37:34.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 0.0 in stage 366.1 (TID 818) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 1.0 in stage 382.0 (TID 817) in 41 ms on 172.20.0.5 (executor 1) (2/11)
[2025-05-07T21:37:34.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 172.20.0.5:37555 (size: 11.9 KiB, free: 432.9 MiB)
[2025-05-07T21:37:34.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:58132
[2025-05-07T21:37:34.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:58132
[2025-05-07T21:37:34.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:58132
[2025-05-07T21:37:34.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:58132
[2025-05-07T21:37:34.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:58132
[2025-05-07T21:37:34.451+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:58132
[2025-05-07T21:37:34.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:58132
[2025-05-07T21:37:34.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:58132
[2025-05-07T21:37:34.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:58132
[2025-05-07T21:37:34.534+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.20.0.5:58132
[2025-05-07T21:37:34.546+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO BlockManagerInfo: Added rdd_394_0 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:34.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO BlockManagerInfo: Added rdd_404_0 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:34.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 1.0 in stage 366.1 (TID 819) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 0.0 in stage 366.1 (TID 818) in 178 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T21:37:34.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO BlockManagerInfo: Added rdd_394_1 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:34.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO BlockManagerInfo: Added rdd_404_1 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:34.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 2.0 in stage 366.1 (TID 820) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 1.0 in stage 366.1 (TID 819) in 91 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T21:37:34.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO BlockManagerInfo: Added rdd_394_2 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:34.739+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO BlockManagerInfo: Added rdd_404_2 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:34.747+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Starting task 3.0 in stage 366.1 (TID 821) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:34.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:34 INFO TaskSetManager: Finished task 2.0 in stage 366.1 (TID 820) in 84 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T21:37:35.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_394_3 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.009+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_404_3 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Starting task 4.0 in stage 366.1 (TID 822) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:35.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Finished task 3.0 in stage 366.1 (TID 821) in 276 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T21:37:35.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_394_4 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_404_4 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Starting task 5.0 in stage 366.1 (TID 823) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:35.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Finished task 4.0 in stage 366.1 (TID 822) in 50 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T21:37:35.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_394_5 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_404_5 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Starting task 6.0 in stage 366.1 (TID 824) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:35.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Finished task 5.0 in stage 366.1 (TID 823) in 42 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T21:37:35.157+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_394_6 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.158+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_404_6 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Starting task 7.0 in stage 366.1 (TID 825) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:35.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Finished task 6.0 in stage 366.1 (TID 824) in 49 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T21:37:35.202+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_394_7 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_404_7 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Starting task 8.0 in stage 366.1 (TID 826) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:35.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Finished task 7.0 in stage 366.1 (TID 825) in 44 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T21:37:35.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_394_8 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:35.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO BlockManagerInfo: Added rdd_404_8 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:37:35.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Starting task 9.0 in stage 366.1 (TID 827) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:35.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:35 INFO TaskSetManager: Finished task 8.0 in stage 366.1 (TID 826) in 212 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T21:37:37.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:37 INFO BlockManagerInfo: Added rdd_394_9 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:37:37.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:37 INFO BlockManagerInfo: Added rdd_404_9 in memory on 172.20.0.5:37555 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:37:38.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:38 INFO TaskSetManager: Starting task 2.0 in stage 382.0 (TID 828) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:39.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:38 INFO TaskSetManager: Finished task 9.0 in stage 366.1 (TID 827) in 3434 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T21:37:39.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:39 INFO TaskSchedulerImpl: Removed TaskSet 366.1, whose tasks have all completed, from pool
[2025-05-07T21:37:39.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:39 INFO DAGScheduler: ShuffleMapStage 366 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 4.753 s
[2025-05-07T21:37:41.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:41.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:39 INFO DAGScheduler: running: Set(ResultStage 384, ShuffleMapStage 382)
[2025-05-07T21:37:41.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:39 INFO DAGScheduler: waiting: Set(ResultStage 367)
[2025-05-07T21:37:41.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:39 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:41.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:39 INFO DAGScheduler: Submitting ResultStage 367 (MapPartitionsRDD[491] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:41.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:39 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 367.
[2025-05-07T21:37:41.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:58132
[2025-05-07T21:37:41.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 7.2 KiB, free 404.3 MiB)
[2025-05-07T21:37:41.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO TaskSetManager: Starting task 3.0 in stage 382.0 (TID 829) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:41.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO TaskSetManager: Finished task 2.0 in stage 382.0 (TID 828) in 2601 ms on 172.20.0.5 (executor 1) (3/11)
[2025-05-07T21:37:41.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 404.3 MiB)
[2025-05-07T21:37:41.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 432.7 MiB)
[2025-05-07T21:37:41.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:41.601+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 367 (MapPartitionsRDD[491] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:41.601+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO TaskSchedulerImpl: Adding task set 367.1 with 1 tasks resource profile 0
[2025-05-07T21:37:41.628+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO TaskSetManager: Starting task 0.0 in stage 367.1 (TID 830) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:41.628+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO TaskSetManager: Finished task 3.0 in stage 382.0 (TID 829) in 195 ms on 172.20.0.5 (executor 1) (4/11)
[2025-05-07T21:37:41.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 172.20.0.5:37555 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T21:37:41.704+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.20.0.5:58132
[2025-05-07T21:37:42.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Starting task 4.0 in stage 382.0 (TID 831) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:42.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Finished task 0.0 in stage 367.1 (TID 830) in 767 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:42.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSchedulerImpl: Removed TaskSet 367.1, whose tasks have all completed, from pool
[2025-05-07T21:37:42.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: ResultStage 367 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.105 s
[2025-05-07T21:37:42.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:37:42.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 367: Stage finished
[2025-05-07T21:37:42.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: Job 61 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 139.191975 s
[2025-05-07T21:37:42.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 1088.0 KiB, free 403.2 MiB)
[2025-05-07T21:37:42.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:58132
[2025-05-07T21:37:42.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 172.20.0.5:37555 in memory (size: 11.9 KiB, free: 432.8 MiB)
[2025-05-07T21:37:42.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 3530b0b864fd:36239 in memory (size: 11.9 KiB, free: 432.7 MiB)
[2025-05-07T21:37:42.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Starting task 5.0 in stage 382.0 (TID 832) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:42.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Finished task 4.0 in stage 382.0 (TID 831) in 137 ms on 172.20.0.5 (executor 1) (5/11)
[2025-05-07T21:37:42.531+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 403.2 MiB)
[2025-05-07T21:37:42.531+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 3530b0b864fd:36239 in memory (size: 8.3 KiB, free: 432.7 MiB)
[2025-05-07T21:37:42.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.20.0.5:37555 in memory (size: 8.3 KiB, free: 432.9 MiB)
[2025-05-07T21:37:42.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 3530b0b864fd:36239 (size: 23.7 KiB, free: 432.7 MiB)
[2025-05-07T21:37:42.534+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO SparkContext: Created broadcast 148 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:42.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 3530b0b864fd:36239 in memory (size: 6.6 KiB, free: 432.7 MiB)
[2025-05-07T21:37:42.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 172.20.0.5:37555 in memory (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-07T21:37:42.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:37:42.554+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Starting task 6.0 in stage 382.0 (TID 833) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:42.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Finished task 5.0 in stage 382.0 (TID 832) in 29 ms on 172.20.0.5 (executor 1) (6/11)
[2025-05-07T21:37:42.557+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 172.20.0.5:37555 in memory (size: 33.9 KiB, free: 432.9 MiB)
[2025-05-07T21:37:42.557+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 3530b0b864fd:36239 in memory (size: 33.9 KiB, free: 432.7 MiB)
[2025-05-07T21:37:42.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 172.20.0.5:37555 in memory (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:37:42.601+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 432.7 MiB)
[2025-05-07T21:37:42.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 3530b0b864fd:36239 in memory (size: 58.4 KiB, free: 432.8 MiB)
[2025-05-07T21:37:42.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO CodeGenerator: Code generated in 30.554098 ms
[2025-05-07T21:37:42.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 172.20.0.5:37555 in memory (size: 58.4 KiB, free: 433.0 MiB)
[2025-05-07T21:37:42.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Starting task 7.0 in stage 382.0 (TID 834) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:42.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Finished task 6.0 in stage 382.0 (TID 833) in 57 ms on 172.20.0.5 (executor 1) (7/11)
[2025-05-07T21:37:42.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 172.20.0.5:37555 in memory (size: 3.8 KiB, free: 433.0 MiB)
[2025-05-07T21:37:42.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T21:37:42.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: Registering RDD 564 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 67
[2025-05-07T21:37:42.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: Got map stage job 69 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:37:42.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: Final stage: ShuffleMapStage 386 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:42.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 385)
[2025-05-07T21:37:42.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:42.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: Submitting ShuffleMapStage 386 (MapPartitionsRDD[564] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:42.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 13.8 KiB, free 403.6 MiB)
[2025-05-07T21:37:42.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 403.6 MiB)
[2025-05-07T21:37:42.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 3530b0b864fd:36239 (size: 6.9 KiB, free: 432.8 MiB)
[2025-05-07T21:37:42.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:42.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 386 (MapPartitionsRDD[564] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:42.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSchedulerImpl: Adding task set 386.0 with 1 tasks resource profile 0
[2025-05-07T21:37:42.673+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Starting task 8.0 in stage 382.0 (TID 835) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:42.674+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Finished task 7.0 in stage 382.0 (TID 834) in 63 ms on 172.20.0.5 (executor 1) (8/11)
[2025-05-07T21:37:42.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Starting task 9.0 in stage 382.0 (TID 836) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:42.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Finished task 8.0 in stage 382.0 (TID 835) in 22 ms on 172.20.0.5 (executor 1) (9/11)
[2025-05-07T21:37:42.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Starting task 10.0 in stage 382.0 (TID 837) (172.20.0.5, executor 1, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:42.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Finished task 9.0 in stage 382.0 (TID 836) in 30 ms on 172.20.0.5 (executor 1) (10/11)
[2025-05-07T21:37:42.948+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Starting task 0.0 in stage 384.0 (TID 838) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:42.948+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSetManager: Finished task 10.0 in stage 382.0 (TID 837) in 224 ms on 172.20.0.5 (executor 1) (11/11)
[2025-05-07T21:37:42.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO TaskSchedulerImpl: Removed TaskSet 382.0, whose tasks have all completed, from pool
[2025-05-07T21:37:42.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 172.20.0.5:37555 (size: 32.5 KiB, free: 432.9 MiB)
[2025-05-07T21:37:42.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: ShuffleMapStage 382 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 10.448 s
[2025-05-07T21:37:42.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:42.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: running: Set(ShuffleMapStage 386, ResultStage 384)
[2025-05-07T21:37:42.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:37:42.954+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:42.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 65 to 172.20.0.5:58132
[2025-05-07T21:37:42.983+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:42 INFO ShufflePartitionsUtil: For shuffle(66), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:37:43.003+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Starting task 0.0 in stage 386.0 (TID 839) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:43.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Finished task 0.0 in stage 384.0 (TID 838) in 56 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:43.005+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Removed TaskSet 384.0, whose tasks have all completed, from pool
[2025-05-07T21:37:43.006+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: ResultStage 384 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 9.670 s
[2025-05-07T21:37:43.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:37:43.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 384: Stage finished
[2025-05-07T21:37:43.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Job 68 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 9.671775 s
[2025-05-07T21:37:43.094+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 172.20.0.5:37555 in memory (size: 32.5 KiB, free: 433.0 MiB)
[2025-05-07T21:37:43.094+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 172.20.0.5:37555 (size: 6.9 KiB, free: 433.0 MiB)
[2025-05-07T21:37:43.096+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:43.097+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 3530b0b864fd:36239 in memory (size: 32.5 KiB, free: 432.8 MiB)
[2025-05-07T21:37:43.099+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 63 to 172.20.0.5:58132
[2025-05-07T21:37:43.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO CodeGenerator: Code generated in 92.93772 ms
[2025-05-07T21:37:43.113+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 1088.0 KiB, free 402.6 MiB)
[2025-05-07T21:37:43.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 172.20.0.5:37555 (size: 23.7 KiB, free: 432.9 MiB)
[2025-05-07T21:37:43.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 22.4 KiB, free 402.6 MiB)
[2025-05-07T21:37:43.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 3530b0b864fd:36239 (size: 22.4 KiB, free: 432.8 MiB)
[2025-05-07T21:37:43.121+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Created broadcast 150 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:43.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Finished task 0.0 in stage 386.0 (TID 839) in 142 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:43.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool
[2025-05-07T21:37:43.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: ShuffleMapStage 386 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.523 s
[2025-05-07T21:37:43.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:43.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: running: Set()
[2025-05-07T21:37:43.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:37:43.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:43.151+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO CodeGenerator: Code generated in 48.743083 ms
[2025-05-07T21:37:43.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Registering RDD 567 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 68
[2025-05-07T21:37:43.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Got map stage job 70 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:37:43.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Final stage: ShuffleMapStage 389 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:43.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 388)
[2025-05-07T21:37:43.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:43.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Submitting ShuffleMapStage 389 (MapPartitionsRDD[567] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:43.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO ShufflePartitionsUtil: For shuffle(67), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:37:43.168+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 130.2 KiB, free 402.5 MiB)
[2025-05-07T21:37:43.170+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 44.6 KiB, free 402.5 MiB)
[2025-05-07T21:37:43.170+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 3530b0b864fd:36239 (size: 44.6 KiB, free: 432.7 MiB)
[2025-05-07T21:37:43.170+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:43.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 389 (MapPartitionsRDD[567] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:43.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Adding task set 389.0 with 1 tasks resource profile 0
[2025-05-07T21:37:43.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Starting task 0.0 in stage 389.0 (TID 840) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:43.177+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 172.20.0.5:37555 (size: 44.6 KiB, free: 432.9 MiB)
[2025-05-07T21:37:43.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:43.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Got job 71 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:37:43.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Final stage: ResultStage 392 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:43.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 391)
[2025-05-07T21:37:43.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:43.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Submitting ResultStage 392 (MapPartitionsRDD[569] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:43.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 7.2 KiB, free 402.5 MiB)
[2025-05-07T21:37:43.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 402.4 MiB)
[2025-05-07T21:37:43.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 432.7 MiB)
[2025-05-07T21:37:43.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:43.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 392 (MapPartitionsRDD[569] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:43.236+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Adding task set 392.0 with 1 tasks resource profile 0
[2025-05-07T21:37:43.239+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 66 to 172.20.0.5:58132
[2025-05-07T21:37:43.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Starting task 0.0 in stage 392.0 (TID 841) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:43.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Finished task 0.0 in stage 389.0 (TID 840) in 194 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:43.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Removed TaskSet 389.0, whose tasks have all completed, from pool
[2025-05-07T21:37:43.367+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: ShuffleMapStage 389 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.204 s
[2025-05-07T21:37:43.367+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:37:43.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: running: Set(ResultStage 392)
[2025-05-07T21:37:43.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:37:43.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: failed: Set()
[2025-05-07T21:37:43.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO ShufflePartitionsUtil: For shuffle(68), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:37:43.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:43.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 3530b0b864fd:36239 in memory (size: 44.6 KiB, free: 432.8 MiB)
[2025-05-07T21:37:43.408+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO CodeGenerator: Code generated in 6.015523 ms
[2025-05-07T21:37:43.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 172.20.0.5:37555 (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:37:43.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 172.20.0.5:37555 in memory (size: 44.6 KiB, free: 432.9 MiB)
[2025-05-07T21:37:43.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 67 to 172.20.0.5:58132
[2025-05-07T21:37:43.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Finished task 0.0 in stage 392.0 (TID 841) in 78 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:43.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Removed TaskSet 392.0, whose tasks have all completed, from pool
[2025-05-07T21:37:43.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: ResultStage 392 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.217 s
[2025-05-07T21:37:43.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:37:43.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 392: Stage finished
[2025-05-07T21:37:43.446+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Job 71 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.220102 s
[2025-05-07T21:37:43.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 2.1 MiB, free 400.6 MiB)
[2025-05-07T21:37:43.455+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 400.5 MiB)
[2025-05-07T21:37:43.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 3530b0b864fd:36239 (size: 20.3 KiB, free: 432.8 MiB)
[2025-05-07T21:37:43.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Created broadcast 153 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:43.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:43.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Got job 72 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:37:43.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Final stage: ResultStage 396 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:43.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 395)
[2025-05-07T21:37:43.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:43.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Submitting ResultStage 396 (MapPartitionsRDD[572] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:43.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 122.7 KiB, free 400.4 MiB)
[2025-05-07T21:37:43.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 41.9 KiB, free 400.4 MiB)
[2025-05-07T21:37:43.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 3530b0b864fd:36239 (size: 41.9 KiB, free: 432.7 MiB)
[2025-05-07T21:37:43.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:43.471+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 396 (MapPartitionsRDD[572] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:43.471+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Adding task set 396.0 with 1 tasks resource profile 0
[2025-05-07T21:37:43.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Starting task 0.0 in stage 396.0 (TID 842) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:43.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 172.20.0.5:37555 (size: 41.9 KiB, free: 432.9 MiB)
[2025-05-07T21:37:43.486+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 68 to 172.20.0.5:58132
[2025-05-07T21:37:43.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Finished task 0.0 in stage 396.0 (TID 842) in 37 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:43.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Removed TaskSet 396.0, whose tasks have all completed, from pool
[2025-05-07T21:37:43.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: ResultStage 396 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.047 s
[2025-05-07T21:37:43.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:37:43.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 396: Stage finished
[2025-05-07T21:37:43.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Job 72 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.050587 s
[2025-05-07T21:37:43.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 2.1 MiB, free 398.3 MiB)
[2025-05-07T21:37:43.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 82.5 KiB, free 398.2 MiB)
[2025-05-07T21:37:43.530+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 3530b0b864fd:36239 (size: 82.5 KiB, free: 432.6 MiB)
[2025-05-07T21:37:43.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Created broadcast 155 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:43.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO ShufflePartitionsUtil: For shuffle(64), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:37:43.571+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO CodeGenerator: Code generated in 4.699361 ms
[2025-05-07T21:37:43.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:37:43.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Got job 73 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:37:43.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Final stage: ResultStage 398 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:37:43.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 397)
[2025-05-07T21:37:43.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:43.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Submitting ResultStage 398 (MapPartitionsRDD[575] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:37:43.589+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 15.6 KiB, free 398.2 MiB)
[2025-05-07T21:37:43.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 432.6 MiB)
[2025-05-07T21:37:43.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 398.2 MiB)
[2025-05-07T21:37:43.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 432.6 MiB)
[2025-05-07T21:37:43.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 172.20.0.5:37555 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:37:43.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:37:43.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 398 (MapPartitionsRDD[575] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:37:43.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Adding task set 398.0 with 1 tasks resource profile 0
[2025-05-07T21:37:43.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Starting task 0.0 in stage 398.0 (TID 843) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:37:43.593+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 3530b0b864fd:36239 in memory (size: 41.9 KiB, free: 432.7 MiB)
[2025-05-07T21:37:43.595+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 172.20.0.5:37555 in memory (size: 41.9 KiB, free: 432.9 MiB)
[2025-05-07T21:37:43.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 172.20.0.5:37555 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:37:43.600+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.20.0.5:58132
[2025-05-07T21:37:43.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 172.20.0.5:37555 (size: 20.3 KiB, free: 432.9 MiB)
[2025-05-07T21:37:43.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 172.20.0.5:37555 (size: 82.5 KiB, free: 432.8 MiB)
[2025-05-07T21:37:43.628+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 172.20.0.5:37555 (size: 22.4 KiB, free: 432.8 MiB)
[2025-05-07T21:37:43.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSetManager: Finished task 0.0 in stage 398.0 (TID 843) in 45 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T21:37:43.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Removed TaskSet 398.0, whose tasks have all completed, from pool
[2025-05-07T21:37:43.639+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: ResultStage 398 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.062 s
[2025-05-07T21:37:43.639+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:37:43.639+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 398: Stage finished
[2025-05-07T21:37:43.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO DAGScheduler: Job 73 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.063442 s
[2025-05-07T21:37:43.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:43 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 432.7 MiB)
[2025-05-07T21:37:54.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 172.20.0.5:37555 in memory (size: 6.7 KiB, free: 432.8 MiB)
[2025-05-07T21:37:54.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO DAGScheduler: Registering RDD 604 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 69
[2025-05-07T21:37:54.355+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:54.355+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO DAGScheduler: Got map stage job 74 (toPandas at /opt/airflow/spark/build_graph.py:216) with 6 output partitions
[2025-05-07T21:37:54.355+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO DAGScheduler: Final stage: ShuffleMapStage 399 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:37:54.355+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:37:54.355+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:37:54.355+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO DAGScheduler: Submitting ShuffleMapStage 399 (MapPartitionsRDD[604] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:37:54.356+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:54.356+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 36.4 KiB, free 398.4 MiB)
[2025-05-07T21:37:54.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:54.375+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:54.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:37:54.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:37:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:38:18.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 398.4 MiB)
[2025-05-07T21:38:18.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 172.20.0.5:37555 in memory (size: 6.9 KiB, free: 432.8 MiB)
[2025-05-07T21:38:18.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 3530b0b864fd:36239 (size: 11.2 KiB, free: 432.7 MiB)
[2025-05-07T21:38:18.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 3530b0b864fd:36239 in memory (size: 6.9 KiB, free: 432.7 MiB)
[2025-05-07T21:38:18.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:38:18.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 399 (MapPartitionsRDD[604] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:38:18.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO TaskSchedulerImpl: Adding task set 399.0 with 6 tasks resource profile 0
[2025-05-07T21:38:18.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Registering RDD 606 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 70
[2025-05-07T21:38:18.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO TaskSetManager: Starting task 0.0 in stage 399.0 (TID 844) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:38:18.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Got map stage job 75 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:38:18.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Final stage: ShuffleMapStage 400 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:38:18.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:38:18.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:38:18.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting ShuffleMapStage 400 (MapPartitionsRDD[606] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:38:18.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 12.6 KiB, free 398.4 MiB)
[2025-05-07T21:38:18.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 3530b0b864fd:36239 in memory (size: 49.7 KiB, free: 432.7 MiB)
[2025-05-07T21:38:18.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 172.20.0.5:37555 in memory (size: 49.7 KiB, free: 432.9 MiB)
[2025-05-07T21:38:18.427+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 398.5 MiB)
[2025-05-07T21:38:18.432+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 432.7 MiB)
[2025-05-07T21:38:18.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:38:18.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 400 (MapPartitionsRDD[606] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:38:18.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO TaskSchedulerImpl: Adding task set 400.0 with 1 tasks resource profile 0
[2025-05-07T21:38:18.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Registering RDD 608 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 71
[2025-05-07T21:38:18.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Got map stage job 76 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:38:18.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Final stage: ShuffleMapStage 401 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:38:18.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:38:18.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:38:18.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting ShuffleMapStage 401 (MapPartitionsRDD[608] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:38:18.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 27.3 KiB, free 398.5 MiB)
[2025-05-07T21:38:18.438+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 398.5 MiB)
[2025-05-07T21:38:18.438+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 432.7 MiB)
[2025-05-07T21:38:18.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:38:18.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 401 (MapPartitionsRDD[608] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:38:18.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO TaskSchedulerImpl: Adding task set 401.0 with 1 tasks resource profile 0
[2025-05-07T21:38:18.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Registering RDD 610 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 72
[2025-05-07T21:38:18.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Got map stage job 77 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:38:18.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Final stage: ShuffleMapStage 402 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:38:18.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:38:18.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:38:18.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting ShuffleMapStage 402 (MapPartitionsRDD[610] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:38:18.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 28.5 KiB, free 398.5 MiB)
[2025-05-07T21:38:18.451+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 398.5 MiB)
[2025-05-07T21:38:18.451+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-07T21:38:18.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 172.20.0.5:37555 (size: 11.2 KiB, free: 432.9 MiB)
[2025-05-07T21:38:18.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:38:18.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 402 (MapPartitionsRDD[610] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:38:18.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO TaskSchedulerImpl: Adding task set 402.0 with 1 tasks resource profile 0
[2025-05-07T21:38:18.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Registering RDD 612 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 73
[2025-05-07T21:38:18.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Got map stage job 78 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:38:18.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Final stage: ShuffleMapStage 403 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:38:18.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:38:18.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:38:18.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting ShuffleMapStage 403 (MapPartitionsRDD[612] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:38:18.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 28.5 KiB, free 398.4 MiB)
[2025-05-07T21:38:18.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 398.4 MiB)
[2025-05-07T21:38:18.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-07T21:38:18.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:38:18.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 403 (MapPartitionsRDD[612] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:38:18.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO TaskSchedulerImpl: Adding task set 403.0 with 1 tasks resource profile 0
[2025-05-07T21:38:18.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Registering RDD 614 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 74
[2025-05-07T21:38:18.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Got map stage job 79 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:38:18.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Final stage: ShuffleMapStage 404 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:38:18.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:38:18.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:38:18.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting ShuffleMapStage 404 (MapPartitionsRDD[614] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:38:18.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 27.4 KiB, free 398.4 MiB)
[2025-05-07T21:38:18.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 398.4 MiB)
[2025-05-07T21:38:18.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 432.7 MiB)
[2025-05-07T21:38:18.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:38:18.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 404 (MapPartitionsRDD[614] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:38:18.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO TaskSchedulerImpl: Adding task set 404.0 with 1 tasks resource profile 0
[2025-05-07T21:38:18.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Registering RDD 616 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 75
[2025-05-07T21:38:18.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Got map stage job 80 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:38:18.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Final stage: ShuffleMapStage 405 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:38:18.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:38:18.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:38:18.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting ShuffleMapStage 405 (MapPartitionsRDD[616] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:38:18.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 28.5 KiB, free 398.4 MiB)
[2025-05-07T21:38:18.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 398.3 MiB)
[2025-05-07T21:38:18.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-07T21:38:18.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:38:18.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 405 (MapPartitionsRDD[616] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:38:18.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO TaskSchedulerImpl: Adding task set 405.0 with 1 tasks resource profile 0
[2025-05-07T21:38:18.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Registering RDD 618 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 76
[2025-05-07T21:38:18.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Got map stage job 81 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:38:18.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Final stage: ShuffleMapStage 406 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:38:18.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:38:18.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:38:18.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting ShuffleMapStage 406 (MapPartitionsRDD[618] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:38:18.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 31.7 KiB, free 398.3 MiB)
[2025-05-07T21:38:18.530+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 398.3 MiB)
[2025-05-07T21:38:18.534+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 3530b0b864fd:36239 (size: 14.9 KiB, free: 432.6 MiB)
[2025-05-07T21:38:18.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:38:18.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 406 (MapPartitionsRDD[618] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:38:18.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:38:18 INFO TaskSchedulerImpl: Adding task set 406.0 with 1 tasks resource profile 0
[2025-05-07T21:40:04.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:40:04 INFO TaskSetManager: Starting task 1.0 in stage 399.0 (TID 845) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:40:04.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:40:04 WARN TaskSetManager: Lost task 0.0 in stage 399.0 (TID 844) (172.20.0.5 executor 1): org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:40:04.424+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:40:04.424+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:40:04.424+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:40:04.424+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:40:04.424+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:40:04.424+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:40:04.425+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:40:04.425+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:40:04.425+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:40:04.425+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:40:04.425+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:40:04.425+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:40:04.427+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:40:04.427+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:40:04.427+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:40:04.427+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:40:04.427+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:40:04.428+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:40:04.429+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:40:04.429+0000] {spark_submit.py:571} INFO - Caused by: java.io.EOFException
[2025-05-07T21:40:04.429+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.receiveChar(PGStream.java:467)
[2025-05-07T21:40:04.429+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:678)
[2025-05-07T21:40:04.429+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:203)
[2025-05-07T21:40:04.429+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:40:04.429+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:40:04.429+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:40:04.450+0000] {spark_submit.py:571} INFO - 25/05/07 21:40:04 INFO TaskSetManager: Starting task 0.1 in stage 399.0 (TID 846) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:40:04.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:40:04 INFO TaskSetManager: Finished task 1.0 in stage 399.0 (TID 845) in 281 ms on 172.20.0.5 (executor 1) (1/6)
[2025-05-07T21:41:48.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:48 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@35df7295)) by listener AppStatusListener took 7.210850792s.
[2025-05-07T21:41:49.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507213450-0005/1 is now LOST (worker lost)
[2025-05-07T21:41:49.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO StandaloneSchedulerBackend: Executor app-20250507213450-0005/1 removed: worker lost
[2025-05-07T21:41:49.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20250507121535-172.20.0.5-41865: Not receiving heartbeat for 60 seconds
[2025-05-07T21:41:49.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO StandaloneSchedulerBackend: Worker worker-20250507121535-172.20.0.5-41865 removed: Not receiving heartbeat for 60 seconds
[2025-05-07T21:41:49.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250507213450-0005/2 on worker-20250507121535-172.20.0.5-41865 (172.20.0.5:41865) with 1 core(s)
[2025-05-07T21:41:49.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 ERROR TaskSchedulerImpl: Lost executor 1 on 172.20.0.5: worker lost
[2025-05-07T21:41:49.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN TaskSetManager: Lost task 0.1 in stage 399.0 (TID 846) (172.20.0.5 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: worker lost
[2025-05-07T21:41:49.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO TaskSchedulerImpl: Handle removed worker worker-20250507121535-172.20.0.5-41865: Not receiving heartbeat for 60 seconds
[2025-05-07T21:41:49.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 846 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
[2025-05-07T21:41:49.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN CoarseGrainedSchedulerBackend$DriverEndpoint: Ignored task status update (846 state FINISHED) from unknown executor with ID 1
[2025-05-07T21:41:49.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250507213450-0005/2 on hostPort 172.20.0.5:41865 with 1 core(s), 1024.0 MiB RAM
[2025-05-07T21:41:49.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO DAGScheduler: Resubmitted ShuffleMapTask(399, 1), so marking it as still running.
[2025-05-07T21:41:49.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO DAGScheduler: Executor lost: 1 (epoch 102)
[2025-05-07T21:41:49.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
[2025-05-07T21:41:49.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_5 !
[2025-05-07T21:41:49.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_7 !
[2025-05-07T21:41:49.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_5 !
[2025-05-07T21:41:49.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_7 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_3 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_8 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_4 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_9 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_7 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_0 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_3 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_4 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_6 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_4 !
[2025-05-07T21:41:49.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_1 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_0 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_0 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_8 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_4 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_6 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_3 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_2 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_6 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_5 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_3 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_4 !
[2025-05-07T21:41:49.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_7 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_9 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_4 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_3 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_9 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_6 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_4 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_1 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_1 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_5 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_2 !
[2025-05-07T21:41:49.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_6 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_3 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_9 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_3 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_8 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_5 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_6 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_2 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_6 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_2 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_0 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_2 !
[2025-05-07T21:41:49.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_8 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_8 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_5 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_0 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_3 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_1 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_3 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_7 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_7 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_1 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_6 !
[2025-05-07T21:41:49.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_1 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_1 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_6 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_2 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_5 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_7 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_2 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_4 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_0 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_4 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_4 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_9 !
[2025-05-07T21:41:49.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_0 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_7 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_0 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_9 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_229_8 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_6 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_9 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_8 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_5 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_0 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_8 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_2 !
[2025-05-07T21:41:49.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_7 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_5 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_2 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_9 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_2 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_9 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_0 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_3 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_264_3 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_0 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_6 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_9 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_8 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_394_7 !
[2025-05-07T21:41:49.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_8 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_5 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_9 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_237_1 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_4 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_231_1 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_233_2 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_5 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_226_7 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_266_8 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_404_1 !
[2025-05-07T21:41:49.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_241_1 !
[2025-05-07T21:41:49.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 172.20.0.5, 37555, None)
[2025-05-07T21:41:49.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
[2025-05-07T21:41:49.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO DAGScheduler: Shuffle files lost for host: 172.20.0.5 (epoch 102)
[2025-05-07T21:41:49.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO DAGScheduler: Shuffle files lost for worker worker-20250507121535-172.20.0.5-41865 on host 172.20.0.5
[2025-05-07T21:41:49.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:41:49 INFO BlockManagerMasterEndpoint: BlockManager (BlockManagerId(1, 172.20.0.5, 37555, None)) re-registration is rejected since the executor (1) has been lost
[2025-05-07T21:42:21.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:42:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507213450-0005/2 is now RUNNING
[2025-05-07T21:43:20.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:40082) with ID 2,  ResourceProfileId 0
[2025-05-07T21:43:21.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:36323 with 434.4 MiB RAM, BlockManagerId(2, 172.20.0.5, 36323, None)
[2025-05-07T21:43:21.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:21 INFO TaskSetManager: Starting task 0.2 in stage 399.0 (TID 847) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:21.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:21 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 172.20.0.5:36323 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T21:43:22.884+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:22 INFO TaskSetManager: Starting task 1.1 in stage 399.0 (TID 848) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:22.884+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:22 INFO TaskSetManager: Finished task 0.2 in stage 399.0 (TID 847) in 1571 ms on 172.20.0.5 (executor 2) (1/6)
[2025-05-07T21:43:22.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:22 INFO TaskSetManager: Starting task 2.0 in stage 399.0 (TID 849) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:22.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:22 INFO TaskSetManager: Finished task 1.1 in stage 399.0 (TID 848) in 96 ms on 172.20.0.5 (executor 2) (2/6)
[2025-05-07T21:43:23.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Starting task 3.0 in stage 399.0 (TID 850) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:23.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Finished task 2.0 in stage 399.0 (TID 849) in 56 ms on 172.20.0.5 (executor 2) (3/6)
[2025-05-07T21:43:23.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Starting task 4.0 in stage 399.0 (TID 851) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:23.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Finished task 3.0 in stage 399.0 (TID 850) in 53 ms on 172.20.0.5 (executor 2) (4/6)
[2025-05-07T21:43:23.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Starting task 5.0 in stage 399.0 (TID 852) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:23.140+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Finished task 4.0 in stage 399.0 (TID 851) in 52 ms on 172.20.0.5 (executor 2) (5/6)
[2025-05-07T21:43:23.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Starting task 0.0 in stage 400.0 (TID 853) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:23.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Finished task 5.0 in stage 399.0 (TID 852) in 522 ms on 172.20.0.5 (executor 2) (6/6)
[2025-05-07T21:43:23.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool
[2025-05-07T21:43:23.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: ShuffleMapStage 399 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 329.321 s
[2025-05-07T21:43:23.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:23.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: running: Set(ShuffleMapStage 404, ShuffleMapStage 401, ShuffleMapStage 405, ShuffleMapStage 406, ShuffleMapStage 402, ShuffleMapStage 403, ShuffleMapStage 400)
[2025-05-07T21:43:23.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:23.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:23.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 172.20.0.5:36323 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:43:23.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO ShufflePartitionsUtil: For shuffle(69), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:23.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO ShufflePartitionsUtil: For shuffle(69), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:23.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Starting task 0.0 in stage 401.0 (TID 854) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:23.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSetManager: Finished task 0.0 in stage 400.0 (TID 853) in 93 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:23.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSchedulerImpl: Removed TaskSet 400.0, whose tasks have all completed, from pool
[2025-05-07T21:43:23.759+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: ShuffleMapStage 400 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 305.339 s
[2025-05-07T21:43:23.759+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:23.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: running: Set(ShuffleMapStage 404, ShuffleMapStage 401, ShuffleMapStage 405, ShuffleMapStage 406, ShuffleMapStage 402, ShuffleMapStage 403)
[2025-05-07T21:43:23.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:23.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:23.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO ShufflePartitionsUtil: For shuffle(70), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:23.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-07T21:43:23.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Got job 82 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:43:23.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Final stage: ResultStage 408 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:43:23.787+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 407)
[2025-05-07T21:43:23.787+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:23.787+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Submitting ResultStage 408 (MapPartitionsRDD[621] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:43:23.788+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 7.2 KiB, free 398.3 MiB)
[2025-05-07T21:43:23.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 172.20.0.5:36323 (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:43:23.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 398.3 MiB)
[2025-05-07T21:43:23.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 432.6 MiB)
[2025-05-07T21:43:23.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:23.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 408 (MapPartitionsRDD[621] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:23.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSchedulerImpl: Adding task set 408.0 with 1 tasks resource profile 0
[2025-05-07T21:43:23.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-07T21:43:23.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Got job 83 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:43:23.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Final stage: ResultStage 410 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:43:23.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 409)
[2025-05-07T21:43:23.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:23.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Submitting ResultStage 410 (MapPartitionsRDD[624] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:43:23.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 7.2 KiB, free 398.3 MiB)
[2025-05-07T21:43:23.815+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 398.3 MiB)
[2025-05-07T21:43:23.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 432.6 MiB)
[2025-05-07T21:43:23.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:23.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 410 (MapPartitionsRDD[624] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:23.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:23 INFO TaskSchedulerImpl: Adding task set 410.0 with 1 tasks resource profile 0
[2025-05-07T21:43:24.048+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Starting task 0.0 in stage 402.0 (TID 855) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:24.048+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Finished task 0.0 in stage 401.0 (TID 854) in 294 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:24.049+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Removed TaskSet 401.0, whose tasks have all completed, from pool
[2025-05-07T21:43:24.049+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: ShuffleMapStage 401 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 305.616 s
[2025-05-07T21:43:24.049+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:24.049+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: running: Set(ShuffleMapStage 404, ResultStage 408, ShuffleMapStage 405, ShuffleMapStage 406, ResultStage 410, ShuffleMapStage 402, ShuffleMapStage 403)
[2025-05-07T21:43:24.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:24.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:24.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 172.20.0.5:36323 (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T21:43:24.157+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Starting task 0.0 in stage 403.0 (TID 856) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:24.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Finished task 0.0 in stage 402.0 (TID 855) in 110 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:24.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool
[2025-05-07T21:43:24.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: ShuffleMapStage 402 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 305.714 s
[2025-05-07T21:43:24.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:24.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: running: Set(ShuffleMapStage 404, ResultStage 408, ShuffleMapStage 405, ShuffleMapStage 406, ResultStage 410, ShuffleMapStage 403)
[2025-05-07T21:43:24.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:24.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:24.170+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 172.20.0.5:36323 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:43:24.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Starting task 0.0 in stage 404.0 (TID 857) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:24.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Finished task 0.0 in stage 403.0 (TID 856) in 88 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:24.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Removed TaskSet 403.0, whose tasks have all completed, from pool
[2025-05-07T21:43:24.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: ShuffleMapStage 403 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 305.787 s
[2025-05-07T21:43:24.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:24.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: running: Set(ShuffleMapStage 404, ResultStage 408, ShuffleMapStage 405, ShuffleMapStage 406, ResultStage 410)
[2025-05-07T21:43:24.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:24.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:24.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 172.20.0.5:36323 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T21:43:24.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Starting task 0.0 in stage 405.0 (TID 858) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Finished task 0.0 in stage 404.0 (TID 857) in 81 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Removed TaskSet 404.0, whose tasks have all completed, from pool
[2025-05-07T21:43:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: ShuffleMapStage 404 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 305.859 s
[2025-05-07T21:43:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:24.328+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: running: Set(ResultStage 408, ShuffleMapStage 405, ShuffleMapStage 406, ResultStage 410)
[2025-05-07T21:43:24.328+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:24.328+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:24.338+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 172.20.0.5:36323 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:43:24.410+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Starting task 0.0 in stage 406.0 (TID 859) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:24.411+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Finished task 0.0 in stage 405.0 (TID 858) in 84 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:24.411+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Removed TaskSet 405.0, whose tasks have all completed, from pool
[2025-05-07T21:43:24.411+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: ShuffleMapStage 405 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 305.902 s
[2025-05-07T21:43:24.411+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:24.411+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: running: Set(ResultStage 408, ShuffleMapStage 406, ResultStage 410)
[2025-05-07T21:43:24.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:24.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:24.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 432.6 MiB)
[2025-05-07T21:43:24.438+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 172.20.0.5:36323 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:43:24.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 172.20.0.5:36323 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:43:24.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 432.6 MiB)
[2025-05-07T21:43:24.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 172.20.0.5:36323 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-07T21:43:24.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-07T21:43:24.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 172.20.0.5:36323 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:43:24.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-07T21:43:24.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 172.20.0.5:36323 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:43:24.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 432.7 MiB)
[2025-05-07T21:43:24.492+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 172.20.0.5:36323 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:43:24.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 3530b0b864fd:36239 in memory (size: 11.2 KiB, free: 432.7 MiB)
[2025-05-07T21:43:24.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 172.20.0.5:36323 in memory (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T21:43:24.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 432.7 MiB)
[2025-05-07T21:43:24.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 172.20.0.5:36323 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:43:24.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Starting task 0.0 in stage 408.0 (TID 860) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:24.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Finished task 0.0 in stage 406.0 (TID 859) in 163 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:24.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Removed TaskSet 406.0, whose tasks have all completed, from pool
[2025-05-07T21:43:24.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: ShuffleMapStage 406 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 306.061 s
[2025-05-07T21:43:24.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:24.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: running: Set(ResultStage 408, ResultStage 410)
[2025-05-07T21:43:24.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:24.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:24.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO ShufflePartitionsUtil: For shuffle(71, 72, 73, 74, 75, 76), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:24.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 172.20.0.5:36323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:43:24.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:24.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:24.634+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:24.639+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:24.642+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:24.646+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:24.661+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-07T21:43:24.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Got job 84 (toPandas at /opt/airflow/spark/build_graph.py:216) with 6 output partitions
[2025-05-07T21:43:24.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Final stage: ResultStage 417 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:43:24.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 411, ShuffleMapStage 412, ShuffleMapStage 416, ShuffleMapStage 413, ShuffleMapStage 414, ShuffleMapStage 415)
[2025-05-07T21:43:24.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:24.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Submitting ResultStage 417 (MapPartitionsRDD[646] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:43:24.667+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 91.7 KiB, free 398.5 MiB)
[2025-05-07T21:43:24.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 398.4 MiB)
[2025-05-07T21:43:24.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 3530b0b864fd:36239 (size: 30.3 KiB, free: 432.7 MiB)
[2025-05-07T21:43:24.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:24.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 417 (MapPartitionsRDD[646] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:43:24.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Adding task set 417.0 with 6 tasks resource profile 0
[2025-05-07T21:43:24.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 69 to 172.20.0.5:40082
[2025-05-07T21:43:24.771+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 3530b0b864fd:36239 in memory (size: 14.9 KiB, free: 432.7 MiB)
[2025-05-07T21:43:24.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 172.20.0.5:36323 in memory (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-07T21:43:24.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Starting task 0.0 in stage 410.0 (TID 861) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:24.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Finished task 0.0 in stage 408.0 (TID 860) in 272 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:24.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Removed TaskSet 408.0, whose tasks have all completed, from pool
[2025-05-07T21:43:24.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: ResultStage 408 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 1.058 s
[2025-05-07T21:43:24.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:24.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 408: Stage finished
[2025-05-07T21:43:24.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Job 82 finished: toPandas at /opt/airflow/spark/build_graph.py:216, took 1.062281 s
[2025-05-07T21:43:24.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 172.20.0.5:36323 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:43:24.861+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 70 to 172.20.0.5:40082
[2025-05-07T21:43:24.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Starting task 0.0 in stage 417.0 (TID 862) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:24.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Finished task 0.0 in stage 410.0 (TID 861) in 24 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:24.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Removed TaskSet 410.0, whose tasks have all completed, from pool
[2025-05-07T21:43:24.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: ResultStage 410 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 1.063 s
[2025-05-07T21:43:24.869+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:24.869+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 410: Stage finished
[2025-05-07T21:43:24.869+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO DAGScheduler: Job 83 finished: toPandas at /opt/airflow/spark/build_graph.py:216, took 1.064250 s
[2025-05-07T21:43:24.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 5.0 MiB, free 393.5 MiB)
[2025-05-07T21:43:24.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 2.1 MiB, free 391.4 MiB)
[2025-05-07T21:43:24.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 391.4 MiB)
[2025-05-07T21:43:24.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 3530b0b864fd:36239 (size: 20.6 KiB, free: 432.7 MiB)
[2025-05-07T21:43:24.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO SparkContext: Created broadcast 169 from toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-07T21:43:24.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 172.20.0.5:36323 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T21:43:24.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 390.9 MiB)
[2025-05-07T21:43:24.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 3530b0b864fd:36239 (size: 502.1 KiB, free: 432.2 MiB)
[2025-05-07T21:43:24.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO SparkContext: Created broadcast 168 from toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-07T21:43:24.916+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:40082
[2025-05-07T21:43:24.956+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Starting task 1.0 in stage 417.0 (TID 863) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:24.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO TaskSetManager: Finished task 0.0 in stage 417.0 (TID 862) in 89 ms on 172.20.0.5 (executor 2) (1/6)
[2025-05-07T21:43:24.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:40082
[2025-05-07T21:43:25.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 2.0 in stage 417.0 (TID 864) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 1.0 in stage 417.0 (TID 863) in 88 ms on 172.20.0.5 (executor 2) (2/6)
[2025-05-07T21:43:25.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:40082
[2025-05-07T21:43:25.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 3.0 in stage 417.0 (TID 865) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 2.0 in stage 417.0 (TID 864) in 39 ms on 172.20.0.5 (executor 2) (3/6)
[2025-05-07T21:43:25.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:40082
[2025-05-07T21:43:25.112+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 4.0 in stage 417.0 (TID 866) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.113+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 3.0 in stage 417.0 (TID 865) in 31 ms on 172.20.0.5 (executor 2) (4/6)
[2025-05-07T21:43:25.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:40082
[2025-05-07T21:43:25.153+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 5.0 in stage 417.0 (TID 867) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.153+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 4.0 in stage 417.0 (TID 866) in 41 ms on 172.20.0.5 (executor 2) (5/6)
[2025-05-07T21:43:25.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:40082
[2025-05-07T21:43:25.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 5.0 in stage 417.0 (TID 867) in 47 ms on 172.20.0.5 (executor 2) (6/6)
[2025-05-07T21:43:25.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSchedulerImpl: Removed TaskSet 417.0, whose tasks have all completed, from pool
[2025-05-07T21:43:25.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: ResultStage 417 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.536 s
[2025-05-07T21:43:25.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:25.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 417: Stage finished
[2025-05-07T21:43:25.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: Job 84 finished: toPandas at /opt/airflow/spark/build_graph.py:216, took 0.539999 s
[2025-05-07T21:43:25.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 2.3 MiB, free 388.6 MiB)
[2025-05-07T21:43:25.209+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 388.5 MiB)
[2025-05-07T21:43:25.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 3530b0b864fd:36239 (size: 114.2 KiB, free: 432.1 MiB)
[2025-05-07T21:43:25.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO SparkContext: Created broadcast 170 from toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-07T21:43:25.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:25.273+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO CodeGenerator: Code generated in 27.680576 ms
[2025-05-07T21:43:25.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO CodeGenerator: Code generated in 6.019889 ms
[2025-05-07T21:43:25.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: Registering RDD 655 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 77
[2025-05-07T21:43:25.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: Got map stage job 85 (toPandas at /opt/airflow/spark/build_graph.py:216) with 11 output partitions
[2025-05-07T21:43:25.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: Final stage: ShuffleMapStage 419 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:43:25.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 418)
[2025-05-07T21:43:25.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:25.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: Submitting ShuffleMapStage 419 (MapPartitionsRDD[655] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:43:25.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 129.6 KiB, free 388.4 MiB)
[2025-05-07T21:43:25.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 45.0 KiB, free 388.4 MiB)
[2025-05-07T21:43:25.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 3530b0b864fd:36239 (size: 45.0 KiB, free: 432.0 MiB)
[2025-05-07T21:43:25.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:25.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 419 (MapPartitionsRDD[655] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T21:43:25.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSchedulerImpl: Adding task set 419.0 with 11 tasks resource profile 0
[2025-05-07T21:43:25.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 0.0 in stage 419.0 (TID 868) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.318+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 172.20.0.5:36323 (size: 45.0 KiB, free: 434.3 MiB)
[2025-05-07T21:43:25.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 70 to 172.20.0.5:40082
[2025-05-07T21:43:25.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 172.20.0.5:36323 (size: 502.1 KiB, free: 433.8 MiB)
[2025-05-07T21:43:25.522+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 172.20.0.5:36323 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T21:43:25.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 172.20.0.5:36323 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T21:43:25.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 1.0 in stage 419.0 (TID 869) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 0.0 in stage 419.0 (TID 868) in 452 ms on 172.20.0.5 (executor 2) (1/11)
[2025-05-07T21:43:25.811+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 2.0 in stage 419.0 (TID 870) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.812+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 1.0 in stage 419.0 (TID 869) in 52 ms on 172.20.0.5 (executor 2) (2/11)
[2025-05-07T21:43:25.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 3.0 in stage 419.0 (TID 871) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 2.0 in stage 419.0 (TID 870) in 62 ms on 172.20.0.5 (executor 2) (3/11)
[2025-05-07T21:43:25.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 4.0 in stage 419.0 (TID 872) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.922+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 3.0 in stage 419.0 (TID 871) in 52 ms on 172.20.0.5 (executor 2) (4/11)
[2025-05-07T21:43:25.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Starting task 5.0 in stage 419.0 (TID 873) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:25.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:25 INFO TaskSetManager: Finished task 4.0 in stage 419.0 (TID 872) in 51 ms on 172.20.0.5 (executor 2) (5/11)
[2025-05-07T21:43:26.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Starting task 6.0 in stage 419.0 (TID 874) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:26.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Finished task 5.0 in stage 419.0 (TID 873) in 52 ms on 172.20.0.5 (executor 2) (6/11)
[2025-05-07T21:43:26.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Starting task 7.0 in stage 419.0 (TID 875) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:26.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Finished task 6.0 in stage 419.0 (TID 874) in 50 ms on 172.20.0.5 (executor 2) (7/11)
[2025-05-07T21:43:26.113+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Starting task 8.0 in stage 419.0 (TID 876) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:26.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Finished task 7.0 in stage 419.0 (TID 875) in 42 ms on 172.20.0.5 (executor 2) (8/11)
[2025-05-07T21:43:26.156+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Starting task 9.0 in stage 419.0 (TID 877) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:26.156+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Finished task 8.0 in stage 419.0 (TID 876) in 43 ms on 172.20.0.5 (executor 2) (9/11)
[2025-05-07T21:43:26.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Starting task 10.0 in stage 419.0 (TID 878) (172.20.0.5, executor 2, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:26.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Finished task 9.0 in stage 419.0 (TID 877) in 32 ms on 172.20.0.5 (executor 2) (10/11)
[2025-05-07T21:43:26.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Finished task 10.0 in stage 419.0 (TID 878) in 353 ms on 172.20.0.5 (executor 2) (11/11)
[2025-05-07T21:43:26.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSchedulerImpl: Removed TaskSet 419.0, whose tasks have all completed, from pool
[2025-05-07T21:43:26.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: ShuffleMapStage 419 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 1.240 s
[2025-05-07T21:43:26.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:26.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: running: Set()
[2025-05-07T21:43:26.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:26.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:26.544+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO ShufflePartitionsUtil: For shuffle(77), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:26.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO CodeGenerator: Code generated in 6.865582 ms
[2025-05-07T21:43:26.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 3530b0b864fd:36239 in memory (size: 30.3 KiB, free: 432.1 MiB)
[2025-05-07T21:43:26.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 172.20.0.5:36323 in memory (size: 30.3 KiB, free: 433.7 MiB)
[2025-05-07T21:43:26.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:216
[2025-05-07T21:43:26.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 3530b0b864fd:36239 in memory (size: 45.0 KiB, free: 432.1 MiB)
[2025-05-07T21:43:26.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: Got job 86 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:43:26.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: Final stage: ResultStage 422 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:43:26.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 421)
[2025-05-07T21:43:26.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:26.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: Submitting ResultStage 422 (MapPartitionsRDD[659] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:43:26.594+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 172.20.0.5:36323 in memory (size: 45.0 KiB, free: 433.8 MiB)
[2025-05-07T21:43:26.597+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 113.5 KiB, free 388.5 MiB)
[2025-05-07T21:43:26.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 38.7 KiB, free 388.5 MiB)
[2025-05-07T21:43:26.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 3530b0b864fd:36239 (size: 38.7 KiB, free: 432.1 MiB)
[2025-05-07T21:43:26.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:26.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 422 (MapPartitionsRDD[659] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:26.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSchedulerImpl: Adding task set 422.0 with 1 tasks resource profile 0
[2025-05-07T21:43:26.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Starting task 0.0 in stage 422.0 (TID 879) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:26.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 172.20.0.5:36323 (size: 38.7 KiB, free: 433.7 MiB)
[2025-05-07T21:43:26.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:40082
[2025-05-07T21:43:26.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSetManager: Finished task 0.0 in stage 422.0 (TID 879) in 129 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:26.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSchedulerImpl: Removed TaskSet 422.0, whose tasks have all completed, from pool
[2025-05-07T21:43:26.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: ResultStage 422 (toPandas at /opt/airflow/spark/build_graph.py:216) finished in 0.135 s
[2025-05-07T21:43:26.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:26.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 422: Stage finished
[2025-05-07T21:43:26.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO DAGScheduler: Job 86 finished: toPandas at /opt/airflow/spark/build_graph.py:216, took 0.138241 s
[2025-05-07T21:43:26.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 3530b0b864fd:36239 in memory (size: 38.7 KiB, free: 432.1 MiB)
[2025-05-07T21:43:26.754+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:26 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 172.20.0.5:36323 in memory (size: 38.7 KiB, free: 433.8 MiB)
[2025-05-07T21:43:26.988+0000] {spark_submit.py:571} INFO - 2025-05-07 21:43:26,988 [INFO] Граф сохранен в /reports/client_graph.graphml
[2025-05-07T21:43:26.988+0000] {spark_submit.py:571} INFO - 2025-05-07 21:43:26,988 [INFO] Сохраняем результаты в graph.client_communities
[2025-05-07T21:43:27.319+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 172.20.0.5:36323 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T21:43:27.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 432.1 MiB)
[2025-05-07T21:43:27.324+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 432.1 MiB)
[2025-05-07T21:43:27.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 172.20.0.5:36323 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T21:43:27.558+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#2570 - id.nullCount#2569) > 0)
[2025-05-07T21:43:27.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 691 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 78
[2025-05-07T21:43:27.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 87 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-07T21:43:27.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 426 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 425, ShuffleMapStage 424)
[2025-05-07T21:43:27.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 425, ShuffleMapStage 424)
[2025-05-07T21:43:27.567+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 423 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:43:27.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 12.6 KiB, free 388.7 MiB)
[2025-05-07T21:43:27.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 388.7 MiB)
[2025-05-07T21:43:27.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 432.1 MiB)
[2025-05-07T21:43:27.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.577+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:27.577+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 423 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:27.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 423.0 with 1 tasks resource profile 0
[2025-05-07T21:43:27.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSetManager: Starting task 0.0 in stage 423.0 (TID 880) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:27.581+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got job 88 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 10 output partitions
[2025-05-07T21:43:27.581+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ResultStage 427 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:43:27.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 423)
[2025-05-07T21:43:27.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 423)
[2025-05-07T21:43:27.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 694 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 79
[2025-05-07T21:43:27.589+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 89 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-07T21:43:27.589+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 450 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.589+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 425, ShuffleMapStage 437, ShuffleMapStage 441, ShuffleMapStage 445, ShuffleMapStage 424, ShuffleMapStage 449, ShuffleMapStage 428, ShuffleMapStage 443, ShuffleMapStage 431, ShuffleMapStage 435, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 433)
[2025-05-07T21:43:27.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 425, ShuffleMapStage 437, ShuffleMapStage 441, ShuffleMapStage 445, ShuffleMapStage 424, ShuffleMapStage 449, ShuffleMapStage 431, ShuffleMapStage 443, ShuffleMapStage 428, ShuffleMapStage 435, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 433)
[2025-05-07T21:43:27.597+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 172.20.0.5:36323 (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-07T21:43:27.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 702 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 80
[2025-05-07T21:43:27.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 90 (jdbc at NativeMethodAccessorImpl.java:0) with 6 output partitions
[2025-05-07T21:43:27.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 451 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:27.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:27.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 451 (MapPartitionsRDD[702] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:27.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 36.4 KiB, free 388.6 MiB)
[2025-05-07T21:43:27.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 388.6 MiB)
[2025-05-07T21:43:27.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 3530b0b864fd:36239 (size: 11.2 KiB, free: 432.1 MiB)
[2025-05-07T21:43:27.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 451 (MapPartitionsRDD[702] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:43:27.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 451.0 with 6 tasks resource profile 0
[2025-05-07T21:43:27.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 704 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 81
[2025-05-07T21:43:27.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 91 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:27.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 452 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:27.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:27.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:27.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 452 (MapPartitionsRDD[704] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:27.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 12.7 KiB, free 388.6 MiB)
[2025-05-07T21:43:27.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 388.6 MiB)
[2025-05-07T21:43:27.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 432.1 MiB)
[2025-05-07T21:43:27.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 452 (MapPartitionsRDD[704] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:27.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 452.0 with 1 tasks resource profile 0
[2025-05-07T21:43:27.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:27.631+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 706 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 82
[2025-05-07T21:43:27.631+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 92 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:27.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 453 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:27.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:27.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 453 (MapPartitionsRDD[706] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:27.635+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 27.3 KiB, free 388.6 MiB)
[2025-05-07T21:43:27.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 388.6 MiB)
[2025-05-07T21:43:27.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 432.1 MiB)
[2025-05-07T21:43:27.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 453 (MapPartitionsRDD[706] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:27.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 453.0 with 1 tasks resource profile 0
[2025-05-07T21:43:27.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:27.642+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 708 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 83
[2025-05-07T21:43:27.642+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 93 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:27.642+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 454 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.643+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:27.643+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:27.643+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 454 (MapPartitionsRDD[708] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:27.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 28.5 KiB, free 388.5 MiB)
[2025-05-07T21:43:27.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 388.5 MiB)
[2025-05-07T21:43:27.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 3530b0b864fd:36239 (size: 13.5 KiB, free: 432.1 MiB)
[2025-05-07T21:43:27.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 454 (MapPartitionsRDD[708] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:27.648+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 454.0 with 1 tasks resource profile 0
[2025-05-07T21:43:27.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:27.669+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSetManager: Starting task 0.0 in stage 451.0 (TID 881) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:27.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSetManager: Finished task 0.0 in stage 423.0 (TID 880) in 92 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:27.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Removed TaskSet 423.0, whose tasks have all completed, from pool
[2025-05-07T21:43:27.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 710 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 84
[2025-05-07T21:43:27.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 94 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:27.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 455 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:27.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:27.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 455 (MapPartitionsRDD[710] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:27.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:27.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 28.5 KiB, free 388.5 MiB)
[2025-05-07T21:43:27.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 388.5 MiB)
[2025-05-07T21:43:27.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 432.0 MiB)
[2025-05-07T21:43:27.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 455 (MapPartitionsRDD[710] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:27.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 455.0 with 1 tasks resource profile 0
[2025-05-07T21:43:27.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: ShuffleMapStage 423 (rdd at GraphFrame.scala:187) finished in 0.113 s
[2025-05-07T21:43:27.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:27.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: running: Set(ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 453, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:27.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 430, ShuffleMapStage 431, ShuffleMapStage 432, ShuffleMapStage 433, ShuffleMapStage 425, ShuffleMapStage 426, ShuffleMapStage 448, ResultStage 427, ShuffleMapStage 449, ShuffleMapStage 428, ShuffleMapStage 450, ShuffleMapStage 429, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 424, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:27.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:27.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 424 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[223] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-07T21:43:27.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:27.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 172.20.0.5:36323 (size: 11.2 KiB, free: 433.8 MiB)
[2025-05-07T21:43:27.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 158.2 KiB, free 388.3 MiB)
[2025-05-07T21:43:27.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 55.6 KiB, free 388.3 MiB)
[2025-05-07T21:43:27.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 3530b0b864fd:36239 (size: 55.6 KiB, free: 432.0 MiB)
[2025-05-07T21:43:27.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.706+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 424 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[223] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:27.707+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 424.0 with 10 tasks resource profile 0
[2025-05-07T21:43:27.708+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 425 (MapPartitionsRDD[31] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:43:27.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 59.1 KiB, free 388.2 MiB)
[2025-05-07T21:43:27.712+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 388.2 MiB)
[2025-05-07T21:43:27.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 3530b0b864fd:36239 (size: 26.0 KiB, free: 432.0 MiB)
[2025-05-07T21:43:27.719+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.721+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 425 (MapPartitionsRDD[31] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:27.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 425.0 with 10 tasks resource profile 0
[2025-05-07T21:43:27.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ResultStage 427 (MapPartitionsRDD[689] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:43:27.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 43.9 KiB, free 388.1 MiB)
[2025-05-07T21:43:27.731+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 388.1 MiB)
[2025-05-07T21:43:27.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 3530b0b864fd:36239 (size: 19.5 KiB, free: 432.0 MiB)
[2025-05-07T21:43:27.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 427 (MapPartitionsRDD[689] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:27.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 427.0 with 10 tasks resource profile 0
[2025-05-07T21:43:27.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 428 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[260] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:27.739+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 161.1 KiB, free 388.0 MiB)
[2025-05-07T21:43:27.741+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 56.8 KiB, free 387.9 MiB)
[2025-05-07T21:43:27.742+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 3530b0b864fd:36239 (size: 56.8 KiB, free: 431.9 MiB)
[2025-05-07T21:43:27.743+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.743+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 428 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[260] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:27.744+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 428.0 with 10 tasks resource profile 0
[2025-05-07T21:43:27.744+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 712 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 85
[2025-05-07T21:43:27.745+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 95 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:27.745+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 456 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:27.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:27.747+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 456 (MapPartitionsRDD[712] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:27.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 27.4 KiB, free 387.9 MiB)
[2025-05-07T21:43:27.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 387.9 MiB)
[2025-05-07T21:43:27.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 3530b0b864fd:36239 (size: 13.0 KiB, free: 431.9 MiB)
[2025-05-07T21:43:27.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 456 (MapPartitionsRDD[712] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:27.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 456.0 with 1 tasks resource profile 0
[2025-05-07T21:43:27.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 714 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 86
[2025-05-07T21:43:27.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 96 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:27.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 457 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:27.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:27.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 457 (MapPartitionsRDD[714] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:27.754+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 28.5 KiB, free 387.8 MiB)
[2025-05-07T21:43:27.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 387.8 MiB)
[2025-05-07T21:43:27.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 3530b0b864fd:36239 (size: 13.4 KiB, free: 431.9 MiB)
[2025-05-07T21:43:27.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 457 (MapPartitionsRDD[714] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:27.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 457.0 with 1 tasks resource profile 0
[2025-05-07T21:43:27.759+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Registering RDD 716 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 87
[2025-05-07T21:43:27.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Got map stage job 97 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:27.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Final stage: ShuffleMapStage 458 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:27.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:27.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:27.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting ShuffleMapStage 458 (MapPartitionsRDD[716] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:27.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 31.7 KiB, free 387.8 MiB)
[2025-05-07T21:43:27.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSetManager: Starting task 0.0 in stage 424.0 (TID 882) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:27.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSetManager: Finished task 0.0 in stage 451.0 (TID 881) in 95 ms on 172.20.0.5 (executor 2) (1/6)
[2025-05-07T21:43:27.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 387.8 MiB)
[2025-05-07T21:43:27.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 3530b0b864fd:36239 (size: 14.9 KiB, free: 431.9 MiB)
[2025-05-07T21:43:27.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:27.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 458 (MapPartitionsRDD[716] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:27.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO TaskSchedulerImpl: Adding task set 458.0 with 1 tasks resource profile 0
[2025-05-07T21:43:27.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 172.20.0.5:36323 (size: 55.6 KiB, free: 433.7 MiB)
[2025-05-07T21:43:27.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:40082
[2025-05-07T21:43:28.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:28 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.20.0.5:36323 (size: 2.0 KiB, free: 433.7 MiB)
[2025-05-07T21:43:28.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:28 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:36323 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T21:43:28.117+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:28 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.20.0.5:36323 (size: 98.0 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 1.0 in stage 424.0 (TID 883) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 0.0 in stage 424.0 (TID 882) in 1577 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:29.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.20.0.5:36323 (size: 2.5 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 2.0 in stage 424.0 (TID 884) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 1.0 in stage 424.0 (TID 883) in 78 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:29.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 3.0 in stage 424.0 (TID 885) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 2.0 in stage 424.0 (TID 884) in 63 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:29.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 431.9 MiB)
[2025-05-07T21:43:29.489+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 172.20.0.5:36323 in memory (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.20.0.5:36323 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.517+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 4.0 in stage 424.0 (TID 886) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 3.0 in stage 424.0 (TID 885) in 58 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:29.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.20.0.5:36323 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 5.0 in stage 424.0 (TID 887) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 4.0 in stage 424.0 (TID 886) in 49 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:29.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.20.0.5:36323 (size: 2.0 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 6.0 in stage 424.0 (TID 888) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 5.0 in stage 424.0 (TID 887) in 62 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:29.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.20.0.5:36323 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 7.0 in stage 424.0 (TID 889) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 6.0 in stage 424.0 (TID 888) in 40 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:29.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.20.0.5:36323 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 8.0 in stage 424.0 (TID 890) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 7.0 in stage 424.0 (TID 889) in 29 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:29.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.20.0.5:36323 (size: 2.4 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.742+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 9.0 in stage 424.0 (TID 891) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.742+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 8.0 in stage 424.0 (TID 890) in 48 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:29.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.20.0.5:36323 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T21:43:29.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 0.0 in stage 425.0 (TID 892) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 9.0 in stage 424.0 (TID 891) in 39 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:29.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSchedulerImpl: Removed TaskSet 424.0, whose tasks have all completed, from pool
[2025-05-07T21:43:29.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO DAGScheduler: ShuffleMapStage 424 (mapPartitions at VertexRDD.scala:356) finished in 2.096 s
[2025-05-07T21:43:29.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:29.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO DAGScheduler: running: Set(ShuffleMapStage 425, ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 427, ShuffleMapStage 428, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:29.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 430, ShuffleMapStage 431, ShuffleMapStage 432, ShuffleMapStage 433, ShuffleMapStage 426, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 429, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:29.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:29.788+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 172.20.0.5:36323 (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T21:43:29.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.5:36323 (size: 28.8 KiB, free: 433.5 MiB)
[2025-05-07T21:43:29.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 1.0 in stage 425.0 (TID 893) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 0.0 in stage 425.0 (TID 892) in 57 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:29.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 2.0 in stage 425.0 (TID 894) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 1.0 in stage 425.0 (TID 893) in 19 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:29.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 3.0 in stage 425.0 (TID 895) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 2.0 in stage 425.0 (TID 894) in 21 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:29.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 4.0 in stage 425.0 (TID 896) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 3.0 in stage 425.0 (TID 895) in 31 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:29.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 5.0 in stage 425.0 (TID 897) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 4.0 in stage 425.0 (TID 896) in 18 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:29.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 6.0 in stage 425.0 (TID 898) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 5.0 in stage 425.0 (TID 897) in 20 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:29.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 7.0 in stage 425.0 (TID 899) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 6.0 in stage 425.0 (TID 898) in 15 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:29.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 8.0 in stage 425.0 (TID 900) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 7.0 in stage 425.0 (TID 899) in 15 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:29.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Starting task 9.0 in stage 425.0 (TID 901) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:29.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:29 INFO TaskSetManager: Finished task 8.0 in stage 425.0 (TID 900) in 24 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:30.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 0.0 in stage 427.0 (TID 902) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 9.0 in stage 425.0 (TID 901) in 31 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:30.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSchedulerImpl: Removed TaskSet 425.0, whose tasks have all completed, from pool
[2025-05-07T21:43:30.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: ShuffleMapStage 425 (map at GraphFrame.scala:187) finished in 2.320 s
[2025-05-07T21:43:30.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:30.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 427, ShuffleMapStage 428, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:30.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 430, ShuffleMapStage 431, ShuffleMapStage 432, ShuffleMapStage 433, ShuffleMapStage 426, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 429, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:30.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:30.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Submitting ShuffleMapStage 426 (MapPartitionsRDD[691] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:30.031+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 23.3 KiB, free 387.8 MiB)
[2025-05-07T21:43:30.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 387.8 MiB)
[2025-05-07T21:43:30.033+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 3530b0b864fd:36239 (size: 9.9 KiB, free: 431.9 MiB)
[2025-05-07T21:43:30.033+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:30.034+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 426 (MapPartitionsRDD[691] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:30.034+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSchedulerImpl: Adding task set 426.0 with 10 tasks resource profile 0
[2025-05-07T21:43:30.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 172.20.0.5:36323 (size: 19.5 KiB, free: 433.5 MiB)
[2025-05-07T21:43:30.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 0.0 in stage 426.0 (TID 903) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 0.0 in stage 427.0 (TID 902) in 30 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:30.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 172.20.0.5:36323 (size: 9.9 KiB, free: 433.5 MiB)
[2025-05-07T21:43:30.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.20.0.5:40082
[2025-05-07T21:43:30.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.20.0.5:40082
[2025-05-07T21:43:30.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_0 in memory on 172.20.0.5:36323 (size: 18.6 KiB, free: 433.5 MiB)
[2025-05-07T21:43:30.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_0 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.5 MiB)
[2025-05-07T21:43:30.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_0 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T21:43:30.374+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_0 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T21:43:30.432+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 1.0 in stage 426.0 (TID 904) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 0.0 in stage 426.0 (TID 903) in 377 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:30.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_1 in memory on 172.20.0.5:36323 (size: 18.6 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_1 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.486+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_1 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.488+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_1 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 2.0 in stage 426.0 (TID 905) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 1.0 in stage 426.0 (TID 904) in 66 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:30.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_2 in memory on 172.20.0.5:36323 (size: 18.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_2 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.529+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_2 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_2 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 3.0 in stage 426.0 (TID 906) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 2.0 in stage 426.0 (TID 905) in 47 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:30.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_3 in memory on 172.20.0.5:36323 (size: 18.2 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_3 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_3 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.571+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_3 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:43:30.578+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 4.0 in stage 426.0 (TID 907) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.578+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 3.0 in stage 426.0 (TID 906) in 34 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:30.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_4 in memory on 172.20.0.5:36323 (size: 18.8 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_4 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_4 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_4 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 5.0 in stage 426.0 (TID 908) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 4.0 in stage 426.0 (TID 907) in 39 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:30.644+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_5 in memory on 172.20.0.5:36323 (size: 18.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.646+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_5 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.649+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_5 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_5 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 6.0 in stage 426.0 (TID 909) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 5.0 in stage 426.0 (TID 908) in 47 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:30.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_6 in memory on 172.20.0.5:36323 (size: 18.4 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_6 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.707+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_6 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_6 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:43:30.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 7.0 in stage 426.0 (TID 910) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 6.0 in stage 426.0 (TID 909) in 54 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:30.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_7 in memory on 172.20.0.5:36323 (size: 18.4 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_7 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.738+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_7 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_7 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 8.0 in stage 426.0 (TID 911) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 7.0 in stage 426.0 (TID 910) in 34 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:30.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_8 in memory on 172.20.0.5:36323 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.769+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_8 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.771+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_8 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_8 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 9.0 in stage 426.0 (TID 912) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 8.0 in stage 426.0 (TID 911) in 31 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:30.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_226_9 in memory on 172.20.0.5:36323 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_231_9 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.800+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_237_9 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.802+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added rdd_241_9 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 1.0 in stage 427.0 (TID 913) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 9.0 in stage 426.0 (TID 912) in 30 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:30.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSchedulerImpl: Removed TaskSet 426.0, whose tasks have all completed, from pool
[2025-05-07T21:43:30.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: ShuffleMapStage 426 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.780 s
[2025-05-07T21:43:30.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:30.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 427, ShuffleMapStage 428, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:30.810+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 430, ShuffleMapStage 431, ShuffleMapStage 432, ShuffleMapStage 433, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 429, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:30.810+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:30.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 2.0 in stage 427.0 (TID 914) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 1.0 in stage 427.0 (TID 913) in 10 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:30.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 3.0 in stage 427.0 (TID 915) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.829+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 2.0 in stage 427.0 (TID 914) in 11 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:30.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO ShufflePartitionsUtil: For shuffle(78), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:30.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO ShufflePartitionsUtil: For shuffle(78), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:30.843+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 4.0 in stage 427.0 (TID 916) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 3.0 in stage 427.0 (TID 915) in 16 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:30.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:30.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Got job 98 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:43:30.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Final stage: ResultStage 460 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:43:30.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 459)
[2025-05-07T21:43:30.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:30.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 5.0 in stage 427.0 (TID 917) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 4.0 in stage 427.0 (TID 916) in 15 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:30.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Submitting ResultStage 460 (MapPartitionsRDD[722] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:43:30.861+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 7.2 KiB, free 387.8 MiB)
[2025-05-07T21:43:30.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 387.8 MiB)
[2025-05-07T21:43:30.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 6.0 in stage 427.0 (TID 918) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.880+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 5.0 in stage 427.0 (TID 917) in 21 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:30.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 431.8 MiB)
[2025-05-07T21:43:30.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:30.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 460 (MapPartitionsRDD[722] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:30.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSchedulerImpl: Adding task set 460.0 with 1 tasks resource profile 0
[2025-05-07T21:43:30.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 3530b0b864fd:36239 in memory (size: 9.9 KiB, free: 431.9 MiB)
[2025-05-07T21:43:30.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 172.20.0.5:36323 in memory (size: 9.9 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 7.0 in stage 427.0 (TID 919) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 6.0 in stage 427.0 (TID 918) in 30 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:30.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 8.0 in stage 427.0 (TID 920) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 7.0 in stage 427.0 (TID 919) in 14 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:30.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 9.0 in stage 427.0 (TID 921) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.931+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 8.0 in stage 427.0 (TID 920) in 12 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:30.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Starting task 0.0 in stage 428.0 (TID 922) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:30.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSetManager: Finished task 9.0 in stage 427.0 (TID 921) in 14 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:30.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSchedulerImpl: Removed TaskSet 427.0, whose tasks have all completed, from pool
[2025-05-07T21:43:30.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: ResultStage 427 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 3.220 s
[2025-05-07T21:43:30.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:30.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 427: Stage finished
[2025-05-07T21:43:30.947+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Job 88 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 3.369352 s
[2025-05-07T21:43:30.962+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 3530b0b864fd:36239 in memory (size: 55.6 KiB, free: 431.9 MiB)
[2025-05-07T21:43:30.967+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 2.1 MiB, free 385.9 MiB)
[2025-05-07T21:43:30.968+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 172.20.0.5:36323 in memory (size: 55.6 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 385.9 MiB)
[2025-05-07T21:43:30.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 3530b0b864fd:36239 (size: 27.5 KiB, free: 431.9 MiB)
[2025-05-07T21:43:30.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO SparkContext: Created broadcast 188 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:30.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 172.20.0.5:36323 (size: 56.8 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 3530b0b864fd:36239 in memory (size: 26.0 KiB, free: 431.9 MiB)
[2025-05-07T21:43:30.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 172.20.0.5:36323 in memory (size: 26.0 KiB, free: 433.2 MiB)
[2025-05-07T21:43:30.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Registering RDD 732 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 88
[2025-05-07T21:43:30.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Got map stage job 99 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:30.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Final stage: ShuffleMapStage 461 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:30.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:30.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:30.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO DAGScheduler: Submitting ShuffleMapStage 461 (MapPartitionsRDD[732] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:30.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 16.6 KiB, free 386.0 MiB)
[2025-05-07T21:43:30.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 386.0 MiB)
[2025-05-07T21:43:31.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:30 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 3530b0b864fd:36239 (size: 8.3 KiB, free: 431.9 MiB)
[2025-05-07T21:43:31.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO SparkContext: Created broadcast 189 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:31.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 461 (MapPartitionsRDD[732] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:31.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSchedulerImpl: Adding task set 461.0 with 1 tasks resource profile 0
[2025-05-07T21:43:31.016+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_0 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_0 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 1.0 in stage 428.0 (TID 923) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 0.0 in stage 428.0 (TID 922) in 81 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:31.047+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_1 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.049+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_1 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 2.0 in stage 428.0 (TID 924) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 1.0 in stage 428.0 (TID 923) in 30 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:31.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_2 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_2 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 3.0 in stage 428.0 (TID 925) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 2.0 in stage 428.0 (TID 924) in 24 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:31.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_3 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.103+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_3 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 4.0 in stage 428.0 (TID 926) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 3.0 in stage 428.0 (TID 925) in 32 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:31.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_4 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_4 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.138+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 5.0 in stage 428.0 (TID 927) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.139+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 4.0 in stage 428.0 (TID 926) in 32 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:31.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_5 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_5 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.168+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 6.0 in stage 428.0 (TID 928) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.168+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 5.0 in stage 428.0 (TID 927) in 30 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:31.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_6 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_6 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 7.0 in stage 428.0 (TID 929) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 6.0 in stage 428.0 (TID 928) in 33 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:31.236+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_7 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_7 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 8.0 in stage 428.0 (TID 930) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 7.0 in stage 428.0 (TID 929) in 43 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:31.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_8 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.265+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_8 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.268+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 9.0 in stage 428.0 (TID 931) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.269+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 8.0 in stage 428.0 (TID 930) in 26 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:31.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_229_9 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_233_9 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.2 MiB)
[2025-05-07T21:43:31.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 1.0 in stage 451.0 (TID 932) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 9.0 in stage 428.0 (TID 931) in 24 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:31.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSchedulerImpl: Removed TaskSet 428.0, whose tasks have all completed, from pool
[2025-05-07T21:43:31.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: ShuffleMapStage 428 (mapPartitions at GraphImpl.scala:208) finished in 3.558 s
[2025-05-07T21:43:31.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:31.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 460, ShuffleMapStage 461, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:31.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 430, ShuffleMapStage 431, ShuffleMapStage 432, ShuffleMapStage 433, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 429, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:31.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:31.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: Submitting ShuffleMapStage 430 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[268] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:31.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 10.1 KiB, free 386.0 MiB)
[2025-05-07T21:43:31.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 385.9 MiB)
[2025-05-07T21:43:31.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 3530b0b864fd:36239 (size: 5.0 KiB, free: 431.9 MiB)
[2025-05-07T21:43:31.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:31.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 430 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[268] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:31.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSchedulerImpl: Adding task set 430.0 with 10 tasks resource profile 0
[2025-05-07T21:43:31.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: Submitting ShuffleMapStage 429 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[278] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:31.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 10.7 KiB, free 385.9 MiB)
[2025-05-07T21:43:31.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 385.9 MiB)
[2025-05-07T21:43:31.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 3530b0b864fd:36239 (size: 5.3 KiB, free: 431.9 MiB)
[2025-05-07T21:43:31.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:31.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 429 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[278] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:31.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSchedulerImpl: Adding task set 429.0 with 10 tasks resource profile 0
[2025-05-07T21:43:31.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 0.0 in stage 429.0 (TID 933) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 1.0 in stage 451.0 (TID 932) in 47 ms on 172.20.0.5 (executor 2) (2/6)
[2025-05-07T21:43:31.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 172.20.0.5:36323 (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.377+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.20.0.5:40082
[2025-05-07T21:43:31.387+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_0 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 1.0 in stage 429.0 (TID 934) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 0.0 in stage 429.0 (TID 933) in 65 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:31.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_1 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 2.0 in stage 429.0 (TID 935) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 1.0 in stage 429.0 (TID 934) in 20 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:31.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_2 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 3.0 in stage 429.0 (TID 936) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 2.0 in stage 429.0 (TID 935) in 20 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:31.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_3 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 4.0 in stage 429.0 (TID 937) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 3.0 in stage 429.0 (TID 936) in 17 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:31.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_4 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 5.0 in stage 429.0 (TID 938) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 4.0 in stage 429.0 (TID 937) in 17 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:31.490+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_5 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 6.0 in stage 429.0 (TID 939) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 5.0 in stage 429.0 (TID 938) in 23 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:31.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_6 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.517+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 7.0 in stage 429.0 (TID 940) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.517+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 6.0 in stage 429.0 (TID 939) in 19 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:31.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_7 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.531+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 8.0 in stage 429.0 (TID 941) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.531+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 7.0 in stage 429.0 (TID 940) in 15 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:31.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_8 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.544+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 9.0 in stage 429.0 (TID 942) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 8.0 in stage 429.0 (TID 941) in 14 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:31.554+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_264_9 in memory on 172.20.0.5:36323 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.559+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 0.0 in stage 430.0 (TID 943) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 9.0 in stage 429.0 (TID 942) in 15 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:31.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSchedulerImpl: Removed TaskSet 429.0, whose tasks have all completed, from pool
[2025-05-07T21:43:31.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: ShuffleMapStage 429 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.261 s
[2025-05-07T21:43:31.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:31.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ShuffleMapStage 430, ResultStage 460, ShuffleMapStage 461, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:31.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 431, ShuffleMapStage 432, ShuffleMapStage 433, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:31.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:31.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 172.20.0.5:36323 (size: 5.0 KiB, free: 433.1 MiB)
[2025-05-07T21:43:31.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 1.0 in stage 430.0 (TID 944) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 0.0 in stage 430.0 (TID 943) in 17 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:31.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 2.0 in stage 430.0 (TID 945) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 1.0 in stage 430.0 (TID 944) in 11 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:31.596+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 3.0 in stage 430.0 (TID 946) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.597+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 2.0 in stage 430.0 (TID 945) in 11 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:31.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 4.0 in stage 430.0 (TID 947) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 3.0 in stage 430.0 (TID 946) in 12 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:31.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 5.0 in stage 430.0 (TID 948) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.620+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 4.0 in stage 430.0 (TID 947) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:31.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 6.0 in stage 430.0 (TID 949) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 5.0 in stage 430.0 (TID 948) in 11 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:31.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 7.0 in stage 430.0 (TID 950) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.641+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 6.0 in stage 430.0 (TID 949) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:31.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 8.0 in stage 430.0 (TID 951) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 7.0 in stage 430.0 (TID 950) in 11 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:31.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 9.0 in stage 430.0 (TID 952) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 8.0 in stage 430.0 (TID 951) in 35 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:31.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 2.0 in stage 451.0 (TID 953) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.697+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 9.0 in stage 430.0 (TID 952) in 13 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:31.697+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSchedulerImpl: Removed TaskSet 430.0, whose tasks have all completed, from pool
[2025-05-07T21:43:31.697+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: ShuffleMapStage 430 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.403 s
[2025-05-07T21:43:31.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:31.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 460, ShuffleMapStage 461, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:31.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 431, ShuffleMapStage 432, ShuffleMapStage 433, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:31.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:31.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: Submitting ShuffleMapStage 431 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[282] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:31.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 163.7 KiB, free 385.8 MiB)
[2025-05-07T21:43:31.713+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 385.7 MiB)
[2025-05-07T21:43:31.714+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 3530b0b864fd:36239 (size: 58.0 KiB, free: 431.8 MiB)
[2025-05-07T21:43:31.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:31.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 431 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[282] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:31.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSchedulerImpl: Adding task set 431.0 with 10 tasks resource profile 0
[2025-05-07T21:43:31.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 0.0 in stage 431.0 (TID 954) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.769+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 2.0 in stage 451.0 (TID 953) in 72 ms on 172.20.0.5 (executor 2) (3/6)
[2025-05-07T21:43:31.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 172.20.0.5:36323 (size: 58.0 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_0 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:31.807+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:31.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 1.0 in stage 431.0 (TID 955) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.815+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 0.0 in stage 431.0 (TID 954) in 47 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:31.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_1 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 2.0 in stage 431.0 (TID 956) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 1.0 in stage 431.0 (TID 955) in 24 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:31.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_2 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 3.0 in stage 431.0 (TID 957) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.861+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 2.0 in stage 431.0 (TID 956) in 23 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:31.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_3 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 4.0 in stage 431.0 (TID 958) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 3.0 in stage 431.0 (TID 957) in 25 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:31.900+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_4 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 5.0 in stage 431.0 (TID 959) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 4.0 in stage 431.0 (TID 958) in 22 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:31.917+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_5 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 6.0 in stage 431.0 (TID 960) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 5.0 in stage 431.0 (TID 959) in 17 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:31.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_6 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 7.0 in stage 431.0 (TID 961) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 6.0 in stage 431.0 (TID 960) in 20 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:31.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_7 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.963+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 8.0 in stage 431.0 (TID 962) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.963+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 7.0 in stage 431.0 (TID 961) in 20 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:31.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_8 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 9.0 in stage 431.0 (TID 963) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 8.0 in stage 431.0 (TID 962) in 17 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:31.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added rdd_266_9 in memory on 172.20.0.5:36323 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:31.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Starting task 3.0 in stage 451.0 (TID 964) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:31.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSetManager: Finished task 9.0 in stage 431.0 (TID 963) in 16 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:31.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSchedulerImpl: Removed TaskSet 431.0, whose tasks have all completed, from pool
[2025-05-07T21:43:31.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: ShuffleMapStage 431 (mapPartitions at GraphImpl.scala:208) finished in 0.296 s
[2025-05-07T21:43:31.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:31.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 460, ShuffleMapStage 461, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:31.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 432, ShuffleMapStage 433, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:31.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:31.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: Submitting ShuffleMapStage 432 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[290] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:31.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 12.0 KiB, free 385.7 MiB)
[2025-05-07T21:43:31.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 385.7 MiB)
[2025-05-07T21:43:31.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 3530b0b864fd:36239 (size: 5.7 KiB, free: 431.8 MiB)
[2025-05-07T21:43:31.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:31.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 432 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[290] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:31.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:31 INFO TaskSchedulerImpl: Adding task set 432.0 with 10 tasks resource profile 0
[2025-05-07T21:43:32.029+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 0.0 in stage 432.0 (TID 965) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.029+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 3.0 in stage 451.0 (TID 964) in 34 ms on 172.20.0.5 (executor 2) (4/6)
[2025-05-07T21:43:32.037+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 172.20.0.5:36323 (size: 5.7 KiB, free: 433.0 MiB)
[2025-05-07T21:43:32.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:32.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 1.0 in stage 432.0 (TID 966) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 0.0 in stage 432.0 (TID 965) in 29 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:32.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 2.0 in stage 432.0 (TID 967) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 1.0 in stage 432.0 (TID 966) in 15 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:32.083+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 3.0 in stage 432.0 (TID 968) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 2.0 in stage 432.0 (TID 967) in 12 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:32.094+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 4.0 in stage 432.0 (TID 969) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.095+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 3.0 in stage 432.0 (TID 968) in 11 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:32.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 5.0 in stage 432.0 (TID 970) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 4.0 in stage 432.0 (TID 969) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:32.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 6.0 in stage 432.0 (TID 971) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 5.0 in stage 432.0 (TID 970) in 12 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:32.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 7.0 in stage 432.0 (TID 972) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 6.0 in stage 432.0 (TID 971) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:32.136+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 8.0 in stage 432.0 (TID 973) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.137+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 7.0 in stage 432.0 (TID 972) in 10 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:32.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 9.0 in stage 432.0 (TID 974) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 8.0 in stage 432.0 (TID 973) in 11 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:32.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 4.0 in stage 451.0 (TID 975) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 9.0 in stage 432.0 (TID 974) in 17 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:32.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Removed TaskSet 432.0, whose tasks have all completed, from pool
[2025-05-07T21:43:32.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: ShuffleMapStage 432 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.167 s
[2025-05-07T21:43:32.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:32.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 460, ShuffleMapStage 461, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:32.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 433, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:32.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:32.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 433 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[294] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:32.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 164.0 KiB, free 385.5 MiB)
[2025-05-07T21:43:32.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 385.5 MiB)
[2025-05-07T21:43:32.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 431.8 MiB)
[2025-05-07T21:43:32.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:32.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 433 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[294] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:32.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Adding task set 433.0 with 10 tasks resource profile 0
[2025-05-07T21:43:32.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 0.0 in stage 433.0 (TID 976) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.219+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 4.0 in stage 451.0 (TID 975) in 56 ms on 172.20.0.5 (executor 2) (5/6)
[2025-05-07T21:43:32.224+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 172.20.0.5:36323 (size: 58.1 KiB, free: 433.0 MiB)
[2025-05-07T21:43:32.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:32.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:32.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:40082
[2025-05-07T21:43:32.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 1.0 in stage 433.0 (TID 977) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 0.0 in stage 433.0 (TID 976) in 26 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:32.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 2.0 in stage 433.0 (TID 978) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 1.0 in stage 433.0 (TID 977) in 15 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:32.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 3.0 in stage 433.0 (TID 979) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 2.0 in stage 433.0 (TID 978) in 16 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:32.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 4.0 in stage 433.0 (TID 980) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 3.0 in stage 433.0 (TID 979) in 16 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:32.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 5.0 in stage 433.0 (TID 981) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 4.0 in stage 433.0 (TID 980) in 15 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:32.318+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 6.0 in stage 433.0 (TID 982) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.318+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 5.0 in stage 433.0 (TID 981) in 15 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:32.334+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 7.0 in stage 433.0 (TID 983) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 6.0 in stage 433.0 (TID 982) in 17 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:32.350+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 8.0 in stage 433.0 (TID 984) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.350+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 7.0 in stage 433.0 (TID 983) in 16 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:32.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 9.0 in stage 433.0 (TID 985) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 8.0 in stage 433.0 (TID 984) in 20 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:32.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 5.0 in stage 451.0 (TID 986) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 9.0 in stage 433.0 (TID 985) in 15 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:32.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Removed TaskSet 433.0, whose tasks have all completed, from pool
[2025-05-07T21:43:32.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: ShuffleMapStage 433 (mapPartitions at GraphImpl.scala:208) finished in 0.217 s
[2025-05-07T21:43:32.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:32.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 460, ShuffleMapStage 461, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 451)
[2025-05-07T21:43:32.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 434, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:32.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:32.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 434 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[302] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:32.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 12.8 KiB, free 385.5 MiB)
[2025-05-07T21:43:32.387+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 385.5 MiB)
[2025-05-07T21:43:32.387+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 3530b0b864fd:36239 (size: 5.9 KiB, free: 431.8 MiB)
[2025-05-07T21:43:32.387+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:32.388+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 434 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[302] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:32.388+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Adding task set 434.0 with 10 tasks resource profile 0
[2025-05-07T21:43:32.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 0.0 in stage 434.0 (TID 987) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 5.0 in stage 451.0 (TID 986) in 56 ms on 172.20.0.5 (executor 2) (6/6)
[2025-05-07T21:43:32.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Removed TaskSet 451.0, whose tasks have all completed, from pool
[2025-05-07T21:43:32.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: ShuffleMapStage 451 (jdbc at NativeMethodAccessorImpl.java:0) finished in 4.825 s
[2025-05-07T21:43:32.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:32.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 460, ShuffleMapStage 434, ShuffleMapStage 461, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454)
[2025-05-07T21:43:32.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:32.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:32.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 172.20.0.5:36323 (size: 5.9 KiB, free: 433.0 MiB)
[2025-05-07T21:43:32.450+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:32.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO ShufflePartitionsUtil: For shuffle(80), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:32.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO ShufflePartitionsUtil: For shuffle(80), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:32.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:40082
[2025-05-07T21:43:32.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 1.0 in stage 434.0 (TID 988) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 0.0 in stage 434.0 (TID 987) in 37 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:32.476+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 3530b0b864fd:36239 in memory (size: 58.0 KiB, free: 431.8 MiB)
[2025-05-07T21:43:32.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:32.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Got job 100 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:43:32.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Final stage: ResultStage 463 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:43:32.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 462)
[2025-05-07T21:43:32.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:32.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting ResultStage 463 (MapPartitionsRDD[737] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:43:32.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 172.20.0.5:36323 in memory (size: 58.0 KiB, free: 433.0 MiB)
[2025-05-07T21:43:32.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 7.2 KiB, free 385.7 MiB)
[2025-05-07T21:43:32.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 385.7 MiB)
[2025-05-07T21:43:32.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 431.8 MiB)
[2025-05-07T21:43:32.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:32.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 463 (MapPartitionsRDD[737] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:32.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Adding task set 463.0 with 1 tasks resource profile 0
[2025-05-07T21:43:32.488+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 3530b0b864fd:36239 in memory (size: 5.0 KiB, free: 431.8 MiB)
[2025-05-07T21:43:32.489+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 172.20.0.5:36323 in memory (size: 5.0 KiB, free: 433.0 MiB)
[2025-05-07T21:43:32.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 2.0 in stage 434.0 (TID 989) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 1.0 in stage 434.0 (TID 988) in 17 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:32.493+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 431.9 MiB)
[2025-05-07T21:43:32.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 172.20.0.5:36323 in memory (size: 58.1 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 3530b0b864fd:36239 in memory (size: 5.3 KiB, free: 431.9 MiB)
[2025-05-07T21:43:32.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 172.20.0.5:36323 in memory (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 3.0 in stage 434.0 (TID 990) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 2.0 in stage 434.0 (TID 989) in 19 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:32.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 3530b0b864fd:36239 in memory (size: 5.7 KiB, free: 431.9 MiB)
[2025-05-07T21:43:32.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 172.20.0.5:36323 in memory (size: 5.7 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 4.0 in stage 434.0 (TID 991) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.524+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 3.0 in stage 434.0 (TID 990) in 14 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:32.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 5.0 in stage 434.0 (TID 992) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 4.0 in stage 434.0 (TID 991) in 16 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:32.551+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 6.0 in stage 434.0 (TID 993) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.552+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 5.0 in stage 434.0 (TID 992) in 13 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:32.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 7.0 in stage 434.0 (TID 994) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.570+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 6.0 in stage 434.0 (TID 993) in 18 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:32.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 8.0 in stage 434.0 (TID 995) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 7.0 in stage 434.0 (TID 994) in 16 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:32.608+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 9.0 in stage 434.0 (TID 996) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 8.0 in stage 434.0 (TID 995) in 23 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:32.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 0.0 in stage 452.0 (TID 997) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 9.0 in stage 434.0 (TID 996) in 14 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:32.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Removed TaskSet 434.0, whose tasks have all completed, from pool
[2025-05-07T21:43:32.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: ShuffleMapStage 434 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.237 s
[2025-05-07T21:43:32.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:32.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 452, ShuffleMapStage 456, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ShuffleMapStage 453, ShuffleMapStage 457, ShuffleMapStage 454)
[2025-05-07T21:43:32.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443, ShuffleMapStage 435, ShuffleMapStage 436)
[2025-05-07T21:43:32.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:32.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 435 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[306] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:32.628+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 172.20.0.5:36323 (size: 6.7 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 164.3 KiB, free 385.8 MiB)
[2025-05-07T21:43:32.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 385.7 MiB)
[2025-05-07T21:43:32.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 431.8 MiB)
[2025-05-07T21:43:32.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:32.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 435 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[306] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:32.633+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Adding task set 435.0 with 10 tasks resource profile 0
[2025-05-07T21:43:32.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 0.0 in stage 435.0 (TID 998) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 0.0 in stage 452.0 (TID 997) in 31 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:32.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Removed TaskSet 452.0, whose tasks have all completed, from pool
[2025-05-07T21:43:32.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: ShuffleMapStage 452 (jdbc at NativeMethodAccessorImpl.java:0) finished in 5.031 s
[2025-05-07T21:43:32.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:32.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 456, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ShuffleMapStage 453, ShuffleMapStage 435, ShuffleMapStage 457, ShuffleMapStage 454)
[2025-05-07T21:43:32.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443, ShuffleMapStage 436)
[2025-05-07T21:43:32.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:32.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 172.20.0.5:36323 (size: 58.1 KiB, free: 433.0 MiB)
[2025-05-07T21:43:32.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:32.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO ShufflePartitionsUtil: For shuffle(81), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:32.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:32.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:40082
[2025-05-07T21:43:32.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:40082
[2025-05-07T21:43:32.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:32.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Got job 101 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:43:32.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Final stage: ResultStage 465 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:43:32.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 464)
[2025-05-07T21:43:32.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:32.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting ResultStage 465 (MapPartitionsRDD[742] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:43:32.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 7.2 KiB, free 385.7 MiB)
[2025-05-07T21:43:32.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 385.7 MiB)
[2025-05-07T21:43:32.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 431.8 MiB)
[2025-05-07T21:43:32.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:32.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 465 (MapPartitionsRDD[742] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:32.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Adding task set 465.0 with 1 tasks resource profile 0
[2025-05-07T21:43:32.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 1.0 in stage 435.0 (TID 999) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 0.0 in stage 435.0 (TID 998) in 41 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:32.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 2.0 in stage 435.0 (TID 1000) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 1.0 in stage 435.0 (TID 999) in 22 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:32.731+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 3.0 in stage 435.0 (TID 1001) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 2.0 in stage 435.0 (TID 1000) in 16 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:32.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 4.0 in stage 435.0 (TID 1002) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 3.0 in stage 435.0 (TID 1001) in 19 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:32.770+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 172.20.0.5:36323 in memory (size: 56.8 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.771+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 3530b0b864fd:36239 in memory (size: 56.8 KiB, free: 431.9 MiB)
[2025-05-07T21:43:32.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 5.0 in stage 435.0 (TID 1003) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 4.0 in stage 435.0 (TID 1002) in 24 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:32.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 3530b0b864fd:36239 in memory (size: 5.9 KiB, free: 431.9 MiB)
[2025-05-07T21:43:32.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 172.20.0.5:36323 in memory (size: 5.9 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 3530b0b864fd:36239 in memory (size: 11.2 KiB, free: 431.9 MiB)
[2025-05-07T21:43:32.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 172.20.0.5:36323 in memory (size: 11.2 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.792+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 3530b0b864fd:36239 in memory (size: 19.5 KiB, free: 431.9 MiB)
[2025-05-07T21:43:32.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 172.20.0.5:36323 in memory (size: 19.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 6.0 in stage 435.0 (TID 1004) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 431.9 MiB)
[2025-05-07T21:43:32.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 5.0 in stage 435.0 (TID 1003) in 26 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:32.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 172.20.0.5:36323 in memory (size: 6.7 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 7.0 in stage 435.0 (TID 1005) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 6.0 in stage 435.0 (TID 1004) in 23 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:32.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 8.0 in stage 435.0 (TID 1006) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 7.0 in stage 435.0 (TID 1005) in 20 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:32.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 9.0 in stage 435.0 (TID 1007) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 8.0 in stage 435.0 (TID 1006) in 15 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:32.869+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 0.0 in stage 453.0 (TID 1008) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.869+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 9.0 in stage 435.0 (TID 1007) in 15 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:32.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Removed TaskSet 435.0, whose tasks have all completed, from pool
[2025-05-07T21:43:32.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: ShuffleMapStage 435 (mapPartitions at GraphImpl.scala:208) finished in 0.246 s
[2025-05-07T21:43:32.871+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:32.871+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 456, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ShuffleMapStage 453, ResultStage 465, ShuffleMapStage 457, ShuffleMapStage 454)
[2025-05-07T21:43:32.871+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443, ShuffleMapStage 436)
[2025-05-07T21:43:32.871+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:32.871+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 436 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[314] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:32.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 13.5 KiB, free 386.1 MiB)
[2025-05-07T21:43:32.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 386.0 MiB)
[2025-05-07T21:43:32.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 3530b0b864fd:36239 (size: 6.1 KiB, free: 431.9 MiB)
[2025-05-07T21:43:32.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:32.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 436 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[314] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:32.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Adding task set 436.0 with 10 tasks resource profile 0
[2025-05-07T21:43:32.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 172.20.0.5:36323 (size: 13.0 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 0.0 in stage 436.0 (TID 1009) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 0.0 in stage 453.0 (TID 1008) in 51 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:32.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSchedulerImpl: Removed TaskSet 453.0, whose tasks have all completed, from pool
[2025-05-07T21:43:32.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: ShuffleMapStage 453 (jdbc at NativeMethodAccessorImpl.java:0) finished in 5.289 s
[2025-05-07T21:43:32.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:32.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 456, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465, ShuffleMapStage 457, ShuffleMapStage 454, ShuffleMapStage 436)
[2025-05-07T21:43:32.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:32.922+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:32.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 172.20.0.5:36323 (size: 6.1 KiB, free: 433.1 MiB)
[2025-05-07T21:43:32.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:32.949+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:40082
[2025-05-07T21:43:32.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:40082
[2025-05-07T21:43:32.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 1.0 in stage 436.0 (TID 1010) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.959+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 0.0 in stage 436.0 (TID 1009) in 38 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:32.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 2.0 in stage 436.0 (TID 1011) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 1.0 in stage 436.0 (TID 1010) in 12 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:32.986+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 3.0 in stage 436.0 (TID 1012) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.986+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 2.0 in stage 436.0 (TID 1011) in 16 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:32.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Starting task 4.0 in stage 436.0 (TID 1013) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:32.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:32 INFO TaskSetManager: Finished task 3.0 in stage 436.0 (TID 1012) in 12 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:33.009+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 5.0 in stage 436.0 (TID 1014) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.010+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 4.0 in stage 436.0 (TID 1013) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:33.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 6.0 in stage 436.0 (TID 1015) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 5.0 in stage 436.0 (TID 1014) in 15 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:33.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 7.0 in stage 436.0 (TID 1016) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 6.0 in stage 436.0 (TID 1015) in 16 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:33.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 8.0 in stage 436.0 (TID 1017) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 7.0 in stage 436.0 (TID 1016) in 14 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:33.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 9.0 in stage 436.0 (TID 1018) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 8.0 in stage 436.0 (TID 1017) in 16 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:33.083+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 0.0 in stage 454.0 (TID 1019) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 9.0 in stage 436.0 (TID 1018) in 15 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:33.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Removed TaskSet 436.0, whose tasks have all completed, from pool
[2025-05-07T21:43:33.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: ShuffleMapStage 436 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.212 s
[2025-05-07T21:43:33.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:33.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 456, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465, ShuffleMapStage 457, ShuffleMapStage 454)
[2025-05-07T21:43:33.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 437, ShuffleMapStage 438, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:33.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:33.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 437 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[318] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:33.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 172.20.0.5:36323 (size: 13.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:33.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 164.6 KiB, free 385.9 MiB)
[2025-05-07T21:43:33.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 385.8 MiB)
[2025-05-07T21:43:33.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 3530b0b864fd:36239 (size: 58.1 KiB, free: 431.9 MiB)
[2025-05-07T21:43:33.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:33.093+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 437 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[318] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:33.093+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Adding task set 437.0 with 10 tasks resource profile 0
[2025-05-07T21:43:33.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 0.0 in stage 437.0 (TID 1020) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 0.0 in stage 454.0 (TID 1019) in 50 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:33.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Removed TaskSet 454.0, whose tasks have all completed, from pool
[2025-05-07T21:43:33.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: ShuffleMapStage 454 (jdbc at NativeMethodAccessorImpl.java:0) finished in 5.493 s
[2025-05-07T21:43:33.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:33.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 437, ShuffleMapStage 456, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465, ShuffleMapStage 457)
[2025-05-07T21:43:33.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 438, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:33.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:33.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 172.20.0.5:36323 (size: 58.1 KiB, free: 433.0 MiB)
[2025-05-07T21:43:33.153+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:33.157+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:33.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:40082
[2025-05-07T21:43:33.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:40082
[2025-05-07T21:43:33.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:40082
[2025-05-07T21:43:33.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 1.0 in stage 437.0 (TID 1021) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 0.0 in stage 437.0 (TID 1020) in 37 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:33.185+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 2.0 in stage 437.0 (TID 1022) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.185+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 1.0 in stage 437.0 (TID 1021) in 16 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:33.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 3.0 in stage 437.0 (TID 1023) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 2.0 in stage 437.0 (TID 1022) in 23 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:33.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 4.0 in stage 437.0 (TID 1024) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 3.0 in stage 437.0 (TID 1023) in 32 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:33.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 5.0 in stage 437.0 (TID 1025) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 4.0 in stage 437.0 (TID 1024) in 20 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:33.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 6.0 in stage 437.0 (TID 1026) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 5.0 in stage 437.0 (TID 1025) in 15 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:33.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 7.0 in stage 437.0 (TID 1027) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 6.0 in stage 437.0 (TID 1026) in 16 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:33.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 8.0 in stage 437.0 (TID 1028) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 7.0 in stage 437.0 (TID 1027) in 16 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:33.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 9.0 in stage 437.0 (TID 1029) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 8.0 in stage 437.0 (TID 1028) in 18 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:33.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 0.0 in stage 455.0 (TID 1030) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 9.0 in stage 437.0 (TID 1029) in 15 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:33.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Removed TaskSet 437.0, whose tasks have all completed, from pool
[2025-05-07T21:43:33.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: ShuffleMapStage 437 (mapPartitions at GraphImpl.scala:208) finished in 0.250 s
[2025-05-07T21:43:33.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:33.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 455, ShuffleMapStage 456, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465, ShuffleMapStage 457)
[2025-05-07T21:43:33.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 438, ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:33.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:33.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 438 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[326] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:33.338+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 14.2 KiB, free 385.8 MiB)
[2025-05-07T21:43:33.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 385.8 MiB)
[2025-05-07T21:43:33.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 3530b0b864fd:36239 (size: 6.1 KiB, free: 431.9 MiB)
[2025-05-07T21:43:33.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:33.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 438 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[326] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:33.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Adding task set 438.0 with 10 tasks resource profile 0
[2025-05-07T21:43:33.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 172.20.0.5:36323 (size: 13.4 KiB, free: 433.0 MiB)
[2025-05-07T21:43:33.388+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 0.0 in stage 438.0 (TID 1031) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.388+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 0.0 in stage 455.0 (TID 1030) in 53 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:33.388+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Removed TaskSet 455.0, whose tasks have all completed, from pool
[2025-05-07T21:43:33.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: ShuffleMapStage 455 (jdbc at NativeMethodAccessorImpl.java:0) finished in 5.715 s
[2025-05-07T21:43:33.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:33.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 456, ShuffleMapStage 438, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465, ShuffleMapStage 457)
[2025-05-07T21:43:33.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:33.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:33.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 172.20.0.5:36323 (size: 6.1 KiB, free: 433.0 MiB)
[2025-05-07T21:43:33.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:33.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:40082
[2025-05-07T21:43:33.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:40082
[2025-05-07T21:43:33.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:40082
[2025-05-07T21:43:33.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 1.0 in stage 438.0 (TID 1032) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 0.0 in stage 438.0 (TID 1031) in 27 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:33.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 2.0 in stage 438.0 (TID 1033) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 1.0 in stage 438.0 (TID 1032) in 20 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:33.452+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 3.0 in stage 438.0 (TID 1034) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 2.0 in stage 438.0 (TID 1033) in 18 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:33.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 4.0 in stage 438.0 (TID 1035) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 3.0 in stage 438.0 (TID 1034) in 28 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:33.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 5.0 in stage 438.0 (TID 1036) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 4.0 in stage 438.0 (TID 1035) in 17 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:33.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 6.0 in stage 438.0 (TID 1037) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 5.0 in stage 438.0 (TID 1036) in 16 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:33.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 7.0 in stage 438.0 (TID 1038) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 6.0 in stage 438.0 (TID 1037) in 14 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:33.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 8.0 in stage 438.0 (TID 1039) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 7.0 in stage 438.0 (TID 1038) in 21 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:33.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 9.0 in stage 438.0 (TID 1040) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 8.0 in stage 438.0 (TID 1039) in 14 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:33.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 0.0 in stage 456.0 (TID 1041) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 9.0 in stage 438.0 (TID 1040) in 14 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:33.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Removed TaskSet 438.0, whose tasks have all completed, from pool
[2025-05-07T21:43:33.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: ShuffleMapStage 438 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.237 s
[2025-05-07T21:43:33.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:33.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 456, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465, ShuffleMapStage 457)
[2025-05-07T21:43:33.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 439, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:33.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:33.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 439 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[330] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:33.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 172.20.0.5:36323 (size: 13.0 KiB, free: 433.0 MiB)
[2025-05-07T21:43:33.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 164.9 KiB, free 385.6 MiB)
[2025-05-07T21:43:33.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 385.6 MiB)
[2025-05-07T21:43:33.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 3530b0b864fd:36239 (size: 58.3 KiB, free: 431.8 MiB)
[2025-05-07T21:43:33.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:33.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 439 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[330] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:33.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Adding task set 439.0 with 10 tasks resource profile 0
[2025-05-07T21:43:33.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 0.0 in stage 439.0 (TID 1042) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 0.0 in stage 456.0 (TID 1041) in 37 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:33.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Removed TaskSet 456.0, whose tasks have all completed, from pool
[2025-05-07T21:43:33.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: ShuffleMapStage 456 (jdbc at NativeMethodAccessorImpl.java:0) finished in 5.868 s
[2025-05-07T21:43:33.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:33.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465, ShuffleMapStage 457, ShuffleMapStage 439)
[2025-05-07T21:43:33.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:33.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:33.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 172.20.0.5:36323 (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T21:43:33.628+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:33.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:33.634+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:40082
[2025-05-07T21:43:33.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:40082
[2025-05-07T21:43:33.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:40082
[2025-05-07T21:43:33.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:40082
[2025-05-07T21:43:33.648+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 1.0 in stage 439.0 (TID 1043) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.648+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 0.0 in stage 439.0 (TID 1042) in 37 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:33.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 2.0 in stage 439.0 (TID 1044) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.667+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 1.0 in stage 439.0 (TID 1043) in 19 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:33.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 3.0 in stage 439.0 (TID 1045) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 2.0 in stage 439.0 (TID 1044) in 16 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:33.707+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 4.0 in stage 439.0 (TID 1046) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.708+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 3.0 in stage 439.0 (TID 1045) in 27 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:33.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 5.0 in stage 439.0 (TID 1047) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 4.0 in stage 439.0 (TID 1046) in 19 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:33.745+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 6.0 in stage 439.0 (TID 1048) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.745+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 5.0 in stage 439.0 (TID 1047) in 20 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:33.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 7.0 in stage 439.0 (TID 1049) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 6.0 in stage 439.0 (TID 1048) in 22 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:33.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 8.0 in stage 439.0 (TID 1050) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 7.0 in stage 439.0 (TID 1049) in 24 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:33.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 9.0 in stage 439.0 (TID 1051) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 8.0 in stage 439.0 (TID 1050) in 15 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:33.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 0.0 in stage 457.0 (TID 1052) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 9.0 in stage 439.0 (TID 1051) in 15 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:33.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Removed TaskSet 439.0, whose tasks have all completed, from pool
[2025-05-07T21:43:33.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: ShuffleMapStage 439 (mapPartitions at GraphImpl.scala:208) finished in 0.245 s
[2025-05-07T21:43:33.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:33.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465, ShuffleMapStage 457)
[2025-05-07T21:43:33.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 440, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:33.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:33.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 440 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:33.823+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 14.9 KiB, free 385.6 MiB)
[2025-05-07T21:43:33.824+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 385.6 MiB)
[2025-05-07T21:43:33.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 3530b0b864fd:36239 (size: 6.3 KiB, free: 431.8 MiB)
[2025-05-07T21:43:33.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:33.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 440 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:33.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Adding task set 440.0 with 10 tasks resource profile 0
[2025-05-07T21:43:33.827+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 172.20.0.5:36323 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T21:43:33.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 0.0 in stage 440.0 (TID 1053) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 0.0 in stage 457.0 (TID 1052) in 38 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:33.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSchedulerImpl: Removed TaskSet 457.0, whose tasks have all completed, from pool
[2025-05-07T21:43:33.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: ShuffleMapStage 457 (jdbc at NativeMethodAccessorImpl.java:0) finished in 6.106 s
[2025-05-07T21:43:33.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:33.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ShuffleMapStage 440, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465)
[2025-05-07T21:43:33.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:33.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:33.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 172.20.0.5:36323 (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-07T21:43:33.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:33.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:40082
[2025-05-07T21:43:33.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:40082
[2025-05-07T21:43:33.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:40082
[2025-05-07T21:43:33.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:40082
[2025-05-07T21:43:33.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 1.0 in stage 440.0 (TID 1054) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.900+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 0.0 in stage 440.0 (TID 1053) in 41 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:33.931+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 2.0 in stage 440.0 (TID 1055) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.931+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 1.0 in stage 440.0 (TID 1054) in 32 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:33.949+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 3.0 in stage 440.0 (TID 1056) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.949+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 2.0 in stage 440.0 (TID 1055) in 18 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:33.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 4.0 in stage 440.0 (TID 1057) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 3.0 in stage 440.0 (TID 1056) in 22 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:33.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Starting task 5.0 in stage 440.0 (TID 1058) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:33.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:33 INFO TaskSetManager: Finished task 4.0 in stage 440.0 (TID 1057) in 19 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:34.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 6.0 in stage 440.0 (TID 1059) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 5.0 in stage 440.0 (TID 1058) in 23 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:34.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 7.0 in stage 440.0 (TID 1060) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 6.0 in stage 440.0 (TID 1059) in 27 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:34.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 172.20.0.5:36323 in memory (size: 58.1 KiB, free: 433.0 MiB)
[2025-05-07T21:43:34.047+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 3530b0b864fd:36239 in memory (size: 58.1 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 172.20.0.5:36323 in memory (size: 58.1 KiB, free: 433.0 MiB)
[2025-05-07T21:43:34.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 3530b0b864fd:36239 in memory (size: 6.1 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 172.20.0.5:36323 in memory (size: 6.1 KiB, free: 433.0 MiB)
[2025-05-07T21:43:34.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 8.0 in stage 440.0 (TID 1061) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.059+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 7.0 in stage 440.0 (TID 1060) in 21 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:34.059+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 3530b0b864fd:36239 in memory (size: 6.1 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 172.20.0.5:36323 in memory (size: 6.1 KiB, free: 433.0 MiB)
[2025-05-07T21:43:34.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 3530b0b864fd:36239 in memory (size: 58.3 KiB, free: 432.0 MiB)
[2025-05-07T21:43:34.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 172.20.0.5:36323 in memory (size: 58.3 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 9.0 in stage 440.0 (TID 1062) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.080+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 8.0 in stage 440.0 (TID 1061) in 22 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:34.104+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 0.0 in stage 458.0 (TID 1063) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 9.0 in stage 440.0 (TID 1062) in 25 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:34.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Removed TaskSet 440.0, whose tasks have all completed, from pool
[2025-05-07T21:43:34.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: ShuffleMapStage 440 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.281 s
[2025-05-07T21:43:34.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:34.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: running: Set(ShuffleMapStage 458, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465)
[2025-05-07T21:43:34.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 441, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:34.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:34.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 441 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[342] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:34.113+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 165.2 KiB, free 386.1 MiB)
[2025-05-07T21:43:34.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 386.0 MiB)
[2025-05-07T21:43:34.115+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 3530b0b864fd:36239 (size: 58.2 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 172.20.0.5:36323 (size: 14.9 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:34.117+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 441 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[342] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:34.117+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Adding task set 441.0 with 10 tasks resource profile 0
[2025-05-07T21:43:34.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 0.0 in stage 441.0 (TID 1064) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 0.0 in stage 458.0 (TID 1063) in 70 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:34.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Removed TaskSet 458.0, whose tasks have all completed, from pool
[2025-05-07T21:43:34.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: ShuffleMapStage 458 (jdbc at NativeMethodAccessorImpl.java:0) finished in 6.414 s
[2025-05-07T21:43:34.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:34.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: running: Set(ShuffleMapStage 441, ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465)
[2025-05-07T21:43:34.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:34.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:34.180+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 172.20.0.5:36323 (size: 58.2 KiB, free: 433.0 MiB)
[2025-05-07T21:43:34.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO ShufflePartitionsUtil: For shuffle(82, 83, 84, 85, 86, 87), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:34.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:34.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:34.198+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:40082
[2025-05-07T21:43:34.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:34.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:40082
[2025-05-07T21:43:34.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:40082
[2025-05-07T21:43:34.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:34.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:40082
[2025-05-07T21:43:34.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:40082
[2025-05-07T21:43:34.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:34.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 1.0 in stage 441.0 (TID 1065) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 0.0 in stage 441.0 (TID 1064) in 43 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:34.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:34.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:34.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:34.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 2.0 in stage 441.0 (TID 1066) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 1.0 in stage 441.0 (TID 1065) in 28 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:34.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 3.0 in stage 441.0 (TID 1067) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 2.0 in stage 441.0 (TID 1066) in 22 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:34.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:34.265+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Got job 102 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T21:43:34.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Final stage: ResultStage 472 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:43:34.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 466, ShuffleMapStage 470, ShuffleMapStage 467, ShuffleMapStage 471, ShuffleMapStage 468, ShuffleMapStage 469)
[2025-05-07T21:43:34.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:34.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting ResultStage 472 (MapPartitionsRDD[775] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:43:34.269+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 91.7 KiB, free 386.0 MiB)
[2025-05-07T21:43:34.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 385.9 MiB)
[2025-05-07T21:43:34.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 3530b0b864fd:36239 (size: 30.3 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:34.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 472 (MapPartitionsRDD[775] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:43:34.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Adding task set 472.0 with 6 tasks resource profile 0
[2025-05-07T21:43:34.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 4.0 in stage 441.0 (TID 1068) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 3.0 in stage 441.0 (TID 1067) in 25 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:34.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 5.0 in stage 441.0 (TID 1069) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 4.0 in stage 441.0 (TID 1068) in 22 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:34.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 6.0 in stage 441.0 (TID 1070) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 5.0 in stage 441.0 (TID 1069) in 17 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:34.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 3530b0b864fd:36239 in memory (size: 6.3 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 7.0 in stage 441.0 (TID 1071) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 6.0 in stage 441.0 (TID 1070) in 35 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:34.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 172.20.0.5:36323 in memory (size: 6.3 KiB, free: 433.0 MiB)
[2025-05-07T21:43:34.375+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 172.20.0.5:36323 in memory (size: 13.4 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 172.20.0.5:36323 in memory (size: 13.0 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 8.0 in stage 441.0 (TID 1072) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 7.0 in stage 441.0 (TID 1071) in 56 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:34.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 3530b0b864fd:36239 in memory (size: 13.0 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.419+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 172.20.0.5:36323 in memory (size: 13.0 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 3530b0b864fd:36239 in memory (size: 13.4 KiB, free: 432.0 MiB)
[2025-05-07T21:43:34.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 172.20.0.5:36323 in memory (size: 13.4 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.426+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 3530b0b864fd:36239 in memory (size: 14.9 KiB, free: 432.0 MiB)
[2025-05-07T21:43:34.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 172.20.0.5:36323 in memory (size: 14.9 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 3530b0b864fd:36239 in memory (size: 13.5 KiB, free: 432.0 MiB)
[2025-05-07T21:43:34.431+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 172.20.0.5:36323 in memory (size: 13.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 9.0 in stage 441.0 (TID 1073) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 8.0 in stage 441.0 (TID 1072) in 22 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:34.455+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 0.0 in stage 460.0 (TID 1074) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.455+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 9.0 in stage 441.0 (TID 1073) in 19 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:34.455+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Removed TaskSet 441.0, whose tasks have all completed, from pool
[2025-05-07T21:43:34.455+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: ShuffleMapStage 441 (mapPartitions at GraphImpl.scala:208) finished in 0.350 s
[2025-05-07T21:43:34.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:34.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: running: Set(ResultStage 463, ResultStage 460, ShuffleMapStage 461, ResultStage 465, ResultStage 472)
[2025-05-07T21:43:34.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 442, ShuffleMapStage 443)
[2025-05-07T21:43:34.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:34.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 442 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[350] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:34.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 15.6 KiB, free 386.2 MiB)
[2025-05-07T21:43:34.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 386.2 MiB)
[2025-05-07T21:43:34.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 3530b0b864fd:36239 (size: 6.4 KiB, free: 432.0 MiB)
[2025-05-07T21:43:34.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:34.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 442 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[350] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:34.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Adding task set 442.0 with 10 tasks resource profile 0
[2025-05-07T21:43:34.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 172.20.0.5:36323 (size: 3.8 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.463+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:40082
[2025-05-07T21:43:34.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 0.0 in stage 442.0 (TID 1075) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 0.0 in stage 460.0 (TID 1074) in 15 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:34.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Removed TaskSet 460.0, whose tasks have all completed, from pool
[2025-05-07T21:43:34.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: ResultStage 460 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 3.609 s
[2025-05-07T21:43:34.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:34.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 460: Stage finished
[2025-05-07T21:43:34.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Job 98 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 3.614245 s
[2025-05-07T21:43:34.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 1088.0 KiB, free 385.1 MiB)
[2025-05-07T21:43:34.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 385.1 MiB)
[2025-05-07T21:43:34.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 172.20.0.5:36323 (size: 6.4 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 3530b0b864fd:36239 (size: 32.6 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 207 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:34.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:34.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:40082
[2025-05-07T21:43:34.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:40082
[2025-05-07T21:43:34.486+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:40082
[2025-05-07T21:43:34.490+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:40082
[2025-05-07T21:43:34.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Registering RDD 780 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 89
[2025-05-07T21:43:34.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Got map stage job 103 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:34.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Final stage: ShuffleMapStage 473 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:34.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:34.500+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:34.500+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 473 (MapPartitionsRDD[780] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:34.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 17.6 KiB, free 385.1 MiB)
[2025-05-07T21:43:34.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 385.1 MiB)
[2025-05-07T21:43:34.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 3530b0b864fd:36239 (size: 8.2 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:40082
[2025-05-07T21:43:34.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:34.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 473 (MapPartitionsRDD[780] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:34.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Adding task set 473.0 with 1 tasks resource profile 0
[2025-05-07T21:43:34.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Registering RDD 782 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 90
[2025-05-07T21:43:34.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Got map stage job 104 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:34.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Final stage: ShuffleMapStage 474 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:34.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:43:34.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:34.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 474 (MapPartitionsRDD[782] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:34.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 78.0 KiB, free 385.0 MiB)
[2025-05-07T21:43:34.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 384.9 MiB)
[2025-05-07T21:43:34.516+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 3530b0b864fd:36239 (size: 33.9 KiB, free: 431.9 MiB)
[2025-05-07T21:43:34.516+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:34.517+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 474 (MapPartitionsRDD[782] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:34.517+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Adding task set 474.0 with 1 tasks resource profile 0
[2025-05-07T21:43:34.517+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 1.0 in stage 442.0 (TID 1076) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 0.0 in stage 442.0 (TID 1075) in 49 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:34.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 2.0 in stage 442.0 (TID 1077) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 1.0 in stage 442.0 (TID 1076) in 18 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:34.559+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 3.0 in stage 442.0 (TID 1078) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.559+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 2.0 in stage 442.0 (TID 1077) in 25 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:34.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 4.0 in stage 442.0 (TID 1079) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 3.0 in stage 442.0 (TID 1078) in 28 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:34.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 5.0 in stage 442.0 (TID 1080) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 4.0 in stage 442.0 (TID 1079) in 19 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:34.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 6.0 in stage 442.0 (TID 1081) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.633+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 5.0 in stage 442.0 (TID 1080) in 28 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:34.651+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 7.0 in stage 442.0 (TID 1082) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.651+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 6.0 in stage 442.0 (TID 1081) in 19 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:34.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 8.0 in stage 442.0 (TID 1083) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 7.0 in stage 442.0 (TID 1082) in 21 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:34.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 9.0 in stage 442.0 (TID 1084) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 8.0 in stage 442.0 (TID 1083) in 19 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:34.708+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 0.0 in stage 461.0 (TID 1085) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 9.0 in stage 442.0 (TID 1084) in 18 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:34.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Removed TaskSet 442.0, whose tasks have all completed, from pool
[2025-05-07T21:43:34.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: ShuffleMapStage 442 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.253 s
[2025-05-07T21:43:34.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:34.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: running: Set(ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 463, ShuffleMapStage 461, ResultStage 465, ResultStage 472)
[2025-05-07T21:43:34.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447, ShuffleMapStage 443)
[2025-05-07T21:43:34.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:34.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 443 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[354] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:34.714+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 172.20.0.5:36323 (size: 8.3 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 165.5 KiB, free 384.8 MiB)
[2025-05-07T21:43:34.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 384.7 MiB)
[2025-05-07T21:43:34.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 3530b0b864fd:36239 (size: 58.4 KiB, free: 431.8 MiB)
[2025-05-07T21:43:34.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:34.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 443 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[354] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:34.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Adding task set 443.0 with 10 tasks resource profile 0
[2025-05-07T21:43:34.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 172.20.0.5:36323 (size: 27.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:34.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 0.0 in stage 443.0 (TID 1086) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 0.0 in stage 461.0 (TID 1085) in 48 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:34.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Removed TaskSet 461.0, whose tasks have all completed, from pool
[2025-05-07T21:43:34.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: ShuffleMapStage 461 (jdbc at NativeMethodAccessorImpl.java:0) finished in 3.761 s
[2025-05-07T21:43:34.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:34.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: running: Set(ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 463, ShuffleMapStage 443, ResultStage 465, ResultStage 472)
[2025-05-07T21:43:34.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447)
[2025-05-07T21:43:34.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:34.762+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 172.20.0.5:36323 (size: 58.4 KiB, free: 433.0 MiB)
[2025-05-07T21:43:34.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:34.771+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:34.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:34.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:40082
[2025-05-07T21:43:34.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:34.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:40082
[2025-05-07T21:43:34.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Got job 105 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:43:34.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Final stage: ResultStage 476 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:43:34.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 475)
[2025-05-07T21:43:34.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:34.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting ResultStage 476 (MapPartitionsRDD[785] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:43:34.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 7.2 KiB, free 384.7 MiB)
[2025-05-07T21:43:34.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:40082
[2025-05-07T21:43:34.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 384.7 MiB)
[2025-05-07T21:43:34.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 431.8 MiB)
[2025-05-07T21:43:34.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:34.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 476 (MapPartitionsRDD[785] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:34.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Adding task set 476.0 with 1 tasks resource profile 0
[2025-05-07T21:43:34.780+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:40082
[2025-05-07T21:43:34.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:40082
[2025-05-07T21:43:34.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:40082
[2025-05-07T21:43:34.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 1.0 in stage 443.0 (TID 1087) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 0.0 in stage 443.0 (TID 1086) in 33 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:34.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 2.0 in stage 443.0 (TID 1088) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 1.0 in stage 443.0 (TID 1087) in 16 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:34.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 3.0 in stage 443.0 (TID 1089) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 2.0 in stage 443.0 (TID 1088) in 16 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:34.835+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 4.0 in stage 443.0 (TID 1090) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 3.0 in stage 443.0 (TID 1089) in 17 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:34.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 5.0 in stage 443.0 (TID 1091) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 4.0 in stage 443.0 (TID 1090) in 16 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:34.865+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 6.0 in stage 443.0 (TID 1092) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 5.0 in stage 443.0 (TID 1091) in 15 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:34.880+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 7.0 in stage 443.0 (TID 1093) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.880+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 6.0 in stage 443.0 (TID 1092) in 15 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:34.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 8.0 in stage 443.0 (TID 1094) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 7.0 in stage 443.0 (TID 1093) in 15 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:34.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 9.0 in stage 443.0 (TID 1095) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 8.0 in stage 443.0 (TID 1094) in 15 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:34.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 0.0 in stage 463.0 (TID 1096) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 9.0 in stage 443.0 (TID 1095) in 17 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:34.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Removed TaskSet 443.0, whose tasks have all completed, from pool
[2025-05-07T21:43:34.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: ShuffleMapStage 443 (mapPartitions at GraphImpl.scala:208) finished in 0.216 s
[2025-05-07T21:43:34.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:34.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 463, ResultStage 465, ResultStage 472)
[2025-05-07T21:43:34.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 444, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447)
[2025-05-07T21:43:34.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:34.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 444 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[362] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:34.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 16.4 KiB, free 384.7 MiB)
[2025-05-07T21:43:34.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 384.7 MiB)
[2025-05-07T21:43:34.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 3530b0b864fd:36239 (size: 6.5 KiB, free: 431.8 MiB)
[2025-05-07T21:43:34.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:34.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 444 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[362] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:34.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Adding task set 444.0 with 10 tasks resource profile 0
[2025-05-07T21:43:34.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 172.20.0.5:36323 (size: 3.8 KiB, free: 433.0 MiB)
[2025-05-07T21:43:34.932+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:40082
[2025-05-07T21:43:34.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 0.0 in stage 444.0 (TID 1097) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 0.0 in stage 463.0 (TID 1096) in 25 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:34.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Removed TaskSet 463.0, whose tasks have all completed, from pool
[2025-05-07T21:43:34.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: ResultStage 463 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 2.470 s
[2025-05-07T21:43:34.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:34.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 463: Stage finished
[2025-05-07T21:43:34.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO DAGScheduler: Job 100 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 2.472125 s
[2025-05-07T21:43:34.955+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 172.20.0.5:36323 (size: 6.5 KiB, free: 433.0 MiB)
[2025-05-07T21:43:34.959+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:34.962+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:40082
[2025-05-07T21:43:34.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:40082
[2025-05-07T21:43:34.965+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 5.0 MiB, free 379.7 MiB)
[2025-05-07T21:43:34.966+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:40082
[2025-05-07T21:43:34.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:40082
[2025-05-07T21:43:34.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:40082
[2025-05-07T21:43:34.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 379.2 MiB)
[2025-05-07T21:43:34.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 3530b0b864fd:36239 (size: 502.1 KiB, free: 431.3 MiB)
[2025-05-07T21:43:34.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO SparkContext: Created broadcast 213 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:34.983+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:40082
[2025-05-07T21:43:34.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Starting task 1.0 in stage 444.0 (TID 1098) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:34.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:34 INFO TaskSetManager: Finished task 0.0 in stage 444.0 (TID 1097) in 38 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:35.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 2.0 in stage 444.0 (TID 1099) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 1.0 in stage 444.0 (TID 1098) in 32 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:35.048+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 3.0 in stage 444.0 (TID 1100) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.048+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 2.0 in stage 444.0 (TID 1099) in 28 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:35.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 4.0 in stage 444.0 (TID 1101) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 3.0 in stage 444.0 (TID 1100) in 21 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:35.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 5.0 in stage 444.0 (TID 1102) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 4.0 in stage 444.0 (TID 1101) in 24 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:35.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 6.0 in stage 444.0 (TID 1103) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 5.0 in stage 444.0 (TID 1102) in 22 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:35.136+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 7.0 in stage 444.0 (TID 1104) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.136+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 6.0 in stage 444.0 (TID 1103) in 22 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:35.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 8.0 in stage 444.0 (TID 1105) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 7.0 in stage 444.0 (TID 1104) in 18 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:35.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 9.0 in stage 444.0 (TID 1106) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 8.0 in stage 444.0 (TID 1105) in 21 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:35.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 0.0 in stage 465.0 (TID 1107) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 9.0 in stage 444.0 (TID 1106) in 30 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:35.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSchedulerImpl: Removed TaskSet 444.0, whose tasks have all completed, from pool
[2025-05-07T21:43:35.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: ShuffleMapStage 444 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.278 s
[2025-05-07T21:43:35.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:35.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 465, ResultStage 472)
[2025-05-07T21:43:35.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 445, ShuffleMapStage 446, ShuffleMapStage 447)
[2025-05-07T21:43:35.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:35.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 445 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[366] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:35.211+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 165.8 KiB, free 379.0 MiB)
[2025-05-07T21:43:35.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 172.20.0.5:36323 (size: 3.8 KiB, free: 433.0 MiB)
[2025-05-07T21:43:35.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 3530b0b864fd:36239 in memory (size: 6.4 KiB, free: 431.3 MiB)
[2025-05-07T21:43:35.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 379.0 MiB)
[2025-05-07T21:43:35.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 3530b0b864fd:36239 (size: 58.5 KiB, free: 431.3 MiB)
[2025-05-07T21:43:35.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:35.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 445 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[366] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:35.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSchedulerImpl: Adding task set 445.0 with 10 tasks resource profile 0
[2025-05-07T21:43:35.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 172.20.0.5:36323 in memory (size: 6.4 KiB, free: 433.0 MiB)
[2025-05-07T21:43:35.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:40082
[2025-05-07T21:43:35.223+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 3530b0b864fd:36239 in memory (size: 58.4 KiB, free: 431.3 MiB)
[2025-05-07T21:43:35.224+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 172.20.0.5:36323 in memory (size: 58.4 KiB, free: 433.1 MiB)
[2025-05-07T21:43:35.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 3530b0b864fd:36239 in memory (size: 58.2 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 0.0 in stage 445.0 (TID 1108) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 172.20.0.5:36323 in memory (size: 58.2 KiB, free: 433.1 MiB)
[2025-05-07T21:43:35.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 0.0 in stage 465.0 (TID 1107) in 23 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:35.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSchedulerImpl: Removed TaskSet 465.0, whose tasks have all completed, from pool
[2025-05-07T21:43:35.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: ResultStage 465 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 2.536 s
[2025-05-07T21:43:35.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:35.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 465: Stage finished
[2025-05-07T21:43:35.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: Job 101 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 2.537703 s
[2025-05-07T21:43:35.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 2.1 MiB, free 377.4 MiB)
[2025-05-07T21:43:35.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 172.20.0.5:36323 (size: 58.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:35.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 377.4 MiB)
[2025-05-07T21:43:35.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 3530b0b864fd:36239 (size: 20.6 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO SparkContext: Created broadcast 215 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:35.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:35.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:35.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:40082
[2025-05-07T21:43:35.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:40082
[2025-05-07T21:43:35.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:40082
[2025-05-07T21:43:35.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:40082
[2025-05-07T21:43:35.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:40082
[2025-05-07T21:43:35.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:40082
[2025-05-07T21:43:35.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:40082
[2025-05-07T21:43:35.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 1.0 in stage 445.0 (TID 1109) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 0.0 in stage 445.0 (TID 1108) in 33 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:35.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 2.0 in stage 445.0 (TID 1110) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.273+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 1.0 in stage 445.0 (TID 1109) in 15 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:35.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 3.0 in stage 445.0 (TID 1111) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 2.0 in stage 445.0 (TID 1110) in 16 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:35.304+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 4.0 in stage 445.0 (TID 1112) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 3.0 in stage 445.0 (TID 1111) in 17 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:35.318+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 5.0 in stage 445.0 (TID 1113) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.318+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 4.0 in stage 445.0 (TID 1112) in 14 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:35.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 6.0 in stage 445.0 (TID 1114) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 5.0 in stage 445.0 (TID 1113) in 14 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:35.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 7.0 in stage 445.0 (TID 1115) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 6.0 in stage 445.0 (TID 1114) in 14 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:35.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 8.0 in stage 445.0 (TID 1116) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 7.0 in stage 445.0 (TID 1115) in 18 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:35.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 9.0 in stage 445.0 (TID 1117) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.377+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 8.0 in stage 445.0 (TID 1116) in 14 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:35.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 0.0 in stage 472.0 (TID 1118) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 9.0 in stage 445.0 (TID 1117) in 13 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:35.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSchedulerImpl: Removed TaskSet 445.0, whose tasks have all completed, from pool
[2025-05-07T21:43:35.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: ShuffleMapStage 445 (mapPartitions at GraphImpl.scala:208) finished in 0.183 s
[2025-05-07T21:43:35.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:35.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 472)
[2025-05-07T21:43:35.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 446, ShuffleMapStage 447)
[2025-05-07T21:43:35.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:35.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 446 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[374] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:35.391+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 17.1 KiB, free 377.3 MiB)
[2025-05-07T21:43:35.392+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 377.3 MiB)
[2025-05-07T21:43:35.393+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 3530b0b864fd:36239 (size: 6.6 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.393+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:35.393+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 446 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[374] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:35.393+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSchedulerImpl: Adding task set 446.0 with 10 tasks resource profile 0
[2025-05-07T21:43:35.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 172.20.0.5:36323 (size: 30.3 KiB, free: 433.0 MiB)
[2025-05-07T21:43:35.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:40082
[2025-05-07T21:43:35.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 0.0 in stage 446.0 (TID 1119) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 0.0 in stage 472.0 (TID 1118) in 26 ms on 172.20.0.5 (executor 2) (1/6)
[2025-05-07T21:43:35.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 172.20.0.5:36323 (size: 6.6 KiB, free: 433.0 MiB)
[2025-05-07T21:43:35.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:35.426+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:40082
[2025-05-07T21:43:35.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:40082
[2025-05-07T21:43:35.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:40082
[2025-05-07T21:43:35.431+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:40082
[2025-05-07T21:43:35.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:40082
[2025-05-07T21:43:35.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:40082
[2025-05-07T21:43:35.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:40082
[2025-05-07T21:43:35.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 1.0 in stage 446.0 (TID 1120) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 0.0 in stage 446.0 (TID 1119) in 54 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:35.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 2.0 in stage 446.0 (TID 1121) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 1.0 in stage 446.0 (TID 1120) in 25 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:35.534+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 3.0 in stage 446.0 (TID 1122) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 2.0 in stage 446.0 (TID 1121) in 40 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:35.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 4.0 in stage 446.0 (TID 1123) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 3.0 in stage 446.0 (TID 1122) in 58 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:35.594+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 3530b0b864fd:36239 in memory (size: 58.5 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 172.20.0.5:36323 in memory (size: 58.5 KiB, free: 433.1 MiB)
[2025-05-07T21:43:35.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 5.0 in stage 446.0 (TID 1124) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 4.0 in stage 446.0 (TID 1123) in 53 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:35.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 6.0 in stage 446.0 (TID 1125) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 5.0 in stage 446.0 (TID 1124) in 29 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:35.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 7.0 in stage 446.0 (TID 1126) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 6.0 in stage 446.0 (TID 1125) in 31 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:35.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 8.0 in stage 446.0 (TID 1127) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 7.0 in stage 446.0 (TID 1126) in 47 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:35.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 9.0 in stage 446.0 (TID 1128) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 8.0 in stage 446.0 (TID 1127) in 28 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:35.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 1.0 in stage 472.0 (TID 1129) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.792+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 9.0 in stage 446.0 (TID 1128) in 31 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:35.792+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSchedulerImpl: Removed TaskSet 446.0, whose tasks have all completed, from pool
[2025-05-07T21:43:35.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: ShuffleMapStage 446 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.402 s
[2025-05-07T21:43:35.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:35.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 472)
[2025-05-07T21:43:35.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450, ShuffleMapStage 447)
[2025-05-07T21:43:35.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:35.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 447 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[378] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:35.800+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:40082
[2025-05-07T21:43:35.811+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 166.0 KiB, free 377.4 MiB)
[2025-05-07T21:43:35.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 377.3 MiB)
[2025-05-07T21:43:35.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 3530b0b864fd:36239 (size: 58.5 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:35.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 447 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[378] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:35.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSchedulerImpl: Adding task set 447.0 with 10 tasks resource profile 0
[2025-05-07T21:43:35.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 0.0 in stage 447.0 (TID 1130) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 1.0 in stage 472.0 (TID 1129) in 65 ms on 172.20.0.5 (executor 2) (2/6)
[2025-05-07T21:43:35.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 172.20.0.5:36323 (size: 58.5 KiB, free: 433.0 MiB)
[2025-05-07T21:43:35.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:35.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:35.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:40082
[2025-05-07T21:43:35.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:40082
[2025-05-07T21:43:35.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:40082
[2025-05-07T21:43:35.880+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:40082
[2025-05-07T21:43:35.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:40082
[2025-05-07T21:43:35.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:40082
[2025-05-07T21:43:35.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:40082
[2025-05-07T21:43:35.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:40082
[2025-05-07T21:43:35.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 3530b0b864fd:36239 in memory (size: 6.5 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 1.0 in stage 447.0 (TID 1131) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 172.20.0.5:36323 in memory (size: 6.5 KiB, free: 433.0 MiB)
[2025-05-07T21:43:35.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 0.0 in stage 447.0 (TID 1130) in 57 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:35.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 3530b0b864fd:36239 in memory (size: 8.3 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 172.20.0.5:36323 in memory (size: 8.3 KiB, free: 433.0 MiB)
[2025-05-07T21:43:35.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 172.20.0.5:36323 in memory (size: 3.8 KiB, free: 433.0 MiB)
[2025-05-07T21:43:35.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 172.20.0.5:36323 in memory (size: 3.8 KiB, free: 433.1 MiB)
[2025-05-07T21:43:35.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 431.4 MiB)
[2025-05-07T21:43:35.932+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 172.20.0.5:36323 in memory (size: 3.8 KiB, free: 433.1 MiB)
[2025-05-07T21:43:35.938+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 2.0 in stage 447.0 (TID 1132) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.939+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 1.0 in stage 447.0 (TID 1131) in 31 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:35.961+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 3.0 in stage 447.0 (TID 1133) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.962+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 2.0 in stage 447.0 (TID 1132) in 24 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:35.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 4.0 in stage 447.0 (TID 1134) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 3.0 in stage 447.0 (TID 1133) in 18 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:35.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Starting task 5.0 in stage 447.0 (TID 1135) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:35.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:35 INFO TaskSetManager: Finished task 4.0 in stage 447.0 (TID 1134) in 18 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:36.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 6.0 in stage 447.0 (TID 1136) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 5.0 in stage 447.0 (TID 1135) in 28 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:36.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 7.0 in stage 447.0 (TID 1137) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 6.0 in stage 447.0 (TID 1136) in 17 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:36.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 8.0 in stage 447.0 (TID 1138) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 7.0 in stage 447.0 (TID 1137) in 16 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:36.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 9.0 in stage 447.0 (TID 1139) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 8.0 in stage 447.0 (TID 1138) in 15 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:36.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 2.0 in stage 472.0 (TID 1140) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 9.0 in stage 447.0 (TID 1139) in 16 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:36.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSchedulerImpl: Removed TaskSet 447.0, whose tasks have all completed, from pool
[2025-05-07T21:43:36.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: ShuffleMapStage 447 (mapPartitions at GraphImpl.scala:208) finished in 0.293 s
[2025-05-07T21:43:36.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:36.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 472)
[2025-05-07T21:43:36.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 450)
[2025-05-07T21:43:36.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:36.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: Submitting ShuffleMapStage 448 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[386] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:43:36.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 17.8 KiB, free 377.4 MiB)
[2025-05-07T21:43:36.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 377.4 MiB)
[2025-05-07T21:43:36.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 3530b0b864fd:36239 (size: 6.7 KiB, free: 431.4 MiB)
[2025-05-07T21:43:36.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:36.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 448 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[386] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:36.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSchedulerImpl: Adding task set 448.0 with 10 tasks resource profile 0
[2025-05-07T21:43:36.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:40082
[2025-05-07T21:43:36.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 0.0 in stage 448.0 (TID 1141) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 2.0 in stage 472.0 (TID 1140) in 20 ms on 172.20.0.5 (executor 2) (3/6)
[2025-05-07T21:43:36.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 172.20.0.5:36323 (size: 6.7 KiB, free: 433.0 MiB)
[2025-05-07T21:43:36.113+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:36.117+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:40082
[2025-05-07T21:43:36.118+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:40082
[2025-05-07T21:43:36.119+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:40082
[2025-05-07T21:43:36.120+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:40082
[2025-05-07T21:43:36.123+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:40082
[2025-05-07T21:43:36.129+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:40082
[2025-05-07T21:43:36.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:40082
[2025-05-07T21:43:36.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:40082
[2025-05-07T21:43:36.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 1.0 in stage 448.0 (TID 1142) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.202+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 0.0 in stage 448.0 (TID 1141) in 96 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:36.283+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 2.0 in stage 448.0 (TID 1143) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 1.0 in stage 448.0 (TID 1142) in 83 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:36.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 3.0 in stage 448.0 (TID 1144) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 2.0 in stage 448.0 (TID 1143) in 81 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:36.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 4.0 in stage 448.0 (TID 1145) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 3.0 in stage 448.0 (TID 1144) in 77 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:36.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 5.0 in stage 448.0 (TID 1146) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 4.0 in stage 448.0 (TID 1145) in 80 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:36.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 6.0 in stage 448.0 (TID 1147) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 5.0 in stage 448.0 (TID 1146) in 94 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:36.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 7.0 in stage 448.0 (TID 1148) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 6.0 in stage 448.0 (TID 1147) in 67 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:36.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 8.0 in stage 448.0 (TID 1149) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 7.0 in stage 448.0 (TID 1148) in 46 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:36.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 9.0 in stage 448.0 (TID 1150) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 8.0 in stage 448.0 (TID 1149) in 59 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:36.827+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 3.0 in stage 472.0 (TID 1151) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.827+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 9.0 in stage 448.0 (TID 1150) in 46 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:36.827+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSchedulerImpl: Removed TaskSet 448.0, whose tasks have all completed, from pool
[2025-05-07T21:43:36.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: ShuffleMapStage 448 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.740 s
[2025-05-07T21:43:36.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:36.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 472)
[2025-05-07T21:43:36.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 449, ShuffleMapStage 450)
[2025-05-07T21:43:36.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:36.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: Submitting ShuffleMapStage 449 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[390] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:43:36.832+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:40082
[2025-05-07T21:43:36.834+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 166.3 KiB, free 377.2 MiB)
[2025-05-07T21:43:36.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 377.2 MiB)
[2025-05-07T21:43:36.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 3530b0b864fd:36239 (size: 58.4 KiB, free: 431.3 MiB)
[2025-05-07T21:43:36.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:36.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 449 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[390] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:36.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSchedulerImpl: Adding task set 449.0 with 10 tasks resource profile 0
[2025-05-07T21:43:36.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 0.0 in stage 449.0 (TID 1152) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 3.0 in stage 472.0 (TID 1151) in 17 ms on 172.20.0.5 (executor 2) (4/6)
[2025-05-07T21:43:36.848+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 172.20.0.5:36323 (size: 58.4 KiB, free: 433.0 MiB)
[2025-05-07T21:43:36.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:40082
[2025-05-07T21:43:36.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:40082
[2025-05-07T21:43:36.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:40082
[2025-05-07T21:43:36.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:40082
[2025-05-07T21:43:36.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:40082
[2025-05-07T21:43:36.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:40082
[2025-05-07T21:43:36.861+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:40082
[2025-05-07T21:43:36.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:40082
[2025-05-07T21:43:36.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:40082
[2025-05-07T21:43:36.865+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:40082
[2025-05-07T21:43:36.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.20.0.5:40082
[2025-05-07T21:43:36.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 1.0 in stage 449.0 (TID 1153) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 0.0 in stage 449.0 (TID 1152) in 31 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:36.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 2.0 in stage 449.0 (TID 1154) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 1.0 in stage 449.0 (TID 1153) in 20 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:36.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 3.0 in stage 449.0 (TID 1155) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 2.0 in stage 449.0 (TID 1154) in 20 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:36.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 4.0 in stage 449.0 (TID 1156) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 3.0 in stage 449.0 (TID 1155) in 29 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:36.982+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 5.0 in stage 449.0 (TID 1157) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.982+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 4.0 in stage 449.0 (TID 1156) in 39 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:36.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Starting task 6.0 in stage 449.0 (TID 1158) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:36.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:36 INFO TaskSetManager: Finished task 5.0 in stage 449.0 (TID 1157) in 18 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:37.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 7.0 in stage 449.0 (TID 1159) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 6.0 in stage 449.0 (TID 1158) in 23 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:37.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 8.0 in stage 449.0 (TID 1160) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 7.0 in stage 449.0 (TID 1159) in 24 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:37.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 9.0 in stage 449.0 (TID 1161) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 8.0 in stage 449.0 (TID 1160) in 24 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:37.083+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 4.0 in stage 472.0 (TID 1162) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.083+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 9.0 in stage 449.0 (TID 1161) in 16 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:37.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSchedulerImpl: Removed TaskSet 449.0, whose tasks have all completed, from pool
[2025-05-07T21:43:37.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: ShuffleMapStage 449 (mapPartitions at GraphImpl.scala:208) finished in 0.255 s
[2025-05-07T21:43:37.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:37.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 472)
[2025-05-07T21:43:37.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 450)
[2025-05-07T21:43:37.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:37.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Submitting ShuffleMapStage 450 (MapPartitionsRDD[694] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:37.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 31.6 KiB, free 377.1 MiB)
[2025-05-07T21:43:37.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 377.1 MiB)
[2025-05-07T21:43:37.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 3530b0b864fd:36239 (size: 11.8 KiB, free: 431.3 MiB)
[2025-05-07T21:43:37.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:37.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 450 (MapPartitionsRDD[694] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:43:37.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSchedulerImpl: Adding task set 450.0 with 10 tasks resource profile 0
[2025-05-07T21:43:37.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:40082
[2025-05-07T21:43:37.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 0.0 in stage 450.0 (TID 1163) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 4.0 in stage 472.0 (TID 1162) in 23 ms on 172.20.0.5 (executor 2) (5/6)
[2025-05-07T21:43:37.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 172.20.0.5:36323 (size: 11.8 KiB, free: 433.0 MiB)
[2025-05-07T21:43:37.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:40082
[2025-05-07T21:43:37.119+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:40082
[2025-05-07T21:43:37.120+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:40082
[2025-05-07T21:43:37.121+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:40082
[2025-05-07T21:43:37.123+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:40082
[2025-05-07T21:43:37.125+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:40082
[2025-05-07T21:43:37.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:40082
[2025-05-07T21:43:37.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:40082
[2025-05-07T21:43:37.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:40082
[2025-05-07T21:43:37.177+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.20.0.5:40082
[2025-05-07T21:43:37.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_0 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:43:37.181+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_0 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:43:37.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 1.0 in stage 450.0 (TID 1164) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 0.0 in stage 450.0 (TID 1163) in 90 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T21:43:37.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_1 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:43:37.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_1 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:43:37.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 2.0 in stage 450.0 (TID 1165) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 1.0 in stage 450.0 (TID 1164) in 125 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T21:43:37.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_2 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:43:37.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_2 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 3.0 in stage 450.0 (TID 1166) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 2.0 in stage 450.0 (TID 1165) in 65 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T21:43:37.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_3 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_3 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.452+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 4.0 in stage 450.0 (TID 1167) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 3.0 in stage 450.0 (TID 1166) in 68 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T21:43:37.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_4 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_4 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.518+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 5.0 in stage 450.0 (TID 1168) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 4.0 in stage 450.0 (TID 1167) in 66 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T21:43:37.570+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_5 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.578+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_5 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 6.0 in stage 450.0 (TID 1169) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 5.0 in stage 450.0 (TID 1168) in 65 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T21:43:37.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_6 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.630+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_6 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 7.0 in stage 450.0 (TID 1170) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 6.0 in stage 450.0 (TID 1169) in 53 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T21:43:37.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_7 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_7 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.700+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 8.0 in stage 450.0 (TID 1171) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.700+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 7.0 in stage 450.0 (TID 1170) in 64 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T21:43:37.745+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_8 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.746+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_8 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 9.0 in stage 450.0 (TID 1172) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 8.0 in stage 450.0 (TID 1171) in 50 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T21:43:37.811+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_394_9 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.812+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added rdd_404_9 in memory on 172.20.0.5:36323 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 5.0 in stage 472.0 (TID 1173) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 9.0 in stage 450.0 (TID 1172) in 66 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T21:43:37.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSchedulerImpl: Removed TaskSet 450.0, whose tasks have all completed, from pool
[2025-05-07T21:43:37.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: ShuffleMapStage 450 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.732 s
[2025-05-07T21:43:37.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:37.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 473, ShuffleMapStage 474, ResultStage 472)
[2025-05-07T21:43:37.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:37.817+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:37.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:40082
[2025-05-07T21:43:37.835+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 0.0 in stage 473.0 (TID 1174) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 5.0 in stage 472.0 (TID 1173) in 19 ms on 172.20.0.5 (executor 2) (6/6)
[2025-05-07T21:43:37.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSchedulerImpl: Removed TaskSet 472.0, whose tasks have all completed, from pool
[2025-05-07T21:43:37.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: ResultStage 472 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 3.568 s
[2025-05-07T21:43:37.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:37.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 472: Stage finished
[2025-05-07T21:43:37.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Job 102 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 3.571292 s
[2025-05-07T21:43:37.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 172.20.0.5:36323 (size: 8.2 KiB, free: 432.9 MiB)
[2025-05-07T21:43:37.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 2.3 MiB, free 374.9 MiB)
[2025-05-07T21:43:37.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 374.8 MiB)
[2025-05-07T21:43:37.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 3530b0b864fd:36239 (size: 114.2 KiB, free: 431.2 MiB)
[2025-05-07T21:43:37.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO SparkContext: Created broadcast 221 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:37.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:37.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 172.20.0.5:36323 (size: 32.6 KiB, free: 432.8 MiB)
[2025-05-07T21:43:37.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Registering RDD 795 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 91
[2025-05-07T21:43:37.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Got map stage job 106 (jdbc at NativeMethodAccessorImpl.java:0) with 11 output partitions
[2025-05-07T21:43:37.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Final stage: ShuffleMapStage 478 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:37.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 477)
[2025-05-07T21:43:37.890+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:37.890+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Submitting ShuffleMapStage 478 (MapPartitionsRDD[795] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:37.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 0.0 in stage 474.0 (TID 1175) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 0.0 in stage 473.0 (TID 1174) in 60 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:37.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSchedulerImpl: Removed TaskSet 473.0, whose tasks have all completed, from pool
[2025-05-07T21:43:37.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 141.2 KiB, free 374.6 MiB)
[2025-05-07T21:43:37.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 49.7 KiB, free 374.6 MiB)
[2025-05-07T21:43:37.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 3530b0b864fd:36239 (size: 49.7 KiB, free: 431.2 MiB)
[2025-05-07T21:43:37.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:37.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 478 (MapPartitionsRDD[795] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T21:43:37.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSchedulerImpl: Adding task set 478.0 with 11 tasks resource profile 0
[2025-05-07T21:43:37.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: ShuffleMapStage 473 (jdbc at NativeMethodAccessorImpl.java:0) finished in 3.399 s
[2025-05-07T21:43:37.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:37.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 474, ShuffleMapStage 478)
[2025-05-07T21:43:37.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:37.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:37.901+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 172.20.0.5:36323 (size: 33.9 KiB, free: 432.8 MiB)
[2025-05-07T21:43:37.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Starting task 0.0 in stage 476.0 (TID 1176) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:37.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSetManager: Finished task 0.0 in stage 474.0 (TID 1175) in 84 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:37.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO TaskSchedulerImpl: Removed TaskSet 474.0, whose tasks have all completed, from pool
[2025-05-07T21:43:37.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: ShuffleMapStage 474 (jdbc at NativeMethodAccessorImpl.java:0) finished in 3.468 s
[2025-05-07T21:43:37.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:37.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: running: Set(ResultStage 476, ShuffleMapStage 478)
[2025-05-07T21:43:37.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:37.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:37.990+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 3530b0b864fd:36239 in memory (size: 11.8 KiB, free: 431.2 MiB)
[2025-05-07T21:43:37.991+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 172.20.0.5:36323 in memory (size: 11.8 KiB, free: 432.8 MiB)
[2025-05-07T21:43:37.991+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 172.20.0.5:36323 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T21:43:37.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 3530b0b864fd:36239 in memory (size: 58.5 KiB, free: 431.2 MiB)
[2025-05-07T21:43:37.994+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:40082
[2025-05-07T21:43:37.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO ShufflePartitionsUtil: For shuffle(90), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:37.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:38.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 172.20.0.5:36323 in memory (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:43:38.008+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 0.0 in stage 478.0 (TID 1177) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.008+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 0.0 in stage 476.0 (TID 1176) in 29 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:38.008+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Removed TaskSet 476.0, whose tasks have all completed, from pool
[2025-05-07T21:43:38.008+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: ResultStage 476 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 3.231 s
[2025-05-07T21:43:38.009+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:38.009+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 476: Stage finished
[2025-05-07T21:43:38.009+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Job 105 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 3.232817 s
[2025-05-07T21:43:38.009+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 3530b0b864fd:36239 in memory (size: 6.7 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.014+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 172.20.0.5:36323 in memory (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:43:38.015+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 172.20.0.5:36323 (size: 49.7 KiB, free: 432.8 MiB)
[2025-05-07T21:43:38.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 3530b0b864fd:36239 in memory (size: 58.4 KiB, free: 431.3 MiB)
[2025-05-07T21:43:38.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:38.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Got job 107 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:43:38.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Final stage: ResultStage 480 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:43:38.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 479)
[2025-05-07T21:43:38.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:38.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting ResultStage 480 (MapPartitionsRDD[798] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:43:38.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:40082
[2025-05-07T21:43:38.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 172.20.0.5:36323 in memory (size: 58.4 KiB, free: 432.9 MiB)
[2025-05-07T21:43:38.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO CodeGenerator: Code generated in 10.294147 ms
[2025-05-07T21:43:38.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 73.5 KiB, free 375.0 MiB)
[2025-05-07T21:43:38.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 375.0 MiB)
[2025-05-07T21:43:38.025+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 3530b0b864fd:36239 (size: 32.5 KiB, free: 431.3 MiB)
[2025-05-07T21:43:38.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 3530b0b864fd:36239 in memory (size: 6.6 KiB, free: 431.3 MiB)
[2025-05-07T21:43:38.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:38.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 480 (MapPartitionsRDD[798] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:38.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Adding task set 480.0 with 1 tasks resource profile 0
[2025-05-07T21:43:38.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 1088.0 KiB, free 373.9 MiB)
[2025-05-07T21:43:38.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 373.9 MiB)
[2025-05-07T21:43:38.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 3530b0b864fd:36239 (size: 30.5 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 172.20.0.5:36323 in memory (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-07T21:43:38.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 224 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:38.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO ShufflePartitionsUtil: For shuffle(79), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:38.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO CodeGenerator: Code generated in 6.608148 ms
[2025-05-07T21:43:38.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Registering RDD 801 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 92
[2025-05-07T21:43:38.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Got map stage job 108 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:38.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Final stage: ShuffleMapStage 507 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:38.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 506)
[2025-05-07T21:43:38.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:38.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting ShuffleMapStage 507 (MapPartitionsRDD[801] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:38.065+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 13.8 KiB, free 373.9 MiB)
[2025-05-07T21:43:38.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 373.9 MiB)
[2025-05-07T21:43:38.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 3530b0b864fd:36239 (size: 6.9 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:38.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 507 (MapPartitionsRDD[801] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:38.075+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Adding task set 507.0 with 1 tasks resource profile 0
[2025-05-07T21:43:38.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 172.20.0.5:36323 (size: 502.1 KiB, free: 432.4 MiB)
[2025-05-07T21:43:38.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 172.20.0.5:36323 (size: 114.2 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 172.20.0.5:36323 (size: 20.6 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 3530b0b864fd:36239 in memory (size: 8.2 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.199+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 172.20.0.5:36323 in memory (size: 8.2 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.208+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 3530b0b864fd:36239 in memory (size: 30.3 KiB, free: 431.3 MiB)
[2025-05-07T21:43:38.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 172.20.0.5:36323 in memory (size: 30.3 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 3530b0b864fd:36239 in memory (size: 33.9 KiB, free: 431.3 MiB)
[2025-05-07T21:43:38.221+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 172.20.0.5:36323 in memory (size: 33.9 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 431.3 MiB)
[2025-05-07T21:43:38.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 172.20.0.5:36323 in memory (size: 3.8 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 1.0 in stage 478.0 (TID 1178) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.254+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 0.0 in stage 478.0 (TID 1177) in 247 ms on 172.20.0.5 (executor 2) (1/11)
[2025-05-07T21:43:38.281+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 2.0 in stage 478.0 (TID 1179) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 1.0 in stage 478.0 (TID 1178) in 32 ms on 172.20.0.5 (executor 2) (2/11)
[2025-05-07T21:43:38.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 3.0 in stage 478.0 (TID 1180) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 2.0 in stage 478.0 (TID 1179) in 33 ms on 172.20.0.5 (executor 2) (3/11)
[2025-05-07T21:43:38.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 4.0 in stage 478.0 (TID 1181) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 3.0 in stage 478.0 (TID 1180) in 27 ms on 172.20.0.5 (executor 2) (4/11)
[2025-05-07T21:43:38.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 5.0 in stage 478.0 (TID 1182) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 4.0 in stage 478.0 (TID 1181) in 31 ms on 172.20.0.5 (executor 2) (5/11)
[2025-05-07T21:43:38.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 6.0 in stage 478.0 (TID 1183) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 5.0 in stage 478.0 (TID 1182) in 15 ms on 172.20.0.5 (executor 2) (6/11)
[2025-05-07T21:43:38.407+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 7.0 in stage 478.0 (TID 1184) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.408+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 6.0 in stage 478.0 (TID 1183) in 23 ms on 172.20.0.5 (executor 2) (7/11)
[2025-05-07T21:43:38.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 8.0 in stage 478.0 (TID 1185) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 7.0 in stage 478.0 (TID 1184) in 34 ms on 172.20.0.5 (executor 2) (8/11)
[2025-05-07T21:43:38.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 9.0 in stage 478.0 (TID 1186) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 8.0 in stage 478.0 (TID 1185) in 20 ms on 172.20.0.5 (executor 2) (9/11)
[2025-05-07T21:43:38.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 10.0 in stage 478.0 (TID 1187) (172.20.0.5, executor 2, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 9.0 in stage 478.0 (TID 1186) in 25 ms on 172.20.0.5 (executor 2) (10/11)
[2025-05-07T21:43:38.581+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 0.0 in stage 480.0 (TID 1188) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 10.0 in stage 478.0 (TID 1187) in 98 ms on 172.20.0.5 (executor 2) (11/11)
[2025-05-07T21:43:38.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Removed TaskSet 478.0, whose tasks have all completed, from pool
[2025-05-07T21:43:38.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: ShuffleMapStage 478 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.690 s
[2025-05-07T21:43:38.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:38.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: running: Set(ShuffleMapStage 507, ResultStage 480)
[2025-05-07T21:43:38.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:38.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:38.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO ShufflePartitionsUtil: For shuffle(91), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:38.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 172.20.0.5:36323 (size: 32.5 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:38.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:40082
[2025-05-07T21:43:38.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Registering RDD 804 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 93
[2025-05-07T21:43:38.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Got map stage job 109 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:38.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Final stage: ShuffleMapStage 510 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:38.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 509)
[2025-05-07T21:43:38.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:38.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting ShuffleMapStage 510 (MapPartitionsRDD[804] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:38.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 130.2 KiB, free 374.0 MiB)
[2025-05-07T21:43:38.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 44.5 KiB, free 374.0 MiB)
[2025-05-07T21:43:38.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 3530b0b864fd:36239 (size: 44.5 KiB, free: 431.3 MiB)
[2025-05-07T21:43:38.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:38.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 510 (MapPartitionsRDD[804] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:38.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Adding task set 510.0 with 1 tasks resource profile 0
[2025-05-07T21:43:38.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 0.0 in stage 507.0 (TID 1189) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4462 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 0.0 in stage 480.0 (TID 1188) in 45 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:38.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Removed TaskSet 480.0, whose tasks have all completed, from pool
[2025-05-07T21:43:38.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: ResultStage 480 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.607 s
[2025-05-07T21:43:38.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:38.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 480: Stage finished
[2025-05-07T21:43:38.628+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Job 107 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.609875 s
[2025-05-07T21:43:38.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 1088.0 KiB, free 372.9 MiB)
[2025-05-07T21:43:38.633+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 22.4 KiB, free 372.9 MiB)
[2025-05-07T21:43:38.633+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 3530b0b864fd:36239 (size: 22.4 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.634+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 227 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:38.635+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 172.20.0.5:36323 (size: 6.9 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:40082
[2025-05-07T21:43:38.648+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 172.20.0.5:36323 (size: 30.5 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 0.0 in stage 510.0 (TID 1190) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.667+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 0.0 in stage 507.0 (TID 1189) in 40 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:38.667+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Removed TaskSet 507.0, whose tasks have all completed, from pool
[2025-05-07T21:43:38.667+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: ShuffleMapStage 507 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.604 s
[2025-05-07T21:43:38.667+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:38.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: running: Set(ShuffleMapStage 510)
[2025-05-07T21:43:38.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:38.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:38.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO ShufflePartitionsUtil: For shuffle(92), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:38.674+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 172.20.0.5:36323 (size: 44.5 KiB, free: 432.2 MiB)
[2025-05-07T21:43:38.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:38.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Got job 110 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:43:38.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Final stage: ResultStage 538 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:43:38.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 537)
[2025-05-07T21:43:38.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:38.687+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting ResultStage 538 (MapPartitionsRDD[806] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:43:38.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 7.2 KiB, free 372.9 MiB)
[2025-05-07T21:43:38.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 372.9 MiB)
[2025-05-07T21:43:38.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 3530b0b864fd:36239 (size: 3.8 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:38.689+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 538 (MapPartitionsRDD[806] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:38.689+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Adding task set 538.0 with 1 tasks resource profile 0
[2025-05-07T21:43:38.712+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:40082
[2025-05-07T21:43:38.772+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 0.0 in stage 538.0 (TID 1191) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 0.0 in stage 510.0 (TID 1190) in 106 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:38.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Removed TaskSet 510.0, whose tasks have all completed, from pool
[2025-05-07T21:43:38.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: ShuffleMapStage 510 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.159 s
[2025-05-07T21:43:38.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:43:38.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: running: Set(ResultStage 538)
[2025-05-07T21:43:38.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:43:38.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: failed: Set()
[2025-05-07T21:43:38.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO ShufflePartitionsUtil: For shuffle(93), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:38.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:43:38.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 172.20.0.5:36323 (size: 3.8 KiB, free: 432.2 MiB)
[2025-05-07T21:43:38.785+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:40082
[2025-05-07T21:43:38.800+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 0.0 in stage 538.0 (TID 1191) in 28 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:38.801+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Removed TaskSet 538.0, whose tasks have all completed, from pool
[2025-05-07T21:43:38.802+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: ResultStage 538 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.116 s
[2025-05-07T21:43:38.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Job 110 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:38.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 538: Stage finished
[2025-05-07T21:43:38.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Job 110 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.120778 s
[2025-05-07T21:43:38.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 2.1 MiB, free 370.8 MiB)
[2025-05-07T21:43:38.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 370.8 MiB)
[2025-05-07T21:43:38.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 3530b0b864fd:36239 (size: 20.7 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 229 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:38.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:38.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Got job 111 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:43:38.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Final stage: ResultStage 542 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:43:38.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 541)
[2025-05-07T21:43:38.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:38.816+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting ResultStage 542 (MapPartitionsRDD[809] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:43:38.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 122.7 KiB, free 370.7 MiB)
[2025-05-07T21:43:38.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 370.6 MiB)
[2025-05-07T21:43:38.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 3530b0b864fd:36239 (size: 41.8 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:38.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 542 (MapPartitionsRDD[809] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:38.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Adding task set 542.0 with 1 tasks resource profile 0
[2025-05-07T21:43:38.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 0.0 in stage 542.0 (TID 1192) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.827+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 172.20.0.5:36323 (size: 41.8 KiB, free: 432.2 MiB)
[2025-05-07T21:43:38.834+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:40082
[2025-05-07T21:43:38.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Finished task 0.0 in stage 542.0 (TID 1192) in 30 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:38.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Removed TaskSet 542.0, whose tasks have all completed, from pool
[2025-05-07T21:43:38.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: ResultStage 542 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.035 s
[2025-05-07T21:43:38.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:38.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 542: Stage finished
[2025-05-07T21:43:38.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Job 111 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.037053 s
[2025-05-07T21:43:38.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 2.1 MiB, free 368.6 MiB)
[2025-05-07T21:43:38.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 82.5 KiB, free 368.5 MiB)
[2025-05-07T21:43:38.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 3530b0b864fd:36239 (size: 82.5 KiB, free: 431.1 MiB)
[2025-05-07T21:43:38.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 231 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:43:38.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO ShufflePartitionsUtil: For shuffle(89), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:43:38.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 3530b0b864fd:36239 in memory (size: 32.5 KiB, free: 431.1 MiB)
[2025-05-07T21:43:38.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 172.20.0.5:36323 in memory (size: 32.5 KiB, free: 432.2 MiB)
[2025-05-07T21:43:38.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 3530b0b864fd:36239 in memory (size: 3.8 KiB, free: 431.1 MiB)
[2025-05-07T21:43:38.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 172.20.0.5:36323 in memory (size: 3.8 KiB, free: 432.2 MiB)
[2025-05-07T21:43:38.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 3530b0b864fd:36239 in memory (size: 6.9 KiB, free: 431.1 MiB)
[2025-05-07T21:43:38.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 172.20.0.5:36323 in memory (size: 6.9 KiB, free: 432.2 MiB)
[2025-05-07T21:43:38.880+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 3530b0b864fd:36239 in memory (size: 41.8 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 172.20.0.5:36323 in memory (size: 41.8 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 3530b0b864fd:36239 in memory (size: 44.5 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 172.20.0.5:36323 in memory (size: 44.5 KiB, free: 432.3 MiB)
[2025-05-07T21:43:38.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-05-07T21:43:38.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Got job 112 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:43:38.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Final stage: ResultStage 544 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:43:38.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 543)
[2025-05-07T21:43:38.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:43:38.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting ResultStage 544 (MapPartitionsRDD[814] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:43:38.933+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 204.3 KiB, free 368.8 MiB)
[2025-05-07T21:43:38.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 72.4 KiB, free 368.7 MiB)
[2025-05-07T21:43:38.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 3530b0b864fd:36239 (size: 72.4 KiB, free: 431.2 MiB)
[2025-05-07T21:43:38.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:43:38.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 544 (MapPartitionsRDD[814] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:43:38.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSchedulerImpl: Adding task set 544.0 with 1 tasks resource profile 0
[2025-05-07T21:43:38.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO TaskSetManager: Starting task 0.0 in stage 544.0 (TID 1193) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:43:38.940+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 172.20.0.5:36323 (size: 72.4 KiB, free: 432.2 MiB)
[2025-05-07T21:43:38.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:40082
[2025-05-07T21:43:38.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 172.20.0.5:36323 (size: 20.7 KiB, free: 432.2 MiB)
[2025-05-07T21:43:38.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 172.20.0.5:36323 (size: 82.5 KiB, free: 432.1 MiB)
[2025-05-07T21:43:38.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:38 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 172.20.0.5:36323 (size: 22.4 KiB, free: 432.1 MiB)
[2025-05-07T21:43:39.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO TaskSetManager: Finished task 0.0 in stage 544.0 (TID 1193) in 164 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T21:43:39.100+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO TaskSchedulerImpl: Removed TaskSet 544.0, whose tasks have all completed, from pool
[2025-05-07T21:43:39.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO DAGScheduler: ResultStage 544 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.189 s
[2025-05-07T21:43:39.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:43:39.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 544: Stage finished
[2025-05-07T21:43:39.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO DAGScheduler: Job 112 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.191059 s
[2025-05-07T21:43:39.128+0000] {spark_submit.py:571} INFO - 2025-05-07 21:43:39,127 [INFO] Анализ графа успешно завершен
[2025-05-07T21:43:39.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO SparkUI: Stopped Spark web UI at http://3530b0b864fd:4040
[2025-05-07T21:43:39.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-05-07T21:43:39.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2025-05-07T21:43:39.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-07T21:43:39.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO MemoryStore: MemoryStore cleared
[2025-05-07T21:43:39.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO BlockManager: BlockManager stopped
[2025-05-07T21:43:39.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-07T21:43:39.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-07T21:43:39.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:39 INFO SparkContext: Successfully stopped SparkContext
[2025-05-07T21:43:39.422+0000] {spark_submit.py:571} INFO - 2025-05-07 21:43:39,421 [INFO] SparkSession остановлена
[2025-05-07T21:43:40.197+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:40 INFO ShutdownHookManager: Shutdown hook called
[2025-05-07T21:43:40.198+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-f267d2b8-753f-4e5d-a947-43ac110363f1/pyspark-8bf28da5-fe1a-4a5f-a45d-610cadd2fa51
[2025-05-07T21:43:40.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-f267d2b8-753f-4e5d-a947-43ac110363f1
[2025-05-07T21:43:40.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:43:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-9fcd31d1-1b49-4704-9206-28dc46724c75
[2025-05-07T21:43:40.324+0000] {taskinstance.py:1345} INFO - Marking task as SUCCESS. dag_id=graph_analysis, task_id=build_graph, execution_date=20250507T212946, start_date=20250507T213446, end_date=20250507T214340
[2025-05-07T21:43:40.428+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2025-05-07T21:43:40.473+0000] {taskinstance.py:2653} INFO - 1 downstream tasks scheduled from follow-on schedule check
