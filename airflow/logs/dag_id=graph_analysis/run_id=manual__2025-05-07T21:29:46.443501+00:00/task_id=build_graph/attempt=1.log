[2025-05-07T21:29:54.685+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-07T21:29:46.443501+00:00 [queued]>
[2025-05-07T21:29:54.692+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-07T21:29:46.443501+00:00 [queued]>
[2025-05-07T21:29:54.692+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 2
[2025-05-07T21:29:54.701+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): build_graph> on 2025-05-07 21:29:46.443501+00:00
[2025-05-07T21:29:54.705+0000] {standard_task_runner.py:57} INFO - Started process 9754 to run task
[2025-05-07T21:29:54.707+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'graph_analysis', 'build_graph', 'manual__2025-05-07T21:29:46.443501+00:00', '--job-id', '282', '--raw', '--subdir', 'DAGS_FOLDER/graph_analysis.py', '--cfg-path', '/tmp/tmpc81xhrto']
[2025-05-07T21:29:54.708+0000] {standard_task_runner.py:85} INFO - Job 282: Subtask build_graph
[2025-05-07T21:29:54.719+0000] {logging_mixin.py:150} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-07T21:29:54.746+0000] {task_command.py:410} INFO - Running <TaskInstance: graph_analysis.build_graph manual__2025-05-07T21:29:46.443501+00:00 [running]> on host 3530b0b864fd
[2025-05-07T21:29:54.814+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='finbest' AIRFLOW_CTX_DAG_ID='graph_analysis' AIRFLOW_CTX_TASK_ID='build_graph' AIRFLOW_CTX_EXECUTION_DATE='2025-05-07T21:29:46.443501+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-07T21:29:46.443501+00:00'
[2025-05-07T21:29:54.822+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-05-07T21:29:54.823+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******
[2025-05-07T21:29:54.837+0000] {spark_submit.py:571} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-05-07T21:29:55.760+0000] {spark_submit.py:571} INFO - Using properties file: null
[2025-05-07T21:29:55.834+0000] {spark_submit.py:571} INFO - WARNING: An illegal reflective access operation has occurred
[2025-05-07T21:29:55.834+0000] {spark_submit.py:571} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2025-05-07T21:29:55.834+0000] {spark_submit.py:571} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2025-05-07T21:29:55.834+0000] {spark_submit.py:571} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-05-07T21:29:55.835+0000] {spark_submit.py:571} INFO - WARNING: All illegal access operations will be denied in a future release
[2025-05-07T21:29:55.870+0000] {spark_submit.py:571} INFO - Parsed arguments:
[2025-05-07T21:29:55.870+0000] {spark_submit.py:571} INFO - master                  spark://spark-master:7077
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - deployMode              null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - executorMemory          1g
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - executorCores           1
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - totalExecutorCores      null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - propertiesFile          null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - driverMemory            1g
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - driverCores             null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - driverExtraClassPath    null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - driverExtraLibraryPath  null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - driverExtraJavaOptions  null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - supervise               false
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - queue                   null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - numExecutors            null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - files                   null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - pyFiles                 null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - archives                null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - mainClass               null
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - primaryResource         file:/opt/airflow/spark/build_graph.py
[2025-05-07T21:29:55.871+0000] {spark_submit.py:571} INFO - name                    arrow-spark
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - childArgs               [--jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ***]
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - jars                    null
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - packages                org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - packagesExclusions      null
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - repositories            null
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - verbose                 true
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - Spark properties used, including those specified through
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - --conf and those from the properties file null:
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:29:55.872+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:29:55.985+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-07T21:29:56.065+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-05-07T21:29:56.065+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-05-07T21:29:56.068+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql added as a dependency
[2025-05-07T21:29:56.068+0000] {spark_submit.py:571} INFO - graphframes#graphframes added as a dependency
[2025-05-07T21:29:56.069+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-a82d6751-9491-4c4c-8cc4-5f11d844d6d0;1.0
[2025-05-07T21:29:56.069+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-07T21:29:56.160+0000] {spark_submit.py:571} INFO - found org.postgresql#postgresql;42.6.0 in central
[2025-05-07T21:29:56.184+0000] {spark_submit.py:571} INFO - found org.checkerframework#checker-qual;3.31.0 in central
[2025-05-07T21:29:56.203+0000] {spark_submit.py:571} INFO - found graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages
[2025-05-07T21:29:56.221+0000] {spark_submit.py:571} INFO - found org.slf4j#slf4j-api;1.7.16 in central
[2025-05-07T21:29:56.247+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 166ms :: artifacts dl 12ms
[2025-05-07T21:29:56.247+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-05-07T21:29:56.247+0000] {spark_submit.py:571} INFO - graphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]
[2025-05-07T21:29:56.247+0000] {spark_submit.py:571} INFO - org.checkerframework#checker-qual;3.31.0 from central in [default]
[2025-05-07T21:29:56.247+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql;42.6.0 from central in [default]
[2025-05-07T21:29:56.247+0000] {spark_submit.py:571} INFO - org.slf4j#slf4j-api;1.7.16 from central in [default]
[2025-05-07T21:29:56.247+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T21:29:56.247+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-05-07T21:29:56.248+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-07T21:29:56.248+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T21:29:56.248+0000] {spark_submit.py:571} INFO - |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
[2025-05-07T21:29:56.248+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T21:29:56.253+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-a82d6751-9491-4c4c-8cc4-5f11d844d6d0
[2025-05-07T21:29:56.253+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-07T21:29:56.258+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 4 already retrieved (0kB/6ms)
[2025-05-07T21:29:56.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-07T21:29:56.667+0000] {spark_submit.py:571} INFO - Main class:
[2025-05-07T21:29:56.667+0000] {spark_submit.py:571} INFO - org.apache.spark.deploy.PythonRunner
[2025-05-07T21:29:56.667+0000] {spark_submit.py:571} INFO - Arguments:
[2025-05-07T21:29:56.667+0000] {spark_submit.py:571} INFO - file:/opt/airflow/spark/build_graph.py
[2025-05-07T21:29:56.667+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T21:29:56.667+0000] {spark_submit.py:571} INFO - --jdbc
[2025-05-07T21:29:56.667+0000] {spark_submit.py:571} INFO - jdbc:postgresql://postgres:5432/finbest
[2025-05-07T21:29:56.667+0000] {spark_submit.py:571} INFO - --user
[2025-05-07T21:29:56.668+0000] {spark_submit.py:571} INFO - finbest
[2025-05-07T21:29:56.668+0000] {spark_submit.py:571} INFO - --password
[2025-05-07T21:29:56.668+0000] {spark_submit.py:571} INFO - ***
[2025-05-07T21:29:56.669+0000] {spark_submit.py:571} INFO - Spark config:
[2025-05-07T21:29:56.669+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-07T21:29:56.669+0000] {spark_submit.py:571} INFO - (spark.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T21:29:56.669+0000] {spark_submit.py:571} INFO - (spark.app.name,arrow-spark)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - (spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,/home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,/home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,/home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - (spark.files,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - (spark.submit.deployMode,client)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - (spark.master,spark://spark-master:7077)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - (spark.executor.memory,1g)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - (spark.executor.cores,1)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - (spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - Classpath elements:
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:29:56.670+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:29:57.886+0000] {spark_submit.py:571} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2025-05-07T21:29:57.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:57 INFO SparkContext: Running Spark version 3.2.4
[2025-05-07T21:29:57.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:57 INFO ResourceUtils: ==============================================================
[2025-05-07T21:29:57.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:57 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-07T21:29:57.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:57 INFO ResourceUtils: ==============================================================
[2025-05-07T21:29:57.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:57 INFO SparkContext: Submitted application: FinBestGraphAnalysis
[2025-05-07T21:29:57.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-07T21:29:57.948+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:57 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-05-07T21:29:57.950+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:57 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-07T21:29:58.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:57 INFO SecurityManager: Changing view acls to: airflow
[2025-05-07T21:29:58.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SecurityManager: Changing modify acls to: airflow
[2025-05-07T21:29:58.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SecurityManager: Changing view acls groups to:
[2025-05-07T21:29:58.001+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SecurityManager: Changing modify acls groups to:
[2025-05-07T21:29:58.001+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(airflow); groups with view permissions: Set(); users  with modify permissions: Set(airflow); groups with modify permissions: Set()
[2025-05-07T21:29:58.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO Utils: Successfully started service 'sparkDriver' on port 37769.
[2025-05-07T21:29:58.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkEnv: Registering MapOutputTracker
[2025-05-07T21:29:58.277+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-07T21:29:58.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-07T21:29:58.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-07T21:29:58.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-07T21:29:58.322+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6cf9a346-e11f-46fa-aa04-c6f96d5c2a0b
[2025-05-07T21:29:58.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-07T21:29:58.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-07T21:29:58.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-07T21:29:58.557+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://3530b0b864fd:4040
[2025-05-07T21:29:58.570+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://3530b0b864fd:37769/jars/org.postgresql_postgresql-42.6.0.jar with timestamp 1746653397884
[2025-05-07T21:29:58.570+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://3530b0b864fd:37769/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746653397884
[2025-05-07T21:29:58.570+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://3530b0b864fd:37769/jars/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746653397884
[2025-05-07T21:29:58.570+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://3530b0b864fd:37769/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746653397884
[2025-05-07T21:29:58.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://3530b0b864fd:37769/files/org.postgresql_postgresql-42.6.0.jar with timestamp 1746653397884
[2025-05-07T21:29:58.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO Utils: Copying /home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar to /tmp/spark-fdb5943c-4a04-43a7-a00f-ce4c15af2a18/userFiles-b73ac464-6dbe-4d65-8c33-9187ef5b8603/org.postgresql_postgresql-42.6.0.jar
[2025-05-07T21:29:58.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://3530b0b864fd:37769/files/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746653397884
[2025-05-07T21:29:58.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO Utils: Copying /home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar to /tmp/spark-fdb5943c-4a04-43a7-a00f-ce4c15af2a18/userFiles-b73ac464-6dbe-4d65-8c33-9187ef5b8603/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-07T21:29:58.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://3530b0b864fd:37769/files/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746653397884
[2025-05-07T21:29:58.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO Utils: Copying /home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar to /tmp/spark-fdb5943c-4a04-43a7-a00f-ce4c15af2a18/userFiles-b73ac464-6dbe-4d65-8c33-9187ef5b8603/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-07T21:29:58.589+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://3530b0b864fd:37769/files/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746653397884
[2025-05-07T21:29:58.590+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO Utils: Copying /home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-fdb5943c-4a04-43a7-a00f-ce4c15af2a18/userFiles-b73ac464-6dbe-4d65-8c33-9187ef5b8603/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T21:29:58.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-05-07T21:29:58.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.2:7077 after 21 ms (0 ms spent in bootstraps)
[2025-05-07T21:29:58.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250507212958-0004
[2025-05-07T21:29:58.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250507212958-0004/0 on worker-20250507121535-172.20.0.5-41865 (172.20.0.5:41865) with 1 core(s)
[2025-05-07T21:29:58.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45373.
[2025-05-07T21:29:58.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO NettyBlockTransferService: Server created on 3530b0b864fd:45373
[2025-05-07T21:29:58.843+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20250507212958-0004/0 on hostPort 172.20.0.5:41865 with 1 core(s), 1024.0 MiB RAM
[2025-05-07T21:29:58.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-07T21:29:58.849+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 3530b0b864fd, 45373, None)
[2025-05-07T21:29:58.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO BlockManagerMasterEndpoint: Registering block manager 3530b0b864fd:45373 with 434.4 MiB RAM, BlockManagerId(driver, 3530b0b864fd, 45373, None)
[2025-05-07T21:29:58.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 3530b0b864fd, 45373, None)
[2025-05-07T21:29:58.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 3530b0b864fd, 45373, None)
[2025-05-07T21:29:58.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507212958-0004/0 is now RUNNING
[2025-05-07T21:29:59.029+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:59 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-05-07T21:29:59.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:59 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-07T21:29:59.195+0000] {spark_submit.py:571} INFO - 25/05/07 21:29:59 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-05-07T21:29:59.947+0000] {spark_submit.py:571} INFO - 2025-05-07 21:29:59,947 [INFO] SparkSession создана
[2025-05-07T21:29:59.948+0000] {spark_submit.py:571} INFO - 2025-05-07 21:29:59,947 [INFO] Загружаем клиентов и транзакции
[2025-05-07T21:30:04.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:43654) with ID 0,  ResourceProfileId 0
[2025-05-07T21:30:04.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:46863 with 434.4 MiB RAM, BlockManagerId(0, 172.20.0.5, 46863, None)
[2025-05-07T21:30:04.689+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO CodeGenerator: Code generated in 97.238678 ms
[2025-05-07T21:30:04.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-05-07T21:30:04.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:30:04.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:30:04.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:04.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:04.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:30:04.835+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-07T21:30:04.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-07T21:30:04.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 3530b0b864fd:45373 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:04.865+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:04.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:04.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-07T21:30:04.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:05.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.5:46863 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:05.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1094 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:05.994+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-07T21:30:06.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.253 s
[2025-05-07T21:30:06.001+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:06.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:06.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:06.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:06.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO CodeGenerator: Code generated in 9.669103 ms
[2025-05-07T21:30:06.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-07T21:30:06.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:30:06.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:30:06.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-07T21:30:06.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:06.075+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:30:06.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-07T21:30:06.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-07T21:30:06.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 3530b0b864fd:45373 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:06.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:06.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-07T21:30:06.095+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:06.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.20.0.5:43654
[2025-05-07T21:30:06.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 201 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:06.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-07T21:30:06.295+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.214 s
[2025-05-07T21:30:06.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:06.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-07T21:30:06.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.226860 s
[2025-05-07T21:30:06.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Registering RDD 8 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-05-07T21:30:06.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:30:06.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:30:06.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:06.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:06.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:30:06.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-07T21:30:06.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.3 MiB)
[2025-05-07T21:30:06.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 3530b0b864fd:45373 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:06.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:06.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-05-07T21:30:06.355+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:06.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.0.5:46863 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 40 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:06.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-07T21:30:06.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.049 s
[2025-05-07T21:30:06.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:06.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:06.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:06.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:06.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-07T21:30:06.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T21:30:06.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T21:30:06.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-07T21:30:06.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:06.438+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T21:30:06.441+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-07T21:30:06.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.3 MiB)
[2025-05-07T21:30:06.446+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 3530b0b864fd:45373 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:06.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:06.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-07T21:30:06.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:06.476+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 3530b0b864fd:45373 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.476+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.0.5:46863 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.486+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 3530b0b864fd:45373 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.490+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.0.5:46863 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.490+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.20.0.5:43654
[2025-05-07T21:30:06.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 3530b0b864fd:45373 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.5:46863 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:06.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 53 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:06.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-07T21:30:06.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.064 s
[2025-05-07T21:30:06.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:06.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-05-07T21:30:06.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:06 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.069571 s
[2025-05-07T21:30:06.507+0000] {spark_submit.py:571} INFO - 2025-05-07 21:30:06,506 [INFO] Загружено 4652 транзакций и 1200 клиентов
[2025-05-07T21:30:06.723+0000] {spark_submit.py:571} INFO - 2025-05-07 21:30:06,723 [INFO] Создаем вершины двудольного графа
[2025-05-07T21:30:07.115+0000] {spark_submit.py:571} INFO - 2025-05-07 21:30:07,115 [INFO] Создаем ATM-хабы
[2025-05-07T21:30:07.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 3530b0b864fd:45373 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:07.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.5:46863 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:07.309+0000] {spark_submit.py:571} INFO - 2025-05-07 21:30:07,309 [INFO] Объединяем ребра двудольного графа
[2025-05-07T21:30:07.409+0000] {spark_submit.py:571} INFO - 2025-05-07 21:30:07,409 [INFO] Создаем P2P-слой
[2025-05-07T21:30:07.446+0000] {spark_submit.py:571} INFO - 2025-05-07 21:30:07,446 [INFO] Создаем проекцию клиент-клиент
[2025-05-07T21:30:08.061+0000] {spark_submit.py:571} INFO - 2025-05-07 21:30:08,061 [INFO] Вычисляем метрики графа
[2025-05-07T21:30:08.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO CodeGenerator: Code generated in 12.154204 ms
[2025-05-07T21:30:08.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Registering RDD 15 (rdd at GraphFrame.scala:187) as input to shuffle 2
[2025-05-07T21:30:08.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Got map stage job 4 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-07T21:30:08.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (rdd at GraphFrame.scala:187)
[2025-05-07T21:30:08.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:08.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:08.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:30:08.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
[2025-05-07T21:30:08.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.4 MiB)
[2025-05-07T21:30:08.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 3530b0b864fd:45373 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T21:30:08.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:08.418+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:08.418+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-05-07T21:30:08.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:08.446+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.5:46863 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T21:30:08.706+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 286 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:08.706+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-05-07T21:30:08.708+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: ShuffleMapStage 6 (rdd at GraphFrame.scala:187) finished in 0.301 s
[2025-05-07T21:30:08.708+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:08.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:08.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:08.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:08.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:08.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:08.759+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:30:08.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:30:08.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-07T21:30:08.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:08.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:30:08.765+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-07T21:30:08.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-07T21:30:08.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:08.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:08.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:08.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-07T21:30:08.769+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:08.785+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:08.792+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.20.0.5:43654
[2025-05-07T21:30:08.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 36 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:08.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-07T21:30:08.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.042 s
[2025-05-07T21:30:08.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:08.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-07T21:30:08.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.047734 s
[2025-05-07T21:30:08.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO CodeGenerator: Code generated in 13.239875 ms
[2025-05-07T21:30:08.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-07T21:30:08.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.8 KiB, free 432.3 MiB)
[2025-05-07T21:30:08.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 3530b0b864fd:45373 (size: 28.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:08.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 3530b0b864fd:45373 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T21:30:08.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO SparkContext: Created broadcast 6 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:08.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.5:46863 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T21:30:08.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:08.918+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:08.962+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO CodeGenerator: Code generated in 14.992621 ms
[2025-05-07T21:30:08.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:08.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:09.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:09 INFO CodeGenerator: Code generated in 48.950137 ms
[2025-05-07T21:30:09.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:09 INFO CodeGenerator: Code generated in 10.724219 ms
[2025-05-07T21:30:09.093+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:09 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#995 - id.nullCount#994) > 0)
[2025-05-07T21:30:09.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:09 INFO CodeGenerator: Code generated in 6.799219 ms
[2025-05-07T21:30:09.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:09 INFO CodeGenerator: Code generated in 4.407625 ms
[2025-05-07T21:30:09.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:09 INFO CodeGenerator: Code generated in 5.099607 ms
[2025-05-07T21:30:09.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:09 INFO CodeGenerator: Code generated in 12.353237 ms
[2025-05-07T21:30:09.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:09 INFO CodeGenerator: Code generated in 4.956358 ms
[2025-05-07T21:30:10.060+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 9.799891 ms
[2025-05-07T21:30:10.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 6.528457 ms
[2025-05-07T21:30:10.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 8.450832 ms
[2025-05-07T21:30:10.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 8.169126 ms
[2025-05-07T21:30:10.115+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 8.857049 ms
[2025-05-07T21:30:10.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 10.455674 ms
[2025-05-07T21:30:10.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Registering RDD 60 (collect at GraphFrame.scala:574) as input to shuffle 4
[2025-05-07T21:30:10.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Got map stage job 6 (collect at GraphFrame.scala:574) with 6 output partitions
[2025-05-07T21:30:10.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:10.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:10.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:10.150+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:10.157+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 8.047605 ms
[2025-05-07T21:30:10.158+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 36.4 KiB, free 432.3 MiB)
[2025-05-07T21:30:10.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 432.3 MiB)
[2025-05-07T21:30:10.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:10.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 3530b0b864fd:45373 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T21:30:10.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:10.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:30:10.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSchedulerImpl: Adding task set 9.0 with 6 tasks resource profile 0
[2025-05-07T21:30:10.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Registering RDD 62 (collect at GraphFrame.scala:574) as input to shuffle 5
[2025-05-07T21:30:10.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Got map stage job 7 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:30:10.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:10.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:10.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:10.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:10.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:10.170+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.6 KiB, free 432.3 MiB)
[2025-05-07T21:30:10.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 432.2 MiB)
[2025-05-07T21:30:10.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 3530b0b864fd:45373 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:30:10.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:10.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:10.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2025-05-07T21:30:10.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 18.368271 ms
[2025-05-07T21:30:10.185+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.5:46863 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T21:30:10.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Registering RDD 64 (collect at GraphFrame.scala:574) as input to shuffle 6
[2025-05-07T21:30:10.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Got map stage job 8 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:30:10.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:10.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:10.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:10.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:10.199+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:10.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 27.3 KiB, free 432.2 MiB)
[2025-05-07T21:30:10.224+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.2 MiB)
[2025-05-07T21:30:10.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 3530b0b864fd:45373 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T21:30:10.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:10.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:10.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-05-07T21:30:10.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 41.292729 ms
[2025-05-07T21:30:10.262+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:10.262+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Registering RDD 66 (collect at GraphFrame.scala:574) as input to shuffle 7
[2025-05-07T21:30:10.262+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Got map stage job 9 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:30:10.262+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:10.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:10.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:10.276+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:10.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 27.382373 ms
[2025-05-07T21:30:10.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 28.5 KiB, free 432.2 MiB)
[2025-05-07T21:30:10.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 432.2 MiB)
[2025-05-07T21:30:10.331+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 3530b0b864fd:45373 (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-07T21:30:10.331+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:10.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:10.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:10.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-05-07T21:30:10.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Registering RDD 68 (collect at GraphFrame.scala:574) as input to shuffle 8
[2025-05-07T21:30:10.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Got map stage job 10 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:30:10.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:10.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:10.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:10.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 7) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:10.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 170 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:30:10.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:10.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-07T21:30:10.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 432.1 MiB)
[2025-05-07T21:30:10.350+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 3530b0b864fd:45373 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:30:10.350+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:10.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:10.352+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-05-07T21:30:10.358+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 20.443627 ms
[2025-05-07T21:30:10.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Registering RDD 70 (collect at GraphFrame.scala:574) as input to shuffle 9
[2025-05-07T21:30:10.364+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Got map stage job 11 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:30:10.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:10.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:10.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:10.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:10.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:10.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 27.4 KiB, free 432.1 MiB)
[2025-05-07T21:30:10.391+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.1 MiB)
[2025-05-07T21:30:10.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 3530b0b864fd:45373 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T21:30:10.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:10.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:10.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-05-07T21:30:10.410+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 39.418147 ms
[2025-05-07T21:30:10.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:10.431+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 8) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:10.432+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 7) in 99 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:30:10.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Registering RDD 72 (collect at GraphFrame.scala:574) as input to shuffle 10
[2025-05-07T21:30:10.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Got map stage job 12 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:30:10.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:10.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:10.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:10.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:10.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-07T21:30:10.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 432.0 MiB)
[2025-05-07T21:30:10.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 3530b0b864fd:45373 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:30:10.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:10.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:10.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-05-07T21:30:10.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 9) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:10.522+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 8) in 96 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:30:10.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO CodeGenerator: Code generated in 85.05193 ms
[2025-05-07T21:30:10.544+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Registering RDD 74 (collect at GraphFrame.scala:574) as input to shuffle 11
[2025-05-07T21:30:10.544+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Got map stage job 13 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:30:10.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:10.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:10.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:10.546+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:10.552+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.7 KiB, free 432.0 MiB)
[2025-05-07T21:30:10.570+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 432.0 MiB)
[2025-05-07T21:30:10.578+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 3530b0b864fd:45373 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:30:10.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:10.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:10.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-05-07T21:30:10.600+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 10) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:10.604+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 9) in 86 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:30:10.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 11) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:10.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:10 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 10) in 85 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:30:11.060+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 12) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:11.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 11) in 378 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:30:11.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-05-07T21:30:11.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: ShuffleMapStage 9 (collect at GraphFrame.scala:574) finished in 0.913 s
[2025-05-07T21:30:11.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:11.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 10, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-07T21:30:11.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:11.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:11.075+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.5:46863 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:30:11.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:11.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:11.123+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 12) in 63 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:11.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-05-07T21:30:11.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 13) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:11.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: ShuffleMapStage 10 (collect at GraphFrame.scala:574) finished in 0.964 s
[2025-05-07T21:30:11.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:11.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-07T21:30:11.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:11.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:11.138+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:11.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:30:11.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Final stage: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:30:11.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-05-07T21:30:11.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:11.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[77] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:30:11.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T21:30:11.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-07T21:30:11.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:11.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[77] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:11.168+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-05-07T21:30:11.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 3530b0b864fd:45373 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.5:46863 (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:30:11.177+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.20.0.5:46863 in memory (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:30:11.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:11.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.20.0.5:46863 in memory (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T21:30:11.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 3530b0b864fd:45373 in memory (size: 11.2 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:11.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:30:11.240+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Final stage: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:30:11.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2025-05-07T21:30:11.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:11.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:30:11.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T21:30:11.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-07T21:30:11.256+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:11.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:11.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2025-05-07T21:30:11.367+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 14) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:11.367+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 13) in 243 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:11.367+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-05-07T21:30:11.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: ShuffleMapStage 11 (collect at GraphFrame.scala:574) finished in 1.170 s
[2025-05-07T21:30:11.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:11.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T21:30:11.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:11.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:11.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.5:46863 (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:11.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 15) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:11.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 14) in 93 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:11.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-05-07T21:30:11.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: ShuffleMapStage 12 (collect at GraphFrame.scala:574) finished in 1.186 s
[2025-05-07T21:30:11.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:11.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T21:30:11.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:11.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:11.492+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.5:46863 (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T21:30:11.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 16) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:11.567+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 15) in 108 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:11.568+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-05-07T21:30:11.570+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: ShuffleMapStage 13 (collect at GraphFrame.scala:574) finished in 1.234 s
[2025-05-07T21:30:11.571+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:11.571+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T21:30:11.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:11.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:11.592+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.5:46863 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.649+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 17) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:11.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 16) in 85 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:11.651+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-05-07T21:30:11.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: ShuffleMapStage 14 (collect at GraphFrame.scala:574) finished in 1.284 s
[2025-05-07T21:30:11.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:11.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-07T21:30:11.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:11.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:11.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.5:46863 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:11.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 17) in 85 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:11.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-07T21:30:11.749+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: ShuffleMapStage 15 (collect at GraphFrame.scala:574) finished in 1.300 s
[2025-05-07T21:30:11.753+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:11.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: running: Set(ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-07T21:30:11.759+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:11.760+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:11.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:46863 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 19) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:11.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 130 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:11.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-05-07T21:30:11.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: ShuffleMapStage 16 (collect at GraphFrame.scala:574) finished in 1.317 s
[2025-05-07T21:30:11.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:11.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: running: Set(ResultStage 20, ResultStage 18)
[2025-05-07T21:30:11.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:11.865+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:11.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO ShufflePartitionsUtil: For shuffle(6, 7, 8, 9, 10, 11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:11.879+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.884+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.20.0.5:43654
[2025-05-07T21:30:11.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 3530b0b864fd:45373 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.902+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.20.0.5:46863 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.20.0.5:46863 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 3530b0b864fd:45373 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.965+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 3530b0b864fd:45373 in memory (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-07T21:30:11.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:11.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 19) in 110 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:11.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-05-07T21:30:11.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.828 s
[2025-05-07T21:30:11.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO CodeGenerator: Code generated in 11.246608 ms
[2025-05-07T21:30:11.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:11.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-05-07T21:30:11.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.836072 s
[2025-05-07T21:30:11.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:11.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.20.0.5:46863 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:11.994+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:11 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 3530b0b864fd:45373 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T21:30:12.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO CodeGenerator: Code generated in 21.697666 ms
[2025-05-07T21:30:12.007+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO CodeGenerator: Code generated in 9.217328 ms
[2025-05-07T21:30:12.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.20.0.5:46863 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:30:12.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:12.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:43654
[2025-05-07T21:30:12.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T21:30:12.046+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:12.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 85 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:12.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-05-07T21:30:12.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.815 s
[2025-05-07T21:30:12.059+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:12.059+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2025-05-07T21:30:12.059+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.820585 s
[2025-05-07T21:30:12.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:12.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 3530b0b864fd:45373 in memory (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-07T21:30:12.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.20.0.5:46863 in memory (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-07T21:30:12.078+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-07T21:30:12.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 430.2 MiB)
[2025-05-07T21:30:12.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 3530b0b864fd:45373 (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-07T21:30:12.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO CodeGenerator: Code generated in 24.209285 ms
[2025-05-07T21:30:12.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:12.099+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 5.0 MiB, free 425.2 MiB)
[2025-05-07T21:30:12.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:12.120+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO CodeGenerator: Code generated in 9.686479 ms
[2025-05-07T21:30:12.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 424.7 MiB)
[2025-05-07T21:30:12.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 3530b0b864fd:45373 (size: 502.1 KiB, free: 433.8 MiB)
[2025-05-07T21:30:12.125+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO SparkContext: Created broadcast 18 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:12.125+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:12.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO CodeGenerator: Code generated in 5.945888 ms
[2025-05-07T21:30:12.137+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:12.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO CodeGenerator: Code generated in 6.524906 ms
[2025-05-07T21:30:12.150+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:12.158+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO CodeGenerator: Code generated in 6.380402 ms
[2025-05-07T21:30:12.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:12.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Got job 16 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T21:30:12.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Final stage: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:30:12.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24, ShuffleMapStage 21, ShuffleMapStage 25, ShuffleMapStage 22, ShuffleMapStage 26, ShuffleMapStage 23)
[2025-05-07T21:30:12.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:12.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[105] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:30:12.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 91.7 KiB, free 424.6 MiB)
[2025-05-07T21:30:12.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 424.6 MiB)
[2025-05-07T21:30:12.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 3530b0b864fd:45373 (size: 30.3 KiB, free: 433.8 MiB)
[2025-05-07T21:30:12.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:12.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T21:30:12.197+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 27 (MapPartitionsRDD[105] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:30:12.197+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSchedulerImpl: Adding task set 27.0 with 6 tasks resource profile 0
[2025-05-07T21:30:12.197+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:12.198+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:12.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.20.0.5:46863 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T21:30:12.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.20.0.5:43654
[2025-05-07T21:30:12.282+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 22) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:12.283+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 86 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:30:12.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.20.0.5:43654
[2025-05-07T21:30:12.352+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 23) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:12.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 3530b0b864fd:45373 in memory (size: 13.0 KiB, free: 433.8 MiB)
[2025-05-07T21:30:12.357+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 22) in 70 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:30:12.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.20.0.5:46863 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T21:30:12.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.20.0.5:43654
[2025-05-07T21:30:12.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 24) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:12.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 23) in 51 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:30:12.419+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.20.0.5:43654
[2025-05-07T21:30:12.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 25) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:12.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 24) in 80 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:30:12.526+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.20.0.5:43654
[2025-05-07T21:30:12.634+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 26) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:12.635+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 25) in 154 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:30:12.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:43654
[2025-05-07T21:30:12.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 26) in 100 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:30:12.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-05-07T21:30:12.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.556 s
[2025-05-07T21:30:12.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:12.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-05-07T21:30:12.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO DAGScheduler: Job 16 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.565404 s
[2025-05-07T21:30:12.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 2.3 MiB, free 422.4 MiB)
[2025-05-07T21:30:12.788+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 422.3 MiB)
[2025-05-07T21:30:12.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 3530b0b864fd:45373 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T21:30:12.790+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO SparkContext: Created broadcast 20 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:12.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO CodeGenerator: Code generated in 70.575849 ms
[2025-05-07T21:30:12.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:13.038+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO CodeGenerator: Code generated in 54.584062 ms
[2025-05-07T21:30:13.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 3530b0b864fd:45373 in memory (size: 30.3 KiB, free: 433.7 MiB)
[2025-05-07T21:30:13.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.20.0.5:46863 in memory (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T21:30:13.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO CodeGenerator: Code generated in 8.792071 ms
[2025-05-07T21:30:13.183+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO DAGScheduler: Registering RDD 112 (collect at GraphFrame.scala:574) as input to shuffle 12
[2025-05-07T21:30:13.183+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO DAGScheduler: Got map stage job 17 (collect at GraphFrame.scala:574) with 11 output partitions
[2025-05-07T21:30:13.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:13.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
[2025-05-07T21:30:13.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:13.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:13.198+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 141.0 KiB, free 422.2 MiB)
[2025-05-07T21:30:13.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 49.8 KiB, free 422.2 MiB)
[2025-05-07T21:30:13.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 3530b0b864fd:45373 (size: 49.8 KiB, free: 433.7 MiB)
[2025-05-07T21:30:13.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:13.219+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T21:30:13.219+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSchedulerImpl: Adding task set 29.0 with 11 tasks resource profile 0
[2025-05-07T21:30:13.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 27) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:13.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.20.0.5:46863 (size: 49.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:13.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:43654
[2025-05-07T21:30:13.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.20.0.5:46863 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-07T21:30:13.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.20.0.5:46863 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T21:30:13.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.20.0.5:46863 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T21:30:13.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 28) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:13.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 27) in 419 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T21:30:13.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 29) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:13.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 28) in 66 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T21:30:13.792+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 30) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:13.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 29) in 93 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T21:30:13.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 31) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:13.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 30) in 62 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T21:30:13.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 32) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:13.947+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 31) in 94 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T21:30:13.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Starting task 6.0 in stage 29.0 (TID 33) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:13.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:13 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 32) in 50 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-07T21:30:14.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Starting task 7.0 in stage 29.0 (TID 34) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:14.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Finished task 6.0 in stage 29.0 (TID 33) in 52 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-07T21:30:14.103+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Starting task 8.0 in stage 29.0 (TID 35) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:14.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Finished task 7.0 in stage 29.0 (TID 34) in 64 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-07T21:30:14.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Starting task 9.0 in stage 29.0 (TID 36) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:14.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Finished task 8.0 in stage 29.0 (TID 35) in 46 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-07T21:30:14.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Starting task 10.0 in stage 29.0 (TID 37) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:14.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Finished task 9.0 in stage 29.0 (TID 36) in 70 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-07T21:30:14.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Finished task 10.0 in stage 29.0 (TID 37) in 93 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-07T21:30:14.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-05-07T21:30:14.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: ShuffleMapStage 29 (collect at GraphFrame.scala:574) finished in 1.121 s
[2025-05-07T21:30:14.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:14.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:14.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:14.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:14.313+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:14.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:14.377+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO CodeGenerator: Code generated in 29.600653 ms
[2025-05-07T21:30:14.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Registering RDD 115 (collect at GraphFrame.scala:574) as input to shuffle 13
[2025-05-07T21:30:14.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Got map stage job 18 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:30:14.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:14.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
[2025-05-07T21:30:14.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:14.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[115] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:14.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 129.7 KiB, free 422.1 MiB)
[2025-05-07T21:30:14.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 44.4 KiB, free 422.0 MiB)
[2025-05-07T21:30:14.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 3530b0b864fd:45373 (size: 44.4 KiB, free: 433.7 MiB)
[2025-05-07T21:30:14.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:14.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[115] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:14.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-05-07T21:30:14.407+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 38) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:14.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.20.0.5:46863 (size: 44.4 KiB, free: 433.7 MiB)
[2025-05-07T21:30:14.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:43654
[2025-05-07T21:30:14.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 38) in 141 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:14.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-05-07T21:30:14.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: ShuffleMapStage 32 (collect at GraphFrame.scala:574) finished in 0.149 s
[2025-05-07T21:30:14.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:14.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:14.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:14.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:14.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:14.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:14.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO CodeGenerator: Code generated in 9.249966 ms
[2025-05-07T21:30:14.597+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO SparkContext: Starting job: collect at GraphFrame.scala:574
[2025-05-07T21:30:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Got job 19 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T21:30:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Final stage: ResultStage 36 (collect at GraphFrame.scala:574)
[2025-05-07T21:30:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-05-07T21:30:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:14.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[118] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T21:30:14.603+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 122.6 KiB, free 421.9 MiB)
[2025-05-07T21:30:14.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 41.9 KiB, free 421.9 MiB)
[2025-05-07T21:30:14.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 3530b0b864fd:45373 (size: 41.9 KiB, free: 433.6 MiB)
[2025-05-07T21:30:14.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:14.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[118] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:14.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-05-07T21:30:14.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 39) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:14.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.20.0.5:46863 (size: 41.9 KiB, free: 433.6 MiB)
[2025-05-07T21:30:14.635+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:43654
[2025-05-07T21:30:14.673+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 39) in 62 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:14.673+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-05-07T21:30:14.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: ResultStage 36 (collect at GraphFrame.scala:574) finished in 0.074 s
[2025-05-07T21:30:14.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:14.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-05-07T21:30:14.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO DAGScheduler: Job 19 finished: collect at GraphFrame.scala:574, took 0.077487 s
[2025-05-07T21:30:14.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 3530b0b864fd:45373 in memory (size: 41.9 KiB, free: 433.7 MiB)
[2025-05-07T21:30:14.841+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.20.0.5:46863 in memory (size: 41.9 KiB, free: 433.7 MiB)
[2025-05-07T21:30:14.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 3530b0b864fd:45373 in memory (size: 49.8 KiB, free: 433.7 MiB)
[2025-05-07T21:30:14.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.20.0.5:46863 in memory (size: 49.8 KiB, free: 433.7 MiB)
[2025-05-07T21:30:14.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.20.0.5:46863 in memory (size: 44.4 KiB, free: 433.8 MiB)
[2025-05-07T21:30:14.880+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:14 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 3530b0b864fd:45373 in memory (size: 44.4 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Registering RDD 149 (rdd at GraphFrame.scala:188) as input to shuffle 14
[2025-05-07T21:30:15.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got map stage job 20 (rdd at GraphFrame.scala:188) with 6 output partitions
[2025-05-07T21:30:15.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:15.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:15.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.356+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:15.358+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 36.4 KiB, free 422.3 MiB)
[2025-05-07T21:30:15.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:15.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 422.3 MiB)
[2025-05-07T21:30:15.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 3530b0b864fd:45373 (size: 11.2 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:30:15.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 37.0 with 6 tasks resource profile 0
[2025-05-07T21:30:15.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Registering RDD 151 (rdd at GraphFrame.scala:188) as input to shuffle 15
[2025-05-07T21:30:15.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got map stage job 21 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:30:15.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:15.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:15.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 40) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:15.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 12.6 KiB, free 422.3 MiB)
[2025-05-07T21:30:15.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 422.3 MiB)
[2025-05-07T21:30:15.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:15.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 3530b0b864fd:45373 (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:15.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
[2025-05-07T21:30:15.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Registering RDD 153 (rdd at GraphFrame.scala:188) as input to shuffle 16
[2025-05-07T21:30:15.373+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got map stage job 22 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:30:15.374+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:15.374+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:15.374+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:15.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 27.3 KiB, free 422.3 MiB)
[2025-05-07T21:30:15.380+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:15.380+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 422.3 MiB)
[2025-05-07T21:30:15.381+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 3530b0b864fd:45373 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.381+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.381+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:15.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-05-07T21:30:15.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Registering RDD 155 (rdd at GraphFrame.scala:188) as input to shuffle 17
[2025-05-07T21:30:15.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got map stage job 23 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:30:15.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:15.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:15.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[155] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:15.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.20.0.5:46863 (size: 11.2 KiB, free: 433.8 MiB)
[2025-05-07T21:30:15.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-07T21:30:15.393+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 422.2 MiB)
[2025-05-07T21:30:15.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 3530b0b864fd:45373 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[155] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:15.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-05-07T21:30:15.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:15.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Registering RDD 157 (rdd at GraphFrame.scala:188) as input to shuffle 18
[2025-05-07T21:30:15.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got map stage job 24 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:30:15.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:15.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:15.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[157] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:15.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-07T21:30:15.419+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 422.2 MiB)
[2025-05-07T21:30:15.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 3530b0b864fd:45373 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[157] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:15.431+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-05-07T21:30:15.431+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:15.433+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 41) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.433+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Registering RDD 159 (rdd at GraphFrame.scala:188) as input to shuffle 19
[2025-05-07T21:30:15.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 40) in 71 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:30:15.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got map stage job 25 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:30:15.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:15.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:15.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[159] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:15.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 27.4 KiB, free 422.2 MiB)
[2025-05-07T21:30:15.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 422.1 MiB)
[2025-05-07T21:30:15.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 3530b0b864fd:45373 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:15.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[159] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:15.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-05-07T21:30:15.472+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Registering RDD 161 (rdd at GraphFrame.scala:188) as input to shuffle 20
[2025-05-07T21:30:15.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got map stage job 26 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:30:15.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:15.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:15.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[161] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:15.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 28.5 KiB, free 422.1 MiB)
[2025-05-07T21:30:15.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 422.1 MiB)
[2025-05-07T21:30:15.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 3530b0b864fd:45373 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[161] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:15.481+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
[2025-05-07T21:30:15.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Registering RDD 163 (rdd at GraphFrame.scala:188) as input to shuffle 21
[2025-05-07T21:30:15.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got map stage job 27 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T21:30:15.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ShuffleMapStage 44 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:15.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:15.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 42) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[163] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:15.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 41) in 66 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:30:15.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 31.7 KiB, free 422.1 MiB)
[2025-05-07T21:30:15.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 422.1 MiB)
[2025-05-07T21:30:15.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 3530b0b864fd:45373 (size: 14.9 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[163] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:15.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-05-07T21:30:15.537+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 43) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 42) in 43 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:30:15.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 44) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 43) in 39 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:30:15.610+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 45) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 44) in 38 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:30:15.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 46) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 45) in 47 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:30:15.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-05-07T21:30:15.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: ShuffleMapStage 37 (rdd at GraphFrame.scala:188) finished in 0.302 s
[2025-05-07T21:30:15.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:15.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: running: Set(ShuffleMapStage 38, ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T21:30:15.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:15.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:15.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.20.0.5:46863 (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-07T21:30:15.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:15.692+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:15.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:15.711+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:30:15.712+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:30:15.712+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
[2025-05-07T21:30:15.713+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.714+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[166] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:30:15.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.2 KiB, free 422.1 MiB)
[2025-05-07T21:30:15.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 47) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 422.1 MiB)
[2025-05-07T21:30:15.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 3530b0b864fd:45373 (size: 3.9 KiB, free: 433.6 MiB)
[2025-05-07T21:30:15.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 46) in 72 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:15.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2025-05-07T21:30:15.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.731+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[166] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:15.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-05-07T21:30:15.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: ShuffleMapStage 38 (rdd at GraphFrame.scala:188) finished in 0.367 s
[2025-05-07T21:30:15.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:15.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: running: Set(ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T21:30:15.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:15.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:15.738+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 3530b0b864fd:45373 in memory (size: 11.2 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.742+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.20.0.5:46863 in memory (size: 11.2 KiB, free: 433.8 MiB)
[2025-05-07T21:30:15.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.20.0.5:46863 (size: 13.0 KiB, free: 433.8 MiB)
[2025-05-07T21:30:15.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:15.762+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:15.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:15.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:15.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:30:15.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:30:15.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-05-07T21:30:15.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:15.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[169] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:30:15.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.2 KiB, free 422.1 MiB)
[2025-05-07T21:30:15.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 422.1 MiB)
[2025-05-07T21:30:15.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.807+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:15.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[169] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:15.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 48) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-05-07T21:30:15.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 47) in 83 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:15.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-05-07T21:30:15.811+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: ShuffleMapStage 39 (rdd at GraphFrame.scala:188) finished in 0.435 s
[2025-05-07T21:30:15.811+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:15.812+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T21:30:15.812+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:15.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:15.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.20.0.5:46863 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 49) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 48) in 87 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:15.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-05-07T21:30:15.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: ShuffleMapStage 40 (rdd at GraphFrame.scala:188) finished in 0.511 s
[2025-05-07T21:30:15.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:15.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T21:30:15.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:15.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:15.925+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.20.0.5:46863 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:15.968+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 50) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:15.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 49) in 80 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:15.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-05-07T21:30:15.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: ShuffleMapStage 41 (rdd at GraphFrame.scala:188) finished in 0.575 s
[2025-05-07T21:30:15.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:15.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-07T21:30:15.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:15.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:15.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:15 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.20.0.5:46863 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 51) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 50) in 56 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:16.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-05-07T21:30:16.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: ShuffleMapStage 42 (rdd at GraphFrame.scala:188) finished in 0.576 s
[2025-05-07T21:30:16.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:16.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-07T21:30:16.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:16.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:16.033+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.20.0.5:46863 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 52) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 51) in 46 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:16.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-05-07T21:30:16.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: ShuffleMapStage 43 (rdd at GraphFrame.scala:188) finished in 0.596 s
[2025-05-07T21:30:16.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:16.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 44)
[2025-05-07T21:30:16.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:16.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:16.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.20.0.5:46863 (size: 14.9 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.125+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 53) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 52) in 60 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:16.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-05-07T21:30:16.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: ShuffleMapStage 44 (rdd at GraphFrame.scala:188) finished in 0.629 s
[2025-05-07T21:30:16.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:16.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46)
[2025-05-07T21:30:16.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:16.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:16.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.20.0.5:46863 (size: 3.9 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.152+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:43654
[2025-05-07T21:30:16.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO ShufflePartitionsUtil: For shuffle(16, 17, 18, 19, 20, 21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:16.170+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO CodeGenerator: Code generated in 6.332302 ms
[2025-05-07T21:30:16.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:16.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 54) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 53) in 46 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:16.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-05-07T21:30:16.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.457 s
[2025-05-07T21:30:16.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:16.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
[2025-05-07T21:30:16.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.462530 s
[2025-05-07T21:30:16.180+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO CodeGenerator: Code generated in 10.708535 ms
[2025-05-07T21:30:16.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:43654
[2025-05-07T21:30:16.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:16.204+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 3530b0b864fd:45373 in memory (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.20.0.5:46863 in memory (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 54) in 35 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:16.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-05-07T21:30:16.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.429 s
[2025-05-07T21:30:16.211+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:16.211+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-05-07T21:30:16.211+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 5.0 MiB, free 417.1 MiB)
[2025-05-07T21:30:16.211+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.436160 s
[2025-05-07T21:30:16.223+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 3530b0b864fd:45373 in memory (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.223+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.20.0.5:46863 in memory (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.224+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 2.1 MiB, free 415.1 MiB)
[2025-05-07T21:30:16.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 415.1 MiB)
[2025-05-07T21:30:16.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 414.6 MiB)
[2025-05-07T21:30:16.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 3530b0b864fd:45373 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 3530b0b864fd:45373 (size: 502.1 KiB, free: 433.2 MiB)
[2025-05-07T21:30:16.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:16.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO SparkContext: Created broadcast 34 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:16.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO CodeGenerator: Code generated in 38.574771 ms
[2025-05-07T21:30:16.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 3530b0b864fd:45373 in memory (size: 13.0 KiB, free: 433.2 MiB)
[2025-05-07T21:30:16.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.20.0.5:46863 in memory (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:16.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 3530b0b864fd:45373 in memory (size: 13.0 KiB, free: 433.2 MiB)
[2025-05-07T21:30:16.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.20.0.5:46863 in memory (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:16.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.20.0.5:46863 in memory (size: 502.1 KiB, free: 434.2 MiB)
[2025-05-07T21:30:16.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 3530b0b864fd:45373 in memory (size: 502.1 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO CodeGenerator: Code generated in 33.598878 ms
[2025-05-07T21:30:16.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:16.317+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 3530b0b864fd:45373 in memory (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.20.0.5:46863 in memory (size: 20.6 KiB, free: 434.2 MiB)
[2025-05-07T21:30:16.328+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO CodeGenerator: Code generated in 9.833552 ms
[2025-05-07T21:30:16.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:16.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 3530b0b864fd:45373 in memory (size: 114.2 KiB, free: 433.8 MiB)
[2025-05-07T21:30:16.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.20.0.5:46863 in memory (size: 114.2 KiB, free: 434.4 MiB)
[2025-05-07T21:30:16.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO CodeGenerator: Code generated in 18.21537 ms
[2025-05-07T21:30:16.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 3530b0b864fd:45373 in memory (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-07T21:30:16.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.20.0.5:46863 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T21:30:16.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:16.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T21:30:16.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:30:16.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 49, ShuffleMapStage 53, ShuffleMapStage 50, ShuffleMapStage 54)
[2025-05-07T21:30:16.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:16.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:30:16.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 91.7 KiB, free 424.6 MiB)
[2025-05-07T21:30:16.411+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.20.0.5:46863 in memory (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-07T21:30:16.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 424.6 MiB)
[2025-05-07T21:30:16.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 3530b0b864fd:45373 in memory (size: 14.9 KiB, free: 433.8 MiB)
[2025-05-07T21:30:16.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 3530b0b864fd:45373 (size: 30.3 KiB, free: 433.8 MiB)
[2025-05-07T21:30:16.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:16.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 55 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:30:16.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Adding task set 55.0 with 6 tasks resource profile 0
[2025-05-07T21:30:16.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 433.8 MiB)
[2025-05-07T21:30:16.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T21:30:16.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 3530b0b864fd:45373 in memory (size: 3.9 KiB, free: 433.8 MiB)
[2025-05-07T21:30:16.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.20.0.5:46863 in memory (size: 3.9 KiB, free: 434.4 MiB)
[2025-05-07T21:30:16.438+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.20.0.5:46863 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T21:30:16.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 3530b0b864fd:45373 in memory (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-07T21:30:16.446+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.20.0.5:46863 in memory (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T21:30:16.450+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:43654
[2025-05-07T21:30:16.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 56) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.500+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 83 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:30:16.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:43654
[2025-05-07T21:30:16.537+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 57) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.538+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 56) in 40 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:30:16.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:43654
[2025-05-07T21:30:16.553+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 58) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.554+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 57) in 17 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:30:16.560+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.20.0.5:43654
[2025-05-07T21:30:16.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 4.0 in stage 55.0 (TID 59) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 58) in 26 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:30:16.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.20.0.5:43654
[2025-05-07T21:30:16.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 5.0 in stage 55.0 (TID 60) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 4.0 in stage 55.0 (TID 59) in 28 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:30:16.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.20.0.5:43654
[2025-05-07T21:30:16.635+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 5.0 in stage 55.0 (TID 60) in 29 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:30:16.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-05-07T21:30:16.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.246 s
[2025-05-07T21:30:16.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:16.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-05-07T21:30:16.639+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.254426 s
[2025-05-07T21:30:16.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 2.3 MiB, free 422.4 MiB)
[2025-05-07T21:30:16.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 422.3 MiB)
[2025-05-07T21:30:16.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 3530b0b864fd:45373 in memory (size: 30.3 KiB, free: 433.9 MiB)
[2025-05-07T21:30:16.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 3530b0b864fd:45373 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.20.0.5:46863 in memory (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T21:30:16.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO SparkContext: Created broadcast 37 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:16.692+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:16.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO CodeGenerator: Code generated in 75.510931 ms
[2025-05-07T21:30:16.826+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO CodeGenerator: Code generated in 6.270821 ms
[2025-05-07T21:30:16.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Registering RDD 198 (rdd at GraphFrame.scala:188) as input to shuffle 22
[2025-05-07T21:30:16.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Got map stage job 31 (rdd at GraphFrame.scala:188) with 11 output partitions
[2025-05-07T21:30:16.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Final stage: ShuffleMapStage 57 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:16.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-05-07T21:30:16.834+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:16.834+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[198] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:16.843+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 129.6 KiB, free 422.2 MiB)
[2025-05-07T21:30:16.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 45.1 KiB, free 422.2 MiB)
[2025-05-07T21:30:16.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 3530b0b864fd:45373 (size: 45.1 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:16.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[198] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T21:30:16.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSchedulerImpl: Adding task set 57.0 with 11 tasks resource profile 0
[2025-05-07T21:30:16.847+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 61) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.20.0.5:46863 (size: 45.1 KiB, free: 434.4 MiB)
[2025-05-07T21:30:16.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:43654
[2025-05-07T21:30:16.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.20.0.5:46863 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-07T21:30:16.939+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.20.0.5:46863 (size: 114.2 KiB, free: 433.8 MiB)
[2025-05-07T21:30:16.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:46863 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T21:30:16.986+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 62) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:16.986+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:16 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 61) in 139 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T21:30:17.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 63) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 62) in 32 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T21:30:17.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 64) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 63) in 42 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T21:30:17.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 4.0 in stage 57.0 (TID 65) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 64) in 31 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T21:30:17.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 5.0 in stage 57.0 (TID 66) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 4.0 in stage 57.0 (TID 65) in 22 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T21:30:17.137+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 6.0 in stage 57.0 (TID 67) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.138+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 5.0 in stage 57.0 (TID 66) in 30 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-07T21:30:17.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 7.0 in stage 57.0 (TID 68) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 6.0 in stage 57.0 (TID 67) in 22 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-07T21:30:17.183+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 8.0 in stage 57.0 (TID 69) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 7.0 in stage 57.0 (TID 68) in 25 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-07T21:30:17.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 9.0 in stage 57.0 (TID 70) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 8.0 in stage 57.0 (TID 69) in 25 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-07T21:30:17.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 10.0 in stage 57.0 (TID 71) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 9.0 in stage 57.0 (TID 70) in 28 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-07T21:30:17.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 10.0 in stage 57.0 (TID 71) in 260 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-07T21:30:17.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-05-07T21:30:17.496+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: ShuffleMapStage 57 (rdd at GraphFrame.scala:188) finished in 0.661 s
[2025-05-07T21:30:17.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:17.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:17.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:17.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:17.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:17.530+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO CodeGenerator: Code generated in 10.822618 ms
[2025-05-07T21:30:17.556+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:17.557+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Got job 32 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:30:17.558+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Final stage: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:30:17.558+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
[2025-05-07T21:30:17.558+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:17.558+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[202] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:30:17.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 116.0 KiB, free 422.1 MiB)
[2025-05-07T21:30:17.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 422.1 MiB)
[2025-05-07T21:30:17.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 3530b0b864fd:45373 (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T21:30:17.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:17.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[202] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:17.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
[2025-05-07T21:30:17.567+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 72) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.577+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.20.0.5:46863 (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T21:30:17.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.20.0.5:43654
[2025-05-07T21:30:17.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 72) in 104 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:17.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-07T21:30:17.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.113 s
[2025-05-07T21:30:17.673+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:17.673+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
[2025-05-07T21:30:17.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Job 32 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.118656 s
[2025-05-07T21:30:17.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 2.0 MiB, free 420.1 MiB)
[2025-05-07T21:30:17.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 3530b0b864fd:45373 in memory (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T21:30:17.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 96.0 KiB, free 420.1 MiB)
[2025-05-07T21:30:17.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 3530b0b864fd:45373 (size: 96.0 KiB, free: 433.6 MiB)
[2025-05-07T21:30:17.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO SparkContext: Created broadcast 40 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:17.707+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.20.0.5:46863 in memory (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T21:30:17.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 3530b0b864fd:45373 in memory (size: 45.1 KiB, free: 433.7 MiB)
[2025-05-07T21:30:17.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.20.0.5:46863 in memory (size: 45.1 KiB, free: 433.8 MiB)
[2025-05-07T21:30:17.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO CodeGenerator: Code generated in 12.857054 ms
[2025-05-07T21:30:17.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1525 - id.nullCount#1524) > 0)
[2025-05-07T21:30:17.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Registering RDD 19 (rdd at GraphFrame.scala:187) as input to shuffle 3
[2025-05-07T21:30:17.786+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Registering RDD 207 (rdd at GraphFrame.scala:188) as input to shuffle 23
[2025-05-07T21:30:17.788+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Got map stage job 33 (rdd at GraphFrame.scala:188) with 10 output partitions
[2025-05-07T21:30:17.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (rdd at GraphFrame.scala:188)
[2025-05-07T21:30:17.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
[2025-05-07T21:30:17.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
[2025-05-07T21:30:17.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:30:17.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.6 KiB, free 420.2 MiB)
[2025-05-07T21:30:17.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 420.2 MiB)
[2025-05-07T21:30:17.801+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 3530b0b864fd:45373 (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T21:30:17.802+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:17.802+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:17.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
[2025-05-07T21:30:17.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 73) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.822+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.20.0.5:46863 (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-07T21:30:17.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 73) in 71 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:17.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool
[2025-05-07T21:30:17.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: ShuffleMapStage 61 (rdd at GraphFrame.scala:187) finished in 0.078 s
[2025-05-07T21:30:17.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:17.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:17.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: waiting: Set(ShuffleMapStage 62)
[2025-05-07T21:30:17.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:17.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[207] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T21:30:17.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 51.0 KiB, free 420.2 MiB)
[2025-05-07T21:30:17.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 420.2 MiB)
[2025-05-07T21:30:17.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 3530b0b864fd:45373 (size: 21.7 KiB, free: 433.6 MiB)
[2025-05-07T21:30:17.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:17.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[207] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:17.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSchedulerImpl: Adding task set 62.0 with 10 tasks resource profile 0
[2025-05-07T21:30:17.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 74) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:17.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:17 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.20.0.5:46863 (size: 21.7 KiB, free: 433.8 MiB)
[2025-05-07T21:30:18.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:43654
[2025-05-07T21:30:18.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.20.0.5:46863 (size: 2.0 KiB, free: 433.7 MiB)
[2025-05-07T21:30:18.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.20.0.5:46863 (size: 96.0 KiB, free: 433.7 MiB)
[2025-05-07T21:30:18.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 75) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 74) in 259 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:18.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.20.0.5:46863 (size: 2.5 KiB, free: 433.7 MiB)
[2025-05-07T21:30:18.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 76) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 75) in 58 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:18.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 77) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.268+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 76) in 43 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:18.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.20.0.5:46863 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 4.0 in stage 62.0 (TID 78) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 77) in 43 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:18.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.20.0.5:46863 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 5.0 in stage 62.0 (TID 79) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 4.0 in stage 62.0 (TID 78) in 36 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:18.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.20.0.5:46863 (size: 2.0 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.376+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 6.0 in stage 62.0 (TID 80) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.377+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 5.0 in stage 62.0 (TID 79) in 33 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:18.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.20.0.5:46863 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 7.0 in stage 62.0 (TID 81) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 6.0 in stage 62.0 (TID 80) in 24 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:18.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.20.0.5:46863 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 8.0 in stage 62.0 (TID 82) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 7.0 in stage 62.0 (TID 81) in 31 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:18.449+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.20.0.5:46863 (size: 2.4 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 9.0 in stage 62.0 (TID 83) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.465+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 8.0 in stage 62.0 (TID 82) in 36 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:18.486+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.20.0.5:46863 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 9.0 in stage 62.0 (TID 83) in 42 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:18.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-05-07T21:30:18.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: ShuffleMapStage 62 (rdd at GraphFrame.scala:188) finished in 0.629 s
[2025-05-07T21:30:18.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:18.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:18.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:18.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:18.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:18.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:18.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Got job 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T21:30:18.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Final stage: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T21:30:18.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
[2025-05-07T21:30:18.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:18.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[209] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T21:30:18.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.2 KiB, free 420.2 MiB)
[2025-05-07T21:30:18.546+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 420.1 MiB)
[2025-05-07T21:30:18.546+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.546+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:18.546+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[209] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:18.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
[2025-05-07T21:30:18.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 84) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.20.0.5:43654
[2025-05-07T21:30:18.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 84) in 28 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:18.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool
[2025-05-07T21:30:18.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.033 s
[2025-05-07T21:30:18.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:18.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
[2025-05-07T21:30:18.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Job 34 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.036727 s
[2025-05-07T21:30:18.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 3530b0b864fd:45373 in memory (size: 21.7 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 2.0 MiB, free 418.1 MiB)
[2025-05-07T21:30:18.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 98.0 KiB, free 418.1 MiB)
[2025-05-07T21:30:18.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.20.0.5:46863 in memory (size: 21.7 KiB, free: 433.7 MiB)
[2025-05-07T21:30:18.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 3530b0b864fd:45373 (size: 98.0 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.591+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO SparkContext: Created broadcast 44 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T21:30:18.594+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 3530b0b864fd:45373 in memory (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.595+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.20.0.5:46863 in memory (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T21:30:18.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.600+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T21:30:18.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO CodeGenerator: Code generated in 10.752158 ms
[2025-05-07T21:30:18.615+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1535 - id.nullCount#1534) > 0)
[2025-05-07T21:30:18.731+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-07T21:30:18.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Registering RDD 222 (mapPartitions at VertexRDD.scala:356) as input to shuffle 28
[2025-05-07T21:30:18.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Registering RDD 31 (map at GraphFrame.scala:187) as input to shuffle 25
[2025-05-07T21:30:18.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Registering RDD 244 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 24
[2025-05-07T21:30:18.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Registering RDD 248 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 26
[2025-05-07T21:30:18.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Registering RDD 252 (mapPartitions at GraphImpl.scala:208) as input to shuffle 27
[2025-05-07T21:30:18.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Got job 35 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-07T21:30:18.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Final stage: ResultStage 72 (fold at VertexRDDImpl.scala:90)
[2025-05-07T21:30:18.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-07T21:30:18.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-07T21:30:18.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Submitting ShuffleMapStage 67 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[222] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-07T21:30:18.775+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 158.2 KiB, free 418.0 MiB)
[2025-05-07T21:30:18.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 55.6 KiB, free 417.9 MiB)
[2025-05-07T21:30:18.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 3530b0b864fd:45373 (size: 55.6 KiB, free: 433.5 MiB)
[2025-05-07T21:30:18.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:18.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 67 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[222] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:18.777+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSchedulerImpl: Adding task set 67.0 with 10 tasks resource profile 0
[2025-05-07T21:30:18.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[31] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-07T21:30:18.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 85) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:18.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 59.1 KiB, free 417.9 MiB)
[2025-05-07T21:30:18.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 417.8 MiB)
[2025-05-07T21:30:18.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 3530b0b864fd:45373 (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:18.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:18.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[31] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:18.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO TaskSchedulerImpl: Adding task set 68.0 with 10 tasks resource profile 0
[2025-05-07T21:30:18.799+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.20.0.5:46863 (size: 55.6 KiB, free: 433.6 MiB)
[2025-05-07T21:30:18.956+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:18 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.20.0.5:46863 (size: 98.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:19.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 86) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:19.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 85) in 1103 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:19.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 87) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:19.900+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 86) in 18 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:19.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 88) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:19.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Finished task 2.0 in stage 67.0 (TID 87) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:19.940+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Starting task 4.0 in stage 67.0 (TID 89) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:19.941+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Finished task 3.0 in stage 67.0 (TID 88) in 23 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:19.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Starting task 5.0 in stage 67.0 (TID 90) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:19.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Finished task 4.0 in stage 67.0 (TID 89) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:19.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Starting task 6.0 in stage 67.0 (TID 91) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:19.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Finished task 5.0 in stage 67.0 (TID 90) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:19.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Starting task 7.0 in stage 67.0 (TID 92) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:19.992+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:19 INFO TaskSetManager: Finished task 6.0 in stage 67.0 (TID 91) in 20 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:20.008+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 8.0 in stage 67.0 (TID 93) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.008+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 7.0 in stage 67.0 (TID 92) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:20.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 9.0 in stage 67.0 (TID 94) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 8.0 in stage 67.0 (TID 93) in 19 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:20.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 95) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 9.0 in stage 67.0 (TID 94) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:20.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool
[2025-05-07T21:30:20.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: ShuffleMapStage 67 (mapPartitions at VertexRDD.scala:356) finished in 1.306 s
[2025-05-07T21:30:20.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:20.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: running: Set(ShuffleMapStage 68)
[2025-05-07T21:30:20.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-07T21:30:20.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:20.047+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:46863 (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.5:46863 (size: 28.8 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 96) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.102+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 95) in 61 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:20.125+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 97) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.125+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 96) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:20.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 98) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 97) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:20.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 4.0 in stage 68.0 (TID 99) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.159+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 98) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:20.175+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 5.0 in stage 68.0 (TID 100) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.176+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 4.0 in stage 68.0 (TID 99) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:20.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 6.0 in stage 68.0 (TID 101) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 5.0 in stage 68.0 (TID 100) in 18 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:20.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 7.0 in stage 68.0 (TID 102) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 6.0 in stage 68.0 (TID 101) in 25 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:20.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 8.0 in stage 68.0 (TID 103) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 7.0 in stage 68.0 (TID 102) in 28 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:20.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 9.0 in stage 68.0 (TID 104) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 8.0 in stage 68.0 (TID 103) in 30 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:20.291+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 9.0 in stage 68.0 (TID 104) in 18 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:20.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool
[2025-05-07T21:30:20.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: ShuffleMapStage 68 (map at GraphFrame.scala:187) finished in 1.512 s
[2025-05-07T21:30:20.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:20.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:20.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-07T21:30:20.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:20.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: Submitting ShuffleMapStage 70 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[248] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:20.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 9.9 KiB, free 417.8 MiB)
[2025-05-07T21:30:20.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 417.8 MiB)
[2025-05-07T21:30:20.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 3530b0b864fd:45373 (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:20.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 70 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[248] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:20.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSchedulerImpl: Adding task set 70.0 with 10 tasks resource profile 0
[2025-05-07T21:30:20.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: Submitting ShuffleMapStage 69 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[244] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:20.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 105) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.311+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 10.3 KiB, free 417.8 MiB)
[2025-05-07T21:30:20.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.8 MiB)
[2025-05-07T21:30:20.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 3530b0b864fd:45373 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:20.331+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.20.0.5:46863 in memory (size: 55.6 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 69 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[244] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:20.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 3530b0b864fd:45373 in memory (size: 55.6 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSchedulerImpl: Adding task set 69.0 with 10 tasks resource profile 0
[2025-05-07T21:30:20.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.20.0.5:46863 (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.20.0.5:43654
[2025-05-07T21:30:20.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.20.0.5:43654
[2025-05-07T21:30:20.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_0 in memory on 172.20.0.5:46863 (size: 18.6 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_0 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.632+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.635+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 106) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.648+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 105) in 340 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:20.654+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.20.0.5:46863 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 107) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.671+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 106) in 23 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:20.691+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_1 in memory on 172.20.0.5:46863 (size: 18.6 KiB, free: 433.5 MiB)
[2025-05-07T21:30:20.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_1 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.704+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 108) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 107) in 35 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:20.727+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_2 in memory on 172.20.0.5:46863 (size: 18.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.730+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_2 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.744+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 109) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.744+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 108) in 40 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:20.759+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_3 in memory on 172.20.0.5:46863 (size: 18.2 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.762+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_3 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.772+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 110) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 109) in 29 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:20.790+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_4 in memory on 172.20.0.5:46863 (size: 18.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:20.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_4 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.795+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 111) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.807+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 110) in 36 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:20.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_5 in memory on 172.20.0.5:46863 (size: 18.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.827+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_5 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.834+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 6.0 in stage 69.0 (TID 112) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 111) in 36 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:20.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_6 in memory on 172.20.0.5:46863 (size: 18.4 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.861+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_6 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 7.0 in stage 69.0 (TID 113) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 6.0 in stage 69.0 (TID 112) in 36 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:20.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_7 in memory on 172.20.0.5:46863 (size: 18.4 KiB, free: 433.3 MiB)
[2025-05-07T21:30:20.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_7 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.899+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.904+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 8.0 in stage 69.0 (TID 114) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.905+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 7.0 in stage 69.0 (TID 113) in 27 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:20.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_8 in memory on 172.20.0.5:46863 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_8 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 9.0 in stage 69.0 (TID 115) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 8.0 in stage 69.0 (TID 114) in 31 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:20.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_225_9 in memory on 172.20.0.5:46863 (size: 18.0 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_230_9 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.960+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_236_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.962+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO BlockManagerInfo: Added rdd_240_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.2 MiB)
[2025-05-07T21:30:20.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 116) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 9.0 in stage 69.0 (TID 115) in 36 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:20.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-07T21:30:20.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: ShuffleMapStage 69 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.661 s
[2025-05-07T21:30:20.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:20.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: running: Set(ShuffleMapStage 70)
[2025-05-07T21:30:20.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-07T21:30:20.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:20.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 117) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.986+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 116) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:20.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 118) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:20.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:20 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 117) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:21.005+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 119) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.005+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 118) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:21.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 5.0 in stage 70.0 (TID 120) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.012+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 119) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:21.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 6.0 in stage 70.0 (TID 121) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 5.0 in stage 70.0 (TID 120) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:21.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 7.0 in stage 70.0 (TID 122) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 6.0 in stage 70.0 (TID 121) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:21.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 8.0 in stage 70.0 (TID 123) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 7.0 in stage 70.0 (TID 122) in 7 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:21.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 9.0 in stage 70.0 (TID 124) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 8.0 in stage 70.0 (TID 123) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:21.049+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 9.0 in stage 70.0 (TID 124) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:21.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-05-07T21:30:21.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: ShuffleMapStage 70 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.755 s
[2025-05-07T21:30:21.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:21.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:21.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-07T21:30:21.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:21.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[252] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:21.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 162.8 KiB, free 417.9 MiB)
[2025-05-07T21:30:21.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 57.5 KiB, free 417.8 MiB)
[2025-05-07T21:30:21.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 3530b0b864fd:45373 (size: 57.5 KiB, free: 433.5 MiB)
[2025-05-07T21:30:21.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:21.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[252] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:21.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Adding task set 71.0 with 10 tasks resource profile 0
[2025-05-07T21:30:21.068+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 3530b0b864fd:45373 in memory (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:21.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 125) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.20.0.5:46863 in memory (size: 5.0 KiB, free: 433.2 MiB)
[2025-05-07T21:30:21.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 3530b0b864fd:45373 in memory (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:21.078+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.20.0.5:46863 in memory (size: 26.0 KiB, free: 433.2 MiB)
[2025-05-07T21:30:21.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.20.0.5:46863 (size: 57.5 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.141+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.144+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.20.0.5:43654
[2025-05-07T21:30:21.151+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.20.0.5:43654
[2025-05-07T21:30:21.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 126) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 125) in 95 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:21.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.180+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 127) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 126) in 30 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:21.213+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.222+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 128) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.228+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 127) in 35 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:21.245+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 129) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 128) in 33 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:21.276+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.277+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.279+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.283+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 130) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 129) in 32 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:21.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.319+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 6.0 in stage 71.0 (TID 131) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 130) in 36 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:21.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.343+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 7.0 in stage 71.0 (TID 132) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 6.0 in stage 71.0 (TID 131) in 27 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:21.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.374+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 8.0 in stage 71.0 (TID 133) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 7.0 in stage 71.0 (TID 132) in 29 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:21.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 9.0 in stage 71.0 (TID 134) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 8.0 in stage 71.0 (TID 133) in 31 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:21.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_228_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.431+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_232_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.433+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_238_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_246_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 9.0 in stage 71.0 (TID 134) in 33 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:21.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-05-07T21:30:21.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: ShuffleMapStage 71 (mapPartitions at GraphImpl.scala:208) finished in 0.392 s
[2025-05-07T21:30:21.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:21.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:21.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: waiting: Set(ResultStage 72)
[2025-05-07T21:30:21.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:21.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[256] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-07T21:30:21.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 11.2 KiB, free 417.9 MiB)
[2025-05-07T21:30:21.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.9 MiB)
[2025-05-07T21:30:21.455+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 3530b0b864fd:45373 (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T21:30:21.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:21.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.20.0.5:46863 in memory (size: 4.9 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.460+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 72 (MapPartitionsRDD[256] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:21.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Adding task set 72.0 with 10 tasks resource profile 0
[2025-05-07T21:30:21.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 3530b0b864fd:45373 in memory (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:21.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 135) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.20.0.5:46863 (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.20.0.5:43654
[2025-05-07T21:30:21.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_0 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 136) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 135) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:21.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_1 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 137) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 136) in 21 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:21.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_2 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 138) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 137) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:21.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_3 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.524+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 4.0 in stage 72.0 (TID 139) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 138) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:21.529+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_4 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.531+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 5.0 in stage 72.0 (TID 140) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 4.0 in stage 72.0 (TID 139) in 7 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:21.536+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_5 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 6.0 in stage 72.0 (TID 141) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.540+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 5.0 in stage 72.0 (TID 140) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:21.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_6 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 7.0 in stage 72.0 (TID 142) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 6.0 in stage 72.0 (TID 141) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:21.552+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_7 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.554+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 8.0 in stage 72.0 (TID 143) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 7.0 in stage 72.0 (TID 142) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:21.562+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_8 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 9.0 in stage 72.0 (TID 144) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 8.0 in stage 72.0 (TID 143) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:21.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added rdd_254_9 in memory on 172.20.0.5:46863 (size: 4.6 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 9.0 in stage 72.0 (TID 144) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:21.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-05-07T21:30:21.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: ResultStage 72 (fold at VertexRDDImpl.scala:90) finished in 0.128 s
[2025-05-07T21:30:21.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:21.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-05-07T21:30:21.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Job 35 finished: fold at VertexRDDImpl.scala:90, took 2.842721 s
[2025-05-07T21:30:21.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO ZippedPartitionsRDD2: Removing RDD 254 from persistence list
[2025-05-07T21:30:21.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManager: Removing RDD 254
[2025-05-07T21:30:21.812+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:21.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Registering RDD 259 (mapPartitions at GraphImpl.scala:208) as input to shuffle 30
[2025-05-07T21:30:21.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Registering RDD 277 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 31
[2025-05-07T21:30:21.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Registering RDD 267 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 29
[2025-05-07T21:30:21.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Registering RDD 281 (mapPartitions at GraphImpl.scala:208) as input to shuffle 33
[2025-05-07T21:30:21.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Registering RDD 289 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 32
[2025-05-07T21:30:21.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Got job 36 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:21.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Final stage: ResultStage 81 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:21.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78, ShuffleMapStage 73, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T21:30:21.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T21:30:21.815+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting ShuffleMapStage 75 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[259] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:21.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 161.1 KiB, free 417.7 MiB)
[2025-05-07T21:30:21.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 56.8 KiB, free 417.7 MiB)
[2025-05-07T21:30:21.831+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManager: Removing RDD 246
[2025-05-07T21:30:21.832+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 3530b0b864fd:45373 (size: 56.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:21.832+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:21.832+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 75 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[259] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:21.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Adding task set 75.0 with 10 tasks resource profile 0
[2025-05-07T21:30:21.834+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 145) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManager: Removing RDD 254
[2025-05-07T21:30:21.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.20.0.5:46863 (size: 56.8 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 3530b0b864fd:45373 in memory (size: 5.3 KiB, free: 433.4 MiB)
[2025-05-07T21:30:21.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.20.0.5:46863 in memory (size: 5.3 KiB, free: 433.0 MiB)
[2025-05-07T21:30:21.848+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 3530b0b864fd:45373 in memory (size: 57.5 KiB, free: 433.5 MiB)
[2025-05-07T21:30:21.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.20.0.5:46863 in memory (size: 57.5 KiB, free: 433.1 MiB)
[2025-05-07T21:30:21.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 146) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 145) in 53 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:21.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 147) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 146) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:21.917+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 148) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.917+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 147) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:21.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 149) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.927+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 148) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:21.934+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 5.0 in stage 75.0 (TID 150) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 4.0 in stage 75.0 (TID 149) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:21.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 6.0 in stage 75.0 (TID 151) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 5.0 in stage 75.0 (TID 150) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:21.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 7.0 in stage 75.0 (TID 152) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 6.0 in stage 75.0 (TID 151) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:21.963+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 8.0 in stage 75.0 (TID 153) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.963+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 7.0 in stage 75.0 (TID 152) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:21.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 9.0 in stage 75.0 (TID 154) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 8.0 in stage 75.0 (TID 153) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:21.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Finished task 9.0 in stage 75.0 (TID 154) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:21.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool
[2025-05-07T21:30:21.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: ShuffleMapStage 75 (mapPartitions at GraphImpl.scala:208) finished in 0.166 s
[2025-05-07T21:30:21.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:21.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:21.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 78, ShuffleMapStage 79, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T21:30:21.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:21.982+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[267] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:21.983+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 10.1 KiB, free 417.9 MiB)
[2025-05-07T21:30:21.983+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.9 MiB)
[2025-05-07T21:30:21.983+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 3530b0b864fd:45373 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:21.984+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:21.984+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[267] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:21.984+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Adding task set 78.0 with 10 tasks resource profile 0
[2025-05-07T21:30:21.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[277] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:21.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 155) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:21.986+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 10.7 KiB, free 417.9 MiB)
[2025-05-07T21:30:21.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.9 MiB)
[2025-05-07T21:30:21.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 3530b0b864fd:45373 (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T21:30:21.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:21.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[277] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:21.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:21 INFO TaskSchedulerImpl: Adding task set 77.0 with 10 tasks resource profile 0
[2025-05-07T21:30:22.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.20.0.5:46863 (size: 5.0 KiB, free: 433.1 MiB)
[2025-05-07T21:30:22.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.20.0.5:43654
[2025-05-07T21:30:22.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_0 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:30:22.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 156) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 155) in 58 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:22.048+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.20.0.5:46863 (size: 5.3 KiB, free: 433.1 MiB)
[2025-05-07T21:30:22.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.1 MiB)
[2025-05-07T21:30:22.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 157) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 156) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:22.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_1 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:30:22.076+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.1 MiB)
[2025-05-07T21:30:22.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 158) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 157) in 18 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:22.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_2 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.1 MiB)
[2025-05-07T21:30:22.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.096+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 159) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.096+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 158) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:22.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_3 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 4.0 in stage 77.0 (TID 160) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 159) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:22.125+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_4 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 5.0 in stage 77.0 (TID 161) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 4.0 in stage 77.0 (TID 160) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:22.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_5 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.146+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.151+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 6.0 in stage 77.0 (TID 162) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.151+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 5.0 in stage 77.0 (TID 161) in 20 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:22.160+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_6 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 7.0 in stage 77.0 (TID 163) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 6.0 in stage 77.0 (TID 162) in 17 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:22.177+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_7 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.178+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 8.0 in stage 77.0 (TID 164) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 7.0 in stage 77.0 (TID 163) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:22.190+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_8 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.192+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 9.0 in stage 77.0 (TID 165) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.196+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 8.0 in stage 77.0 (TID 164) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:22.202+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_263_9 in memory on 172.20.0.5:46863 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_273_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.209+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 166) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.209+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 9.0 in stage 77.0 (TID 165) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:22.209+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool
[2025-05-07T21:30:22.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: ShuffleMapStage 77 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.224 s
[2025-05-07T21:30:22.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:22.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: running: Set(ShuffleMapStage 78)
[2025-05-07T21:30:22.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-07T21:30:22.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:22.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 167) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 166) in 6 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:22.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 168) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 167) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:22.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 169) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 168) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:22.241+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 5.0 in stage 78.0 (TID 170) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 169) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:22.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 6.0 in stage 78.0 (TID 171) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.253+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 5.0 in stage 78.0 (TID 170) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:22.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 7.0 in stage 78.0 (TID 172) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 6.0 in stage 78.0 (TID 171) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:22.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 8.0 in stage 78.0 (TID 173) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 7.0 in stage 78.0 (TID 172) in 5 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:22.273+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 9.0 in stage 78.0 (TID 174) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.274+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 8.0 in stage 78.0 (TID 173) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:22.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 9.0 in stage 78.0 (TID 174) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:22.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-05-07T21:30:22.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: ShuffleMapStage 78 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.298 s
[2025-05-07T21:30:22.280+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:22.281+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:22.281+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-07T21:30:22.281+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:22.281+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Submitting ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[281] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:22.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 163.7 KiB, free 417.7 MiB)
[2025-05-07T21:30:22.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 57.9 KiB, free 417.7 MiB)
[2025-05-07T21:30:22.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 3530b0b864fd:45373 in memory (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T21:30:22.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 3530b0b864fd:45373 (size: 57.9 KiB, free: 433.4 MiB)
[2025-05-07T21:30:22.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:22.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[281] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:22.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.20.0.5:46863 in memory (size: 5.3 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Adding task set 79.0 with 10 tasks resource profile 0
[2025-05-07T21:30:22.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 175) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 3530b0b864fd:45373 in memory (size: 56.8 KiB, free: 433.5 MiB)
[2025-05-07T21:30:22.308+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.20.0.5:46863 in memory (size: 56.8 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.311+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.20.0.5:46863 (size: 57.9 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.326+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:43654
[2025-05-07T21:30:22.341+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.343+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:43654
[2025-05-07T21:30:22.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 176) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 175) in 47 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:22.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.367+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 177) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 176) in 19 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:22.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.381+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.385+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 178) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 177) in 18 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:22.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 4.0 in stage 79.0 (TID 179) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.408+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 178) in 22 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:22.419+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 5.0 in stage 79.0 (TID 180) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 4.0 in stage 79.0 (TID 179) in 23 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:22.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.445+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.449+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 6.0 in stage 79.0 (TID 181) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.450+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 5.0 in stage 79.0 (TID 180) in 21 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:22.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.466+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 7.0 in stage 79.0 (TID 182) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.470+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 6.0 in stage 79.0 (TID 181) in 21 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:22.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 8.0 in stage 79.0 (TID 183) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.488+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 7.0 in stage 79.0 (TID 182) in 18 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:22.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 9.0 in stage 79.0 (TID 184) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 8.0 in stage 79.0 (TID 183) in 24 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:22.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_265_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.527+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_275_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 9.0 in stage 79.0 (TID 184) in 21 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:22.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-05-07T21:30:22.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: ShuffleMapStage 79 (mapPartitions at GraphImpl.scala:208) finished in 0.250 s
[2025-05-07T21:30:22.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:22.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:22.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 80)
[2025-05-07T21:30:22.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:22.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Submitting ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[289] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:22.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 12.0 KiB, free 417.9 MiB)
[2025-05-07T21:30:22.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 417.9 MiB)
[2025-05-07T21:30:22.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 3530b0b864fd:45373 (size: 5.7 KiB, free: 433.5 MiB)
[2025-05-07T21:30:22.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:22.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[289] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:22.550+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Adding task set 80.0 with 10 tasks resource profile 0
[2025-05-07T21:30:22.550+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 3530b0b864fd:45373 in memory (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:22.550+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 185) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.553+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.20.0.5:46863 in memory (size: 5.0 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.20.0.5:46863 (size: 5.7 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:43654
[2025-05-07T21:30:22.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 186) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.579+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 185) in 30 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:22.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.600+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 187) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.600+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 186) in 21 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:22.608+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 188) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 187) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:22.620+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 4.0 in stage 80.0 (TID 189) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.627+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 188) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:22.633+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 5.0 in stage 80.0 (TID 190) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 4.0 in stage 80.0 (TID 189) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:22.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 6.0 in stage 80.0 (TID 191) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.652+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 5.0 in stage 80.0 (TID 190) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:22.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 7.0 in stage 80.0 (TID 192) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 6.0 in stage 80.0 (TID 191) in 21 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:22.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 8.0 in stage 80.0 (TID 193) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 7.0 in stage 80.0 (TID 192) in 26 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:22.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 9.0 in stage 80.0 (TID 194) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 8.0 in stage 80.0 (TID 193) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:22.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_285_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 9.0 in stage 80.0 (TID 194) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:22.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool
[2025-05-07T21:30:22.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: ShuffleMapStage 80 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.188 s
[2025-05-07T21:30:22.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:22.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:22.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: waiting: Set(ResultStage 81)
[2025-05-07T21:30:22.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:22.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Submitting ResultStage 81 (EdgeRDDImpl[292] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:22.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 163.5 KiB, free 417.7 MiB)
[2025-05-07T21:30:22.739+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 57.6 KiB, free 417.8 MiB)
[2025-05-07T21:30:22.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 3530b0b864fd:45373 in memory (size: 57.9 KiB, free: 433.6 MiB)
[2025-05-07T21:30:22.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 3530b0b864fd:45373 (size: 57.6 KiB, free: 433.5 MiB)
[2025-05-07T21:30:22.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:22.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 81 (EdgeRDDImpl[292] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:22.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Adding task set 81.0 with 10 tasks resource profile 0
[2025-05-07T21:30:22.743+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 195) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.743+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.20.0.5:46863 in memory (size: 57.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.20.0.5:46863 (size: 57.6 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:43654
[2025-05-07T21:30:22.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:43654
[2025-05-07T21:30:22.771+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 196) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.781+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 195) in 40 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:22.807+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.812+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 197) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 196) in 33 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:22.826+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.829+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 198) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 197) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:22.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 199) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 198) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:22.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 200) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 199) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:22.879+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 6.0 in stage 81.0 (TID 201) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 200) in 22 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:22.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 7.0 in stage 81.0 (TID 202) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 6.0 in stage 81.0 (TID 201) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:22.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 8.0 in stage 81.0 (TID 203) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 7.0 in stage 81.0 (TID 202) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:22.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 9.0 in stage 81.0 (TID 204) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 8.0 in stage 81.0 (TID 203) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:22.938+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added rdd_291_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:22.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Finished task 9.0 in stage 81.0 (TID 204) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:22.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-05-07T21:30:22.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: ResultStage 81 (foreachPartition at PageRank.scala:199) finished in 0.219 s
[2025-05-07T21:30:22.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:22.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
[2025-05-07T21:30:22.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Job 36 finished: foreachPartition at PageRank.scala:199, took 1.131298 s
[2025-05-07T21:30:22.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO PageRank: PageRank finished iteration 0.
[2025-05-07T21:30:22.944+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MapPartitionsRDD: Removing RDD 273 from persistence list
[2025-05-07T21:30:22.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManager: Removing RDD 273
[2025-05-07T21:30:22.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MapPartitionsRDD: Removing RDD 275 from persistence list
[2025-05-07T21:30:22.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManager: Removing RDD 275
[2025-05-07T21:30:22.962+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:22.963+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Registering RDD 293 (mapPartitions at GraphImpl.scala:208) as input to shuffle 35
[2025-05-07T21:30:22.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Registering RDD 301 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 34
[2025-05-07T21:30:22.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Got job 37 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:22.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Final stage: ResultStage 92 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:22.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82, ShuffleMapStage 89, ShuffleMapStage 86, ShuffleMapStage 87, ShuffleMapStage 91)
[2025-05-07T21:30:22.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
[2025-05-07T21:30:22.965+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Submitting ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[293] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:22.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 164.0 KiB, free 417.7 MiB)
[2025-05-07T21:30:22.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.7 MiB)
[2025-05-07T21:30:22.986+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 3530b0b864fd:45373 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T21:30:22.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 3530b0b864fd:45373 in memory (size: 57.6 KiB, free: 433.5 MiB)
[2025-05-07T21:30:22.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:22.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[293] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:22.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSchedulerImpl: Adding task set 90.0 with 10 tasks resource profile 0
[2025-05-07T21:30:22.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.20.0.5:46863 in memory (size: 57.6 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 205) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:22.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 3530b0b864fd:45373 in memory (size: 5.7 KiB, free: 433.5 MiB)
[2025-05-07T21:30:22.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.20.0.5:46863 in memory (size: 5.7 KiB, free: 433.0 MiB)
[2025-05-07T21:30:22.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:22 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.20.0.5:46863 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.012+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 206) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.013+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 205) in 25 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:23.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 207) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.022+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 206) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:23.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 208) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 207) in 22 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:23.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 4.0 in stage 90.0 (TID 209) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 208) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:23.069+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 5.0 in stage 90.0 (TID 210) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 4.0 in stage 90.0 (TID 209) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:23.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 6.0 in stage 90.0 (TID 211) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 5.0 in stage 90.0 (TID 210) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:23.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 7.0 in stage 90.0 (TID 212) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 6.0 in stage 90.0 (TID 211) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:23.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 8.0 in stage 90.0 (TID 213) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 7.0 in stage 90.0 (TID 212) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:23.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 9.0 in stage 90.0 (TID 214) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 8.0 in stage 90.0 (TID 213) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:23.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 9.0 in stage 90.0 (TID 214) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:23.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-05-07T21:30:23.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: ShuffleMapStage 90 (mapPartitions at GraphImpl.scala:208) finished in 0.165 s
[2025-05-07T21:30:23.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:23.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:23.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: waiting: Set(ShuffleMapStage 91, ResultStage 92)
[2025-05-07T21:30:23.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:23.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[301] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:23.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.8 KiB, free 417.9 MiB)
[2025-05-07T21:30:23.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 417.9 MiB)
[2025-05-07T21:30:23.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 3530b0b864fd:45373 (size: 5.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:23.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:23.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[301] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:23.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Adding task set 91.0 with 10 tasks resource profile 0
[2025-05-07T21:30:23.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 215) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.20.0.5:46863 (size: 5.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:43654
[2025-05-07T21:30:23.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 3530b0b864fd:45373 in memory (size: 58.2 KiB, free: 433.6 MiB)
[2025-05-07T21:30:23.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.20.0.5:46863 in memory (size: 58.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 216) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.185+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 215) in 49 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:23.195+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 217) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.202+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 216) in 17 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:23.213+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 218) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 217) in 31 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:23.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 219) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 218) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:23.260+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.265+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 220) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.265+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 219) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:23.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.279+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 221) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.279+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 220) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:23.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.292+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 222) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.293+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 221) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:23.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.305+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 8.0 in stage 91.0 (TID 223) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 222) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:23.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.319+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 9.0 in stage 91.0 (TID 224) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 8.0 in stage 91.0 (TID 223) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:23.330+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_297_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.334+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 9.0 in stage 91.0 (TID 224) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:23.334+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-05-07T21:30:23.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: ShuffleMapStage 91 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.203 s
[2025-05-07T21:30:23.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:23.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:23.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: waiting: Set(ResultStage 92)
[2025-05-07T21:30:23.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:23.335+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting ResultStage 92 (EdgeRDDImpl[304] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:23.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 163.8 KiB, free 417.9 MiB)
[2025-05-07T21:30:23.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 57.7 KiB, free 417.9 MiB)
[2025-05-07T21:30:23.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 3530b0b864fd:45373 (size: 57.7 KiB, free: 433.5 MiB)
[2025-05-07T21:30:23.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:23.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 92 (EdgeRDDImpl[304] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:23.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Adding task set 92.0 with 10 tasks resource profile 0
[2025-05-07T21:30:23.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 225) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.351+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.20.0.5:46863 (size: 57.7 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:43654
[2025-05-07T21:30:23.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 226) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 225) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:23.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 227) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.386+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 226) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:23.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 228) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 227) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:23.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 229) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 228) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:23.427+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 5.0 in stage 92.0 (TID 230) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 229) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:23.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 6.0 in stage 92.0 (TID 231) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.444+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 5.0 in stage 92.0 (TID 230) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:23.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.456+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 7.0 in stage 92.0 (TID 232) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.457+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 6.0 in stage 92.0 (TID 231) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:23.471+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 8.0 in stage 92.0 (TID 233) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 7.0 in stage 92.0 (TID 232) in 19 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:23.485+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 9.0 in stage 92.0 (TID 234) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 8.0 in stage 92.0 (TID 233) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:23.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_303_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 9.0 in stage 92.0 (TID 234) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:23.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool
[2025-05-07T21:30:23.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: ResultStage 92 (foreachPartition at PageRank.scala:199) finished in 0.165 s
[2025-05-07T21:30:23.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:23.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
[2025-05-07T21:30:23.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Job 37 finished: foreachPartition at PageRank.scala:199, took 0.539847 s
[2025-05-07T21:30:23.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO PageRank: PageRank finished iteration 1.
[2025-05-07T21:30:23.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO ZippedPartitionsRDD2: Removing RDD 285 from persistence list
[2025-05-07T21:30:23.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManager: Removing RDD 285
[2025-05-07T21:30:23.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO ZippedPartitionsRDD2: Removing RDD 291 from persistence list
[2025-05-07T21:30:23.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManager: Removing RDD 291
[2025-05-07T21:30:23.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:23.522+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Registering RDD 305 (mapPartitions at GraphImpl.scala:208) as input to shuffle 37
[2025-05-07T21:30:23.522+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Registering RDD 313 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 36
[2025-05-07T21:30:23.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Got job 38 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:23.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Final stage: ResultStage 105 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:23.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 100, ShuffleMapStage 104, ShuffleMapStage 93, ShuffleMapStage 97, ShuffleMapStage 98)
[2025-05-07T21:30:23.524+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
[2025-05-07T21:30:23.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[305] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:23.529+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 164.3 KiB, free 417.7 MiB)
[2025-05-07T21:30:23.540+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.7 MiB)
[2025-05-07T21:30:23.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 3530b0b864fd:45373 in memory (size: 57.7 KiB, free: 433.6 MiB)
[2025-05-07T21:30:23.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 3530b0b864fd:45373 (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T21:30:23.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:23.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[305] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:23.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Adding task set 103.0 with 10 tasks resource profile 0
[2025-05-07T21:30:23.542+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.20.0.5:46863 in memory (size: 57.7 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 235) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 3530b0b864fd:45373 in memory (size: 5.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:23.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.20.0.5:46863 in memory (size: 5.9 KiB, free: 433.0 MiB)
[2025-05-07T21:30:23.551+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.20.0.5:46863 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.561+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 236) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.562+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 235) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:23.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 237) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.581+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 236) in 20 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:23.600+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 238) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.601+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 237) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:23.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 239) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.626+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 238) in 21 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:23.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 240) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 239) in 26 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:23.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 6.0 in stage 103.0 (TID 241) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 240) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:23.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 7.0 in stage 103.0 (TID 242) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 6.0 in stage 103.0 (TID 241) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:23.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 8.0 in stage 103.0 (TID 243) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 7.0 in stage 103.0 (TID 242) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:23.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 9.0 in stage 103.0 (TID 244) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.684+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 8.0 in stage 103.0 (TID 243) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:23.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 9.0 in stage 103.0 (TID 244) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:23.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-05-07T21:30:23.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: ShuffleMapStage 103 (mapPartitions at GraphImpl.scala:208) finished in 0.168 s
[2025-05-07T21:30:23.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:23.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:23.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: waiting: Set(ShuffleMapStage 104, ResultStage 105)
[2025-05-07T21:30:23.693+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:23.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[313] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:23.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 13.5 KiB, free 417.9 MiB)
[2025-05-07T21:30:23.700+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.9 MiB)
[2025-05-07T21:30:23.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 3530b0b864fd:45373 (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T21:30:23.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:23.701+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[313] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:23.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Adding task set 104.0 with 10 tasks resource profile 0
[2025-05-07T21:30:23.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 245) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.20.0.5:46863 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.713+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:43654
[2025-05-07T21:30:23.719+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 246) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 245) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:23.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 247) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 246) in 26 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:23.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 248) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.769+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 247) in 32 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:23.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.788+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 4.0 in stage 104.0 (TID 249) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.789+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 248) in 21 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:23.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 5.0 in stage 104.0 (TID 250) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 4.0 in stage 104.0 (TID 249) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:23.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.825+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 6.0 in stage 104.0 (TID 251) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.826+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 5.0 in stage 104.0 (TID 250) in 22 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:23.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 7.0 in stage 104.0 (TID 252) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.839+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 6.0 in stage 104.0 (TID 251) in 16 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:23.848+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 8.0 in stage 104.0 (TID 253) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 7.0 in stage 104.0 (TID 252) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:23.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 9.0 in stage 104.0 (TID 254) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 8.0 in stage 104.0 (TID 253) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:23.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_309_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 9.0 in stage 104.0 (TID 254) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:23.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool
[2025-05-07T21:30:23.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: ShuffleMapStage 104 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.188 s
[2025-05-07T21:30:23.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:23.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:23.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: waiting: Set(ResultStage 105)
[2025-05-07T21:30:23.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:23.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting ResultStage 105 (EdgeRDDImpl[316] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:23.888+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 164.1 KiB, free 417.7 MiB)
[2025-05-07T21:30:23.901+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 3530b0b864fd:45373 in memory (size: 58.2 KiB, free: 433.6 MiB)
[2025-05-07T21:30:23.901+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 57.9 KiB, free 417.9 MiB)
[2025-05-07T21:30:23.902+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 3530b0b864fd:45373 (size: 57.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:23.903+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:23.903+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.20.0.5:46863 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.903+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 105 (EdgeRDDImpl[316] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:23.903+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSchedulerImpl: Adding task set 105.0 with 10 tasks resource profile 0
[2025-05-07T21:30:23.905+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 255) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.20.0.5:46863 (size: 57.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.925+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:43654
[2025-05-07T21:30:23.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_315_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.932+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 256) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.933+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 255) in 29 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:23.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_315_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:23.948+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 257) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:23.965+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 256) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:23.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:23 INFO BlockManagerInfo: Added rdd_315_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 258) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.003+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 257) in 53 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:24.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_315_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 4.0 in stage 105.0 (TID 259) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 258) in 25 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:24.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_315_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.046+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 5.0 in stage 105.0 (TID 260) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.047+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 4.0 in stage 105.0 (TID 259) in 20 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:24.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_315_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 6.0 in stage 105.0 (TID 261) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 5.0 in stage 105.0 (TID 260) in 31 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:24.102+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_315_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.106+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 7.0 in stage 105.0 (TID 262) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 6.0 in stage 105.0 (TID 261) in 31 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:24.119+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_315_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.121+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 8.0 in stage 105.0 (TID 263) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.122+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 7.0 in stage 105.0 (TID 262) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:24.132+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_315_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.134+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 9.0 in stage 105.0 (TID 264) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.135+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 8.0 in stage 105.0 (TID 263) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:24.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_315_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 9.0 in stage 105.0 (TID 264) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:24.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool
[2025-05-07T21:30:24.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: ResultStage 105 (foreachPartition at PageRank.scala:199) finished in 0.264 s
[2025-05-07T21:30:24.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:24.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
[2025-05-07T21:30:24.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Job 38 finished: foreachPartition at PageRank.scala:199, took 0.628229 s
[2025-05-07T21:30:24.149+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO PageRank: PageRank finished iteration 2.
[2025-05-07T21:30:24.149+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO ZippedPartitionsRDD2: Removing RDD 297 from persistence list
[2025-05-07T21:30:24.149+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManager: Removing RDD 297
[2025-05-07T21:30:24.149+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO ZippedPartitionsRDD2: Removing RDD 303 from persistence list
[2025-05-07T21:30:24.150+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManager: Removing RDD 303
[2025-05-07T21:30:24.163+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:24.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Registering RDD 317 (mapPartitions at GraphImpl.scala:208) as input to shuffle 39
[2025-05-07T21:30:24.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Registering RDD 325 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 38
[2025-05-07T21:30:24.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Got job 39 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:24.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Final stage: ResultStage 120 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:24.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 115, ShuffleMapStage 119, ShuffleMapStage 111, ShuffleMapStage 106, ShuffleMapStage 113, ShuffleMapStage 110)
[2025-05-07T21:30:24.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
[2025-05-07T21:30:24.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[317] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:24.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 164.6 KiB, free 417.7 MiB)
[2025-05-07T21:30:24.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 3530b0b864fd:45373 in memory (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T21:30:24.183+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.7 MiB)
[2025-05-07T21:30:24.183+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 3530b0b864fd:45373 (size: 58.0 KiB, free: 433.4 MiB)
[2025-05-07T21:30:24.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.20.0.5:46863 in memory (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:24.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[317] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:24.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Adding task set 118.0 with 10 tasks resource profile 0
[2025-05-07T21:30:24.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 265) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 3530b0b864fd:45373 in memory (size: 57.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:24.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.20.0.5:46863 in memory (size: 57.9 KiB, free: 433.0 MiB)
[2025-05-07T21:30:24.195+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.20.0.5:46863 (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.209+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 266) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.209+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 265) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:24.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 267) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 266) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:24.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 268) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 267) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:24.255+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 269) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 268) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:24.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 270) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 269) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:24.276+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 271) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.277+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 270) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:24.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 272) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 271) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:24.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 8.0 in stage 118.0 (TID 273) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 272) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:24.306+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 9.0 in stage 118.0 (TID 274) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.307+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 8.0 in stage 118.0 (TID 273) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:24.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 9.0 in stage 118.0 (TID 274) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:24.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-05-07T21:30:24.316+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: ShuffleMapStage 118 (mapPartitions at GraphImpl.scala:208) finished in 0.147 s
[2025-05-07T21:30:24.316+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:24.316+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:24.316+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: waiting: Set(ShuffleMapStage 119, ResultStage 120)
[2025-05-07T21:30:24.316+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:24.316+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[325] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:24.318+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 14.2 KiB, free 417.9 MiB)
[2025-05-07T21:30:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.9 MiB)
[2025-05-07T21:30:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 3530b0b864fd:45373 (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T21:30:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[325] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:24.327+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Adding task set 119.0 with 10 tasks resource profile 0
[2025-05-07T21:30:24.328+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 275) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.20.0.5:46863 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:43654
[2025-05-07T21:30:24.342+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 276) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 275) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:24.358+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.375+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 277) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.375+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 276) in 28 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:24.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 278) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 277) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:24.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 4.0 in stage 119.0 (TID 279) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 278) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:24.411+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 5.0 in stage 119.0 (TID 280) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 4.0 in stage 119.0 (TID 279) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:24.424+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 6.0 in stage 119.0 (TID 281) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 5.0 in stage 119.0 (TID 280) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:24.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 7.0 in stage 119.0 (TID 282) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.440+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 6.0 in stage 119.0 (TID 281) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:24.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 8.0 in stage 119.0 (TID 283) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.453+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 7.0 in stage 119.0 (TID 282) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:24.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 9.0 in stage 119.0 (TID 284) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 8.0 in stage 119.0 (TID 283) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:24.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_321_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 9.0 in stage 119.0 (TID 284) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:24.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-05-07T21:30:24.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: ShuffleMapStage 119 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.166 s
[2025-05-07T21:30:24.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:24.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:24.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: waiting: Set(ResultStage 120)
[2025-05-07T21:30:24.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:24.485+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting ResultStage 120 (EdgeRDDImpl[328] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:24.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 164.4 KiB, free 417.7 MiB)
[2025-05-07T21:30:24.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 57.8 KiB, free 417.9 MiB)
[2025-05-07T21:30:24.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 3530b0b864fd:45373 in memory (size: 58.0 KiB, free: 433.6 MiB)
[2025-05-07T21:30:24.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 3530b0b864fd:45373 (size: 57.8 KiB, free: 433.5 MiB)
[2025-05-07T21:30:24.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:24.504+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 120 (EdgeRDDImpl[328] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:24.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Adding task set 120.0 with 10 tasks resource profile 0
[2025-05-07T21:30:24.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 285) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.20.0.5:46863 in memory (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.524+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.20.0.5:46863 (size: 57.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.536+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:43654
[2025-05-07T21:30:24.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 286) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 285) in 38 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:24.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.567+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 287) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.567+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 286) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:24.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 288) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.585+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 287) in 19 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:24.598+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.601+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 4.0 in stage 120.0 (TID 289) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 288) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:24.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 5.0 in stage 120.0 (TID 290) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.616+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 4.0 in stage 120.0 (TID 289) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:24.625+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 6.0 in stage 120.0 (TID 291) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 5.0 in stage 120.0 (TID 290) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:24.638+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 7.0 in stage 120.0 (TID 292) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 6.0 in stage 120.0 (TID 291) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:24.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 8.0 in stage 120.0 (TID 293) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 7.0 in stage 120.0 (TID 292) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:24.663+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 9.0 in stage 120.0 (TID 294) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 8.0 in stage 120.0 (TID 293) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:24.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_327_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 9.0 in stage 120.0 (TID 294) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:24.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool
[2025-05-07T21:30:24.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: ResultStage 120 (foreachPartition at PageRank.scala:199) finished in 0.194 s
[2025-05-07T21:30:24.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:24.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished
[2025-05-07T21:30:24.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Job 39 finished: foreachPartition at PageRank.scala:199, took 0.517010 s
[2025-05-07T21:30:24.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO PageRank: PageRank finished iteration 3.
[2025-05-07T21:30:24.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO ZippedPartitionsRDD2: Removing RDD 309 from persistence list
[2025-05-07T21:30:24.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManager: Removing RDD 309
[2025-05-07T21:30:24.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO ZippedPartitionsRDD2: Removing RDD 315 from persistence list
[2025-05-07T21:30:24.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManager: Removing RDD 315
[2025-05-07T21:30:24.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:24.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Registering RDD 329 (mapPartitions at GraphImpl.scala:208) as input to shuffle 41
[2025-05-07T21:30:24.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Registering RDD 337 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 40
[2025-05-07T21:30:24.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Got job 40 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:24.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Final stage: ResultStage 137 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:24.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132, ShuffleMapStage 121, ShuffleMapStage 136, ShuffleMapStage 125, ShuffleMapStage 126, ShuffleMapStage 130, ShuffleMapStage 134, ShuffleMapStage 128)
[2025-05-07T21:30:24.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
[2025-05-07T21:30:24.700+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[329] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:24.707+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 164.9 KiB, free 417.7 MiB)
[2025-05-07T21:30:24.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 3530b0b864fd:45373 in memory (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T21:30:24.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.7 MiB)
[2025-05-07T21:30:24.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 3530b0b864fd:45373 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T21:30:24.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:24.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[329] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:24.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Adding task set 135.0 with 10 tasks resource profile 0
[2025-05-07T21:30:24.718+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.20.0.5:46863 in memory (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.719+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 295) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.721+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 3530b0b864fd:45373 in memory (size: 57.8 KiB, free: 433.5 MiB)
[2025-05-07T21:30:24.721+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.20.0.5:46863 in memory (size: 57.8 KiB, free: 433.0 MiB)
[2025-05-07T21:30:24.728+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.20.0.5:46863 (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.742+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 296) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.743+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 295) in 25 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:24.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 297) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.752+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 296) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:24.768+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 298) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.769+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 297) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:24.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 4.0 in stage 135.0 (TID 299) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 298) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:24.786+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 5.0 in stage 135.0 (TID 300) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.787+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 4.0 in stage 135.0 (TID 299) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:24.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 6.0 in stage 135.0 (TID 301) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.796+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 5.0 in stage 135.0 (TID 300) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:24.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 7.0 in stage 135.0 (TID 302) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 6.0 in stage 135.0 (TID 301) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:24.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 8.0 in stage 135.0 (TID 303) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 7.0 in stage 135.0 (TID 302) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:24.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 9.0 in stage 135.0 (TID 304) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 8.0 in stage 135.0 (TID 303) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:24.829+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 9.0 in stage 135.0 (TID 304) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:24.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool
[2025-05-07T21:30:24.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: ShuffleMapStage 135 (mapPartitions at GraphImpl.scala:208) finished in 0.128 s
[2025-05-07T21:30:24.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:24.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:24.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: waiting: Set(ShuffleMapStage 136, ResultStage 137)
[2025-05-07T21:30:24.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:24.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[337] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:24.831+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 14.9 KiB, free 417.9 MiB)
[2025-05-07T21:30:24.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 417.9 MiB)
[2025-05-07T21:30:24.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 3530b0b864fd:45373 (size: 6.3 KiB, free: 433.5 MiB)
[2025-05-07T21:30:24.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:24.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[337] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:24.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Adding task set 136.0 with 10 tasks resource profile 0
[2025-05-07T21:30:24.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 305) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.20.0.5:46863 (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.848+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:43654
[2025-05-07T21:30:24.852+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 306) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 305) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:24.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.880+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 2.0 in stage 136.0 (TID 307) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.880+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 306) in 24 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:24.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 3.0 in stage 136.0 (TID 308) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 2.0 in stage 136.0 (TID 307) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:24.901+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.905+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 4.0 in stage 136.0 (TID 309) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.905+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 3.0 in stage 136.0 (TID 308) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:24.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.925+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 5.0 in stage 136.0 (TID 310) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 4.0 in stage 136.0 (TID 309) in 21 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:24.931+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 6.0 in stage 136.0 (TID 311) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 5.0 in stage 136.0 (TID 310) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:24.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 7.0 in stage 136.0 (TID 312) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 6.0 in stage 136.0 (TID 311) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:24.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.955+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 8.0 in stage 136.0 (TID 313) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.955+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 7.0 in stage 136.0 (TID 312) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:24.963+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.967+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Starting task 9.0 in stage 136.0 (TID 314) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:24.967+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 8.0 in stage 136.0 (TID 313) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:24.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added rdd_333_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSetManager: Finished task 9.0 in stage 136.0 (TID 314) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:24.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-05-07T21:30:24.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: ShuffleMapStage 136 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.148 s
[2025-05-07T21:30:24.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:24.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:24.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: waiting: Set(ResultStage 137)
[2025-05-07T21:30:24.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:24.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting ResultStage 137 (EdgeRDDImpl[340] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:24.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 164.7 KiB, free 417.7 MiB)
[2025-05-07T21:30:24.995+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.7 MiB)
[2025-05-07T21:30:24.996+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 3530b0b864fd:45373 in memory (size: 58.3 KiB, free: 433.6 MiB)
[2025-05-07T21:30:24.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 3530b0b864fd:45373 (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:24.997+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.20.0.5:46863 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:24.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:24.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 137 (EdgeRDDImpl[340] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:24.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:24 INFO TaskSchedulerImpl: Adding task set 137.0 with 10 tasks resource profile 0
[2025-05-07T21:30:25.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 315) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.009+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.20.0.5:46863 (size: 58.0 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:43654
[2025-05-07T21:30:25.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.029+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 316) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 315) in 30 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:25.059+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 2.0 in stage 137.0 (TID 317) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.064+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 316) in 34 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:25.080+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.084+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 3.0 in stage 137.0 (TID 318) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 2.0 in stage 137.0 (TID 317) in 22 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:25.099+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 4.0 in stage 137.0 (TID 319) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.102+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 3.0 in stage 137.0 (TID 318) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:25.112+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 5.0 in stage 137.0 (TID 320) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.115+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 4.0 in stage 137.0 (TID 319) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:25.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.130+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 6.0 in stage 137.0 (TID 321) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 5.0 in stage 137.0 (TID 320) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:25.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 7.0 in stage 137.0 (TID 322) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 6.0 in stage 137.0 (TID 321) in 17 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:25.158+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 8.0 in stage 137.0 (TID 323) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 7.0 in stage 137.0 (TID 322) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:25.170+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 9.0 in stage 137.0 (TID 324) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 8.0 in stage 137.0 (TID 323) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:25.184+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_339_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 9.0 in stage 137.0 (TID 324) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:25.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool
[2025-05-07T21:30:25.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: ResultStage 137 (foreachPartition at PageRank.scala:199) finished in 0.206 s
[2025-05-07T21:30:25.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:25.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
[2025-05-07T21:30:25.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Job 40 finished: foreachPartition at PageRank.scala:199, took 0.493097 s
[2025-05-07T21:30:25.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO PageRank: PageRank finished iteration 4.
[2025-05-07T21:30:25.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO ZippedPartitionsRDD2: Removing RDD 321 from persistence list
[2025-05-07T21:30:25.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManager: Removing RDD 321
[2025-05-07T21:30:25.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO ZippedPartitionsRDD2: Removing RDD 327 from persistence list
[2025-05-07T21:30:25.190+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManager: Removing RDD 327
[2025-05-07T21:30:25.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:25.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Registering RDD 341 (mapPartitions at GraphImpl.scala:208) as input to shuffle 43
[2025-05-07T21:30:25.205+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Registering RDD 349 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 42
[2025-05-07T21:30:25.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Got job 41 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:25.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Final stage: ResultStage 156 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:25.206+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143, ShuffleMapStage 153, ShuffleMapStage 147, ShuffleMapStage 151, ShuffleMapStage 155, ShuffleMapStage 138, ShuffleMapStage 145, ShuffleMapStage 142, ShuffleMapStage 149)
[2025-05-07T21:30:25.207+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 155)
[2025-05-07T21:30:25.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[341] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:25.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 165.2 KiB, free 417.7 MiB)
[2025-05-07T21:30:25.224+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.7 MiB)
[2025-05-07T21:30:25.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 3530b0b864fd:45373 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T21:30:25.225+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:25.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 3530b0b864fd:45373 in memory (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:25.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[341] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:25.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Adding task set 154.0 with 10 tasks resource profile 0
[2025-05-07T21:30:25.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 325) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.20.0.5:46863 in memory (size: 58.0 KiB, free: 433.0 MiB)
[2025-05-07T21:30:25.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 3530b0b864fd:45373 in memory (size: 6.3 KiB, free: 433.5 MiB)
[2025-05-07T21:30:25.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.20.0.5:46863 in memory (size: 6.3 KiB, free: 433.0 MiB)
[2025-05-07T21:30:25.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.20.0.5:46863 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.247+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 326) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 325) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:25.258+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 327) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 326) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:25.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 328) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 327) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:25.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 329) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 328) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:25.301+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 5.0 in stage 154.0 (TID 330) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 329) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:25.311+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 6.0 in stage 154.0 (TID 331) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 5.0 in stage 154.0 (TID 330) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:25.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 7.0 in stage 154.0 (TID 332) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 6.0 in stage 154.0 (TID 331) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:25.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 8.0 in stage 154.0 (TID 333) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.337+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 7.0 in stage 154.0 (TID 332) in 18 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:25.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 9.0 in stage 154.0 (TID 334) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.349+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 8.0 in stage 154.0 (TID 333) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:25.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 9.0 in stage 154.0 (TID 334) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:25.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool
[2025-05-07T21:30:25.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: ShuffleMapStage 154 (mapPartitions at GraphImpl.scala:208) finished in 0.157 s
[2025-05-07T21:30:25.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:25.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:25.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 155, ResultStage 156)
[2025-05-07T21:30:25.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:25.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[349] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:25.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 15.6 KiB, free 417.9 MiB)
[2025-05-07T21:30:25.377+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 417.9 MiB)
[2025-05-07T21:30:25.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 3530b0b864fd:45373 (size: 6.4 KiB, free: 433.5 MiB)
[2025-05-07T21:30:25.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:25.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[349] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:25.378+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Adding task set 155.0 with 10 tasks resource profile 0
[2025-05-07T21:30:25.379+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 335) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.384+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.20.0.5:46863 (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.387+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:43654
[2025-05-07T21:30:25.392+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 336) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 335) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:25.403+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 337) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.409+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 336) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:25.425+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 338) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 337) in 21 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:25.436+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 4.0 in stage 155.0 (TID 339) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 338) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:25.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.452+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 5.0 in stage 155.0 (TID 340) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.452+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 4.0 in stage 155.0 (TID 339) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:25.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 6.0 in stage 155.0 (TID 341) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.463+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 5.0 in stage 155.0 (TID 340) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:25.469+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 7.0 in stage 155.0 (TID 342) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 6.0 in stage 155.0 (TID 341) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:25.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 8.0 in stage 155.0 (TID 343) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.484+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 7.0 in stage 155.0 (TID 342) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:25.491+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 9.0 in stage 155.0 (TID 344) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.495+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 8.0 in stage 155.0 (TID 343) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:25.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_345_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 9.0 in stage 155.0 (TID 344) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:25.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool
[2025-05-07T21:30:25.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: ShuffleMapStage 155 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.138 s
[2025-05-07T21:30:25.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:25.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:25.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: waiting: Set(ResultStage 156)
[2025-05-07T21:30:25.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:25.506+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting ResultStage 156 (EdgeRDDImpl[352] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:25.512+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 165.0 KiB, free 417.7 MiB)
[2025-05-07T21:30:25.520+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 3530b0b864fd:45373 in memory (size: 58.2 KiB, free: 433.6 MiB)
[2025-05-07T21:30:25.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.9 MiB)
[2025-05-07T21:30:25.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 3530b0b864fd:45373 (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T21:30:25.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:25.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 156 (EdgeRDDImpl[352] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:25.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Adding task set 156.0 with 10 tasks resource profile 0
[2025-05-07T21:30:25.522+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.20.0.5:46863 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.525+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 345) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.530+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.20.0.5:46863 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:43654
[2025-05-07T21:30:25.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 346) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.550+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 345) in 27 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:25.569+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.572+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 347) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 346) in 23 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:25.584+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 348) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 347) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:25.597+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 4.0 in stage 156.0 (TID 349) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 348) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:25.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 5.0 in stage 156.0 (TID 350) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 4.0 in stage 156.0 (TID 349) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:25.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.623+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 6.0 in stage 156.0 (TID 351) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.624+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 5.0 in stage 156.0 (TID 350) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:25.637+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 7.0 in stage 156.0 (TID 352) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.640+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 6.0 in stage 156.0 (TID 351) in 17 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:25.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 8.0 in stage 156.0 (TID 353) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 7.0 in stage 156.0 (TID 352) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:25.662+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 9.0 in stage 156.0 (TID 354) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 8.0 in stage 156.0 (TID 353) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:25.673+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_351_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 9.0 in stage 156.0 (TID 354) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:25.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool
[2025-05-07T21:30:25.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: ResultStage 156 (foreachPartition at PageRank.scala:199) finished in 0.171 s
[2025-05-07T21:30:25.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:25.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished
[2025-05-07T21:30:25.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Job 41 finished: foreachPartition at PageRank.scala:199, took 0.475319 s
[2025-05-07T21:30:25.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO PageRank: PageRank finished iteration 5.
[2025-05-07T21:30:25.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO ZippedPartitionsRDD2: Removing RDD 333 from persistence list
[2025-05-07T21:30:25.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManager: Removing RDD 333
[2025-05-07T21:30:25.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO ZippedPartitionsRDD2: Removing RDD 339 from persistence list
[2025-05-07T21:30:25.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManager: Removing RDD 339
[2025-05-07T21:30:25.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:25.697+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Registering RDD 353 (mapPartitions at GraphImpl.scala:208) as input to shuffle 45
[2025-05-07T21:30:25.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Registering RDD 361 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 44
[2025-05-07T21:30:25.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Got job 42 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:25.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Final stage: ResultStage 177 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:25.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 161, ShuffleMapStage 168, ShuffleMapStage 157, ShuffleMapStage 172, ShuffleMapStage 166, ShuffleMapStage 176, ShuffleMapStage 170, ShuffleMapStage 162, ShuffleMapStage 174, ShuffleMapStage 164)
[2025-05-07T21:30:25.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 176)
[2025-05-07T21:30:25.699+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[353] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:25.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 165.5 KiB, free 417.7 MiB)
[2025-05-07T21:30:25.707+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 417.7 MiB)
[2025-05-07T21:30:25.708+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 3530b0b864fd:45373 (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-07T21:30:25.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:25.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[353] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:25.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Adding task set 175.0 with 10 tasks resource profile 0
[2025-05-07T21:30:25.710+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 355) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.20.0.5:46863 (size: 58.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 1.0 in stage 175.0 (TID 356) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.729+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 355) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:25.743+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 2.0 in stage 175.0 (TID 357) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.743+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 1.0 in stage 175.0 (TID 356) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:25.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 3.0 in stage 175.0 (TID 358) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.755+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 2.0 in stage 175.0 (TID 357) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:25.773+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 4.0 in stage 175.0 (TID 359) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 3.0 in stage 175.0 (TID 358) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:25.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 5.0 in stage 175.0 (TID 360) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 4.0 in stage 175.0 (TID 359) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:25.793+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 6.0 in stage 175.0 (TID 361) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 5.0 in stage 175.0 (TID 360) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:25.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 7.0 in stage 175.0 (TID 362) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 6.0 in stage 175.0 (TID 361) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:25.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 8.0 in stage 175.0 (TID 363) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.815+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 7.0 in stage 175.0 (TID 362) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:25.823+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 9.0 in stage 175.0 (TID 364) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.824+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 8.0 in stage 175.0 (TID 363) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:25.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 9.0 in stage 175.0 (TID 364) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:25.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool
[2025-05-07T21:30:25.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: ShuffleMapStage 175 (mapPartitions at GraphImpl.scala:208) finished in 0.138 s
[2025-05-07T21:30:25.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:25.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:25.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 176, ResultStage 177)
[2025-05-07T21:30:25.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:25.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[361] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:25.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 16.4 KiB, free 417.6 MiB)
[2025-05-07T21:30:25.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 417.6 MiB)
[2025-05-07T21:30:25.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 3530b0b864fd:45373 (size: 6.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:25.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:25.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[361] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:25.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Adding task set 176.0 with 10 tasks resource profile 0
[2025-05-07T21:30:25.843+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 365) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.849+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.20.0.5:46863 (size: 6.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:43654
[2025-05-07T21:30:25.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 1.0 in stage 176.0 (TID 366) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 365) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:25.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 2.0 in stage 176.0 (TID 367) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 1.0 in stage 176.0 (TID 366) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:25.878+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 3.0 in stage 176.0 (TID 368) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 2.0 in stage 176.0 (TID 367) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:25.887+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 4.0 in stage 176.0 (TID 369) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.893+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 3.0 in stage 176.0 (TID 368) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:25.901+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.904+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 5.0 in stage 176.0 (TID 370) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.905+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 4.0 in stage 176.0 (TID 369) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:25.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:25.917+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 6.0 in stage 176.0 (TID 371) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.917+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 5.0 in stage 176.0 (TID 370) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:25.923+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:25.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 7.0 in stage 176.0 (TID 372) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 6.0 in stage 176.0 (TID 371) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:25.935+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:25.939+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 8.0 in stage 176.0 (TID 373) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.940+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 7.0 in stage 176.0 (TID 372) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:25.947+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:25.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 9.0 in stage 176.0 (TID 374) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 8.0 in stage 176.0 (TID 373) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:25.959+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added rdd_357_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:25.963+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Finished task 9.0 in stage 176.0 (TID 374) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:25.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool
[2025-05-07T21:30:25.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: ShuffleMapStage 176 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.125 s
[2025-05-07T21:30:25.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:25.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:25.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: waiting: Set(ResultStage 177)
[2025-05-07T21:30:25.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:25.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting ResultStage 177 (EdgeRDDImpl[364] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:25.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 165.3 KiB, free 417.5 MiB)
[2025-05-07T21:30:25.978+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 3530b0b864fd:45373 in memory (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T21:30:25.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.5 MiB)
[2025-05-07T21:30:25.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 3530b0b864fd:45373 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T21:30:25.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:25.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 177 (EdgeRDDImpl[364] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:25.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSchedulerImpl: Adding task set 177.0 with 10 tasks resource profile 0
[2025-05-07T21:30:25.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 375) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:25.982+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.20.0.5:46863 in memory (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 3530b0b864fd:45373 in memory (size: 6.4 KiB, free: 433.4 MiB)
[2025-05-07T21:30:25.985+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.20.0.5:46863 in memory (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 3530b0b864fd:45373 in memory (size: 58.4 KiB, free: 433.5 MiB)
[2025-05-07T21:30:25.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.20.0.5:46863 in memory (size: 58.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.20.0.5:46863 (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:25.998+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:43654
[2025-05-07T21:30:26.001+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 376) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.004+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 375) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:26.015+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 2.0 in stage 177.0 (TID 377) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 376) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:26.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.045+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 3.0 in stage 177.0 (TID 378) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.045+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 2.0 in stage 177.0 (TID 377) in 28 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:26.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.061+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 4.0 in stage 177.0 (TID 379) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 3.0 in stage 177.0 (TID 378) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:26.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 5.0 in stage 177.0 (TID 380) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.077+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 4.0 in stage 177.0 (TID 379) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:26.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 6.0 in stage 177.0 (TID 381) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 5.0 in stage 177.0 (TID 380) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:26.104+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 7.0 in stage 177.0 (TID 382) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.109+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 6.0 in stage 177.0 (TID 381) in 21 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:26.121+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 8.0 in stage 177.0 (TID 383) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 7.0 in stage 177.0 (TID 382) in 19 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:26.146+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.149+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 9.0 in stage 177.0 (TID 384) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.149+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 8.0 in stage 177.0 (TID 383) in 24 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:26.162+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_363_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 9.0 in stage 177.0 (TID 384) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:26.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool
[2025-05-07T21:30:26.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: ResultStage 177 (foreachPartition at PageRank.scala:199) finished in 0.200 s
[2025-05-07T21:30:26.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:26.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished
[2025-05-07T21:30:26.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Job 42 finished: foreachPartition at PageRank.scala:199, took 0.470615 s
[2025-05-07T21:30:26.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO PageRank: PageRank finished iteration 6.
[2025-05-07T21:30:26.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO ZippedPartitionsRDD2: Removing RDD 345 from persistence list
[2025-05-07T21:30:26.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManager: Removing RDD 345
[2025-05-07T21:30:26.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO ZippedPartitionsRDD2: Removing RDD 351 from persistence list
[2025-05-07T21:30:26.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManager: Removing RDD 351
[2025-05-07T21:30:26.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:26.185+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Registering RDD 365 (mapPartitions at GraphImpl.scala:208) as input to shuffle 47
[2025-05-07T21:30:26.185+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Registering RDD 373 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 46
[2025-05-07T21:30:26.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Got job 43 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:26.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Final stage: ResultStage 200 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:26.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 197, ShuffleMapStage 183, ShuffleMapStage 187, ShuffleMapStage 191, ShuffleMapStage 195, ShuffleMapStage 189, ShuffleMapStage 199, ShuffleMapStage 178, ShuffleMapStage 193, ShuffleMapStage 185, ShuffleMapStage 182)
[2025-05-07T21:30:26.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 199)
[2025-05-07T21:30:26.186+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[365] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:26.193+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 165.8 KiB, free 417.7 MiB)
[2025-05-07T21:30:26.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 417.7 MiB)
[2025-05-07T21:30:26.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 3530b0b864fd:45373 (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:26.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[365] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:26.195+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Adding task set 198.0 with 10 tasks resource profile 0
[2025-05-07T21:30:26.195+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 385) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.200+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.20.0.5:46863 (size: 58.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 1.0 in stage 198.0 (TID 386) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 385) in 15 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:26.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 2.0 in stage 198.0 (TID 387) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 1.0 in stage 198.0 (TID 386) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:26.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 3.0 in stage 198.0 (TID 388) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 2.0 in stage 198.0 (TID 387) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:26.233+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 4.0 in stage 198.0 (TID 389) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 3.0 in stage 198.0 (TID 388) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:26.242+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 5.0 in stage 198.0 (TID 390) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 4.0 in stage 198.0 (TID 389) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:26.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 6.0 in stage 198.0 (TID 391) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.250+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 5.0 in stage 198.0 (TID 390) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:26.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 7.0 in stage 198.0 (TID 392) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.259+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 6.0 in stage 198.0 (TID 391) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:26.266+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 8.0 in stage 198.0 (TID 393) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.267+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 7.0 in stage 198.0 (TID 392) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:26.277+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 9.0 in stage 198.0 (TID 394) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.277+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 8.0 in stage 198.0 (TID 393) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:26.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 9.0 in stage 198.0 (TID 394) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:26.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool
[2025-05-07T21:30:26.285+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: ShuffleMapStage 198 (mapPartitions at GraphImpl.scala:208) finished in 0.097 s
[2025-05-07T21:30:26.285+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:26.285+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:26.285+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 199, ResultStage 200)
[2025-05-07T21:30:26.285+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:26.285+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[373] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:26.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 17.1 KiB, free 417.6 MiB)
[2025-05-07T21:30:26.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 417.6 MiB)
[2025-05-07T21:30:26.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 3530b0b864fd:45373 (size: 6.6 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.287+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:26.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[373] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:26.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Adding task set 199.0 with 10 tasks resource profile 0
[2025-05-07T21:30:26.288+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 395) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.294+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.20.0.5:46863 (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.297+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:43654
[2025-05-07T21:30:26.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 1.0 in stage 199.0 (TID 396) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.303+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 395) in 15 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:26.310+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.314+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 2.0 in stage 199.0 (TID 397) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.315+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 1.0 in stage 199.0 (TID 396) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:26.320+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.324+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 3.0 in stage 199.0 (TID 398) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.325+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 2.0 in stage 199.0 (TID 397) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:26.330+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.334+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 4.0 in stage 199.0 (TID 399) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.334+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 3.0 in stage 199.0 (TID 398) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:26.343+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.347+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 5.0 in stage 199.0 (TID 400) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.347+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 4.0 in stage 199.0 (TID 399) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:26.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.359+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 6.0 in stage 199.0 (TID 401) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 5.0 in stage 199.0 (TID 400) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:26.367+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.371+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 7.0 in stage 199.0 (TID 402) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.372+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 6.0 in stage 199.0 (TID 401) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:26.380+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 8.0 in stage 199.0 (TID 403) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 7.0 in stage 199.0 (TID 402) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:26.388+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.393+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 9.0 in stage 199.0 (TID 404) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.393+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 8.0 in stage 199.0 (TID 403) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:26.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_369_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 9.0 in stage 199.0 (TID 404) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:26.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool
[2025-05-07T21:30:26.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: ShuffleMapStage 199 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.116 s
[2025-05-07T21:30:26.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:26.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:26.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: waiting: Set(ResultStage 200)
[2025-05-07T21:30:26.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:26.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting ResultStage 200 (EdgeRDDImpl[376] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:26.407+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 165.6 KiB, free 417.5 MiB)
[2025-05-07T21:30:26.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 3530b0b864fd:45373 in memory (size: 6.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.4 MiB)
[2025-05-07T21:30:26.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 3530b0b864fd:45373 (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:26.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 200 (EdgeRDDImpl[376] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:26.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Adding task set 200.0 with 10 tasks resource profile 0
[2025-05-07T21:30:26.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.20.0.5:46863 in memory (size: 6.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 405) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 3530b0b864fd:45373 in memory (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.418+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.20.0.5:46863 in memory (size: 58.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.419+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 3530b0b864fd:45373 in memory (size: 58.4 KiB, free: 433.5 MiB)
[2025-05-07T21:30:26.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.20.0.5:46863 in memory (size: 58.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.20.0.5:46863 (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.430+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:43654
[2025-05-07T21:30:26.433+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 406) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.435+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 405) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:26.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.463+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 2.0 in stage 200.0 (TID 407) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 406) in 28 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:26.483+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.486+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 3.0 in stage 200.0 (TID 408) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 2.0 in stage 200.0 (TID 407) in 24 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:26.497+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 4.0 in stage 200.0 (TID 409) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 3.0 in stage 200.0 (TID 408) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:26.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 5.0 in stage 200.0 (TID 410) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 4.0 in stage 200.0 (TID 409) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:26.519+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 6.0 in stage 200.0 (TID 411) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.521+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 5.0 in stage 200.0 (TID 410) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:26.530+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 7.0 in stage 200.0 (TID 412) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 6.0 in stage 200.0 (TID 411) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:26.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 8.0 in stage 200.0 (TID 413) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.544+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 7.0 in stage 200.0 (TID 412) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:26.551+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.553+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 9.0 in stage 200.0 (TID 414) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.553+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 8.0 in stage 200.0 (TID 413) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:26.562+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_375_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 9.0 in stage 200.0 (TID 414) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:26.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool
[2025-05-07T21:30:26.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: ResultStage 200 (foreachPartition at PageRank.scala:199) finished in 0.163 s
[2025-05-07T21:30:26.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:26.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished
[2025-05-07T21:30:26.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Job 43 finished: foreachPartition at PageRank.scala:199, took 0.383728 s
[2025-05-07T21:30:26.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO PageRank: PageRank finished iteration 7.
[2025-05-07T21:30:26.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO ZippedPartitionsRDD2: Removing RDD 357 from persistence list
[2025-05-07T21:30:26.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManager: Removing RDD 357
[2025-05-07T21:30:26.566+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO ZippedPartitionsRDD2: Removing RDD 363 from persistence list
[2025-05-07T21:30:26.567+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManager: Removing RDD 363
[2025-05-07T21:30:26.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:26.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Registering RDD 377 (mapPartitions at GraphImpl.scala:208) as input to shuffle 49
[2025-05-07T21:30:26.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Registering RDD 385 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 48
[2025-05-07T21:30:26.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Got job 44 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:26.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Final stage: ResultStage 225 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:26.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 212, ShuffleMapStage 222, ShuffleMapStage 201, ShuffleMapStage 216, ShuffleMapStage 208, ShuffleMapStage 205, ShuffleMapStage 220, ShuffleMapStage 206, ShuffleMapStage 224, ShuffleMapStage 210, ShuffleMapStage 214, ShuffleMapStage 218)
[2025-05-07T21:30:26.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 224)
[2025-05-07T21:30:26.583+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[377] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:26.586+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 166.0 KiB, free 417.7 MiB)
[2025-05-07T21:30:26.587+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.7 MiB)
[2025-05-07T21:30:26.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 3530b0b864fd:45373 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:26.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[377] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:26.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Adding task set 223.0 with 10 tasks resource profile 0
[2025-05-07T21:30:26.589+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 415) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.595+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.20.0.5:46863 (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 1.0 in stage 223.0 (TID 416) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 415) in 13 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:26.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 2.0 in stage 223.0 (TID 417) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 1.0 in stage 223.0 (TID 416) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:26.619+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 3.0 in stage 223.0 (TID 418) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.620+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 2.0 in stage 223.0 (TID 417) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:26.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 4.0 in stage 223.0 (TID 419) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.629+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 3.0 in stage 223.0 (TID 418) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:26.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 5.0 in stage 223.0 (TID 420) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 4.0 in stage 223.0 (TID 419) in 7 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:26.643+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 6.0 in stage 223.0 (TID 421) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.644+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 5.0 in stage 223.0 (TID 420) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:26.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 7.0 in stage 223.0 (TID 422) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 6.0 in stage 223.0 (TID 421) in 7 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:26.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 8.0 in stage 223.0 (TID 423) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.659+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 7.0 in stage 223.0 (TID 422) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:26.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 9.0 in stage 223.0 (TID 424) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 8.0 in stage 223.0 (TID 423) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:26.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 9.0 in stage 223.0 (TID 424) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:26.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool
[2025-05-07T21:30:26.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: ShuffleMapStage 223 (mapPartitions at GraphImpl.scala:208) finished in 0.089 s
[2025-05-07T21:30:26.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:26.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:26.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 224, ResultStage 225)
[2025-05-07T21:30:26.672+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:26.673+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[385] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:26.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 17.8 KiB, free 417.6 MiB)
[2025-05-07T21:30:26.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.6 MiB)
[2025-05-07T21:30:26.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 3530b0b864fd:45373 (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:26.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[385] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:26.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Adding task set 224.0 with 10 tasks resource profile 0
[2025-05-07T21:30:26.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 425) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.20.0.5:46863 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:43654
[2025-05-07T21:30:26.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 1.0 in stage 224.0 (TID 426) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.688+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 425) in 11 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:26.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.697+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 2.0 in stage 224.0 (TID 427) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.698+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 1.0 in stage 224.0 (TID 426) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:26.702+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.705+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 3.0 in stage 224.0 (TID 428) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.706+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 2.0 in stage 224.0 (TID 427) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:26.712+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 4.0 in stage 224.0 (TID 429) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 3.0 in stage 224.0 (TID 428) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:26.720+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.725+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 5.0 in stage 224.0 (TID 430) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.726+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 4.0 in stage 224.0 (TID 429) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:26.732+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 6.0 in stage 224.0 (TID 431) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 5.0 in stage 224.0 (TID 430) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:26.744+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.750+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 7.0 in stage 224.0 (TID 432) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.751+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 6.0 in stage 224.0 (TID 431) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:26.759+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 8.0 in stage 224.0 (TID 433) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 7.0 in stage 224.0 (TID 432) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:26.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 9.0 in stage 224.0 (TID 434) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.784+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 8.0 in stage 224.0 (TID 433) in 20 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:26.788+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_381_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:26.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 9.0 in stage 224.0 (TID 434) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:26.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool
[2025-05-07T21:30:26.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: ShuffleMapStage 224 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.121 s
[2025-05-07T21:30:26.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:26.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:26.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: waiting: Set(ResultStage 225)
[2025-05-07T21:30:26.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:26.794+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting ResultStage 225 (EdgeRDDImpl[388] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:26.798+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 165.8 KiB, free 417.5 MiB)
[2025-05-07T21:30:26.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 3530b0b864fd:45373 in memory (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T21:30:26.805+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.5 MiB)
[2025-05-07T21:30:26.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 3530b0b864fd:45373 (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.20.0.5:46863 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:26.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 225 (EdgeRDDImpl[388] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:26.806+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Adding task set 225.0 with 10 tasks resource profile 0
[2025-05-07T21:30:26.808+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 435) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.809+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 3530b0b864fd:45373 in memory (size: 6.6 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.811+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.20.0.5:46863 in memory (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 3530b0b864fd:45373 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-07T21:30:26.813+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.20.0.5:46863 in memory (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.814+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.20.0.5:46863 (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.820+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.20.0.5:43654
[2025-05-07T21:30:26.824+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 1.0 in stage 225.0 (TID 436) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.828+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 435) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:26.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 2.0 in stage 225.0 (TID 437) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 1.0 in stage 225.0 (TID 436) in 27 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:26.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.869+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 3.0 in stage 225.0 (TID 438) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 2.0 in stage 225.0 (TID 437) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:26.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 4.0 in stage 225.0 (TID 439) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.884+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 3.0 in stage 225.0 (TID 438) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:26.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 5.0 in stage 225.0 (TID 440) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 4.0 in stage 225.0 (TID 439) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:26.902+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.904+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 6.0 in stage 225.0 (TID 441) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.904+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 5.0 in stage 225.0 (TID 440) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:26.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 7.0 in stage 225.0 (TID 442) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 6.0 in stage 225.0 (TID 441) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:26.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 8.0 in stage 225.0 (TID 443) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 7.0 in stage 225.0 (TID 442) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:26.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.938+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 9.0 in stage 225.0 (TID 444) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.938+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 8.0 in stage 225.0 (TID 443) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:26.948+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added rdd_387_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:26.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Finished task 9.0 in stage 225.0 (TID 444) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:26.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool
[2025-05-07T21:30:26.951+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: ResultStage 225 (foreachPartition at PageRank.scala:199) finished in 0.156 s
[2025-05-07T21:30:26.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:26.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished
[2025-05-07T21:30:26.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Job 44 finished: foreachPartition at PageRank.scala:199, took 0.371955 s
[2025-05-07T21:30:26.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO PageRank: PageRank finished iteration 8.
[2025-05-07T21:30:26.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO ZippedPartitionsRDD2: Removing RDD 369 from persistence list
[2025-05-07T21:30:26.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO ZippedPartitionsRDD2: Removing RDD 375 from persistence list
[2025-05-07T21:30:26.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManager: Removing RDD 369
[2025-05-07T21:30:26.953+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManager: Removing RDD 375
[2025-05-07T21:30:26.966+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T21:30:26.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Registering RDD 389 (mapPartitions at GraphImpl.scala:208) as input to shuffle 51
[2025-05-07T21:30:26.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Registering RDD 397 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 50
[2025-05-07T21:30:26.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Got job 45 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T21:30:26.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Final stage: ResultStage 252 (foreachPartition at PageRank.scala:199)
[2025-05-07T21:30:26.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 233, ShuffleMapStage 230, ShuffleMapStage 251, ShuffleMapStage 237, ShuffleMapStage 249, ShuffleMapStage 241, ShuffleMapStage 235, ShuffleMapStage 245, ShuffleMapStage 239, ShuffleMapStage 231, ShuffleMapStage 243, ShuffleMapStage 247, ShuffleMapStage 226)
[2025-05-07T21:30:26.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 251)
[2025-05-07T21:30:26.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[389] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T21:30:26.977+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 166.3 KiB, free 417.7 MiB)
[2025-05-07T21:30:26.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.7 MiB)
[2025-05-07T21:30:26.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 3530b0b864fd:45373 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-07T21:30:26.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:26.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[389] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:26.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSchedulerImpl: Adding task set 250.0 with 10 tasks resource profile 0
[2025-05-07T21:30:26.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 0.0 in stage 250.0 (TID 445) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:26.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.20.0.5:46863 (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:26 INFO TaskSetManager: Starting task 1.0 in stage 250.0 (TID 446) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 0.0 in stage 250.0 (TID 445) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:27.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 2.0 in stage 250.0 (TID 447) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 1.0 in stage 250.0 (TID 446) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:27.019+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 3.0 in stage 250.0 (TID 448) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.020+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 2.0 in stage 250.0 (TID 447) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:27.031+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 4.0 in stage 250.0 (TID 449) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 3.0 in stage 250.0 (TID 448) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:27.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 5.0 in stage 250.0 (TID 450) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 4.0 in stage 250.0 (TID 449) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:27.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 6.0 in stage 250.0 (TID 451) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 5.0 in stage 250.0 (TID 450) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:27.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 7.0 in stage 250.0 (TID 452) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 6.0 in stage 250.0 (TID 451) in 7 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:27.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 8.0 in stage 250.0 (TID 453) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.066+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 7.0 in stage 250.0 (TID 452) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:27.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 9.0 in stage 250.0 (TID 454) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.075+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 8.0 in stage 250.0 (TID 453) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:27.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 9.0 in stage 250.0 (TID 454) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:27.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool
[2025-05-07T21:30:27.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: ShuffleMapStage 250 (mapPartitions at GraphImpl.scala:208) finished in 0.115 s
[2025-05-07T21:30:27.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:27.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:27.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: waiting: Set(ShuffleMapStage 251, ResultStage 252)
[2025-05-07T21:30:27.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:27.086+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Submitting ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[397] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T21:30:27.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 18.5 KiB, free 417.6 MiB)
[2025-05-07T21:30:27.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 417.6 MiB)
[2025-05-07T21:30:27.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 3530b0b864fd:45373 (size: 6.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:27.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:27.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[397] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:27.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Adding task set 251.0 with 10 tasks resource profile 0
[2025-05-07T21:30:27.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 455) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.098+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.20.0.5:46863 (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.101+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.20.0.5:43654
[2025-05-07T21:30:27.120+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 1.0 in stage 251.0 (TID 456) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 455) in 36 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:27.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.136+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 2.0 in stage 251.0 (TID 457) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.137+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 1.0 in stage 251.0 (TID 456) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:27.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 3.0 in stage 251.0 (TID 458) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 2.0 in stage 251.0 (TID 457) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:27.152+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 4.0 in stage 251.0 (TID 459) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 3.0 in stage 251.0 (TID 458) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:27.161+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.164+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 5.0 in stage 251.0 (TID 460) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.165+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 4.0 in stage 251.0 (TID 459) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:27.169+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:27.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 6.0 in stage 251.0 (TID 461) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.173+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 5.0 in stage 251.0 (TID 460) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:27.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:27.183+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 7.0 in stage 251.0 (TID 462) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.183+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 6.0 in stage 251.0 (TID 461) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:27.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:27.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 8.0 in stage 251.0 (TID 463) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 7.0 in stage 251.0 (TID 462) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:27.199+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:27.202+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 9.0 in stage 251.0 (TID 464) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 8.0 in stage 251.0 (TID 463) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:27.210+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_393_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:27.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 9.0 in stage 251.0 (TID 464) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:27.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool
[2025-05-07T21:30:27.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: ShuffleMapStage 251 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.127 s
[2025-05-07T21:30:27.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:27.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:27.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: waiting: Set(ResultStage 252)
[2025-05-07T21:30:27.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:27.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Submitting ResultStage 252 (EdgeRDDImpl[400] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T21:30:27.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 166.1 KiB, free 417.5 MiB)
[2025-05-07T21:30:27.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 3530b0b864fd:45373 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-07T21:30:27.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.5 MiB)
[2025-05-07T21:30:27.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 3530b0b864fd:45373 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T21:30:27.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:27.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 252 (EdgeRDDImpl[400] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:27.231+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Adding task set 252.0 with 10 tasks resource profile 0
[2025-05-07T21:30:27.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.20.0.5:46863 in memory (size: 58.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.232+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 0.0 in stage 252.0 (TID 465) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.234+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 3530b0b864fd:45373 in memory (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T21:30:27.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.20.0.5:46863 in memory (size: 58.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.236+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 3530b0b864fd:45373 in memory (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T21:30:27.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.20.0.5:46863 in memory (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.238+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.20.0.5:46863 (size: 58.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:43654
[2025-05-07T21:30:27.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_0 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 1.0 in stage 252.0 (TID 466) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 0.0 in stage 252.0 (TID 465) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:27.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_1 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 2.0 in stage 252.0 (TID 467) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 1.0 in stage 252.0 (TID 466) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:27.283+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_2 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 3.0 in stage 252.0 (TID 468) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.286+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 2.0 in stage 252.0 (TID 467) in 23 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:27.296+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_3 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.298+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 4.0 in stage 252.0 (TID 469) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.299+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 3.0 in stage 252.0 (TID 468) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:27.309+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_4 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 5.0 in stage 252.0 (TID 470) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.312+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 4.0 in stage 252.0 (TID 469) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:27.319+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_5 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.321+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 6.0 in stage 252.0 (TID 471) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.322+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 5.0 in stage 252.0 (TID 470) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:27.331+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_6 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 7.0 in stage 252.0 (TID 472) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.334+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 6.0 in stage 252.0 (TID 471) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:27.344+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_7 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 8.0 in stage 252.0 (TID 473) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.346+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 7.0 in stage 252.0 (TID 472) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:27.354+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_8 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.356+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 9.0 in stage 252.0 (TID 474) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.356+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 8.0 in stage 252.0 (TID 473) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:27.366+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added rdd_399_9 in memory on 172.20.0.5:46863 (size: 2.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 9.0 in stage 252.0 (TID 474) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:27.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool
[2025-05-07T21:30:27.368+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: ResultStage 252 (foreachPartition at PageRank.scala:199) finished in 0.153 s
[2025-05-07T21:30:27.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:27.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished
[2025-05-07T21:30:27.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Job 45 finished: foreachPartition at PageRank.scala:199, took 0.403041 s
[2025-05-07T21:30:27.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO PageRank: PageRank finished iteration 9.
[2025-05-07T21:30:27.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO ZippedPartitionsRDD2: Removing RDD 381 from persistence list
[2025-05-07T21:30:27.369+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManager: Removing RDD 381
[2025-05-07T21:30:27.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO ZippedPartitionsRDD2: Removing RDD 387 from persistence list
[2025-05-07T21:30:27.370+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManager: Removing RDD 387
[2025-05-07T21:30:27.390+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO SparkContext: Starting job: sum at PageRank.scala:503
[2025-05-07T21:30:27.394+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Got job 46 (sum at PageRank.scala:503) with 10 output partitions
[2025-05-07T21:30:27.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Final stage: ResultStage 278 (sum at PageRank.scala:503)
[2025-05-07T21:30:27.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 269, ShuffleMapStage 263, ShuffleMapStage 273, ShuffleMapStage 255, ShuffleMapStage 267, ShuffleMapStage 277, ShuffleMapStage 259, ShuffleMapStage 256, ShuffleMapStage 271, ShuffleMapStage 275, ShuffleMapStage 261, ShuffleMapStage 265, ShuffleMapStage 254)
[2025-05-07T21:30:27.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:27.395+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Submitting ResultStage 278 (MapPartitionsRDD[401] at values at PageRank.scala:503), which has no missing parents
[2025-05-07T21:30:27.397+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 18.9 KiB, free 417.9 MiB)
[2025-05-07T21:30:27.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 417.9 MiB)
[2025-05-07T21:30:27.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 3530b0b864fd:45373 (size: 7.1 KiB, free: 433.5 MiB)
[2025-05-07T21:30:27.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:27.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 278 (MapPartitionsRDD[401] at values at PageRank.scala:503) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:27.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Adding task set 278.0 with 10 tasks resource profile 0
[2025-05-07T21:30:27.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 475) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.20.0.5:46863 (size: 7.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.428+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 1.0 in stage 278.0 (TID 476) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.429+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 475) in 29 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:27.432+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 2.0 in stage 278.0 (TID 477) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.433+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 1.0 in stage 278.0 (TID 476) in 4 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:27.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 3.0 in stage 278.0 (TID 478) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.437+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 2.0 in stage 278.0 (TID 477) in 5 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:27.442+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 4.0 in stage 278.0 (TID 479) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.443+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 3.0 in stage 278.0 (TID 478) in 6 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:27.446+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 5.0 in stage 278.0 (TID 480) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 4.0 in stage 278.0 (TID 479) in 5 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:27.450+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 6.0 in stage 278.0 (TID 481) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.451+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 5.0 in stage 278.0 (TID 480) in 4 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:27.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 7.0 in stage 278.0 (TID 482) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.454+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 6.0 in stage 278.0 (TID 481) in 4 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:27.458+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 8.0 in stage 278.0 (TID 483) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.459+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 7.0 in stage 278.0 (TID 482) in 6 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:27.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 9.0 in stage 278.0 (TID 484) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 8.0 in stage 278.0 (TID 483) in 5 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:27.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 9.0 in stage 278.0 (TID 484) in 4 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:27.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool
[2025-05-07T21:30:27.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: ResultStage 278 (sum at PageRank.scala:503) finished in 0.072 s
[2025-05-07T21:30:27.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:27.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 278: Stage finished
[2025-05-07T21:30:27.468+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Job 46 finished: sum at PageRank.scala:503, took 0.077462 s
[2025-05-07T21:30:27.471+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-07T21:30:27.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Got job 47 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-07T21:30:27.474+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Final stage: ResultStage 304 (fold at VertexRDDImpl.scala:90)
[2025-05-07T21:30:27.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 287, ShuffleMapStage 299, ShuffleMapStage 281, ShuffleMapStage 291, ShuffleMapStage 303, ShuffleMapStage 285, ShuffleMapStage 289, ShuffleMapStage 293, ShuffleMapStage 282, ShuffleMapStage 297, ShuffleMapStage 301, ShuffleMapStage 280, ShuffleMapStage 295)
[2025-05-07T21:30:27.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:27.475+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Submitting ResultStage 304 (MapPartitionsRDD[402] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-07T21:30:27.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 18.7 KiB, free 417.8 MiB)
[2025-05-07T21:30:27.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 417.8 MiB)
[2025-05-07T21:30:27.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 3530b0b864fd:45373 (size: 6.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:27.478+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:27.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 304 (MapPartitionsRDD[402] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:27.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Adding task set 304.0 with 10 tasks resource profile 0
[2025-05-07T21:30:27.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 485) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.487+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.20.0.5:46863 (size: 6.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.493+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 1.0 in stage 304.0 (TID 486) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 485) in 12 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:27.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 2.0 in stage 304.0 (TID 487) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.498+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 1.0 in stage 304.0 (TID 486) in 7 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:27.502+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 3.0 in stage 304.0 (TID 488) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.503+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 2.0 in stage 304.0 (TID 487) in 6 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:27.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 4.0 in stage 304.0 (TID 489) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.510+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 3.0 in stage 304.0 (TID 488) in 6 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:27.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 5.0 in stage 304.0 (TID 490) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.523+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 4.0 in stage 304.0 (TID 489) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:27.528+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 6.0 in stage 304.0 (TID 491) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.529+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 5.0 in stage 304.0 (TID 490) in 6 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:27.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 7.0 in stage 304.0 (TID 492) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 6.0 in stage 304.0 (TID 491) in 5 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:27.538+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 8.0 in stage 304.0 (TID 493) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.538+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 7.0 in stage 304.0 (TID 492) in 5 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:27.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Starting task 9.0 in stage 304.0 (TID 494) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:27.544+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 8.0 in stage 304.0 (TID 493) in 5 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:27.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSetManager: Finished task 9.0 in stage 304.0 (TID 494) in 4 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:27.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool
[2025-05-07T21:30:27.547+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: ResultStage 304 (fold at VertexRDDImpl.scala:90) finished in 0.072 s
[2025-05-07T21:30:27.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:27.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 304: Stage finished
[2025-05-07T21:30:27.548+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO DAGScheduler: Job 47 finished: fold at VertexRDDImpl.scala:90, took 0.076854 s
[2025-05-07T21:30:27.769+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 3530b0b864fd:45373 in memory (size: 6.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:27.770+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.20.0.5:46863 in memory (size: 6.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:27.771+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 3530b0b864fd:45373 in memory (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T21:30:27.772+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.20.0.5:46863 in memory (size: 58.2 KiB, free: 433.0 MiB)
[2025-05-07T21:30:27.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 3530b0b864fd:45373 in memory (size: 7.1 KiB, free: 433.6 MiB)
[2025-05-07T21:30:27.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.20.0.5:46863 in memory (size: 7.1 KiB, free: 433.0 MiB)
[2025-05-07T21:30:27.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 3530b0b864fd:45373 in memory (size: 6.8 KiB, free: 433.6 MiB)
[2025-05-07T21:30:27.779+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:27 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.20.0.5:46863 in memory (size: 6.8 KiB, free: 433.0 MiB)
[2025-05-07T21:30:27.826+0000] {spark_submit.py:571} INFO - 2025-05-07 21:30:27,825 [INFO] Экспортируем граф в GraphML
[2025-05-07T21:30:28.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 4.889261 ms
[2025-05-07T21:30:28.821+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#2022 - id.nullCount#2021) > 0)
[2025-05-07T21:30:28.835+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:28.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Got job 48 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-07T21:30:28.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Final stage: ResultStage 306 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:28.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 305)
[2025-05-07T21:30:28.836+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:28.837+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Submitting ResultStage 306 (MapPartitionsRDD[441] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:28.838+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 43.9 KiB, free 418.1 MiB)
[2025-05-07T21:30:28.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 418.1 MiB)
[2025-05-07T21:30:28.840+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 3530b0b864fd:45373 (size: 19.4 KiB, free: 433.5 MiB)
[2025-05-07T21:30:28.842+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:28.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 306 (MapPartitionsRDD[441] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:28.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSchedulerImpl: Adding task set 306.0 with 10 tasks resource profile 0
[2025-05-07T21:30:28.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 13.653936 ms
[2025-05-07T21:30:28.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 0.0 in stage 306.0 (TID 495) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.848+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Registering RDD 444 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 53
[2025-05-07T21:30:28.849+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Got map stage job 49 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-07T21:30:28.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Final stage: ShuffleMapStage 309 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:28.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 307, ShuffleMapStage 308)
[2025-05-07T21:30:28.850+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:28.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Submitting ShuffleMapStage 309 (MapPartitionsRDD[444] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:28.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 23.3 KiB, free 418.0 MiB)
[2025-05-07T21:30:28.856+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 418.0 MiB)
[2025-05-07T21:30:28.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 3530b0b864fd:45373 (size: 9.9 KiB, free: 433.5 MiB)
[2025-05-07T21:30:28.860+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:28.861+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 309 (MapPartitionsRDD[444] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:28.862+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSchedulerImpl: Adding task set 309.0 with 10 tasks resource profile 0
[2025-05-07T21:30:28.865+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 12.729406 ms
[2025-05-07T21:30:28.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.20.0.5:46863 (size: 19.4 KiB, free: 433.0 MiB)
[2025-05-07T21:30:28.871+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Registering RDD 447 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 54
[2025-05-07T21:30:28.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Got map stage job 50 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-07T21:30:28.872+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Final stage: ShuffleMapStage 332 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:28.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 317, ShuffleMapStage 321, ShuffleMapStage 310, ShuffleMapStage 325, ShuffleMapStage 307, ShuffleMapStage 329, ShuffleMapStage 308, ShuffleMapStage 323, ShuffleMapStage 315, ShuffleMapStage 327, ShuffleMapStage 319, ShuffleMapStage 331, ShuffleMapStage 313)
[2025-05-07T21:30:28.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:28.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Submitting ShuffleMapStage 332 (MapPartitionsRDD[447] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:28.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 31.6 KiB, free 418.0 MiB)
[2025-05-07T21:30:28.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 11.750631 ms
[2025-05-07T21:30:28.883+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 418.0 MiB)
[2025-05-07T21:30:28.884+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 3530b0b864fd:45373 (size: 11.8 KiB, free: 433.5 MiB)
[2025-05-07T21:30:28.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:28.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 332 (MapPartitionsRDD[447] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T21:30:28.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSchedulerImpl: Adding task set 332.0 with 10 tasks resource profile 0
[2025-05-07T21:30:28.897+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 9.383682 ms
[2025-05-07T21:30:28.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 1.0 in stage 306.0 (TID 496) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.898+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Finished task 0.0 in stage 306.0 (TID 495) in 54 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:28.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 2.0 in stage 306.0 (TID 497) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Finished task 1.0 in stage 306.0 (TID 496) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:28.913+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 8.344055 ms
[2025-05-07T21:30:28.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 3.0 in stage 306.0 (TID 498) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.922+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Finished task 2.0 in stage 306.0 (TID 497) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:28.931+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 14.220939 ms
[2025-05-07T21:30:28.936+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 4.0 in stage 306.0 (TID 499) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.937+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Finished task 3.0 in stage 306.0 (TID 498) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:28.945+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 9.959264 ms
[2025-05-07T21:30:28.946+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 5.0 in stage 306.0 (TID 500) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.947+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Finished task 4.0 in stage 306.0 (TID 499) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:28.955+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 6.0 in stage 306.0 (TID 501) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Finished task 5.0 in stage 306.0 (TID 500) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:28.964+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 12.725804 ms
[2025-05-07T21:30:28.966+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 7.0 in stage 306.0 (TID 502) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Finished task 6.0 in stage 306.0 (TID 501) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:28.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Registering RDD 455 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 55
[2025-05-07T21:30:28.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Got map stage job 51 (toPandas at /opt/airflow/spark/build_graph.py:207) with 6 output partitions
[2025-05-07T21:30:28.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Final stage: ShuffleMapStage 333 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:28.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:28.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:28.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Submitting ShuffleMapStage 333 (MapPartitionsRDD[455] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:28.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 36.4 KiB, free 418.0 MiB)
[2025-05-07T21:30:28.978+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 417.9 MiB)
[2025-05-07T21:30:28.979+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO CodeGenerator: Code generated in 9.17115 ms
[2025-05-07T21:30:28.980+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 8.0 in stage 306.0 (TID 503) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Finished task 7.0 in stage 306.0 (TID 502) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:28.982+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 3530b0b864fd:45373 (size: 11.2 KiB, free: 433.5 MiB)
[2025-05-07T21:30:28.986+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:28.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:28.987+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 333 (MapPartitionsRDD[455] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:30:28.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSchedulerImpl: Adding task set 333.0 with 6 tasks resource profile 0
[2025-05-07T21:30:28.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Registering RDD 457 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 56
[2025-05-07T21:30:28.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Got map stage job 52 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:28.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Final stage: ShuffleMapStage 334 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:28.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:28.990+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:28.990+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO DAGScheduler: Submitting ShuffleMapStage 334 (MapPartitionsRDD[457] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:28.991+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 12.7 KiB, free 417.9 MiB)
[2025-05-07T21:30:28.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Starting task 9.0 in stage 306.0 (TID 504) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:28.994+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:28 INFO TaskSetManager: Finished task 8.0 in stage 306.0 (TID 503) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:29.016+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.9 MiB)
[2025-05-07T21:30:29.016+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 3530b0b864fd:45373 (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T21:30:29.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 334 (MapPartitionsRDD[457] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 334.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.021+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO CodeGenerator: Code generated in 35.852995 ms
[2025-05-07T21:30:29.027+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:29.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Registering RDD 459 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 57
[2025-05-07T21:30:29.031+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got map stage job 53 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.031+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ShuffleMapStage 335 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:29.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ShuffleMapStage 335 (MapPartitionsRDD[459] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.034+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 27.3 KiB, free 417.9 MiB)
[2025-05-07T21:30:29.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 417.9 MiB)
[2025-05-07T21:30:29.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 505) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.037+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 9.0 in stage 306.0 (TID 504) in 45 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:29.037+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool
[2025-05-07T21:30:29.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 3530b0b864fd:45373 (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T21:30:29.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 335 (MapPartitionsRDD[459] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.043+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 335.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: ResultStage 306 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.205 s
[2025-05-07T21:30:29.048+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:29.050+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 306: Stage finished
[2025-05-07T21:30:29.051+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Job 48 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.209688 s
[2025-05-07T21:30:29.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.20.0.5:46863 (size: 9.9 KiB, free: 433.0 MiB)
[2025-05-07T21:30:29.062+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO CodeGenerator: Code generated in 25.831125 ms
[2025-05-07T21:30:29.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Registering RDD 461 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 58
[2025-05-07T21:30:29.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got map stage job 54 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ShuffleMapStage 336 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:29.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:29.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO CodeGenerator: Code generated in 14.473468 ms
[2025-05-07T21:30:29.075+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ShuffleMapStage 336 (MapPartitionsRDD[461] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.079+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 28.5 KiB, free 417.9 MiB)
[2025-05-07T21:30:29.081+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 417.8 MiB)
[2025-05-07T21:30:29.082+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 2.1 MiB, free 415.8 MiB)
[2025-05-07T21:30:29.083+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 3530b0b864fd:45373 (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T21:30:29.085+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.087+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 336 (MapPartitionsRDD[461] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 336.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.090+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 415.8 MiB)
[2025-05-07T21:30:29.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 3530b0b864fd:45373 (size: 27.5 KiB, free: 433.5 MiB)
[2025-05-07T21:30:29.092+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 93 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:29.114+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO CodeGenerator: Code generated in 25.836084 ms
[2025-05-07T21:30:29.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:29.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Registering RDD 463 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 59
[2025-05-07T21:30:29.116+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got map stage job 55 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.117+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ShuffleMapStage 337 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.117+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:29.120+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.121+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ShuffleMapStage 337 (MapPartitionsRDD[463] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.129+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 28.5 KiB, free 415.7 MiB)
[2025-05-07T21:30:29.166+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 1.0 in stage 309.0 (TID 506) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 505) in 129 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:29.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 415.7 MiB)
[2025-05-07T21:30:29.167+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 3530b0b864fd:45373 (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.168+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.171+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO CodeGenerator: Code generated in 46.798334 ms
[2025-05-07T21:30:29.174+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 337 (MapPartitionsRDD[463] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.181+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 337.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Registering RDD 465 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 60
[2025-05-07T21:30:29.182+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:29.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got map stage job 56 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.187+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ShuffleMapStage 338 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:29.190+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.191+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ShuffleMapStage 338 (MapPartitionsRDD[465] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.191+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 27.4 KiB, free 415.7 MiB)
[2025-05-07T21:30:29.194+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 415.7 MiB)
[2025-05-07T21:30:29.203+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 3530b0b864fd:45373 (size: 13.0 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 338 (MapPartitionsRDD[465] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 338.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO CodeGenerator: Code generated in 12.852265 ms
[2025-05-07T21:30:29.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Registering RDD 467 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 61
[2025-05-07T21:30:29.215+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 2.0 in stage 309.0 (TID 507) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got map stage job 57 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ShuffleMapStage 339 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:29.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:29.216+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 1.0 in stage 309.0 (TID 506) in 34 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:29.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ShuffleMapStage 339 (MapPartitionsRDD[467] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 28.5 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.217+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 3530b0b864fd:45373 (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 339 (MapPartitionsRDD[467] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.218+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 339.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.223+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 3.0 in stage 309.0 (TID 508) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.229+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 2.0 in stage 309.0 (TID 507) in 27 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:29.235+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO CodeGenerator: Code generated in 23.073942 ms
[2025-05-07T21:30:29.236+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Registering RDD 469 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 62
[2025-05-07T21:30:29.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got map stage job 58 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ShuffleMapStage 340 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:29.237+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.243+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ShuffleMapStage 340 (MapPartitionsRDD[469] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 31.7 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.244+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 3530b0b864fd:45373 (size: 14.9 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.246+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 340 (MapPartitionsRDD[469] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 340.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.248+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 4.0 in stage 309.0 (TID 509) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.249+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 3.0 in stage 309.0 (TID 508) in 29 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:29.270+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 5.0 in stage 309.0 (TID 510) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.271+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 4.0 in stage 309.0 (TID 509) in 23 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:29.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 6.0 in stage 309.0 (TID 511) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.290+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 5.0 in stage 309.0 (TID 510) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:29.300+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 7.0 in stage 309.0 (TID 512) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.302+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 6.0 in stage 309.0 (TID 511) in 18 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:29.323+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 7.0 in stage 309.0 (TID 512) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:29.330+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 8.0 in stage 309.0 (TID 513) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.345+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 9.0 in stage 309.0 (TID 514) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.348+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 8.0 in stage 309.0 (TID 513) in 22 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:29.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO CodeGenerator: Code generated in 23.316878 ms
[2025-05-07T21:30:29.358+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Registering RDD 475 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 63
[2025-05-07T21:30:29.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got map stage job 59 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ShuffleMapStage 341 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:29.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.361+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ShuffleMapStage 341 (MapPartitionsRDD[475] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 0.0 in stage 332.0 (TID 515) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 9.0 in stage 309.0 (TID 514) in 19 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:29.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool
[2025-05-07T21:30:29.365+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 16.6 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.389+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.391+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 3530b0b864fd:45373 (size: 8.3 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.393+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.396+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 341 (MapPartitionsRDD[475] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 341.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.20.0.5:46863 in memory (size: 19.4 KiB, free: 433.0 MiB)
[2025-05-07T21:30:29.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.20.0.5:46863 (size: 11.8 KiB, free: 433.0 MiB)
[2025-05-07T21:30:29.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: ShuffleMapStage 309 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.547 s
[2025-05-07T21:30:29.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:29.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ShuffleMapStage 332, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ShuffleMapStage 341, ShuffleMapStage 333, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T21:30:29.401+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:29.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:29.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO CodeGenerator: Code generated in 38.485712 ms
[2025-05-07T21:30:29.405+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 3530b0b864fd:45373 in memory (size: 19.4 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_0 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:29.412+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Registering RDD 477 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 64
[2025-05-07T21:30:29.413+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got map stage job 60 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ShuffleMapStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.414+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:30:29.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ShuffleMapStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 15.0 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.418+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 3530b0b864fd:45373 (size: 7.7 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.420+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.421+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 342.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.431+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:29.433+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 0.0 in stage 332.0 (TID 515) in 70 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-07T21:30:29.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 1.0 in stage 332.0 (TID 516) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.434+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:29.449+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_1 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:29.463+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 2.0 in stage 332.0 (TID 517) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.464+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 1.0 in stage 332.0 (TID 516) in 29 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-07T21:30:29.501+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_2 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:29.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 3.0 in stage 332.0 (TID 518) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 2.0 in stage 332.0 (TID 517) in 52 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-07T21:30:29.529+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_3 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:29.540+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 4.0 in stage 332.0 (TID 519) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.541+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 3.0 in stage 332.0 (TID 518) in 29 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-07T21:30:29.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:29.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got job 61 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.549+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ResultStage 344 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.550+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 343)
[2025-05-07T21:30:29.550+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.551+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ResultStage 344 (MapPartitionsRDD[480] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.551+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.552+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_4 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:29.553+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.557+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 344 (MapPartitionsRDD[480] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 344.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 5.0 in stage 332.0 (TID 520) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.564+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 4.0 in stage 332.0 (TID 519) in 21 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-07T21:30:29.567+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_5 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 433.0 MiB)
[2025-05-07T21:30:29.576+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 6.0 in stage 332.0 (TID 521) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.578+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 5.0 in stage 332.0 (TID 520) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-07T21:30:29.582+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_6 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:29.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 7.0 in stage 332.0 (TID 522) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.588+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 6.0 in stage 332.0 (TID 521) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-07T21:30:29.599+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_7 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:29.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 8.0 in stage 332.0 (TID 523) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 7.0 in stage 332.0 (TID 522) in 18 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-07T21:30:29.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_8 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:29.620+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 9.0 in stage 332.0 (TID 524) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 8.0 in stage 332.0 (TID 523) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-07T21:30:29.628+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added rdd_403_9 in memory on 172.20.0.5:46863 (size: 5.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:29.645+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 0.0 in stage 333.0 (TID 525) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.646+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 9.0 in stage 332.0 (TID 524) in 26 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-07T21:30:29.646+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Removed TaskSet 332.0, whose tasks have all completed, from pool
[2025-05-07T21:30:29.646+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: ShuffleMapStage 332 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.769 s
[2025-05-07T21:30:29.646+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:29.646+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 333, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T21:30:29.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:29.647+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:29.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.20.0.5:46863 (size: 11.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:29.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO ShufflePartitionsUtil: For shuffle(54), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:29.716+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:29.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 1.0 in stage 333.0 (TID 526) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.717+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 0.0 in stage 333.0 (TID 525) in 72 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:30:29.720+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Got job 62 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:29.721+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Final stage: ResultStage 368 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:29.721+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 367)
[2025-05-07T21:30:29.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:29.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting ResultStage 368 (MapPartitionsRDD[483] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:29.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-07T21:30:29.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.738+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:29.738+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 368 (MapPartitionsRDD[483] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:29.739+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Adding task set 368.0 with 1 tasks resource profile 0
[2025-05-07T21:30:29.744+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 3530b0b864fd:45373 in memory (size: 11.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.747+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.20.0.5:46863 in memory (size: 11.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:29.754+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 3530b0b864fd:45373 in memory (size: 9.9 KiB, free: 433.4 MiB)
[2025-05-07T21:30:29.756+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.20.0.5:46863 in memory (size: 9.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:29.769+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 2.0 in stage 333.0 (TID 527) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.770+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 1.0 in stage 333.0 (TID 526) in 53 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:30:29.818+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 3.0 in stage 333.0 (TID 528) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.819+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 2.0 in stage 333.0 (TID 527) in 49 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:30:29.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 4.0 in stage 333.0 (TID 529) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 3.0 in stage 333.0 (TID 528) in 46 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:30:29.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 5.0 in stage 333.0 (TID 530) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 4.0 in stage 333.0 (TID 529) in 31 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:30:29.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 0.0 in stage 334.0 (TID 531) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:29.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 5.0 in stage 333.0 (TID 530) in 76 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:30:29.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool
[2025-05-07T21:30:29.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: ShuffleMapStage 333 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.999 s
[2025-05-07T21:30:29.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:29.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T21:30:29.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:29.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:29.977+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.20.0.5:46863 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:30:29.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:29.989+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:29.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Starting task 0.0 in stage 335.0 (TID 532) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSetManager: Finished task 0.0 in stage 334.0 (TID 531) in 29 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:29 INFO TaskSchedulerImpl: Removed TaskSet 334.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ShuffleMapStage 334 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.016 s
[2025-05-07T21:30:30.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:30.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337)
[2025-05-07T21:30:30.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:30.001+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:30.006+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.20.0.5:46863 (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:30.039+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Got job 63 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:30.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Final stage: ResultStage 370 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:30.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 369)
[2025-05-07T21:30:30.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:30.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Submitting ResultStage 370 (MapPartitionsRDD[486] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:30.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-07T21:30:30.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-07T21:30:30.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.041+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:30.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 370 (MapPartitionsRDD[486] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:30.044+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Adding task set 370.0 with 1 tasks resource profile 0
[2025-05-07T21:30:30.052+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO ShufflePartitionsUtil: For shuffle(56), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:30.070+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 336.0 (TID 533) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 335.0 (TID 532) in 72 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.071+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 335.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.072+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ShuffleMapStage 335 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.042 s
[2025-05-07T21:30:30.073+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:30.074+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ResultStage 370)
[2025-05-07T21:30:30.075+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:30.078+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:30.094+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.20.0.5:46863 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.105+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:30.108+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Got job 64 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:30.110+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Final stage: ResultStage 372 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:30.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 371)
[2025-05-07T21:30:30.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:30.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Submitting ResultStage 372 (MapPartitionsRDD[489] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:30.111+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 7.2 KiB, free 415.6 MiB)
[2025-05-07T21:30:30.123+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-07T21:30:30.124+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 3530b0b864fd:45373 in memory (size: 13.0 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:30.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 372 (MapPartitionsRDD[489] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:30.127+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Adding task set 372.0 with 1 tasks resource profile 0
[2025-05-07T21:30:30.128+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.20.0.5:46863 in memory (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 3530b0b864fd:45373 in memory (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.131+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.20.0.5:46863 in memory (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.153+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 337.0 (TID 534) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 336.0 (TID 533) in 84 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 336.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ShuffleMapStage 336 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.081 s
[2025-05-07T21:30:30.154+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:30.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ShuffleMapStage 337, ResultStage 370)
[2025-05-07T21:30:30.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:30.155+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:30.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.20.0.5:46863 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 3530b0b864fd:45373 in memory (size: 11.2 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.230+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.20.0.5:46863 in memory (size: 11.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 338.0 (TID 535) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 337.0 (TID 534) in 111 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.264+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.271+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ShuffleMapStage 337 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.148 s
[2025-05-07T21:30:30.271+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:30.272+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-07T21:30:30.273+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:30.275+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:30.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.20.0.5:46863 (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.330+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 339.0 (TID 536) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.331+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 338.0 (TID 535) in 69 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 338.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.332+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ShuffleMapStage 338 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.158 s
[2025-05-07T21:30:30.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:30.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ShuffleMapStage 339, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-07T21:30:30.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:30.334+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:30.340+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.20.0.5:46863 (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 340.0 (TID 537) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 339.0 (TID 536) in 69 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.399+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 339.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ShuffleMapStage 339 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.203 s
[2025-05-07T21:30:30.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:30.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ResultStage 372, ShuffleMapStage 340, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-07T21:30:30.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:30.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:30.406+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.20.0.5:46863 (size: 14.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 341.0 (TID 538) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 340.0 (TID 537) in 63 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.461+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 340.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ShuffleMapStage 340 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.230 s
[2025-05-07T21:30:30.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:30.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ResultStage 372, ResultStage 344, ShuffleMapStage 341, ResultStage 370)
[2025-05-07T21:30:30.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:30.462+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:30.467+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.20.0.5:46863 (size: 8.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.477+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO ShufflePartitionsUtil: For shuffle(57, 58, 59, 60, 61, 62), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:30.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.20.0.5:46863 (size: 27.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:30.533+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 342.0 (TID 539) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.534+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 341.0 (TID 538) in 74 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 341.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.535+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ShuffleMapStage 341 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.177 s
[2025-05-07T21:30:30.536+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:30.537+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: running: Set(ResultStage 368, ShuffleMapStage 342, ResultStage 372, ResultStage 344, ResultStage 370)
[2025-05-07T21:30:30.537+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:30.537+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:30.543+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.20.0.5:46863 (size: 7.7 KiB, free: 432.8 MiB)
[2025-05-07T21:30:30.558+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 23.581674 ms
[2025-05-07T21:30:30.559+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:30.574+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 9.846979 ms
[2025-05-07T21:30:30.580+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:30.596+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 10.865045 ms
[2025-05-07T21:30:30.604+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:30.605+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 344.0 (TID 540) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 342.0 (TID 539) in 72 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.606+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 342.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ShuffleMapStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.199 s
[2025-05-07T21:30:30.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:30.613+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: running: Set(ResultStage 368, ResultStage 372, ResultStage 344, ResultStage 370)
[2025-05-07T21:30:30.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:30.614+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:30.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 11.854927 ms
[2025-05-07T21:30:30.648+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:30.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T21:30:30.660+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:43654
[2025-05-07T21:30:30.670+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 19.631999 ms
[2025-05-07T21:30:30.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 368.0 (TID 541) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:30.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 344.0 (TID 540) in 71 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ResultStage 344 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.131 s
[2025-05-07T21:30:30.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:30.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 344: Stage finished
[2025-05-07T21:30:30.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Job 61 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 1.133990 s
[2025-05-07T21:30:30.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T21:30:30.690+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.20.0.5:43654
[2025-05-07T21:30:30.692+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 13.059312 ms
[2025-05-07T21:30:30.707+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 16.589028 ms
[2025-05-07T21:30:30.709+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 3530b0b864fd:45373 in memory (size: 7.7 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.713+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.20.0.5:46863 in memory (size: 7.7 KiB, free: 432.8 MiB)
[2025-05-07T21:30:30.714+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 370.0 (TID 542) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.714+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 368.0 (TID 541) in 40 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.715+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 368.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ResultStage 368 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.995 s
[2025-05-07T21:30:30.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:30.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:30.722+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 368: Stage finished
[2025-05-07T21:30:30.733+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Job 62 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 1.007343 s
[2025-05-07T21:30:30.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 1088.0 KiB, free 414.7 MiB)
[2025-05-07T21:30:30.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 3530b0b864fd:45373 in memory (size: 8.3 KiB, free: 433.5 MiB)
[2025-05-07T21:30:30.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 414.7 MiB)
[2025-05-07T21:30:30.736+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 3530b0b864fd:45373 (size: 32.6 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.737+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Created broadcast 104 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:30.738+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 1088.0 KiB, free 413.6 MiB)
[2025-05-07T21:30:30.745+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.20.0.5:46863 in memory (size: 8.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.747+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 413.6 MiB)
[2025-05-07T21:30:30.757+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 3530b0b864fd:45373 in memory (size: 14.9 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 26.92407 ms
[2025-05-07T21:30:30.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T21:30:30.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 3530b0b864fd:45373 (size: 23.7 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.765+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.20.0.5:46863 in memory (size: 14.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:43654
[2025-05-07T21:30:30.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Created broadcast 105 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:30.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:30.776+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO ShufflePartitionsUtil: For shuffle(64), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:30.778+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 3530b0b864fd:45373 in memory (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.20.0.5:46863 in memory (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.797+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.20.0.5:46863 in memory (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.803+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 3530b0b864fd:45373 in memory (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.804+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:30.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Got job 65 (toPandas at /opt/airflow/spark/build_graph.py:207) with 6 output partitions
[2025-05-07T21:30:30.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Final stage: ResultStage 379 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:30.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 374, ShuffleMapStage 375, ShuffleMapStage 376, ShuffleMapStage 373, ShuffleMapStage 377, ShuffleMapStage 378)
[2025-05-07T21:30:30.833+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:30.843+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.844+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Submitting ResultStage 379 (MapPartitionsRDD[513] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:30.848+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 372.0 (TID 543) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.853+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 370.0 (TID 542) in 140 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.855+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 370.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.866+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 91.7 KiB, free 413.7 MiB)
[2025-05-07T21:30:30.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 413.6 MiB)
[2025-05-07T21:30:30.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 3530b0b864fd:45373 in memory (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T21:30:30.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 3530b0b864fd:45373 (size: 30.3 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.869+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.20.0.5:46863 in memory (size: 13.4 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.871+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 15.71603 ms
[2025-05-07T21:30:30.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:30.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 379 (MapPartitionsRDD[513] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:30:30.879+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Adding task set 379.0 with 6 tasks resource profile 0
[2025-05-07T21:30:30.885+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ResultStage 370 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.839 s
[2025-05-07T21:30:30.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:30.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 370: Stage finished
[2025-05-07T21:30:30.887+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 3530b0b864fd:45373 in memory (size: 13.0 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.890+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Job 63 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.844326 s
[2025-05-07T21:30:30.894+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Registering RDD 516 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 65
[2025-05-07T21:30:30.895+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Got map stage job 66 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:30.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Final stage: ShuffleMapStage 381 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:30.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 380)
[2025-05-07T21:30:30.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:30.901+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Submitting ShuffleMapStage 381 (MapPartitionsRDD[516] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:30.905+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 13.4 KiB, free 413.7 MiB)
[2025-05-07T21:30:30.906+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.20.0.5:46863 in memory (size: 13.0 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 413.7 MiB)
[2025-05-07T21:30:30.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 3530b0b864fd:45373 (size: 6.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.908+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:30.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 381 (MapPartitionsRDD[516] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:30.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Adding task set 381.0 with 1 tasks resource profile 0
[2025-05-07T21:30:30.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 5.0 MiB, free 408.7 MiB)
[2025-05-07T21:30:30.926+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:43654
[2025-05-07T21:30:30.948+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T21:30:30.957+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.963+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 408.2 MiB)
[2025-05-07T21:30:30.968+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 3530b0b864fd:45373 (size: 502.1 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Starting task 0.0 in stage 379.0 (TID 544) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:30.969+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSetManager: Finished task 0.0 in stage 372.0 (TID 543) in 109 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:30.970+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Removed TaskSet 372.0, whose tasks have all completed, from pool
[2025-05-07T21:30:30.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO SparkContext: Created broadcast 108 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:30.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: ResultStage 372 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.854 s
[2025-05-07T21:30:30.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:30.973+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 372: Stage finished
[2025-05-07T21:30:30.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO DAGScheduler: Job 64 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.856868 s
[2025-05-07T21:30:30.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO CodeGenerator: Code generated in 67.815142 ms
[2025-05-07T21:30:30.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.978+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.20.0.5:46863 (size: 30.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:30.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 2.1 MiB, free 406.2 MiB)
[2025-05-07T21:30:31.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 172.20.0.5:43654
[2025-05-07T21:30:31.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:30 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 406.1 MiB)
[2025-05-07T21:30:31.001+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 3530b0b864fd:45373 (size: 20.6 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO SparkContext: Created broadcast 109 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:31.011+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Registering RDD 519 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 66
[2025-05-07T21:30:31.013+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Got map stage job 67 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:31.016+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Final stage: ShuffleMapStage 383 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:31.017+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 382)
[2025-05-07T21:30:31.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:31.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Submitting ShuffleMapStage 383 (MapPartitionsRDD[519] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:31.024+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 78.0 KiB, free 406.1 MiB)
[2025-05-07T21:30:31.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 406.0 MiB)
[2025-05-07T21:30:31.032+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 3530b0b864fd:45373 (size: 34.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.034+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:31.035+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 383 (MapPartitionsRDD[519] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:31.036+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSchedulerImpl: Adding task set 383.0 with 1 tasks resource profile 0
[2025-05-07T21:30:31.048+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:31.103+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Starting task 1.0 in stage 379.0 (TID 545) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:31.107+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Finished task 0.0 in stage 379.0 (TID 544) in 149 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T21:30:31.133+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.20.0.5:43654
[2025-05-07T21:30:31.214+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO CodeGenerator: Code generated in 9.456062 ms
[2025-05-07T21:30:31.219+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Registering RDD 523 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 67
[2025-05-07T21:30:31.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Got map stage job 68 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:31.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Final stage: ShuffleMapStage 384 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:31.220+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 380)
[2025-05-07T21:30:31.222+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:31.222+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Submitting ShuffleMapStage 384 (MapPartitionsRDD[523] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:31.223+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Starting task 2.0 in stage 379.0 (TID 546) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:31.226+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 13.8 KiB, free 406.0 MiB)
[2025-05-07T21:30:31.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Finished task 1.0 in stage 379.0 (TID 545) in 148 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T21:30:31.251+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.20.0.5:43654
[2025-05-07T21:30:31.252+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 406.0 MiB)
[2025-05-07T21:30:31.254+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.254+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 3530b0b864fd:45373 (size: 6.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.256+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:31.257+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 384 (MapPartitionsRDD[523] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:31.261+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSchedulerImpl: Adding task set 384.0 with 1 tasks resource profile 0
[2025-05-07T21:30:31.263+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.283+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Starting task 3.0 in stage 379.0 (TID 547) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:31.284+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Finished task 2.0 in stage 379.0 (TID 546) in 63 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T21:30:31.289+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 172.20.0.5:43654
[2025-05-07T21:30:31.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Starting task 4.0 in stage 379.0 (TID 548) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:31.333+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Finished task 3.0 in stage 379.0 (TID 547) in 51 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T21:30:31.339+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.20.0.5:43654
[2025-05-07T21:30:31.352+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Starting task 5.0 in stage 379.0 (TID 549) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:31.353+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Finished task 4.0 in stage 379.0 (TID 548) in 20 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T21:30:31.360+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.20.0.5:43654
[2025-05-07T21:30:31.381+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Starting task 0.0 in stage 381.0 (TID 550) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:31.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Finished task 5.0 in stage 379.0 (TID 549) in 30 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T21:30:31.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSchedulerImpl: Removed TaskSet 379.0, whose tasks have all completed, from pool
[2025-05-07T21:30:31.382+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: ResultStage 379 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.528 s
[2025-05-07T21:30:31.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:31.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 379: Stage finished
[2025-05-07T21:30:31.383+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Job 65 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.578933 s
[2025-05-07T21:30:31.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.20.0.5:46863 (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.398+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 3530b0b864fd:45373 in memory (size: 30.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.400+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.20.0.5:46863 in memory (size: 30.3 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.402+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 63 to 172.20.0.5:43654
[2025-05-07T21:30:31.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 2.3 MiB, free 403.9 MiB)
[2025-05-07T21:30:31.423+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 403.8 MiB)
[2025-05-07T21:30:31.425+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 3530b0b864fd:45373 (size: 114.2 KiB, free: 432.8 MiB)
[2025-05-07T21:30:31.425+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO SparkContext: Created broadcast 112 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:31.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.20.0.5:46863 (size: 32.6 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.499+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Starting task 0.0 in stage 383.0 (TID 551) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:31.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Finished task 0.0 in stage 381.0 (TID 550) in 120 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:31.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSchedulerImpl: Removed TaskSet 381.0, whose tasks have all completed, from pool
[2025-05-07T21:30:31.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: ShuffleMapStage 381 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.622 s
[2025-05-07T21:30:31.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:31.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: running: Set(ShuffleMapStage 383, ShuffleMapStage 384)
[2025-05-07T21:30:31.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:31.507+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:31.532+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.20.0.5:46863 (size: 34.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.544+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO CodeGenerator: Code generated in 32.454377 ms
[2025-05-07T21:30:31.545+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:31.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO CodeGenerator: Code generated in 44.768789 ms
[2025-05-07T21:30:31.622+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.20.0.5:43654
[2025-05-07T21:30:31.634+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 3530b0b864fd:45373 in memory (size: 6.8 KiB, free: 432.8 MiB)
[2025-05-07T21:30:31.643+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 172.20.0.5:46863 in memory (size: 6.8 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.655+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO CodeGenerator: Code generated in 13.277051 ms
[2025-05-07T21:30:31.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Registering RDD 530 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 68
[2025-05-07T21:30:31.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Got map stage job 69 (toPandas at /opt/airflow/spark/build_graph.py:207) with 11 output partitions
[2025-05-07T21:30:31.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Final stage: ShuffleMapStage 386 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:31.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 385)
[2025-05-07T21:30:31.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:31.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Submitting ShuffleMapStage 386 (MapPartitionsRDD[530] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:31.686+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 141.2 KiB, free 403.7 MiB)
[2025-05-07T21:30:31.692+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 49.6 KiB, free 403.6 MiB)
[2025-05-07T21:30:31.694+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 3530b0b864fd:45373 (size: 49.6 KiB, free: 432.8 MiB)
[2025-05-07T21:30:31.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:31.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 386 (MapPartitionsRDD[530] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T21:30:31.696+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSchedulerImpl: Adding task set 386.0 with 11 tasks resource profile 0
[2025-05-07T21:30:31.763+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Starting task 0.0 in stage 384.0 (TID 552) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:31.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Finished task 0.0 in stage 383.0 (TID 551) in 264 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:31.764+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSchedulerImpl: Removed TaskSet 383.0, whose tasks have all completed, from pool
[2025-05-07T21:30:31.765+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: ShuffleMapStage 383 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.753 s
[2025-05-07T21:30:31.765+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:31.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: running: Set(ShuffleMapStage 386, ShuffleMapStage 384)
[2025-05-07T21:30:31.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:31.767+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:31.783+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO ShufflePartitionsUtil: For shuffle(66), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:31.830+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.20.0.5:46863 (size: 6.9 KiB, free: 432.9 MiB)
[2025-05-07T21:30:31.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:31.864+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.20.0.5:46863 (size: 23.7 KiB, free: 432.8 MiB)
[2025-05-07T21:30:31.873+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO CodeGenerator: Code generated in 14.445671 ms
[2025-05-07T21:30:31.900+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:31.902+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Got job 70 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:31.902+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Final stage: ResultStage 389 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:31.902+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 388)
[2025-05-07T21:30:31.902+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:31.902+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Submitting ResultStage 389 (MapPartitionsRDD[533] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:31.910+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Starting task 0.0 in stage 386.0 (TID 553) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:31.912+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSetManager: Finished task 0.0 in stage 384.0 (TID 552) in 143 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:31.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSchedulerImpl: Removed TaskSet 384.0, whose tasks have all completed, from pool
[2025-05-07T21:30:31.917+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 75.2 KiB, free 403.5 MiB)
[2025-05-07T21:30:31.958+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 33.2 KiB, free 403.5 MiB)
[2025-05-07T21:30:31.966+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 3530b0b864fd:45373 (size: 33.2 KiB, free: 432.7 MiB)
[2025-05-07T21:30:31.966+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:31.967+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 389 (MapPartitionsRDD[533] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:31.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO TaskSchedulerImpl: Adding task set 389.0 with 1 tasks resource profile 0
[2025-05-07T21:30:31.999+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 3530b0b864fd:45373 in memory (size: 34.5 KiB, free: 432.8 MiB)
[2025-05-07T21:30:32.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: ShuffleMapStage 384 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.744 s
[2025-05-07T21:30:32.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:32.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: running: Set(ResultStage 389, ShuffleMapStage 386)
[2025-05-07T21:30:32.001+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:32.001+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:32.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO ShufflePartitionsUtil: For shuffle(67), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:32.002+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.20.0.5:46863 in memory (size: 34.5 KiB, free: 432.9 MiB)
[2025-05-07T21:30:32.003+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:31 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.20.0.5:46863 (size: 49.6 KiB, free: 432.8 MiB)
[2025-05-07T21:30:32.067+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:43654
[2025-05-07T21:30:32.139+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:32.142+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: Got job 71 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:32.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: Final stage: ResultStage 392 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:32.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 391)
[2025-05-07T21:30:32.143+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:32.145+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: Submitting ResultStage 392 (MapPartitionsRDD[535] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:32.147+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 7.2 KiB, free 403.6 MiB)
[2025-05-07T21:30:32.148+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.20.0.5:46863 (size: 502.1 KiB, free: 432.3 MiB)
[2025-05-07T21:30:32.172+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 403.6 MiB)
[2025-05-07T21:30:32.179+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 3530b0b864fd:45373 (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T21:30:32.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:32.188+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 392 (MapPartitionsRDD[535] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:32.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSchedulerImpl: Adding task set 392.0 with 1 tasks resource profile 0
[2025-05-07T21:30:32.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 3530b0b864fd:45373 in memory (size: 6.9 KiB, free: 432.8 MiB)
[2025-05-07T21:30:32.189+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.20.0.5:46863 in memory (size: 6.9 KiB, free: 432.3 MiB)
[2025-05-07T21:30:32.201+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.20.0.5:46863 (size: 114.2 KiB, free: 432.2 MiB)
[2025-05-07T21:30:32.227+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.20.0.5:46863 (size: 20.6 KiB, free: 432.2 MiB)
[2025-05-07T21:30:32.362+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 1.0 in stage 386.0 (TID 554) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.363+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 0.0 in stage 386.0 (TID 553) in 457 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T21:30:32.416+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 2.0 in stage 386.0 (TID 555) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.418+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 1.0 in stage 386.0 (TID 554) in 55 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T21:30:32.447+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 3.0 in stage 386.0 (TID 556) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.448+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 2.0 in stage 386.0 (TID 555) in 32 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T21:30:32.479+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 4.0 in stage 386.0 (TID 557) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.480+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 3.0 in stage 386.0 (TID 556) in 34 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T21:30:32.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 5.0 in stage 386.0 (TID 558) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.511+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 4.0 in stage 386.0 (TID 557) in 31 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T21:30:32.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 6.0 in stage 386.0 (TID 559) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.565+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 5.0 in stage 386.0 (TID 558) in 54 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-07T21:30:32.609+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 7.0 in stage 386.0 (TID 560) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.635+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 6.0 in stage 386.0 (TID 559) in 47 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-07T21:30:32.636+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 8.0 in stage 386.0 (TID 561) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.645+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 7.0 in stage 386.0 (TID 560) in 36 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-07T21:30:32.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 9.0 in stage 386.0 (TID 562) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.666+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 8.0 in stage 386.0 (TID 561) in 39 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-07T21:30:32.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 10.0 in stage 386.0 (TID 563) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.695+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 9.0 in stage 386.0 (TID 562) in 30 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-07T21:30:32.882+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 0.0 in stage 389.0 (TID 564) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 10.0 in stage 386.0 (TID 563) in 192 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-07T21:30:32.887+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool
[2025-05-07T21:30:32.889+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: ShuffleMapStage 386 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.206 s
[2025-05-07T21:30:32.891+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:32.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: running: Set(ResultStage 389, ResultStage 392)
[2025-05-07T21:30:32.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:32.892+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:32.921+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO ShufflePartitionsUtil: For shuffle(68), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:32.924+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.20.0.5:46863 (size: 33.2 KiB, free: 432.2 MiB)
[2025-05-07T21:30:32.929+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 66 to 172.20.0.5:43654
[2025-05-07T21:30:32.952+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:32.974+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Starting task 0.0 in stage 392.0 (TID 565) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:32.975+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSetManager: Finished task 0.0 in stage 389.0 (TID 564) in 94 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:32.976+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSchedulerImpl: Removed TaskSet 389.0, whose tasks have all completed, from pool
[2025-05-07T21:30:32.977+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: ResultStage 389 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.078 s
[2025-05-07T21:30:32.978+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:32.978+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 389: Stage finished
[2025-05-07T21:30:32.981+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO DAGScheduler: Job 70 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 1.082948 s
[2025-05-07T21:30:32.988+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.20.0.5:46863 (size: 3.8 KiB, free: 432.2 MiB)
[2025-05-07T21:30:32.993+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 67 to 172.20.0.5:43654
[2025-05-07T21:30:33.018+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.20.0.5:46863 in memory (size: 49.6 KiB, free: 432.2 MiB)
[2025-05-07T21:30:33.023+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 3530b0b864fd:45373 in memory (size: 49.6 KiB, free: 432.8 MiB)
[2025-05-07T21:30:33.028+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO TaskSetManager: Finished task 0.0 in stage 392.0 (TID 565) in 52 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:33.029+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO TaskSchedulerImpl: Removed TaskSet 392.0, whose tasks have all completed, from pool
[2025-05-07T21:30:33.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.20.0.5:46863 in memory (size: 33.2 KiB, free: 432.2 MiB)
[2025-05-07T21:30:33.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO CodeGenerator: Code generated in 39.918976 ms
[2025-05-07T21:30:33.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 3530b0b864fd:45373 in memory (size: 33.2 KiB, free: 432.9 MiB)
[2025-05-07T21:30:33.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: ResultStage 392 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.883 s
[2025-05-07T21:30:33.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:33.030+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 392: Stage finished
[2025-05-07T21:30:33.033+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO CodeGenerator: Code generated in 71.101016 ms
[2025-05-07T21:30:33.034+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: Job 71 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.893148 s
[2025-05-07T21:30:33.040+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 1088.0 KiB, free 402.8 MiB)
[2025-05-07T21:30:33.042+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 2.1 MiB, free 400.8 MiB)
[2025-05-07T21:30:33.049+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 22.4 KiB, free 400.8 MiB)
[2025-05-07T21:30:33.051+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 3530b0b864fd:45373 (size: 22.4 KiB, free: 432.8 MiB)
[2025-05-07T21:30:33.053+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO SparkContext: Created broadcast 116 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:33.054+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: Registering RDD 538 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 69
[2025-05-07T21:30:33.055+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: Got map stage job 72 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:33.056+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: Final stage: ShuffleMapStage 395 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:33.057+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 394)
[2025-05-07T21:30:33.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:33.058+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: Submitting ShuffleMapStage 395 (MapPartitionsRDD[538] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:33.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 400.7 MiB)
[2025-05-07T21:30:33.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 3530b0b864fd:45373 (size: 20.3 KiB, free: 432.8 MiB)
[2025-05-07T21:30:33.063+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO SparkContext: Created broadcast 117 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:33.083+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 130.2 KiB, free 400.6 MiB)
[2025-05-07T21:30:33.088+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 44.6 KiB, free 400.6 MiB)
[2025-05-07T21:30:33.089+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 3530b0b864fd:45373 (size: 44.6 KiB, free: 432.8 MiB)
[2025-05-07T21:30:33.091+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:33.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 395 (MapPartitionsRDD[538] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:33.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO TaskSchedulerImpl: Adding task set 395.0 with 1 tasks resource profile 0
[2025-05-07T21:30:33.126+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO TaskSetManager: Starting task 0.0 in stage 395.0 (TID 566) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:33.336+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.20.0.5:46863 (size: 44.6 KiB, free: 432.2 MiB)
[2025-05-07T21:30:33.417+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 68 to 172.20.0.5:43654
[2025-05-07T21:30:33.513+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 3530b0b864fd:45373 in memory (size: 3.8 KiB, free: 432.8 MiB)
[2025-05-07T21:30:33.811+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:33 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.20.0.5:46863 in memory (size: 3.8 KiB, free: 432.2 MiB)
[2025-05-07T21:30:35.485+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(0,WrappedArray((566,395,0,Vector(AccumulableInfo(6925,Some(internal.metrics.shuffle.read.remoteBlocksFetched),Some(0),None,true,true,None), AccumulableInfo(6926,Some(internal.metrics.shuffle.read.localBlocksFetched),Some(1),None,true,true,None), AccumulableInfo(6927,Some(internal.metrics.shuffle.read.remoteBytesRead),Some(0),None,true,true,None), AccumulableInfo(6928,Some(internal.metrics.shuffle.read.remoteBytesReadToDisk),Some(0),None,true,true,None), AccumulableInfo(6929,Some(internal.metrics.shuffle.read.localBytesRead),Some(78838),None,true,true,None), AccumulableInfo(6930,Some(internal.metrics.shuffle.read.fetchWaitTime),Some(0),None,true,true,None), AccumulableInfo(6931,Some(internal.metrics.shuffle.read.recordsRead),Some(0),None,true,true,None), AccumulableInfo(6663,Some(local bytes read),Some(78838),None,true,true,Some(sql)), AccumulableInfo(6660,Some(local blocks read),Some(1),None,true,true,Some(sql))))),Map((118,0) -> org.apache.spark.executor.ExecutorMetrics@6f51ee32, (309,0) -> org.apache.spark.executor.ExecutorMetrics@7d5ea63f, (120,0) -> org.apache.spark.executor.ExecutorMetrics@626587d3, (335,0) -> org.apache.spark.executor.ExecutorMetrics@1b4e32b, (278,0) -> org.apache.spark.executor.ExecutorMetrics@61f4ad51, (381,0) -> org.apache.spark.executor.ExecutorMetrics@6993800e, (336,0) -> org.apache.spark.executor.ExecutorMetrics@2786d9f0, (199,0) -> org.apache.spark.executor.ExecutorMetrics@10ddb90, (342,0) -> org.apache.spark.executor.ExecutorMetrics@45d770c5, (250,0) -> org.apache.spark.executor.ExecutorMetrics@30310b81, (137,0) -> org.apache.spark.executor.ExecutorMetrics@21e90d2e, (200,0) -> org.apache.spark.executor.ExecutorMetrics@4ed783d8, (104,0) -> org.apache.spark.executor.ExecutorMetrics@30f8939f, (338,0) -> org.apache.spark.executor.ExecutorMetrics@8adeb02, (224,0) -> org.apache.spark.executor.ExecutorMetrics@61440744, (223,0) -> org.apache.spark.executor.ExecutorMetrics@13ff91f7, (136,0) -> org.apache.spark.executor.ExecutorMetrics@67ef8c7c, (333,0) -> org.apache.spark.executor.ExecutorMetrics@fd9e78, (225,0) -> org.apache.spark.executor.ExecutorMetrics@4142c704, (389,0) -> org.apache.spark.executor.ExecutorMetrics@2e5d86f2, (383,0) -> org.apache.spark.executor.ExecutorMetrics@354a7329, (176,0) -> org.apache.spark.executor.ExecutorMetrics@59a825a6, (135,0) -> org.apache.spark.executor.ExecutorMetrics@e05a370, (119,0) -> org.apache.spark.executor.ExecutorMetrics@4c2dde54, (105,0) -> org.apache.spark.executor.ExecutorMetrics@2a983fc3, (341,0) -> org.apache.spark.executor.ExecutorMetrics@3285aa23, (154,0) -> org.apache.spark.executor.ExecutorMetrics@11b88120, (304,0) -> org.apache.spark.executor.ExecutorMetrics@3345323d, (332,0) -> org.apache.spark.executor.ExecutorMetrics@58c865b1, (340,0) -> org.apache.spark.executor.ExecutorMetrics@47830839, (198,0) -> org.apache.spark.executor.ExecutorMetrics@12672068, (306,0) -> org.apache.spark.executor.ExecutorMetrics@8293cc3, (337,0) -> org.apache.spark.executor.ExecutorMetrics@13d7359a, (392,0) -> org.apache.spark.executor.ExecutorMetrics@4cca3519, (386,0) -> org.apache.spark.executor.ExecutorMetrics@67052888, (177,0) -> org.apache.spark.executor.ExecutorMetrics@268bcf8f, (251,0) -> org.apache.spark.executor.ExecutorMetrics@c5a5521, (334,0) -> org.apache.spark.executor.ExecutorMetrics@11a5db4e, (384,0) -> org.apache.spark.executor.ExecutorMetrics@5faaf09a, (368,0) -> org.apache.spark.executor.ExecutorMetrics@2725bb57, (252,0) -> org.apache.spark.executor.ExecutorMetrics@798811cf, (175,0) -> org.apache.spark.executor.ExecutorMetrics@46c8ca1b, (370,0) -> org.apache.spark.executor.ExecutorMetrics@4eeecc78, (379,0) -> org.apache.spark.executor.ExecutorMetrics@441b39f1, (339,0) -> org.apache.spark.executor.ExecutorMetrics@7d245ed4, (395,0) -> org.apache.spark.executor.ExecutorMetrics@7dbcdb79, (155,0) -> org.apache.spark.executor.ExecutorMetrics@450955ba, (344,0) -> org.apache.spark.executor.ExecutorMetrics@5840385b, (372,0) -> org.apache.spark.executor.ExecutorMetrics@7cd0f79, (156,0) -> org.apache.spark.executor.ExecutorMetrics@1c316bea)) by listener AppStatusListener took 1.475618992s.
[2025-05-07T21:30:35.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO TaskSetManager: Finished task 0.0 in stage 395.0 (TID 566) in 2371 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:35.514+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO TaskSchedulerImpl: Removed TaskSet 395.0, whose tasks have all completed, from pool
[2025-05-07T21:30:35.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: ShuffleMapStage 395 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 2.436 s
[2025-05-07T21:30:35.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T21:30:35.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: running: Set()
[2025-05-07T21:30:35.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: waiting: Set()
[2025-05-07T21:30:35.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: failed: Set()
[2025-05-07T21:30:35.515+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO ShufflePartitionsUtil: For shuffle(69), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:30:35.539+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:30:35.573+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO CodeGenerator: Code generated in 27.414358 ms
[2025-05-07T21:30:35.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:30:35.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: Got job 73 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:30:35.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: Final stage: ResultStage 399 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:30:35.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 398)
[2025-05-07T21:30:35.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:30:35.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: Submitting ResultStage 399 (MapPartitionsRDD[541] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:30:35.621+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 122.7 KiB, free 400.5 MiB)
[2025-05-07T21:30:35.649+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 42.0 KiB, free 400.5 MiB)
[2025-05-07T21:30:35.649+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 3530b0b864fd:45373 (size: 42.0 KiB, free: 432.7 MiB)
[2025-05-07T21:30:35.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:30:35.651+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 399 (MapPartitionsRDD[541] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:30:35.651+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 3530b0b864fd:45373 in memory (size: 44.6 KiB, free: 432.8 MiB)
[2025-05-07T21:30:35.651+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO TaskSchedulerImpl: Adding task set 399.0 with 1 tasks resource profile 0
[2025-05-07T21:30:35.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO TaskSetManager: Starting task 0.0 in stage 399.0 (TID 567) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T21:30:35.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 172.20.0.5:46863 in memory (size: 44.6 KiB, free: 432.2 MiB)
[2025-05-07T21:30:35.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.20.0.5:46863 (size: 42.0 KiB, free: 432.2 MiB)
[2025-05-07T21:30:35.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 69 to 172.20.0.5:43654
[2025-05-07T21:30:35.740+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO TaskSetManager: Finished task 0.0 in stage 399.0 (TID 567) in 88 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:30:35.741+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool
[2025-05-07T21:30:35.748+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: ResultStage 399 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.129 s
[2025-05-07T21:30:35.762+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:30:35.765+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 399: Stage finished
[2025-05-07T21:30:35.766+0000] {spark_submit.py:571} INFO - 25/05/07 21:30:35 INFO DAGScheduler: Job 73 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.148651 s
[2025-05-07T21:31:12.563+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 2.1 MiB, free 398.5 MiB)
[2025-05-07T21:31:12.656+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 3530b0b864fd:45373 in memory (size: 42.0 KiB, free: 432.8 MiB)
[2025-05-07T21:31:12.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 82.5 KiB, free 398.6 MiB)
[2025-05-07T21:31:12.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.20.0.5:46863 in memory (size: 42.0 KiB, free: 432.2 MiB)
[2025-05-07T21:31:12.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 3530b0b864fd:45373 (size: 82.5 KiB, free: 432.7 MiB)
[2025-05-07T21:31:12.657+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO SparkContext: Created broadcast 120 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:31:12.658+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO ShufflePartitionsUtil: For shuffle(65), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T21:31:12.685+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO CodeGenerator: Code generated in 26.152096 ms
[2025-05-07T21:31:12.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T21:31:12.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO DAGScheduler: Got job 74 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T21:31:12.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO DAGScheduler: Final stage: ResultStage 402 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T21:31:12.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 401)
[2025-05-07T21:31:12.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:31:12.723+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO DAGScheduler: Submitting ResultStage 402 (MapPartitionsRDD[544] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T21:31:12.724+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 15.6 KiB, free 398.6 MiB)
[2025-05-07T21:31:12.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 398.6 MiB)
[2025-05-07T21:31:12.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 3530b0b864fd:45373 (size: 6.6 KiB, free: 432.7 MiB)
[2025-05-07T21:31:12.734+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:31:12.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 402 (MapPartitionsRDD[544] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:31:12.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO TaskSchedulerImpl: Adding task set 402.0 with 1 tasks resource profile 0
[2025-05-07T21:31:12.735+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO TaskSetManager: Starting task 0.0 in stage 402.0 (TID 568) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T21:31:12.761+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.20.0.5:46863 (size: 6.6 KiB, free: 432.2 MiB)
[2025-05-07T21:31:12.802+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 65 to 172.20.0.5:43654
[2025-05-07T21:31:12.843+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.20.0.5:46863 (size: 20.3 KiB, free: 432.2 MiB)
[2025-05-07T21:31:12.863+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.20.0.5:46863 (size: 82.5 KiB, free: 432.1 MiB)
[2025-05-07T21:31:12.931+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.20.0.5:46863 (size: 22.4 KiB, free: 432.1 MiB)
[2025-05-07T21:31:12.971+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO TaskSetManager: Finished task 0.0 in stage 402.0 (TID 568) in 236 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T21:31:12.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool
[2025-05-07T21:31:12.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO DAGScheduler: ResultStage 402 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.248 s
[2025-05-07T21:31:12.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T21:31:12.972+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 402: Stage finished
[2025-05-07T21:31:12.977+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:12 INFO DAGScheduler: Job 74 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.251900 s
[2025-05-07T21:31:36.601+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:35 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 3530b0b864fd:45373 in memory (size: 6.6 KiB, free: 432.7 MiB)
[2025-05-07T21:31:45.494+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.20.0.5:46863 in memory (size: 6.6 KiB, free: 432.1 MiB)
[2025-05-07T21:31:47.473+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO DAGScheduler: Registering RDD 573 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 70
[2025-05-07T21:31:47.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO DAGScheduler: Got map stage job 75 (toPandas at /opt/airflow/spark/build_graph.py:216) with 6 output partitions
[2025-05-07T21:31:47.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO DAGScheduler: Final stage: ShuffleMapStage 403 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:31:47.505+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:31:47.508+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:31:47.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO DAGScheduler: Submitting ShuffleMapStage 403 (MapPartitionsRDD[573] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:31:47.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:31:47.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:31:47.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:31:47.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:31:47.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:31:47.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T21:31:47.509+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:45 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 36.4 KiB, free 398.6 MiB)
[2025-05-07T21:31:49.450+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 398.6 MiB)
[2025-05-07T21:31:49.758+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 3530b0b864fd:45373 (size: 11.2 KiB, free: 432.7 MiB)
[2025-05-07T21:31:49.774+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:31:49.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 403 (MapPartitionsRDD[573] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T21:31:49.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO TaskSchedulerImpl: Adding task set 403.0 with 6 tasks resource profile 0
[2025-05-07T21:31:49.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Registering RDD 575 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 71
[2025-05-07T21:31:49.782+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO TaskSetManager: Starting task 0.0 in stage 403.0 (TID 569) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:31:49.786+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Got map stage job 76 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:31:49.786+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Final stage: ShuffleMapStage 404 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:31:49.786+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:31:49.786+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:31:49.787+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting ShuffleMapStage 404 (MapPartitionsRDD[575] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:31:49.791+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 12.6 KiB, free 398.6 MiB)
[2025-05-07T21:31:49.843+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 398.5 MiB)
[2025-05-07T21:31:49.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 3530b0b864fd:45373 (size: 6.7 KiB, free: 432.7 MiB)
[2025-05-07T21:31:49.845+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:31:49.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 404 (MapPartitionsRDD[575] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:31:49.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO TaskSchedulerImpl: Adding task set 404.0 with 1 tasks resource profile 0
[2025-05-07T21:31:49.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Registering RDD 577 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 72
[2025-05-07T21:31:49.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Got map stage job 77 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:31:49.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Final stage: ShuffleMapStage 405 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:31:49.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:31:49.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:31:49.846+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting ShuffleMapStage 405 (MapPartitionsRDD[577] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:31:49.847+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 27.3 KiB, free 398.5 MiB)
[2025-05-07T21:31:49.851+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 398.5 MiB)
[2025-05-07T21:31:49.854+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 3530b0b864fd:45373 (size: 13.0 KiB, free: 432.7 MiB)
[2025-05-07T21:31:49.857+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:31:49.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 405 (MapPartitionsRDD[577] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:31:49.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO TaskSchedulerImpl: Adding task set 405.0 with 1 tasks resource profile 0
[2025-05-07T21:31:49.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Registering RDD 579 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 73
[2025-05-07T21:31:49.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Got map stage job 78 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:31:49.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Final stage: ShuffleMapStage 406 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:31:49.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:31:49.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:31:49.858+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting ShuffleMapStage 406 (MapPartitionsRDD[579] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:31:49.859+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 28.5 KiB, free 398.5 MiB)
[2025-05-07T21:31:49.861+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 398.5 MiB)
[2025-05-07T21:31:49.865+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 3530b0b864fd:45373 (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-07T21:31:49.867+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:31:49.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 406 (MapPartitionsRDD[579] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:31:49.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO TaskSchedulerImpl: Adding task set 406.0 with 1 tasks resource profile 0
[2025-05-07T21:31:49.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Registering RDD 581 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 74
[2025-05-07T21:31:49.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Got map stage job 79 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:31:49.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Final stage: ShuffleMapStage 407 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:31:49.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:31:49.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:31:49.868+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting ShuffleMapStage 407 (MapPartitionsRDD[581] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:31:49.870+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 28.5 KiB, free 398.4 MiB)
[2025-05-07T21:31:49.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 398.4 MiB)
[2025-05-07T21:31:49.874+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 3530b0b864fd:45373 (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-07T21:31:49.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:31:49.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 407 (MapPartitionsRDD[581] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:31:49.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO TaskSchedulerImpl: Adding task set 407.0 with 1 tasks resource profile 0
[2025-05-07T21:31:49.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Registering RDD 583 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 75
[2025-05-07T21:31:49.875+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Got map stage job 80 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:31:49.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Final stage: ShuffleMapStage 408 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:31:49.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:31:49.876+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:31:49.877+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting ShuffleMapStage 408 (MapPartitionsRDD[583] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:31:49.879+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 27.4 KiB, free 398.4 MiB)
[2025-05-07T21:31:49.896+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 398.4 MiB)
[2025-05-07T21:31:49.901+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 3530b0b864fd:45373 (size: 13.0 KiB, free: 432.7 MiB)
[2025-05-07T21:31:49.903+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:31:49.904+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 408 (MapPartitionsRDD[583] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:31:49.904+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO TaskSchedulerImpl: Adding task set 408.0 with 1 tasks resource profile 0
[2025-05-07T21:31:49.904+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Registering RDD 585 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 76
[2025-05-07T21:31:49.905+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Got map stage job 81 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:31:49.905+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Final stage: ShuffleMapStage 409 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:31:49.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:31:49.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:31:49.907+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting ShuffleMapStage 409 (MapPartitionsRDD[585] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:31:49.909+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 28.5 KiB, free 398.4 MiB)
[2025-05-07T21:31:49.911+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 398.3 MiB)
[2025-05-07T21:31:49.914+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 3530b0b864fd:45373 (size: 13.4 KiB, free: 432.7 MiB)
[2025-05-07T21:31:49.915+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:31:49.917+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 409 (MapPartitionsRDD[585] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:31:49.918+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO TaskSchedulerImpl: Adding task set 409.0 with 1 tasks resource profile 0
[2025-05-07T21:31:49.919+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Registering RDD 587 (toPandas at /opt/airflow/spark/build_graph.py:216) as input to shuffle 77
[2025-05-07T21:31:49.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Got map stage job 82 (toPandas at /opt/airflow/spark/build_graph.py:216) with 1 output partitions
[2025-05-07T21:31:49.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Final stage: ShuffleMapStage 410 (toPandas at /opt/airflow/spark/build_graph.py:216)
[2025-05-07T21:31:49.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T21:31:49.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Missing parents: List()
[2025-05-07T21:31:49.920+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting ShuffleMapStage 410 (MapPartitionsRDD[587] at toPandas at /opt/airflow/spark/build_graph.py:216), which has no missing parents
[2025-05-07T21:31:49.930+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 31.7 KiB, free 398.3 MiB)
[2025-05-07T21:31:49.939+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 398.3 MiB)
[2025-05-07T21:31:49.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 3530b0b864fd:45373 (size: 14.9 KiB, free: 432.6 MiB)
[2025-05-07T21:31:49.942+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1474
[2025-05-07T21:31:49.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 410 (MapPartitionsRDD[587] at toPandas at /opt/airflow/spark/build_graph.py:216) (first 15 tasks are for partitions Vector(0))
[2025-05-07T21:31:49.943+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO TaskSchedulerImpl: Adding task set 410.0 with 1 tasks resource profile 0
[2025-05-07T21:31:49.947+0000] {spark_submit.py:571} INFO - 25/05/07 21:31:49 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.20.0.5:46863 (size: 11.2 KiB, free: 432.1 MiB)
[2025-05-07T21:32:39.835+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:39 INFO TaskSetManager: Starting task 1.0 in stage 403.0 (TID 570) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:32:39.928+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:39 WARN TaskSetManager: Lost task 0.0 in stage 403.0 (TID 569) (172.20.0.5 executor 0): org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:39.928+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:39.928+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:39.928+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:39.928+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:39.928+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:39.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:39.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:39.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:39.930+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:39.931+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:39.931+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:39.931+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:39.931+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:39.931+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:39.931+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:39.931+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:39.931+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:39.931+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:40.482+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Starting task 0.1 in stage 403.0 (TID 571) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:32:40.555+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Lost task 1.0 in stage 403.0 (TID 570) on 172.20.0.5, executor 0: org.postgresql.util.PSQLException (The connection attempt failed.) [duplicate 1]
[2025-05-07T21:32:40.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Starting task 1.1 in stage 403.0 (TID 572) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:32:40.575+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Lost task 0.1 in stage 403.0 (TID 571) on 172.20.0.5, executor 0: org.postgresql.util.PSQLException (The connection attempt failed.) [duplicate 2]
[2025-05-07T21:32:40.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Starting task 0.2 in stage 403.0 (TID 573) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:32:40.602+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Lost task 1.1 in stage 403.0 (TID 572) on 172.20.0.5, executor 0: org.postgresql.util.PSQLException (The connection attempt failed.) [duplicate 3]
[2025-05-07T21:32:40.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Starting task 1.2 in stage 403.0 (TID 574) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:32:40.607+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Lost task 0.2 in stage 403.0 (TID 573) on 172.20.0.5, executor 0: org.postgresql.util.PSQLException (The connection attempt failed.) [duplicate 4]
[2025-05-07T21:32:40.611+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Starting task 0.3 in stage 403.0 (TID 575) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:32:40.612+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Lost task 1.2 in stage 403.0 (TID 574) on 172.20.0.5, executor 0: org.postgresql.util.PSQLException (The connection attempt failed.) [duplicate 5]
[2025-05-07T21:32:40.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Starting task 1.3 in stage 403.0 (TID 576) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T21:32:40.617+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Lost task 0.3 in stage 403.0 (TID 575) on 172.20.0.5, executor 0: org.postgresql.util.PSQLException (The connection attempt failed.) [duplicate 6]
[2025-05-07T21:32:40.618+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 ERROR TaskSetManager: Task 0 in stage 403.0 failed 4 times; aborting job
[2025-05-07T21:32:40.642+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Starting task 0.0 in stage 404.0 (TID 577) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T21:32:40.644+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Cancelling stage 403
[2025-05-07T21:32:40.644+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 403: Stage cancelled
[2025-05-07T21:32:40.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Removed TaskSet 403.0, whose tasks have all completed, from pool
[2025-05-07T21:32:40.650+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Stage 403 was cancelled
[2025-05-07T21:32:40.651+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSetManager: Lost task 1.3 in stage 403.0 (TID 576) on 172.20.0.5, executor 0: org.postgresql.util.PSQLException (The connection attempt failed.) [duplicate 7]
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Removed TaskSet 403.0, whose tasks have all completed, from pool
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: ShuffleMapStage 403 (toPandas at /opt/airflow/spark/build_graph.py:216) failed in 55.138 s due to Job aborted due to stage failure: Task 0 in stage 403.0 failed 4 times, most recent failure: Lost task 0.3 in stage 403.0 (TID 575) (172.20.0.5 executor 0): org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:40.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:40.655+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:40.656+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:40.656+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:40.656+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:40.656+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:40.656+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:40.656+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:40.656+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:40.656+0000] {spark_submit.py:571} INFO - Driver stacktrace:
[2025-05-07T21:32:40.664+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: Asked to cancel job 76
[2025-05-07T21:32:40.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: Asked to cancel job 77
[2025-05-07T21:32:40.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: Asked to cancel job 78
[2025-05-07T21:32:40.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: Asked to cancel job 79
[2025-05-07T21:32:40.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: Asked to cancel job 80
[2025-05-07T21:32:40.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: Asked to cancel job 81
[2025-05-07T21:32:40.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: Asked to cancel job 82
[2025-05-07T21:32:40.665+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: Asked to cancel job 76
[2025-05-07T21:32:40.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Cancelling stage 404
[2025-05-07T21:32:40.668+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 404: Stage cancelled
[2025-05-07T21:32:40.674+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Stage 404 was cancelled
[2025-05-07T21:32:40.674+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: ShuffleMapStage 404 (toPandas at /opt/airflow/spark/build_graph.py:216) failed in 50.886 s due to Job 76 cancelled
[2025-05-07T21:32:40.675+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Cancelling stage 405
[2025-05-07T21:32:40.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 405: Stage cancelled
[2025-05-07T21:32:40.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Removed TaskSet 405.0, whose tasks have all completed, from pool
[2025-05-07T21:32:40.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Stage 405 was cancelled
[2025-05-07T21:32:40.676+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: ShuffleMapStage 405 (toPandas at /opt/airflow/spark/build_graph.py:216) failed in 50.829 s due to Job 77 cancelled
[2025-05-07T21:32:40.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Cancelling stage 406
[2025-05-07T21:32:40.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 406: Stage cancelled
[2025-05-07T21:32:40.677+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Removed TaskSet 406.0, whose tasks have all completed, from pool
[2025-05-07T21:32:40.678+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Stage 406 was cancelled
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: ShuffleMapStage 406 (toPandas at /opt/airflow/spark/build_graph.py:216) failed in 50.821 s due to Job 78 cancelled
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Cancelling stage 407
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 407: Stage cancelled
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Removed TaskSet 407.0, whose tasks have all completed, from pool
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Stage 407 was cancelled
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: ShuffleMapStage 407 (toPandas at /opt/airflow/spark/build_graph.py:216) failed in 50.812 s due to Job 79 cancelled
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Cancelling stage 408
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 408: Stage cancelled
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Removed TaskSet 408.0, whose tasks have all completed, from pool
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Stage 408 was cancelled
[2025-05-07T21:32:40.679+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: ShuffleMapStage 408 (toPandas at /opt/airflow/spark/build_graph.py:216) failed in 50.802 s due to Job 80 cancelled
[2025-05-07T21:32:40.680+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Cancelling stage 409
[2025-05-07T21:32:40.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 409: Stage cancelled
[2025-05-07T21:32:40.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Removed TaskSet 409.0, whose tasks have all completed, from pool
[2025-05-07T21:32:40.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Stage 409 was cancelled
[2025-05-07T21:32:40.681+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: ShuffleMapStage 409 (toPandas at /opt/airflow/spark/build_graph.py:216) failed in 50.773 s due to Job 81 cancelled
[2025-05-07T21:32:40.682+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Cancelling stage 410
[2025-05-07T21:32:40.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 410: Stage cancelled
[2025-05-07T21:32:40.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Removed TaskSet 410.0, whose tasks have all completed, from pool
[2025-05-07T21:32:40.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Stage 410 was cancelled
[2025-05-07T21:32:40.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO DAGScheduler: ShuffleMapStage 410 (toPandas at /opt/airflow/spark/build_graph.py:216) failed in 50.766 s due to Job 82 cancelled
[2025-05-07T21:32:40.683+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.20.0.5:46863 (size: 6.7 KiB, free: 432.1 MiB)
[2025-05-07T21:32:40.703+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 WARN TaskSetManager: Lost task 0.0 in stage 404.0 (TID 577) (172.20.0.5 executor 0): TaskKilled (Stage cancelled)
[2025-05-07T21:32:40.704+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:40 INFO TaskSchedulerImpl: Removed TaskSet 404.0, whose tasks have all completed, from pool
[2025-05-07T21:32:40.885+0000] {spark_submit.py:571} INFO - 2025-05-07 21:32:40,807 [ERROR] Ошибка при обработке транзакционного графа: An error occurred while calling o323.collectToPython.
[2025-05-07T21:32:40.886+0000] {spark_submit.py:571} INFO - : org.apache.spark.SparkException: Multiple failures in stage materialization.
[2025-05-07T21:32:40.886+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.errors.QueryExecutionErrors$.multiFailuresInStageMaterializationError(QueryExecutionErrors.scala:1567)
[2025-05-07T21:32:40.886+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.cleanUpAndThrowException(AdaptiveSparkPlanExec.scala:743)
[2025-05-07T21:32:40.886+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:287)
[2025-05-07T21:32:40.886+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
[2025-05-07T21:32:40.886+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:228)
[2025-05-07T21:32:40.886+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:370)
[2025-05-07T21:32:40.886+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:343)
[2025-05-07T21:32:40.886+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3538)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3535)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2025-05-07T21:32:40.887+0000] {spark_submit.py:571} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at py4j.Gateway.invoke(Gateway.java:282)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - Suppressed: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 403.0 failed 4 times, most recent failure: Lost task 0.3 in stage 403.0 (TID 575) (172.20.0.5 executor 0): org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:40.888+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.889+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:40.890+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:40.891+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - Driver stacktrace:
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2399)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2398)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2398)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1156)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1156)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at scala.Option.foreach(Option.scala:407)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1156)
[2025-05-07T21:32:40.892+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2638)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - Caused by: org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:40.893+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:40.895+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - Caused by: [CIRCULAR REFERENCE: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 403.0 failed 4 times, most recent failure: Lost task 0.3 in stage 403.0 (TID 575) (172.20.0.5 executor 0): org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:40.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:40.898+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - Driver stacktrace:]
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - Traceback (most recent call last):
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - File "/opt/airflow/spark/build_graph.py", line 216, in main
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - edges_df = final_edges.toPandas()
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py", line 157, in toPandas
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - pdf = pd.DataFrame.from_records(self.collect(), columns=self.columns)
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 693, in collect
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - sock_info = self._jdf.collectToPython()
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - return_value = get_return_value(
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
[2025-05-07T21:32:40.899+0000] {spark_submit.py:571} INFO - return f(*a, **kw)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py", line 326, in get_return_value
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - raise Py4JJavaError(
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - py4j.protocol.Py4JJavaError: An error occurred while calling o323.collectToPython.
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - : org.apache.spark.SparkException: Multiple failures in stage materialization.
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.errors.QueryExecutionErrors$.multiFailuresInStageMaterializationError(QueryExecutionErrors.scala:1567)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.cleanUpAndThrowException(AdaptiveSparkPlanExec.scala:743)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:287)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:228)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:370)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:343)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3538)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
[2025-05-07T21:32:40.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3535)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at py4j.Gateway.invoke(Gateway.java:282)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - Suppressed: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 403.0 failed 4 times, most recent failure: Lost task 0.3 in stage 403.0 (TID 575) (172.20.0.5 executor 0): org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:40.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:40.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - Driver stacktrace:
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2399)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2398)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
[2025-05-07T21:32:40.903+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2398)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1156)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1156)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at scala.Option.foreach(Option.scala:407)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1156)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2638)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - Caused by: org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:40.904+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:40.905+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - Caused by: [CIRCULAR REFERENCE: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 403.0 failed 4 times, most recent failure: Lost task 0.3 in stage 403.0 (TID 575) (172.20.0.5 executor 0): org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:40.906+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.907+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:40.908+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - Driver stacktrace:]
[2025-05-07T21:32:40.909+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:42.829+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:42 INFO SparkUI: Stopped Spark web UI at http://3530b0b864fd:4040
[2025-05-07T21:32:42.881+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:42 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-05-07T21:32:42.886+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:42 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2025-05-07T21:32:43.026+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-07T21:32:43.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:43 INFO MemoryStore: MemoryStore cleared
[2025-05-07T21:32:43.404+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:43 INFO BlockManager: BlockManager stopped
[2025-05-07T21:32:43.415+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:43 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-07T21:32:43.422+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-07T21:32:43.439+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:43 INFO SparkContext: Successfully stopped SparkContext
[2025-05-07T21:32:43.549+0000] {spark_submit.py:571} INFO - 2025-05-07 21:32:43,549 [INFO] SparkSession остановлена
[2025-05-07T21:32:43.549+0000] {spark_submit.py:571} INFO - Traceback (most recent call last):
[2025-05-07T21:32:43.549+0000] {spark_submit.py:571} INFO - File "/opt/airflow/spark/build_graph.py", line 246, in <module>
[2025-05-07T21:32:43.551+0000] {spark_submit.py:571} INFO - main()
[2025-05-07T21:32:43.552+0000] {spark_submit.py:571} INFO - File "/opt/airflow/spark/build_graph.py", line 216, in main
[2025-05-07T21:32:43.552+0000] {spark_submit.py:571} INFO - edges_df = final_edges.toPandas()
[2025-05-07T21:32:43.552+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py", line 157, in toPandas
[2025-05-07T21:32:43.605+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 693, in collect
[2025-05-07T21:32:43.607+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
[2025-05-07T21:32:43.608+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
[2025-05-07T21:32:43.608+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py", line 326, in get_return_value
[2025-05-07T21:32:43.616+0000] {spark_submit.py:571} INFO - py4j.protocol.Py4JJavaError: An error occurred while calling o323.collectToPython.
[2025-05-07T21:32:43.618+0000] {spark_submit.py:571} INFO - : org.apache.spark.SparkException: Multiple failures in stage materialization.
[2025-05-07T21:32:43.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.errors.QueryExecutionErrors$.multiFailuresInStageMaterializationError(QueryExecutionErrors.scala:1567)
[2025-05-07T21:32:43.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.cleanUpAndThrowException(AdaptiveSparkPlanExec.scala:743)
[2025-05-07T21:32:43.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:287)
[2025-05-07T21:32:43.620+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
[2025-05-07T21:32:43.620+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:228)
[2025-05-07T21:32:43.620+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:370)
[2025-05-07T21:32:43.620+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:343)
[2025-05-07T21:32:43.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3538)
[2025-05-07T21:32:43.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
[2025-05-07T21:32:43.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
[2025-05-07T21:32:43.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
[2025-05-07T21:32:43.624+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
[2025-05-07T21:32:43.625+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
[2025-05-07T21:32:43.625+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
[2025-05-07T21:32:43.626+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
[2025-05-07T21:32:43.626+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3535)
[2025-05-07T21:32:43.626+0000] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-05-07T21:32:43.627+0000] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[2025-05-07T21:32:43.627+0000] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2025-05-07T21:32:43.627+0000] {spark_submit.py:571} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2025-05-07T21:32:43.627+0000] {spark_submit.py:571} INFO - at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-05-07T21:32:43.628+0000] {spark_submit.py:571} INFO - at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
[2025-05-07T21:32:43.628+0000] {spark_submit.py:571} INFO - at py4j.Gateway.invoke(Gateway.java:282)
[2025-05-07T21:32:43.628+0000] {spark_submit.py:571} INFO - at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-05-07T21:32:43.628+0000] {spark_submit.py:571} INFO - at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-05-07T21:32:43.629+0000] {spark_submit.py:571} INFO - at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-05-07T21:32:43.629+0000] {spark_submit.py:571} INFO - at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-05-07T21:32:43.629+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:43.629+0000] {spark_submit.py:571} INFO - Suppressed: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 403.0 failed 4 times, most recent failure: Lost task 0.3 in stage 403.0 (TID 575) (172.20.0.5 executor 0): org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:43.630+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:43.630+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:43.630+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:43.630+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:43.631+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:43.631+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:43.631+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:43.631+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:43.632+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:43.632+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.632+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.632+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:43.633+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.633+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.633+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:43.633+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.634+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.634+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:43.634+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.634+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.634+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:43.635+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:43.635+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:43.635+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:43.635+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:43.636+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:43.636+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:43.636+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:43.636+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:43.637+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:43.637+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:43.637+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:43.637+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:43.637+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:43.638+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:43.638+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:43.638+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:43.638+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:43.638+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:43.638+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:43.639+0000] {spark_submit.py:571} INFO - Driver stacktrace:
[2025-05-07T21:32:43.639+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)
[2025-05-07T21:32:43.639+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2399)
[2025-05-07T21:32:43.639+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2398)
[2025-05-07T21:32:43.639+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
[2025-05-07T21:32:43.640+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
[2025-05-07T21:32:43.640+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
[2025-05-07T21:32:43.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2398)
[2025-05-07T21:32:43.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1156)
[2025-05-07T21:32:43.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1156)
[2025-05-07T21:32:43.640+0000] {spark_submit.py:571} INFO - at scala.Option.foreach(Option.scala:407)
[2025-05-07T21:32:43.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1156)
[2025-05-07T21:32:43.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2638)
[2025-05-07T21:32:43.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)
[2025-05-07T21:32:43.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)
[2025-05-07T21:32:43.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
[2025-05-07T21:32:43.641+0000] {spark_submit.py:571} INFO - Caused by: org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:43.641+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:43.641+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:43.641+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:43.642+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:43.642+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:43.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:43.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:43.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:43.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:43.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:43.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:43.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:43.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:43.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:43.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:43.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:43.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:43.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:43.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:43.645+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:43.645+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:43.645+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:43.645+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:43.645+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:43.645+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:43.646+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:43.646+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:43.646+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:43.646+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:43.646+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:43.646+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:43.647+0000] {spark_submit.py:571} INFO - Caused by: [CIRCULAR REFERENCE: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 403.0 failed 4 times, most recent failure: Lost task 0.3 in stage 403.0 (TID 575) (172.20.0.5 executor 0): org.postgresql.util.PSQLException: The connection attempt failed.
[2025-05-07T21:32:43.647+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:354)
[2025-05-07T21:32:43.647+0000] {spark_submit.py:571} INFO - at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
[2025-05-07T21:32:43.647+0000] {spark_submit.py:571} INFO - at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:263)
[2025-05-07T21:32:43.647+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.makeConnection(Driver.java:443)
[2025-05-07T21:32:43.647+0000] {spark_submit.py:571} INFO - at org.postgresql.Driver.connect(Driver.java:297)
[2025-05-07T21:32:43.647+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
[2025-05-07T21:32:43.648+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
[2025-05-07T21:32:43.648+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
[2025-05-07T21:32:43.648+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:325)
[2025-05-07T21:32:43.648+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.648+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.648+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:43.648+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.648+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.648+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T21:32:43.649+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.649+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.649+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T21:32:43.649+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T21:32:43.649+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T21:32:43.649+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T21:32:43.649+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T21:32:43.649+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T21:32:43.650+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T21:32:43.650+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T21:32:43.650+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T21:32:43.650+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T21:32:43.650+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T21:32:43.650+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T21:32:43.650+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T21:32:43.650+0000] {spark_submit.py:571} INFO - Caused by: java.net.UnknownHostException: postgres
[2025-05-07T21:32:43.651+0000] {spark_submit.py:571} INFO - at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:229)
[2025-05-07T21:32:43.651+0000] {spark_submit.py:571} INFO - at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
[2025-05-07T21:32:43.651+0000] {spark_submit.py:571} INFO - at java.base/java.net.Socket.connect(Socket.java:609)
[2025-05-07T21:32:43.651+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.createSocket(PGStream.java:243)
[2025-05-07T21:32:43.651+0000] {spark_submit.py:571} INFO - at org.postgresql.core.PGStream.<init>(PGStream.java:98)
[2025-05-07T21:32:43.651+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:132)
[2025-05-07T21:32:43.651+0000] {spark_submit.py:571} INFO - at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
[2025-05-07T21:32:43.651+0000] {spark_submit.py:571} INFO - ... 29 more
[2025-05-07T21:32:43.651+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:43.652+0000] {spark_submit.py:571} INFO - Driver stacktrace:]
[2025-05-07T21:32:43.652+0000] {spark_submit.py:571} INFO - 
[2025-05-07T21:32:44.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:44 INFO ShutdownHookManager: Shutdown hook called
[2025-05-07T21:32:44.000+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-fdb5943c-4a04-43a7-a00f-ce4c15af2a18/pyspark-6b6cdde7-ee90-4bcd-84f2-bebff68576a8
[2025-05-07T21:32:44.003+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-fdb5943c-4a04-43a7-a00f-ce4c15af2a18
[2025-05-07T21:32:44.006+0000] {spark_submit.py:571} INFO - 25/05/07 21:32:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-b23b6a54-3aa4-4569-87ac-bcbbdd4c1155
[2025-05-07T21:32:44.110+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 174, in execute
    self._hook.submit(self.application)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 502, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******. Error code is: 1.
[2025-05-07T21:32:44.114+0000] {taskinstance.py:1345} INFO - Marking task as UP_FOR_RETRY. dag_id=graph_analysis, task_id=build_graph, execution_date=20250507T212946, start_date=20250507T212954, end_date=20250507T213244
[2025-05-07T21:32:44.174+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 282 for task build_graph (Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******. Error code is: 1.; 9754)
[2025-05-07T21:32:44.191+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2025-05-07T21:32:44.278+0000] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
