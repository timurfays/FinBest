[2025-05-06T13:17:00.355+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-06T13:16:53.463919+00:00 [queued]>
[2025-05-06T13:17:00.360+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-06T13:16:53.463919+00:00 [queued]>
[2025-05-06T13:17:00.360+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 2
[2025-05-06T13:17:00.369+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): build_graph> on 2025-05-06 13:16:53.463919+00:00
[2025-05-06T13:17:00.373+0000] {standard_task_runner.py:57} INFO - Started process 2326 to run task
[2025-05-06T13:17:00.374+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'graph_analysis', 'build_graph', 'manual__2025-05-06T13:16:53.463919+00:00', '--job-id', '209', '--raw', '--subdir', 'DAGS_FOLDER/graph_analysis.py', '--cfg-path', '/tmp/tmpda2g3i_x']
[2025-05-06T13:17:00.375+0000] {standard_task_runner.py:85} INFO - Job 209: Subtask build_graph
[2025-05-06T13:17:00.387+0000] {logging_mixin.py:150} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-06T13:17:00.413+0000] {task_command.py:410} INFO - Running <TaskInstance: graph_analysis.build_graph manual__2025-05-06T13:16:53.463919+00:00 [running]> on host 016737cbcc7e
[2025-05-06T13:17:00.503+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='finbest' AIRFLOW_CTX_DAG_ID='graph_analysis' AIRFLOW_CTX_TASK_ID='build_graph' AIRFLOW_CTX_EXECUTION_DATE='2025-05-06T13:16:53.463919+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-06T13:16:53.463919+00:00'
[2025-05-06T13:17:00.511+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-05-06T13:17:00.512+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --jars /opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar --packages org.postgresql:postgresql:42.6.0 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******
[2025-05-06T13:17:00.526+0000] {spark_submit.py:571} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-05-06T13:17:01.399+0000] {spark_submit.py:571} INFO - Using properties file: null
[2025-05-06T13:17:01.462+0000] {spark_submit.py:571} INFO - WARNING: An illegal reflective access operation has occurred
[2025-05-06T13:17:01.462+0000] {spark_submit.py:571} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2025-05-06T13:17:01.463+0000] {spark_submit.py:571} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2025-05-06T13:17:01.463+0000] {spark_submit.py:571} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-05-06T13:17:01.463+0000] {spark_submit.py:571} INFO - WARNING: All illegal access operations will be denied in a future release
[2025-05-06T13:17:01.500+0000] {spark_submit.py:571} INFO - Parsed arguments:
[2025-05-06T13:17:01.500+0000] {spark_submit.py:571} INFO - master                  spark://spark-master:7077
[2025-05-06T13:17:01.500+0000] {spark_submit.py:571} INFO - deployMode              null
[2025-05-06T13:17:01.500+0000] {spark_submit.py:571} INFO - executorMemory          1g
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - executorCores           1
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - totalExecutorCores      null
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - propertiesFile          null
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - driverMemory            1g
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - driverCores             null
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - driverExtraClassPath    null
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - driverExtraLibraryPath  null
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - driverExtraJavaOptions  null
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - supervise               false
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - queue                   null
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - numExecutors            null
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - files                   null
[2025-05-06T13:17:01.501+0000] {spark_submit.py:571} INFO - pyFiles                 null
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - archives                null
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - mainClass               null
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - primaryResource         file:/opt/airflow/spark/build_graph.py
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - name                    arrow-spark
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - childArgs               [--jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ***]
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - jars                    file:/opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - packages                org.postgresql:postgresql:42.6.0
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - packagesExclusions      null
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - repositories            null
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - verbose                 true
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - 
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - Spark properties used, including those specified through
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - --conf and those from the properties file null:
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-06T13:17:01.502+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-06T13:17:01.503+0000] {spark_submit.py:571} INFO - 
[2025-05-06T13:17:01.503+0000] {spark_submit.py:571} INFO - 
[2025-05-06T13:17:01.598+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-06T13:17:01.664+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-05-06T13:17:01.664+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-05-06T13:17:01.668+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql added as a dependency
[2025-05-06T13:17:01.669+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-1916df88-afb3-4ebd-b949-d039591dd486;1.0
[2025-05-06T13:17:01.669+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-06T13:17:01.752+0000] {spark_submit.py:571} INFO - found org.postgresql#postgresql;42.6.0 in central
[2025-05-06T13:17:01.769+0000] {spark_submit.py:571} INFO - found org.checkerframework#checker-qual;3.31.0 in central
[2025-05-06T13:17:01.782+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 110ms :: artifacts dl 4ms
[2025-05-06T13:17:01.783+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-05-06T13:17:01.783+0000] {spark_submit.py:571} INFO - org.checkerframework#checker-qual;3.31.0 from central in [default]
[2025-05-06T13:17:01.783+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql;42.6.0 from central in [default]
[2025-05-06T13:17:01.783+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-06T13:17:01.783+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-05-06T13:17:01.783+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-06T13:17:01.783+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-06T13:17:01.783+0000] {spark_submit.py:571} INFO - |      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
[2025-05-06T13:17:01.784+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-06T13:17:01.788+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-1916df88-afb3-4ebd-b949-d039591dd486
[2025-05-06T13:17:01.788+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-06T13:17:01.792+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 2 already retrieved (0kB/4ms)
[2025-05-06T13:17:01.967+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-06T13:17:02.114+0000] {spark_submit.py:571} INFO - Main class:
[2025-05-06T13:17:02.114+0000] {spark_submit.py:571} INFO - org.apache.spark.deploy.PythonRunner
[2025-05-06T13:17:02.114+0000] {spark_submit.py:571} INFO - Arguments:
[2025-05-06T13:17:02.115+0000] {spark_submit.py:571} INFO - file:/opt/airflow/spark/build_graph.py
[2025-05-06T13:17:02.115+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-06T13:17:02.115+0000] {spark_submit.py:571} INFO - --jdbc
[2025-05-06T13:17:02.115+0000] {spark_submit.py:571} INFO - jdbc:postgresql://postgres:5432/finbest
[2025-05-06T13:17:02.115+0000] {spark_submit.py:571} INFO - --user
[2025-05-06T13:17:02.115+0000] {spark_submit.py:571} INFO - finbest
[2025-05-06T13:17:02.115+0000] {spark_submit.py:571} INFO - --password
[2025-05-06T13:17:02.115+0000] {spark_submit.py:571} INFO - ***
[2025-05-06T13:17:02.116+0000] {spark_submit.py:571} INFO - Spark config:
[2025-05-06T13:17:02.116+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.jars,file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.app.name,arrow-spark)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,/home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.files,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.submit.deployMode,client)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.master,spark://spark-master:7077)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.executor.memory,1g)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.executor.cores,1)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.repl.local.jars,file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - Classpath elements:
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - 
[2025-05-06T13:17:02.117+0000] {spark_submit.py:571} INFO - 
[2025-05-06T13:17:02.711+0000] {spark_submit.py:571} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2025-05-06T13:17:02.718+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO SparkContext: Running Spark version 3.2.4
[2025-05-06T13:17:02.734+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO ResourceUtils: ==============================================================
[2025-05-06T13:17:02.734+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-06T13:17:02.734+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO ResourceUtils: ==============================================================
[2025-05-06T13:17:02.734+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO SparkContext: Submitted application: FinBestGraphAnalysis
[2025-05-06T13:17:02.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-06T13:17:02.759+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-05-06T13:17:02.760+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-06T13:17:02.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO SecurityManager: Changing view acls to: airflow
[2025-05-06T13:17:02.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO SecurityManager: Changing modify acls to: airflow
[2025-05-06T13:17:02.803+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO SecurityManager: Changing view acls groups to:
[2025-05-06T13:17:02.804+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO SecurityManager: Changing modify acls groups to:
[2025-05-06T13:17:02.804+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(airflow); groups with view permissions: Set(); users  with modify permissions: Set(airflow); groups with modify permissions: Set()
[2025-05-06T13:17:02.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:02 INFO Utils: Successfully started service 'sparkDriver' on port 42299.
[2025-05-06T13:17:03.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkEnv: Registering MapOutputTracker
[2025-05-06T13:17:03.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-06T13:17:03.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-06T13:17:03.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-06T13:17:03.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-06T13:17:03.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7b385607-c490-4a0a-84a7-124058825928
[2025-05-06T13:17:03.098+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-06T13:17:03.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-06T13:17:03.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-06T13:17:03.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://016737cbcc7e:4040
[2025-05-06T13:17:03.304+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkContext: Added JAR file:///opt/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar at spark://016737cbcc7e:42299/jars/graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746537422708
[2025-05-06T13:17:03.304+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://016737cbcc7e:42299/jars/org.postgresql_postgresql-42.6.0.jar with timestamp 1746537422708
[2025-05-06T13:17:03.304+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://016737cbcc7e:42299/jars/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746537422708
[2025-05-06T13:17:03.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://016737cbcc7e:42299/files/org.postgresql_postgresql-42.6.0.jar with timestamp 1746537422708
[2025-05-06T13:17:03.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO Utils: Copying /home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar to /tmp/spark-2399efd9-b3ac-480d-8fec-d0b0db6b3ccd/userFiles-5e7c2b29-ebbc-44fb-a44f-cbbb4cc09f71/org.postgresql_postgresql-42.6.0.jar
[2025-05-06T13:17:03.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://016737cbcc7e:42299/files/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746537422708
[2025-05-06T13:17:03.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO Utils: Copying /home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar to /tmp/spark-2399efd9-b3ac-480d-8fec-d0b0db6b3ccd/userFiles-5e7c2b29-ebbc-44fb-a44f-cbbb4cc09f71/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-06T13:17:03.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-05-06T13:17:03.467+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.2:7077 after 19 ms (0 ms spent in bootstraps)
[2025-05-06T13:17:03.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250506131703-0001
[2025-05-06T13:17:03.555+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250506131703-0001/0 on worker-20250506113546-172.18.0.4-40121 (172.18.0.4:40121) with 1 core(s)
[2025-05-06T13:17:03.555+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32777.
[2025-05-06T13:17:03.556+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO NettyBlockTransferService: Server created on 016737cbcc7e:32777
[2025-05-06T13:17:03.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250506131703-0001/0 on hostPort 172.18.0.4:40121 with 1 core(s), 1024.0 MiB RAM
[2025-05-06T13:17:03.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-06T13:17:03.562+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 016737cbcc7e, 32777, None)
[2025-05-06T13:17:03.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO BlockManagerMasterEndpoint: Registering block manager 016737cbcc7e:32777 with 434.4 MiB RAM, BlockManagerId(driver, 016737cbcc7e, 32777, None)
[2025-05-06T13:17:03.567+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 016737cbcc7e, 32777, None)
[2025-05-06T13:17:03.568+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 016737cbcc7e, 32777, None)
[2025-05-06T13:17:03.615+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250506131703-0001/0 is now RUNNING
[2025-05-06T13:17:03.704+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-05-06T13:17:03.870+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-06T13:17:03.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:03 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-05-06T13:17:04.453+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:04,453 [INFO] SparkSession создана
[2025-05-06T13:17:04.454+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:04,453 [INFO] Загружаем транзакции из raw.masked_transactions
[2025-05-06T13:17:05.924+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.4:59552) with ID 0,  ResourceProfileId 0
[2025-05-06T13:17:06.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:06 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.4:44293 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.4, 44293, None)
[2025-05-06T13:17:07.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO CodeGenerator: Code generated in 115.457202 ms
[2025-05-06T13:17:07.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-05-06T13:17:07.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:07.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:07.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:07.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:07.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:07.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-06T13:17:07.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-06T13:17:07.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:07.244+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:07.257+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:07.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-06T13:17:07.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:07.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:08.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 911 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:08.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-06T13:17:08.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.079 s
[2025-05-06T13:17:08.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:08.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:08.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:08.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:08.236+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO CodeGenerator: Code generated in 8.518367 ms
[2025-05-06T13:17:08.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T13:17:08.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:08.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:08.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-06T13:17:08.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:08.267+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:08.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-06T13:17:08.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-06T13:17:08.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 016737cbcc7e:32777 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:08.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:08.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:08.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-06T13:17:08.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:08.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.4:44293 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:08.363+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.4:59552
[2025-05-06T13:17:08.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 180 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:08.463+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-06T13:17:08.463+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.191 s
[2025-05-06T13:17:08.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:08.465+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-06T13:17:08.466+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.202037 s
[2025-05-06T13:17:08.471+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:08,471 [INFO] Загружено 4652 транзакций
[2025-05-06T13:17:08.471+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:08,471 [INFO] Схема данных транзакций:
[2025-05-06T13:17:08.475+0000] {spark_submit.py:571} INFO - root
[2025-05-06T13:17:08.475+0000] {spark_submit.py:571} INFO - |-- transaction_id: string (nullable = true)
[2025-05-06T13:17:08.475+0000] {spark_submit.py:571} INFO - |-- client_id: string (nullable = true)
[2025-05-06T13:17:08.475+0000] {spark_submit.py:571} INFO - |-- datetime: timestamp (nullable = true)
[2025-05-06T13:17:08.475+0000] {spark_submit.py:571} INFO - |-- amount: double (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- currency: string (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- merchant: string (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- transaction_type: string (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- category: string (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- country_code: string (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- region: string (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- device_type: string (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- session_id: string (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- channel: string (nullable = true)
[2025-05-06T13:17:08.476+0000] {spark_submit.py:571} INFO - |-- transaction_purpose: string (nullable = true)
[2025-05-06T13:17:08.477+0000] {spark_submit.py:571} INFO - |-- ip_network: string (nullable = true)
[2025-05-06T13:17:08.477+0000] {spark_submit.py:571} INFO - |-- recipient_id_hash: string (nullable = true)
[2025-05-06T13:17:08.477+0000] {spark_submit.py:571} INFO - 
[2025-05-06T13:17:08.486+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:08,486 [INFO] Создаем вершины графа
[2025-05-06T13:17:08.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:08.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:08.533+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 016737cbcc7e:32777 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:08.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.4:44293 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:08.579+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:08.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO CodeGenerator: Code generated in 27.47592 ms
[2025-05-06T13:17:08.630+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Registering RDD 8 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-05-06T13:17:08.630+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:08.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:08.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:08.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:08.632+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:08.636+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 19.7 KiB, free 434.4 MiB)
[2025-05-06T13:17:08.637+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 434.4 MiB)
[2025-05-06T13:17:08.637+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 016737cbcc7e:32777 (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T13:17:08.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:08.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:08.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-05-06T13:17:08.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:08.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.4:44293 (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T13:17:08.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 312 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:08.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-06T13:17:08.952+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.320 s
[2025-05-06T13:17:08.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:08.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:08.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:08.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:08.965+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:08.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:09.006+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO CodeGenerator: Code generated in 18.185347 ms
[2025-05-06T13:17:09.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Registering RDD 11 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-05-06T13:17:09.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:09.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:09.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-06T13:17:09.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:09.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:09.033+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 33.9 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 016737cbcc7e:32777 (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:09.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:09.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-06T13:17:09.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:09.052+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.4:44293 (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.085+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.4:59552
[2025-05-06T13:17:09.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 81 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:09.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-06T13:17:09.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.091 s
[2025-05-06T13:17:09.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:09.122+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:09.122+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:09.122+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:09.145+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO CodeGenerator: Code generated in 9.771791 ms
[2025-05-06T13:17:09.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T13:17:09.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:09.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:09.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-06T13:17:09.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:09.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:09.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.175+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 016737cbcc7e:32777 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:09.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:09.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-06T13:17:09.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:09.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.4:44293 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.4:59552
[2025-05-06T13:17:09.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 56 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:09.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-06T13:17:09.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.069 s
[2025-05-06T13:17:09.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:09.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-06T13:17:09.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.079093 s
[2025-05-06T13:17:09.242+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:09,242 [INFO] Создано 1139 вершин
[2025-05-06T13:17:09.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2025-05-06T13:17:09.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:09.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:09.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:09.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:09.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:09.387+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.0 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.388+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.388+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 016737cbcc7e:32777 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:09.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:09.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-05-06T13:17:09.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:09.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.4:44293 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 33 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:09.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-05-06T13:17:09.424+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.039 s
[2025-05-06T13:17:09.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:09.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:09.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:09.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:09.446+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T13:17:09.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:09.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:09.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-05-06T13:17:09.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:09.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:09.450+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.459+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 016737cbcc7e:32777 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:09.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:09.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-05-06T13:17:09.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 016737cbcc7e:32777 in memory (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 6) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:09.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.4:44293 in memory (size: 15.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 016737cbcc7e:32777 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.496+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.4:44293 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.497+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.4:44293 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.506+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.4:59552
[2025-05-06T13:17:09.510+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 016737cbcc7e:32777 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.4:44293 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.520+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 6) in 57 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:09.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-05-06T13:17:09.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 016737cbcc7e:32777 in memory (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.522+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.073 s
[2025-05-06T13:17:09.522+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:09.523+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2025-05-06T13:17:09.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.076999 s
[2025-05-06T13:17:09.526+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:09,525 [INFO] Найдено 1774 P2P транзакций (transaction_type='p2p')
[2025-05-06T13:17:09.527+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:09,525 [INFO] Найден столбец recipient_id_hash для P2P транзакций
[2025-05-06T13:17:09.527+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:09,525 [INFO] Создаем ребра на основе P2P транзакций
[2025-05-06T13:17:09.528+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.4:44293 in memory (size: 9.6 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2025-05-06T13:17:09.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:09.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:09.640+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:09.640+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:09.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:09.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.0 KiB, free 434.4 MiB)
[2025-05-06T13:17:09.648+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 434.4 MiB)
[2025-05-06T13:17:09.648+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 016737cbcc7e:32777 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.649+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:09.650+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:09.650+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-05-06T13:17:09.651+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 7) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:09.664+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.4:44293 (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.687+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 7) in 36 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:09.687+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-05-06T13:17:09.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.045 s
[2025-05-06T13:17:09.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:09.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:09.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:09.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:09.706+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T13:17:09.707+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:09.708+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:09.708+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2025-05-06T13:17:09.708+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:09.708+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:09.710+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-06T13:17:09.711+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.712+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 016737cbcc7e:32777 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.712+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:09.712+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:09.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-05-06T13:17:09.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 8) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:09.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.4:44293 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.730+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.4:59552
[2025-05-06T13:17:09.740+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 8) in 26 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:09.740+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-05-06T13:17:09.741+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s
[2025-05-06T13:17:09.741+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:09.741+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2025-05-06T13:17:09.741+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.034805 s
[2025-05-06T13:17:09.743+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:09,742 [INFO] Создано 1774 P2P ребер
[2025-05-06T13:17:09.743+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:09,743 [INFO] Создаем ребра на основе общих мерчантов
[2025-05-06T13:17:09.957+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO CodeGenerator: Code generated in 7.730998 ms
[2025-05-06T13:17:09.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2025-05-06T13:17:09.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Got map stage job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:09.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:09.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:09.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:09.963+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:09.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.8 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.981+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.3 MiB)
[2025-05-06T13:17:09.982+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.982+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:09.983+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:09.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-05-06T13:17:09.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 016737cbcc7e:32777 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:09.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 9) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:09.989+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:09 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.4:44293 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 016737cbcc7e:32777 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.024+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.4:44293 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 016737cbcc7e:32777 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.4:44293 in memory (size: 6.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 9) in 83 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:10.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-06T13:17:10.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.106 s
[2025-05-06T13:17:10.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:10.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:10.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:10.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:10.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:10.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:10.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Got job 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:10.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Final stage: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:10.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
[2025-05-06T13:17:10.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:10.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[32] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:10.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-06T13:17:10.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-06T13:17:10.116+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:10.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[32] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:10.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2025-05-06T13:17:10.118+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 10) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:10.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.4:59552
[2025-05-06T13:17:10.149+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 10) in 31 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:10.149+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2025-05-06T13:17:10.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.037 s
[2025-05-06T13:17:10.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:10.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2025-05-06T13:17:10.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Job 10 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.041210 s
[2025-05-06T13:17:10.171+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO CodeGenerator: Code generated in 7.039728 ms
[2025-05-06T13:17:10.189+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T13:17:10.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 432.3 MiB)
[2025-05-06T13:17:10.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 016737cbcc7e:32777 (size: 23.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:10.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:10.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO CodeGenerator: Code generated in 14.289303 ms
[2025-05-06T13:17:10.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Registering RDD 35 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2025-05-06T13:17:10.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Got map stage job 11 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:10.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:10.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
[2025-05-06T13:17:10.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:10.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:10.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 14.8 KiB, free 432.3 MiB)
[2025-05-06T13:17:10.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 432.3 MiB)
[2025-05-06T13:17:10.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 016737cbcc7e:32777 (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:10.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[35] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:10.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
[2025-05-06T13:17:10.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 11) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:10.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.4:44293 (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.4:44293 (size: 23.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 11) in 99 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:10.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-05-06T13:17:10.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0) finished in 0.106 s
[2025-05-06T13:17:10.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:10.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:10.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:10.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:10.395+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO CodeGenerator: Code generated in 5.801135 ms
[2025-05-06T13:17:10.406+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T13:17:10.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Got job 12 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:10.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Final stage: ResultStage 22 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:10.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2025-05-06T13:17:10.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:10.408+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:10.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 11.0 KiB, free 432.3 MiB)
[2025-05-06T13:17:10.412+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 432.3 MiB)
[2025-05-06T13:17:10.412+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 016737cbcc7e:32777 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.412+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:10.413+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[38] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:10.413+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-05-06T13:17:10.414+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 12) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:10.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.4:44293 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.429+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.18.0.4:59552
[2025-05-06T13:17:10.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 016737cbcc7e:32777 in memory (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.4:44293 in memory (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.479+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 12) in 65 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:10.480+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-05-06T13:17:10.480+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: ResultStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0.072 s
[2025-05-06T13:17:10.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:10.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
[2025-05-06T13:17:10.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Job 12 finished: count at NativeMethodAccessorImpl.java:0, took 0.074884 s
[2025-05-06T13:17:10.482+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:10,482 [INFO] Создано 270444 ребер по общим мерчантам
[2025-05-06T13:17:10.483+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:10,483 [INFO] Создаем ребра на основе общих IP-адресов
[2025-05-06T13:17:10.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Registering RDD 42 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2025-05-06T13:17:10.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Got map stage job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:10.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Final stage: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:10.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:10.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:10.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[42] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:10.575+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 12.8 KiB, free 432.3 MiB)
[2025-05-06T13:17:10.576+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.3 MiB)
[2025-05-06T13:17:10.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:10.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[42] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:10.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
[2025-05-06T13:17:10.580+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 13) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:10.589+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.625+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 13) in 47 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:10.626+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool
[2025-05-06T13:17:10.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0) finished in 0.055 s
[2025-05-06T13:17:10.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:10.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:10.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:10.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:10.634+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:10.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:10.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:10.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Final stage: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:10.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
[2025-05-06T13:17:10.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:10.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[44] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:10.656+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.2 KiB, free 432.3 MiB)
[2025-05-06T13:17:10.657+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.3 MiB)
[2025-05-06T13:17:10.658+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.659+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:10.659+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[44] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:10.659+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-05-06T13:17:10.660+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 14) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:10.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.676+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.4:59552
[2025-05-06T13:17:10.686+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 14) in 26 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:10.686+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-05-06T13:17:10.687+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.031 s
[2025-05-06T13:17:10.687+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:10.687+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
[2025-05-06T13:17:10.687+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.034210 s
[2025-05-06T13:17:10.708+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 016737cbcc7e:32777 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.711+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T13:17:10.711+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.4:44293 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.718+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 430.1 MiB)
[2025-05-06T13:17:10.718+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 016737cbcc7e:32777 (size: 58.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.720+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.721+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Created broadcast 16 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:10.721+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.727+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:10.729+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 016737cbcc7e:32777 in memory (size: 23.7 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.4:44293 in memory (size: 23.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.751+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.752+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.756+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Registering RDD 47 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2025-05-06T13:17:10.756+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Got map stage job 15 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:10.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:10.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2025-05-06T13:17:10.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:10.759+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:10.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 14.8 KiB, free 432.2 MiB)
[2025-05-06T13:17:10.765+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 432.2 MiB)
[2025-05-06T13:17:10.765+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 016737cbcc7e:32777 (size: 7.3 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:10.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:10.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2025-05-06T13:17:10.767+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 15) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:10.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.4:44293 (size: 7.3 KiB, free: 434.4 MiB)
[2025-05-06T13:17:10.786+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.4:44293 (size: 58.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.850+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 15) in 82 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:10.850+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-05-06T13:17:10.851+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0.091 s
[2025-05-06T13:17:10.851+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:10.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:10.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:10.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:10.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T13:17:10.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Got job 16 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:10.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:10.867+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
[2025-05-06T13:17:10.867+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:10.867+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:10.869+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 11.0 KiB, free 432.2 MiB)
[2025-05-06T13:17:10.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 432.2 MiB)
[2025-05-06T13:17:10.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 016737cbcc7e:32777 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:10.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:10.878+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 016737cbcc7e:32777 in memory (size: 7.3 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.878+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
[2025-05-06T13:17:10.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 16) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:10.882+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.4:44293 in memory (size: 7.3 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.4:44293 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T13:17:10.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.18.0.4:59552
[2025-05-06T13:17:10.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 16) in 29 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:10.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2025-05-06T13:17:10.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0.040 s
[2025-05-06T13:17:10.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:10.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
[2025-05-06T13:17:10.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:10 INFO DAGScheduler: Job 16 finished: count at NativeMethodAccessorImpl.java:0, took 0.043346 s
[2025-05-06T13:17:10.911+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:10,910 [INFO] Создано 1069538 ребер по общим IP-адресам
[2025-05-06T13:17:11.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Registering RDD 57 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2025-05-06T13:17:11.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Got map stage job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:11.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:11.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:11.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:11.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:11.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 12.8 KiB, free 432.2 MiB)
[2025-05-06T13:17:11.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.2 MiB)
[2025-05-06T13:17:11.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:11.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:11.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:11.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
[2025-05-06T13:17:11.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 17) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO CodeGenerator: Code generated in 7.870957 ms
[2025-05-06T13:17:11.073+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Registering RDD 59 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2025-05-06T13:17:11.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Got map stage job 18 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:11.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:11.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:11.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:11.076+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:11.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 12.8 KiB, free 432.2 MiB)
[2025-05-06T13:17:11.086+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.2 MiB)
[2025-05-06T13:17:11.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:11.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:11.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:11.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-05-06T13:17:11.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 016737cbcc7e:32777 in memory (size: 58.0 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:11.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.4:44293 in memory (size: 58.0 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 016737cbcc7e:32777 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.4:44293 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 18) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 17) in 84 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:11.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-05-06T13:17:11.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0.092 s
[2025-05-06T13:17:11.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:11.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: running: Set(ShuffleMapStage 32)
[2025-05-06T13:17:11.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:11.158+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:11.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:11.200+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:11.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Got job 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:11.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Final stage: ResultStage 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:11.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
[2025-05-06T13:17:11.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:11.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[62] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:11.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-06T13:17:11.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-06T13:17:11.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:11.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[62] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:11.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
[2025-05-06T13:17:11.227+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 19) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.228+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 18) in 79 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:11.228+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-05-06T13:17:11.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0) finished in 0.154 s
[2025-05-06T13:17:11.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:11.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: running: Set(ResultStage 34)
[2025-05-06T13:17:11.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:11.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:11.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:11.246+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.18.0.4:59552
[2025-05-06T13:17:11.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:11.261+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Got job 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:11.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Final stage: ResultStage 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:11.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-05-06T13:17:11.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:11.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:11.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.2 KiB, free 434.3 MiB)
[2025-05-06T13:17:11.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.3 MiB)
[2025-05-06T13:17:11.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 19) in 54 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:11.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool
[2025-05-06T13:17:11.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:11.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:11.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-05-06T13:17:11.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: ResultStage 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.080 s
[2025-05-06T13:17:11.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 20) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:11.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
[2025-05-06T13:17:11.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Job 19 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.088505 s
[2025-05-06T13:17:11.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T13:17:11.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 432.3 MiB)
[2025-05-06T13:17:11.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 016737cbcc7e:32777 (size: 23.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO SparkContext: Created broadcast 23 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:11.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.18.0.4:59552
[2025-05-06T13:17:11.343+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 20) in 56 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:11.343+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-05-06T13:17:11.343+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: ResultStage 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.081 s
[2025-05-06T13:17:11.344+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:11.344+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-05-06T13:17:11.344+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Job 20 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.084251 s
[2025-05-06T13:17:11.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T13:17:11.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.363+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 430.1 MiB)
[2025-05-06T13:17:11.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 016737cbcc7e:32777 (size: 58.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:11.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO SparkContext: Created broadcast 24 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:11.370+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:11.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.394+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:11.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO CodeGenerator: Code generated in 14.067964 ms
[2025-05-06T13:17:11.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO CodeGenerator: Code generated in 6.223669 ms
[2025-05-06T13:17:11.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO CodeGenerator: Code generated in 10.190267 ms
[2025-05-06T13:17:11.452+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO CodeGenerator: Code generated in 9.067827 ms
[2025-05-06T13:17:11.482+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Registering RDD 76 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 11
[2025-05-06T13:17:11.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Got map stage job 21 (count at NativeMethodAccessorImpl.java:0) with 21 output partitions
[2025-05-06T13:17:11.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:11.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37, ShuffleMapStage 38)
[2025-05-06T13:17:11.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:11.483+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[76] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:11.489+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 52.5 KiB, free 430.1 MiB)
[2025-05-06T13:17:11.490+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 430.1 MiB)
[2025-05-06T13:17:11.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 016737cbcc7e:32777 (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:11.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:11.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO DAGScheduler: Submitting 21 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[76] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-06T13:17:11.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSchedulerImpl: Adding task set 39.0 with 21 tasks resource profile 0
[2025-05-06T13:17:11.494+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 21) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.511+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.4:44293 (size: 21.6 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.18.0.4:59552
[2025-05-06T13:17:11.576+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.4:44293 (size: 23.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:11.637+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 22) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.637+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 21) in 144 ms on 172.18.0.4 (executor 0) (1/21)
[2025-05-06T13:17:11.681+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 23) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.681+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 22) in 45 ms on 172.18.0.4 (executor 0) (2/21)
[2025-05-06T13:17:11.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 4.0 in stage 39.0 (TID 24) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 23) in 51 ms on 172.18.0.4 (executor 0) (3/21)
[2025-05-06T13:17:11.748+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 5.0 in stage 39.0 (TID 25) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.748+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 4.0 in stage 39.0 (TID 24) in 18 ms on 172.18.0.4 (executor 0) (4/21)
[2025-05-06T13:17:11.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 6.0 in stage 39.0 (TID 26) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 5.0 in stage 39.0 (TID 25) in 16 ms on 172.18.0.4 (executor 0) (5/21)
[2025-05-06T13:17:11.785+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 7.0 in stage 39.0 (TID 27) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.785+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 6.0 in stage 39.0 (TID 26) in 22 ms on 172.18.0.4 (executor 0) (6/21)
[2025-05-06T13:17:11.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 8.0 in stage 39.0 (TID 28) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 7.0 in stage 39.0 (TID 27) in 106 ms on 172.18.0.4 (executor 0) (7/21)
[2025-05-06T13:17:11.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Starting task 9.0 in stage 39.0 (TID 29) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:11.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:11 INFO TaskSetManager: Finished task 8.0 in stage 39.0 (TID 28) in 72 ms on 172.18.0.4 (executor 0) (8/21)
[2025-05-06T13:17:12.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 10.0 in stage 39.0 (TID 30) (172.18.0.4, executor 0, partition 10, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 9.0 in stage 39.0 (TID 29) in 74 ms on 172.18.0.4 (executor 0) (9/21)
[2025-05-06T13:17:12.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 11.0 in stage 39.0 (TID 31) (172.18.0.4, executor 0, partition 11, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 10.0 in stage 39.0 (TID 30) in 95 ms on 172.18.0.4 (executor 0) (10/21)
[2025-05-06T13:17:12.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.4:44293 (size: 58.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:12.228+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 12.0 in stage 39.0 (TID 32) (172.18.0.4, executor 0, partition 12, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 11.0 in stage 39.0 (TID 31) in 100 ms on 172.18.0.4 (executor 0) (11/21)
[2025-05-06T13:17:12.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 13.0 in stage 39.0 (TID 33) (172.18.0.4, executor 0, partition 13, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.259+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 12.0 in stage 39.0 (TID 32) in 31 ms on 172.18.0.4 (executor 0) (12/21)
[2025-05-06T13:17:12.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 14.0 in stage 39.0 (TID 34) (172.18.0.4, executor 0, partition 14, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 13.0 in stage 39.0 (TID 33) in 27 ms on 172.18.0.4 (executor 0) (13/21)
[2025-05-06T13:17:12.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 15.0 in stage 39.0 (TID 35) (172.18.0.4, executor 0, partition 15, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 14.0 in stage 39.0 (TID 34) in 30 ms on 172.18.0.4 (executor 0) (14/21)
[2025-05-06T13:17:12.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 16.0 in stage 39.0 (TID 36) (172.18.0.4, executor 0, partition 16, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.346+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 15.0 in stage 39.0 (TID 35) in 32 ms on 172.18.0.4 (executor 0) (15/21)
[2025-05-06T13:17:12.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 17.0 in stage 39.0 (TID 37) (172.18.0.4, executor 0, partition 17, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 16.0 in stage 39.0 (TID 36) in 20 ms on 172.18.0.4 (executor 0) (16/21)
[2025-05-06T13:17:12.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 18.0 in stage 39.0 (TID 38) (172.18.0.4, executor 0, partition 18, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 17.0 in stage 39.0 (TID 37) in 21 ms on 172.18.0.4 (executor 0) (17/21)
[2025-05-06T13:17:12.646+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 19.0 in stage 39.0 (TID 39) (172.18.0.4, executor 0, partition 19, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.646+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 18.0 in stage 39.0 (TID 38) in 262 ms on 172.18.0.4 (executor 0) (18/21)
[2025-05-06T13:17:12.663+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 20.0 in stage 39.0 (TID 40) (172.18.0.4, executor 0, partition 20, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.664+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 19.0 in stage 39.0 (TID 39) in 19 ms on 172.18.0.4 (executor 0) (19/21)
[2025-05-06T13:17:12.911+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:12.911+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:12 INFO TaskSetManager: Finished task 20.0 in stage 39.0 (TID 40) in 248 ms on 172.18.0.4 (executor 0) (20/21)
[2025-05-06T13:17:13.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 346 ms on 172.18.0.4 (executor 0) (21/21)
[2025-05-06T13:17:13.257+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-05-06T13:17:13.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 1.772 s
[2025-05-06T13:17:13.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:13.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:13.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:13.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:13.261+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 2501973, minimum partition size: 1048576
[2025-05-06T13:17:13.267+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:13.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO CodeGenerator: Code generated in 12.034059 ms
[2025-05-06T13:17:13.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Registering RDD 79 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 12
[2025-05-06T13:17:13.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-05-06T13:17:13.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:13.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
[2025-05-06T13:17:13.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:13.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:13.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 49.4 KiB, free 430.0 MiB)
[2025-05-06T13:17:13.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 430.0 MiB)
[2025-05-06T13:17:13.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 016737cbcc7e:32777 (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T13:17:13.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 016737cbcc7e:32777 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:13.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:13.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-06T13:17:13.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks resource profile 0
[2025-05-06T13:17:13.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 42) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:13.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.18.0.4:44293 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:13.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.4:44293 (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T13:17:13.329+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.18.0.4:59552
[2025-05-06T13:17:13.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 43) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:13.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 42) in 209 ms on 172.18.0.4 (executor 0) (1/2)
[2025-05-06T13:17:13.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 43) in 127 ms on 172.18.0.4 (executor 0) (2/2)
[2025-05-06T13:17:13.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-05-06T13:17:13.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0) finished in 0.351 s
[2025-05-06T13:17:13.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:13.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:13.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:13.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:13.661+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO CodeGenerator: Code generated in 8.450632 ms
[2025-05-06T13:17:13.667+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-06T13:17:13.668+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:17:13.668+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Final stage: ResultStage 48 (count at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:17:13.669+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-05-06T13:17:13.669+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:13.669+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:17:13.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 11.0 KiB, free 430.1 MiB)
[2025-05-06T13:17:13.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 430.0 MiB)
[2025-05-06T13:17:13.680+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 016737cbcc7e:32777 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T13:17:13.681+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:13.681+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:13.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-05-06T13:17:13.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 016737cbcc7e:32777 in memory (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T13:17:13.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 44) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:13.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.4:44293 in memory (size: 22.3 KiB, free: 434.3 MiB)
[2025-05-06T13:17:13.697+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.18.0.4:44293 (size: 5.5 KiB, free: 434.3 MiB)
[2025-05-06T13:17:13.703+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.18.0.4:59552
[2025-05-06T13:17:13.727+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 44) in 45 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:13.728+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-05-06T13:17:13.728+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: ResultStage 48 (count at NativeMethodAccessorImpl.java:0) finished in 0.058 s
[2025-05-06T13:17:13.728+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:13.728+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-05-06T13:17:13.729+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0.061472 s
[2025-05-06T13:17:13.730+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:13,730 [INFO] Всего создано 410196 уникальных ребер
[2025-05-06T13:17:13.731+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:13,730 [INFO] Создаем граф
[2025-05-06T13:17:13.754+0000] {spark_submit.py:571} INFO - 2025-05-06 13:17:13,754 [INFO] Запускаем алгоритм обнаружения сообществ
[2025-05-06T13:17:13.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:13.965+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Registering RDD 86 (rdd at GraphFrame.scala:187) as input to shuffle 13
[2025-05-06T13:17:13.965+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Got map stage job 24 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-06T13:17:13.965+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Final stage: ShuffleMapStage 49 (rdd at GraphFrame.scala:187)
[2025-05-06T13:17:13.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:13.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:13.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[86] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-06T13:17:13.968+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 19.9 KiB, free 430.1 MiB)
[2025-05-06T13:17:13.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 432.2 MiB)
[2025-05-06T13:17:13.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 016737cbcc7e:32777 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T13:17:13.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:13.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[86] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:13.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
[2025-05-06T13:17:13.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 016737cbcc7e:32777 in memory (size: 58.0 KiB, free: 434.4 MiB)
[2025-05-06T13:17:13.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 45) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:13.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.4:44293 in memory (size: 58.0 KiB, free: 434.4 MiB)
[2025-05-06T13:17:13.990+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 016737cbcc7e:32777 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:13.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.18.0.4:44293 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-06T13:17:13.997+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:13 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.4:44293 (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.016+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 016737cbcc7e:32777 in memory (size: 23.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.019+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.4:44293 in memory (size: 23.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 45) in 56 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:14.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool
[2025-05-06T13:17:14.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: ShuffleMapStage 49 (rdd at GraphFrame.scala:187) finished in 0.069 s
[2025-05-06T13:17:14.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:14.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:14.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:14.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:14.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:14.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:14.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO CodeGenerator: Code generated in 11.512298 ms
[2025-05-06T13:17:14.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:14.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Got job 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:14.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Final stage: ResultStage 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:14.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
[2025-05-06T13:17:14.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:14.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[89] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:14.078+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 32.6 KiB, free 434.3 MiB)
[2025-05-06T13:17:14.085+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 434.3 MiB)
[2025-05-06T13:17:14.086+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 016737cbcc7e:32777 (size: 15.3 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.086+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 016737cbcc7e:32777 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.086+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:14.086+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[89] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:14.086+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
[2025-05-06T13:17:14.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 46) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.18.0.4:44293 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.4:44293 (size: 15.3 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.103+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.18.0.4:59552
[2025-05-06T13:17:14.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 46) in 42 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:14.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool
[2025-05-06T13:17:14.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: ResultStage 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.054 s
[2025-05-06T13:17:14.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:14.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
[2025-05-06T13:17:14.132+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Job 25 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.056398 s
[2025-05-06T13:17:14.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO CodeGenerator: Code generated in 6.773144 ms
[2025-05-06T13:17:14.145+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-06T13:17:14.146+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 432.3 MiB)
[2025-05-06T13:17:14.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 016737cbcc7e:32777 (size: 27.1 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Created broadcast 30 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:14.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO CodeGenerator: Code generated in 7.970356 ms
[2025-05-06T13:17:14.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:14.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:14.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:14.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO CodeGenerator: Code generated in 18.901071 ms
[2025-05-06T13:17:14.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:14.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#305 - id.nullCount#304) > 0)
[2025-05-06T13:17:14.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Registering RDD 110 (collect at GraphFrame.scala:574) as input to shuffle 15
[2025-05-06T13:17:14.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Got map stage job 26 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-06T13:17:14.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Final stage: ShuffleMapStage 52 (collect at GraphFrame.scala:574)
[2025-05-06T13:17:14.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:14.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:14.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[110] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T13:17:14.413+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 12.8 KiB, free 432.3 MiB)
[2025-05-06T13:17:14.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.2 MiB)
[2025-05-06T13:17:14.422+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:14.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 016737cbcc7e:32777 in memory (size: 15.3 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[110] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:14.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
[2025-05-06T13:17:14.424+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Registering RDD 112 (collect at GraphFrame.scala:574) as input to shuffle 16
[2025-05-06T13:17:14.424+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Got map stage job 27 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-06T13:17:14.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Final stage: ShuffleMapStage 53 (collect at GraphFrame.scala:574)
[2025-05-06T13:17:14.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.18.0.4:44293 in memory (size: 15.3 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 47) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:14.427+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:14.432+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T13:17:14.435+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 12.8 KiB, free 432.3 MiB)
[2025-05-06T13:17:14.435+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 432.3 MiB)
[2025-05-06T13:17:14.435+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.436+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:14.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:14.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-05-06T13:17:14.440+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.465+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 48) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.466+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 47) in 41 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:14.466+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool
[2025-05-06T13:17:14.467+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: ShuffleMapStage 52 (collect at GraphFrame.scala:574) finished in 0.054 s
[2025-05-06T13:17:14.467+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:14.467+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: running: Set(ShuffleMapStage 53)
[2025-05-06T13:17:14.468+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:14.468+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:14.478+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.485+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:14.511+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:14.511+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:14.511+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:14.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
[2025-05-06T13:17:14.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:14.512+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[115] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:14.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.2 KiB, free 432.3 MiB)
[2025-05-06T13:17:14.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.3 MiB)
[2025-05-06T13:17:14.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 48) in 61 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:14.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-05-06T13:17:14.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:14.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[115] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:14.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-05-06T13:17:14.528+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.529+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 49) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.529+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: ShuffleMapStage 53 (collect at GraphFrame.scala:574) finished in 0.099 s
[2025-05-06T13:17:14.530+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:14.530+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: running: Set(ResultStage 55)
[2025-05-06T13:17:14.530+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:14.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:14.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.542+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.543+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:14.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.4:59552
[2025-05-06T13:17:14.574+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 49) in 46 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:14.575+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-05-06T13:17:14.576+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.061 s
[2025-05-06T13:17:14.576+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:14.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-05-06T13:17:14.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.065531 s
[2025-05-06T13:17:14.580+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:14.580+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:14.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Final stage: ResultStage 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:14.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-05-06T13:17:14.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:14.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[118] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:14.584+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.2 KiB, free 430.2 MiB)
[2025-05-06T13:17:14.585+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T13:17:14.586+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 430.2 MiB)
[2025-05-06T13:17:14.587+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 430.2 MiB)
[2025-05-06T13:17:14.587+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.587+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 016737cbcc7e:32777 (size: 23.7 KiB, free: 434.3 MiB)
[2025-05-06T13:17:14.587+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:14.588+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[118] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:14.588+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-05-06T13:17:14.588+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:14.589+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 50) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.602+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.606+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.18.0.4:59552
[2025-05-06T13:17:14.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:14.626+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.630+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 50) in 41 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:14.630+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-05-06T13:17:14.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: ResultStage 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.047 s
[2025-05-06T13:17:14.632+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:14.632+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-05-06T13:17:14.632+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.052606 s
[2025-05-06T13:17:14.633+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:14.633+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 2.1 MiB, free 428.1 MiB)
[2025-05-06T13:17:14.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 428.0 MiB)
[2025-05-06T13:17:14.646+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 016737cbcc7e:32777 (size: 58.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:14.656+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Created broadcast 36 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:14.673+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:14.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Registering RDD 128 (collect at GraphFrame.scala:574) as input to shuffle 17
[2025-05-06T13:17:14.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Got map stage job 30 (collect at GraphFrame.scala:574) with 21 output partitions
[2025-05-06T13:17:14.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (collect at GraphFrame.scala:574)
[2025-05-06T13:17:14.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58, ShuffleMapStage 59)
[2025-05-06T13:17:14.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:14.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[128] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T13:17:14.697+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 52.5 KiB, free 428.0 MiB)
[2025-05-06T13:17:14.704+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 428.0 MiB)
[2025-05-06T13:17:14.705+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 016737cbcc7e:32777 (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:14.705+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:14.705+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO DAGScheduler: Submitting 21 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[128] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-06T13:17:14.706+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSchedulerImpl: Adding task set 60.0 with 21 tasks resource profile 0
[2025-05-06T13:17:14.707+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:14.708+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 51) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.720+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.18.0.4:44293 (size: 21.6 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.724+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.4:59552
[2025-05-06T13:17:14.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.4:44293 (size: 23.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:14.759+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 52) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.759+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 51) in 52 ms on 172.18.0.4 (executor 0) (1/21)
[2025-05-06T13:17:14.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 53) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 52) in 34 ms on 172.18.0.4 (executor 0) (2/21)
[2025-05-06T13:17:14.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 54) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 53) in 36 ms on 172.18.0.4 (executor 0) (3/21)
[2025-05-06T13:17:14.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 5.0 in stage 60.0 (TID 55) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 54) in 16 ms on 172.18.0.4 (executor 0) (4/21)
[2025-05-06T13:17:14.855+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 6.0 in stage 60.0 (TID 56) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.856+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 5.0 in stage 60.0 (TID 55) in 14 ms on 172.18.0.4 (executor 0) (5/21)
[2025-05-06T13:17:14.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 7.0 in stage 60.0 (TID 57) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 6.0 in stage 60.0 (TID 56) in 16 ms on 172.18.0.4 (executor 0) (6/21)
[2025-05-06T13:17:14.919+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 8.0 in stage 60.0 (TID 58) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.920+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 7.0 in stage 60.0 (TID 57) in 49 ms on 172.18.0.4 (executor 0) (7/21)
[2025-05-06T13:17:14.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 9.0 in stage 60.0 (TID 59) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 8.0 in stage 60.0 (TID 58) in 24 ms on 172.18.0.4 (executor 0) (8/21)
[2025-05-06T13:17:14.991+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Starting task 10.0 in stage 60.0 (TID 60) (172.18.0.4, executor 0, partition 10, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:14.991+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:14 INFO TaskSetManager: Finished task 9.0 in stage 60.0 (TID 59) in 49 ms on 172.18.0.4 (executor 0) (9/21)
[2025-05-06T13:17:15.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 11.0 in stage 60.0 (TID 61) (172.18.0.4, executor 0, partition 11, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 10.0 in stage 60.0 (TID 60) in 50 ms on 172.18.0.4 (executor 0) (10/21)
[2025-05-06T13:17:15.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.4:44293 (size: 58.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:15.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 12.0 in stage 60.0 (TID 62) (172.18.0.4, executor 0, partition 12, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 11.0 in stage 60.0 (TID 61) in 48 ms on 172.18.0.4 (executor 0) (11/21)
[2025-05-06T13:17:15.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 13.0 in stage 60.0 (TID 63) (172.18.0.4, executor 0, partition 13, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 12.0 in stage 60.0 (TID 62) in 20 ms on 172.18.0.4 (executor 0) (12/21)
[2025-05-06T13:17:15.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 14.0 in stage 60.0 (TID 64) (172.18.0.4, executor 0, partition 14, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 13.0 in stage 60.0 (TID 63) in 19 ms on 172.18.0.4 (executor 0) (13/21)
[2025-05-06T13:17:15.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 15.0 in stage 60.0 (TID 65) (172.18.0.4, executor 0, partition 15, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 14.0 in stage 60.0 (TID 64) in 15 ms on 172.18.0.4 (executor 0) (14/21)
[2025-05-06T13:17:15.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 16.0 in stage 60.0 (TID 66) (172.18.0.4, executor 0, partition 16, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 15.0 in stage 60.0 (TID 65) in 12 ms on 172.18.0.4 (executor 0) (15/21)
[2025-05-06T13:17:15.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 17.0 in stage 60.0 (TID 67) (172.18.0.4, executor 0, partition 17, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 16.0 in stage 60.0 (TID 66) in 13 ms on 172.18.0.4 (executor 0) (16/21)
[2025-05-06T13:17:15.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 18.0 in stage 60.0 (TID 68) (172.18.0.4, executor 0, partition 18, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 17.0 in stage 60.0 (TID 67) in 15 ms on 172.18.0.4 (executor 0) (17/21)
[2025-05-06T13:17:15.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 19.0 in stage 60.0 (TID 69) (172.18.0.4, executor 0, partition 19, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 18.0 in stage 60.0 (TID 68) in 166 ms on 172.18.0.4 (executor 0) (18/21)
[2025-05-06T13:17:15.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 20.0 in stage 60.0 (TID 70) (172.18.0.4, executor 0, partition 20, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 19.0 in stage 60.0 (TID 69) in 12 ms on 172.18.0.4 (executor 0) (19/21)
[2025-05-06T13:17:15.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 71) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 20.0 in stage 60.0 (TID 70) in 214 ms on 172.18.0.4 (executor 0) (20/21)
[2025-05-06T13:17:15.589+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 71) in 20 ms on 172.18.0.4 (executor 0) (21/21)
[2025-05-06T13:17:15.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-06T13:17:15.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: ShuffleMapStage 60 (collect at GraphFrame.scala:574) finished in 0.895 s
[2025-05-06T13:17:15.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:15.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:15.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:15.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:15.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 2501973, minimum partition size: 1048576
[2025-05-06T13:17:15.602+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:15.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO CodeGenerator: Code generated in 22.96961 ms
[2025-05-06T13:17:15.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: Registering RDD 131 (collect at GraphFrame.scala:574) as input to shuffle 18
[2025-05-06T13:17:15.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: Got map stage job 31 (collect at GraphFrame.scala:574) with 2 output partitions
[2025-05-06T13:17:15.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: Final stage: ShuffleMapStage 64 (collect at GraphFrame.scala:574)
[2025-05-06T13:17:15.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
[2025-05-06T13:17:15.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:15.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[131] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T13:17:15.644+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 59.5 KiB, free 427.9 MiB)
[2025-05-06T13:17:15.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 427.9 MiB)
[2025-05-06T13:17:15.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 016737cbcc7e:32777 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:15.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 016737cbcc7e:32777 (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:15.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:15.656+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[131] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-06T13:17:15.656+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks resource profile 0
[2025-05-06T13:17:15.656+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.18.0.4:44293 in memory (size: 21.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:15.657+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 72) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.665+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.18.0.4:44293 (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:15.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.18.0.4:59552
[2025-05-06T13:17:15.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 73) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:15.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:15 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 72) in 268 ms on 172.18.0.4 (executor 0) (1/2)
[2025-05-06T13:17:16.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 73) in 144 ms on 172.18.0.4 (executor 0) (2/2)
[2025-05-06T13:17:16.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-05-06T13:17:16.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: ShuffleMapStage 64 (collect at GraphFrame.scala:574) finished in 0.426 s
[2025-05-06T13:17:16.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:16.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:16.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:16.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:16.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:16.076+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:16.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO CodeGenerator: Code generated in 10.276912 ms
[2025-05-06T13:17:16.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO SparkContext: Starting job: collect at GraphFrame.scala:574
[2025-05-06T13:17:16.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Got job 32 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-06T13:17:16.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Final stage: ResultStage 69 (collect at GraphFrame.scala:574)
[2025-05-06T13:17:16.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
[2025-05-06T13:17:16.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:16.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[134] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-06T13:17:16.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 54.8 KiB, free 427.9 MiB)
[2025-05-06T13:17:16.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 427.9 MiB)
[2025-05-06T13:17:16.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 016737cbcc7e:32777 (size: 23.8 KiB, free: 434.2 MiB)
[2025-05-06T13:17:16.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:16.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[134] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:16.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
[2025-05-06T13:17:16.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.18.0.4:44293 in memory (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 74) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:16.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 016737cbcc7e:32777 in memory (size: 24.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.18.0.4:44293 (size: 23.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.18.0.4:59552
[2025-05-06T13:17:16.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 74) in 512 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:16.640+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-06T13:17:16.640+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: ResultStage 69 (collect at GraphFrame.scala:574) finished in 0.528 s
[2025-05-06T13:17:16.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:16.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
[2025-05-06T13:17:16.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Job 32 finished: collect at GraphFrame.scala:574, took 0.530967 s
[2025-05-06T13:17:16.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Registering RDD 143 (rdd at GraphFrame.scala:188) as input to shuffle 19
[2025-05-06T13:17:16.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Got map stage job 33 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-06T13:17:16.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (rdd at GraphFrame.scala:188)
[2025-05-06T13:17:16.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:16.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:16.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[143] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T13:17:16.828+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 12.8 KiB, free 428.0 MiB)
[2025-05-06T13:17:16.835+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 428.0 MiB)
[2025-05-06T13:17:16.835+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 016737cbcc7e:32777 in memory (size: 23.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:16.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[143] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:16.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
[2025-05-06T13:17:16.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:16.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Registering RDD 145 (rdd at GraphFrame.scala:188) as input to shuffle 20
[2025-05-06T13:17:16.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Got map stage job 34 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-06T13:17:16.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Final stage: ShuffleMapStage 71 (rdd at GraphFrame.scala:188)
[2025-05-06T13:17:16.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:16.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:16.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T13:17:16.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 75) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:16.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.18.0.4:44293 in memory (size: 23.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 12.8 KiB, free 428.0 MiB)
[2025-05-06T13:17:16.844+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 428.0 MiB)
[2025-05-06T13:17:16.845+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:16.847+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:16.847+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0
[2025-05-06T13:17:16.853+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO CodeGenerator: Code generated in 13.890868 ms
[2025-05-06T13:17:16.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Registering RDD 147 (rdd at GraphFrame.scala:188) as input to shuffle 21
[2025-05-06T13:17:16.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Got map stage job 35 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-06T13:17:16.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Final stage: ShuffleMapStage 72 (rdd at GraphFrame.scala:188)
[2025-05-06T13:17:16.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:17:16.861+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:16.861+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[147] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T13:17:16.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.864+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 19.9 KiB, free 428.0 MiB)
[2025-05-06T13:17:16.864+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 428.0 MiB)
[2025-05-06T13:17:16.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 016737cbcc7e:32777 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:16.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[147] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:16.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
[2025-05-06T13:17:16.894+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 76) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:16.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 75) in 56 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:16.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-05-06T13:17:16.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: ShuffleMapStage 70 (rdd at GraphFrame.scala:188) finished in 0.069 s
[2025-05-06T13:17:16.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:16.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: running: Set(ShuffleMapStage 71, ShuffleMapStage 72)
[2025-05-06T13:17:16.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:16.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:16.910+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.920+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:16.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:16.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Got job 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:16.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Final stage: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:16.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
[2025-05-06T13:17:16.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:16.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[150] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:16.935+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.2 KiB, free 428.0 MiB)
[2025-05-06T13:17:16.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 428.0 MiB)
[2025-05-06T13:17:16.945+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 77) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:16.945+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.946+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 016737cbcc7e:32777 in memory (size: 23.7 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 76) in 52 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:16.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-05-06T13:17:16.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:16.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[150] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:16.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
[2025-05-06T13:17:16.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: ShuffleMapStage 71 (rdd at GraphFrame.scala:188) finished in 0.110 s
[2025-05-06T13:17:16.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:16.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: running: Set(ResultStage 74, ShuffleMapStage 72)
[2025-05-06T13:17:16.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:16.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:16.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.18.0.4:44293 in memory (size: 23.7 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.956+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.18.0.4:44293 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.956+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:16.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.18.0.4:44293 in memory (size: 58.0 KiB, free: 434.4 MiB)
[2025-05-06T13:17:16.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 016737cbcc7e:32777 in memory (size: 58.0 KiB, free: 434.4 MiB)
[2025-05-06T13:17:16.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:16.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:16.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Got job 37 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:16.997+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Final stage: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:16.998+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
[2025-05-06T13:17:16.998+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:16.999+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[153] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:16.999+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 7.2 KiB, free 432.2 MiB)
[2025-05-06T13:17:16.999+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.2 MiB)
[2025-05-06T13:17:17.000+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:17.000+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:17.000+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[153] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:17.001+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:16 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
[2025-05-06T13:17:17.001+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 78) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.001+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 77) in 56 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:17.001+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-05-06T13:17:17.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: ShuffleMapStage 72 (rdd at GraphFrame.scala:188) finished in 0.144 s
[2025-05-06T13:17:17.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:17.003+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: running: Set(ResultStage 74, ResultStage 76)
[2025-05-06T13:17:17.003+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:17.003+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:17.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.18.0.4:59552
[2025-05-06T13:17:17.024+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.026+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:17.030+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:17:17.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 79) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.033+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 016737cbcc7e:32777 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 78) in 33 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:17.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool
[2025-05-06T13:17:17.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.100 s
[2025-05-06T13:17:17.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:17.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
[2025-05-06T13:17:17.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Job 36 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.101879 s
[2025-05-06T13:17:17.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:17:17.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.18.0.4:44293 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-06T13:17:17.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 430.2 MiB)
[2025-05-06T13:17:17.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 016737cbcc7e:32777 (size: 23.7 KiB, free: 434.3 MiB)
[2025-05-06T13:17:17.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO SparkContext: Created broadcast 45 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:17.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.051+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.18.0.4:59552
[2025-05-06T13:17:17.052+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO CodeGenerator: Code generated in 10.85355 ms
[2025-05-06T13:17:17.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 79) in 36 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:17.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-05-06T13:17:17.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.073 s
[2025-05-06T13:17:17.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:17.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
[2025-05-06T13:17:17.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Job 37 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.076346 s
[2025-05-06T13:17:17.076+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 2.1 MiB, free 428.1 MiB)
[2025-05-06T13:17:17.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:17.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Got job 38 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:17:17.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Final stage: ResultStage 78 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:17:17.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
[2025-05-06T13:17:17.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:17.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[158] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:17:17.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 428.0 MiB)
[2025-05-06T13:17:17.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 016737cbcc7e:32777 (size: 58.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:17.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO SparkContext: Created broadcast 46 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:17.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 30.8 KiB, free 428.0 MiB)
[2025-05-06T13:17:17.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 14.4 KiB, free 428.0 MiB)
[2025-05-06T13:17:17.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 016737cbcc7e:32777 (size: 14.4 KiB, free: 434.3 MiB)
[2025-05-06T13:17:17.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:17.083+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[158] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:17.083+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
[2025-05-06T13:17:17.084+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 80) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.18.0.4:59552
[2025-05-06T13:17:17.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:17.118+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-06T13:17:17.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO CodeGenerator: Code generated in 9.842365 ms
[2025-05-06T13:17:17.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 80) in 48 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:17.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-05-06T13:17:17.132+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: ResultStage 78 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.052 s
[2025-05-06T13:17:17.132+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:17:17.132+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
[2025-05-06T13:17:17.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Job 38 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.055686 s
[2025-05-06T13:17:17.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO CodeGenerator: Code generated in 10.413202 ms
[2025-05-06T13:17:17.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 2.1 MiB, free 425.9 MiB)
[2025-05-06T13:17:17.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 425.9 MiB)
[2025-05-06T13:17:17.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 016737cbcc7e:32777 (size: 19.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:17.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO SparkContext: Created broadcast 48 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:17:17.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO CodeGenerator: Code generated in 6.817332 ms
[2025-05-06T13:17:17.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Registering RDD 167 (rdd at GraphFrame.scala:188) as input to shuffle 22
[2025-05-06T13:17:17.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Got map stage job 39 (rdd at GraphFrame.scala:188) with 21 output partitions
[2025-05-06T13:17:17.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Final stage: ShuffleMapStage 81 (rdd at GraphFrame.scala:188)
[2025-05-06T13:17:17.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-06T13:17:17.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:17.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[167] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T13:17:17.185+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 49.4 KiB, free 425.9 MiB)
[2025-05-06T13:17:17.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 20.9 KiB, free 425.9 MiB)
[2025-05-06T13:17:17.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 016737cbcc7e:32777 in memory (size: 14.4 KiB, free: 434.3 MiB)
[2025-05-06T13:17:17.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 016737cbcc7e:32777 (size: 20.9 KiB, free: 434.3 MiB)
[2025-05-06T13:17:17.192+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:17.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO DAGScheduler: Submitting 21 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[167] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-06T13:17:17.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSchedulerImpl: Adding task set 81.0 with 21 tasks resource profile 0
[2025-05-06T13:17:17.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.18.0.4:44293 in memory (size: 14.4 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 81) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.18.0.4:44293 (size: 20.9 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.18.0.4:59552
[2025-05-06T13:17:17.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.18.0.4:44293 (size: 23.7 KiB, free: 434.4 MiB)
[2025-05-06T13:17:17.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 82) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 81) in 225 ms on 172.18.0.4 (executor 0) (1/21)
[2025-05-06T13:17:17.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 83) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.514+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 82) in 93 ms on 172.18.0.4 (executor 0) (2/21)
[2025-05-06T13:17:17.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 84) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 83) in 105 ms on 172.18.0.4 (executor 0) (3/21)
[2025-05-06T13:17:17.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 85) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 84) in 9 ms on 172.18.0.4 (executor 0) (4/21)
[2025-05-06T13:17:17.636+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 6.0 in stage 81.0 (TID 86) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 85) in 11 ms on 172.18.0.4 (executor 0) (5/21)
[2025-05-06T13:17:17.663+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 7.0 in stage 81.0 (TID 87) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.664+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 6.0 in stage 81.0 (TID 86) in 27 ms on 172.18.0.4 (executor 0) (6/21)
[2025-05-06T13:17:17.784+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 8.0 in stage 81.0 (TID 88) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.785+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 7.0 in stage 81.0 (TID 87) in 121 ms on 172.18.0.4 (executor 0) (7/21)
[2025-05-06T13:17:17.899+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 9.0 in stage 81.0 (TID 89) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.899+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 8.0 in stage 81.0 (TID 88) in 115 ms on 172.18.0.4 (executor 0) (8/21)
[2025-05-06T13:17:17.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Starting task 10.0 in stage 81.0 (TID 90) (172.18.0.4, executor 0, partition 10, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:17.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:17 INFO TaskSetManager: Finished task 9.0 in stage 81.0 (TID 89) in 94 ms on 172.18.0.4 (executor 0) (9/21)
[2025-05-06T13:17:18.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Starting task 11.0 in stage 81.0 (TID 91) (172.18.0.4, executor 0, partition 11, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:18.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Finished task 10.0 in stage 81.0 (TID 90) in 151 ms on 172.18.0.4 (executor 0) (10/21)
[2025-05-06T13:17:18.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.18.0.4:59552
[2025-05-06T13:17:18.159+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.18.0.4:44293 (size: 58.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:18.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Starting task 12.0 in stage 81.0 (TID 92) (172.18.0.4, executor 0, partition 12, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:18.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Finished task 11.0 in stage 81.0 (TID 91) in 106 ms on 172.18.0.4 (executor 0) (11/21)
[2025-05-06T13:17:18.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Starting task 13.0 in stage 81.0 (TID 93) (172.18.0.4, executor 0, partition 13, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:18.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Finished task 12.0 in stage 81.0 (TID 92) in 28 ms on 172.18.0.4 (executor 0) (12/21)
[2025-05-06T13:17:18.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Starting task 14.0 in stage 81.0 (TID 94) (172.18.0.4, executor 0, partition 14, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:18.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Finished task 13.0 in stage 81.0 (TID 93) in 23 ms on 172.18.0.4 (executor 0) (13/21)
[2025-05-06T13:17:18.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Starting task 15.0 in stage 81.0 (TID 95) (172.18.0.4, executor 0, partition 15, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:18.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Finished task 14.0 in stage 81.0 (TID 94) in 19 ms on 172.18.0.4 (executor 0) (14/21)
[2025-05-06T13:17:18.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Starting task 16.0 in stage 81.0 (TID 96) (172.18.0.4, executor 0, partition 16, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:18.346+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Finished task 15.0 in stage 81.0 (TID 95) in 30 ms on 172.18.0.4 (executor 0) (15/21)
[2025-05-06T13:17:18.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Starting task 17.0 in stage 81.0 (TID 97) (172.18.0.4, executor 0, partition 17, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:18.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Finished task 16.0 in stage 81.0 (TID 96) in 17 ms on 172.18.0.4 (executor 0) (16/21)
[2025-05-06T13:17:18.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Starting task 18.0 in stage 81.0 (TID 98) (172.18.0.4, executor 0, partition 18, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:18.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Finished task 17.0 in stage 81.0 (TID 97) in 24 ms on 172.18.0.4 (executor 0) (17/21)
[2025-05-06T13:17:18.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Starting task 19.0 in stage 81.0 (TID 99) (172.18.0.4, executor 0, partition 19, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:18.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:18 INFO TaskSetManager: Finished task 18.0 in stage 81.0 (TID 98) in 608 ms on 172.18.0.4 (executor 0) (18/21)
[2025-05-06T13:17:19.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO TaskSetManager: Starting task 20.0 in stage 81.0 (TID 100) (172.18.0.4, executor 0, partition 20, NODE_LOCAL, 4574 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:19.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO TaskSetManager: Finished task 19.0 in stage 81.0 (TID 99) in 22 ms on 172.18.0.4 (executor 0) (19/21)
[2025-05-06T13:17:19.784+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 101) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:19.785+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO TaskSetManager: Finished task 20.0 in stage 81.0 (TID 100) in 771 ms on 172.18.0.4 (executor 0) (20/21)
[2025-05-06T13:17:19.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 101) in 42 ms on 172.18.0.4 (executor 0) (21/21)
[2025-05-06T13:17:19.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-05-06T13:17:19.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: ShuffleMapStage 81 (rdd at GraphFrame.scala:188) finished in 2.663 s
[2025-05-06T13:17:19.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:19.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:19.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:19.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:19.835+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 3162157, minimum partition size: 1048576
[2025-05-06T13:17:19.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO CodeGenerator: Code generated in 5.828199 ms
[2025-05-06T13:17:19.855+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: Registering RDD 171 (rdd at GraphFrame.scala:188) as input to shuffle 23
[2025-05-06T13:17:19.856+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: Got map stage job 40 (rdd at GraphFrame.scala:188) with 2 output partitions
[2025-05-06T13:17:19.856+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: Final stage: ShuffleMapStage 85 (rdd at GraphFrame.scala:188)
[2025-05-06T13:17:19.856+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
[2025-05-06T13:17:19.857+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:17:19.857+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[171] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T13:17:19.868+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 50.0 KiB, free 425.8 MiB)
[2025-05-06T13:17:19.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 425.8 MiB)
[2025-05-06T13:17:19.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 016737cbcc7e:32777 (size: 21.9 KiB, free: 434.2 MiB)
[2025-05-06T13:17:19.880+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:19.880+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 016737cbcc7e:32777 in memory (size: 20.9 KiB, free: 434.3 MiB)
[2025-05-06T13:17:19.881+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[171] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-06T13:17:19.882+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks resource profile 0
[2025-05-06T13:17:19.882+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.18.0.4:44293 in memory (size: 20.9 KiB, free: 434.3 MiB)
[2025-05-06T13:17:19.882+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 102) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:19.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.18.0.4:44293 (size: 21.9 KiB, free: 434.3 MiB)
[2025-05-06T13:17:19.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.18.0.4:59552
[2025-05-06T13:17:20.520+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:20 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 103) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:20.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:20 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 102) in 642 ms on 172.18.0.4 (executor 0) (1/2)
[2025-05-06T13:17:21.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 103) in 518 ms on 172.18.0.4 (executor 0) (2/2)
[2025-05-06T13:17:21.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool
[2025-05-06T13:17:21.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: ShuffleMapStage 85 (rdd at GraphFrame.scala:188) finished in 1.182 s
[2025-05-06T13:17:21.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:21.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:21.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:21.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:21.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO CodeGenerator: Code generated in 9.429816 ms
[2025-05-06T13:17:21.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO CodeGenerator: Code generated in 4.238358 ms
[2025-05-06T13:17:21.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO CodeGenerator: Code generated in 5.573843 ms
[2025-05-06T13:17:21.078+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#519 - id.nullCount#518) > 0)
[2025-05-06T13:17:21.094+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Registering RDD 91 (rdd at GraphFrame.scala:187) as input to shuffle 14
[2025-05-06T13:17:21.094+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Registering RDD 180 (rdd at GraphFrame.scala:188) as input to shuffle 24
[2025-05-06T13:17:21.095+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Got map stage job 41 (rdd at GraphFrame.scala:188) with 10 output partitions
[2025-05-06T13:17:21.095+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Final stage: ShuffleMapStage 91 (rdd at GraphFrame.scala:188)
[2025-05-06T13:17:21.095+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89, ShuffleMapStage 90)
[2025-05-06T13:17:21.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 89)
[2025-05-06T13:17:21.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[91] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-06T13:17:21.098+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 19.7 KiB, free 425.9 MiB)
[2025-05-06T13:17:21.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 425.9 MiB)
[2025-05-06T13:17:21.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 016737cbcc7e:32777 in memory (size: 21.9 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 016737cbcc7e:32777 (size: 9.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:21.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[91] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:17:21.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
[2025-05-06T13:17:21.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.18.0.4:44293 in memory (size: 21.9 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 104) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:21.114+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.18.0.4:44293 (size: 9.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 104) in 26 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:17:21.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool
[2025-05-06T13:17:21.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: ShuffleMapStage 89 (rdd at GraphFrame.scala:187) finished in 0.037 s
[2025-05-06T13:17:21.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:21.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:21.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: waiting: Set(ShuffleMapStage 91)
[2025-05-06T13:17:21.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:21.149+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[180] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-06T13:17:21.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 101.2 KiB, free 425.8 MiB)
[2025-05-06T13:17:21.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 40.2 KiB, free 425.8 MiB)
[2025-05-06T13:17:21.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 016737cbcc7e:32777 (size: 40.2 KiB, free: 434.2 MiB)
[2025-05-06T13:17:21.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:21.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[180] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:17:21.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSchedulerImpl: Adding task set 91.0 with 10 tasks resource profile 0
[2025-05-06T13:17:21.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 105) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:21.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.18.0.4:44293 (size: 40.2 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.18.0.4:59552
[2025-05-06T13:17:21.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 016737cbcc7e:32777 in memory (size: 9.6 KiB, free: 434.2 MiB)
[2025-05-06T13:17:21.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.18.0.4:44293 in memory (size: 9.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.18.0.4:59552
[2025-05-06T13:17:21.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added rdd_95_0 in memory on 172.18.0.4:44293 (size: 1992.0 B, free: 434.3 MiB)
[2025-05-06T13:17:21.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.4:44293 (size: 19.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.471+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 106) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:21.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 105) in 318 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:17:21.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added rdd_95_1 in memory on 172.18.0.4:44293 (size: 2.4 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 107) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:21.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 106) in 111 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:17:21.597+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added rdd_95_2 in memory on 172.18.0.4:44293 (size: 2.2 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.662+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 108) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:21.662+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 107) in 80 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:17:21.677+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added rdd_95_3 in memory on 172.18.0.4:44293 (size: 2.2 KiB, free: 434.3 MiB)
[2025-05-06T13:17:21.747+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 109) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:21.748+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 108) in 87 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:17:21.761+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added rdd_95_4 in memory on 172.18.0.4:44293 (size: 2024.0 B, free: 434.3 MiB)
[2025-05-06T13:17:21.819+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 110) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:21.819+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 109) in 72 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:17:21.837+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added rdd_95_5 in memory on 172.18.0.4:44293 (size: 2040.0 B, free: 434.2 MiB)
[2025-05-06T13:17:21.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 111) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:21.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 110) in 71 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:17:21.903+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added rdd_95_6 in memory on 172.18.0.4:44293 (size: 2.1 KiB, free: 434.2 MiB)
[2025-05-06T13:17:21.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 112) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:21.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 111) in 62 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:17:21.969+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:21 INFO BlockManagerInfo: Added rdd_95_7 in memory on 172.18.0.4:44293 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T13:17:22.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO TaskSetManager: Starting task 8.0 in stage 91.0 (TID 113) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:22.023+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 112) in 71 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:17:22.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO BlockManagerInfo: Added rdd_95_8 in memory on 172.18.0.4:44293 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T13:17:22.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO TaskSetManager: Starting task 9.0 in stage 91.0 (TID 114) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:22.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO TaskSetManager: Finished task 8.0 in stage 91.0 (TID 113) in 58 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:17:22.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO BlockManagerInfo: Added rdd_95_9 in memory on 172.18.0.4:44293 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-06T13:17:22.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO TaskSetManager: Finished task 9.0 in stage 91.0 (TID 114) in 59 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:17:22.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-05-06T13:17:22.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: ShuffleMapStage 91 (rdd at GraphFrame.scala:188) finished in 0.992 s
[2025-05-06T13:17:22.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:22.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:22.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:17:22.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:22.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO CodeGenerator: Code generated in 6.261293 ms
[2025-05-06T13:17:22.158+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO CodeGenerator: Code generated in 4.395522 ms
[2025-05-06T13:17:22.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO CodeGenerator: Code generated in 5.837607 ms
[2025-05-06T13:17:22.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#529 - id.nullCount#528) > 0)
[2025-05-06T13:17:22.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 016737cbcc7e:32777 in memory (size: 40.2 KiB, free: 434.3 MiB)
[2025-05-06T13:17:22.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:17:22.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Registering RDD 103 (map at GraphFrame.scala:187) as input to shuffle 26
[2025-05-06T13:17:22.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.18.0.4:44293 in memory (size: 40.2 KiB, free: 434.3 MiB)
[2025-05-06T13:17:22.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Registering RDD 197 (mapPartitions at VertexRDD.scala:356) as input to shuffle 29
[2025-05-06T13:17:22.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Registering RDD 219 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 25
[2025-05-06T13:17:22.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Registering RDD 223 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 27
[2025-05-06T13:17:22.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Registering RDD 227 (mapPartitions at GraphImpl.scala:208) as input to shuffle 28
[2025-05-06T13:17:22.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Got job 42 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:17:22.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Final stage: ResultStage 103 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:17:22.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 99, ShuffleMapStage 93)
[2025-05-06T13:17:22.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 102, ShuffleMapStage 99, ShuffleMapStage 93)
[2025-05-06T13:17:22.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[103] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-06T13:17:22.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 67.6 KiB, free 425.9 MiB)
[2025-05-06T13:17:22.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 425.9 MiB)
[2025-05-06T13:17:22.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 016737cbcc7e:32777 (size: 27.6 KiB, free: 434.2 MiB)
[2025-05-06T13:17:22.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:22.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[103] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:17:22.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO TaskSchedulerImpl: Adding task set 93.0 with 10 tasks resource profile 0
[2025-05-06T13:17:22.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Submitting ShuffleMapStage 99 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[197] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-06T13:17:22.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 115) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:22.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.18.0.4:44293 (size: 27.6 KiB, free: 434.3 MiB)
[2025-05-06T13:17:22.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 114.9 KiB, free 425.8 MiB)
[2025-05-06T13:17:22.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 45.9 KiB, free 425.7 MiB)
[2025-05-06T13:17:22.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 016737cbcc7e:32777 (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T13:17:22.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:22.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 99 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[197] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:17:22.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO TaskSchedulerImpl: Adding task set 99.0 with 10 tasks resource profile 0
[2025-05-06T13:17:22.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:22 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.18.0.4:44293 (size: 27.1 KiB, free: 434.2 MiB)
[2025-05-06T13:17:23.095+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 116) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.095+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 115) in 824 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:17:23.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 117) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 116) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:17:23.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 118) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 117) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:17:23.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 4.0 in stage 93.0 (TID 119) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.132+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 118) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:17:23.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 5.0 in stage 93.0 (TID 120) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 4.0 in stage 93.0 (TID 119) in 16 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:17:23.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 6.0 in stage 93.0 (TID 121) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 5.0 in stage 93.0 (TID 120) in 17 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:17:23.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 7.0 in stage 93.0 (TID 122) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 6.0 in stage 93.0 (TID 121) in 16 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:17:23.192+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 8.0 in stage 93.0 (TID 123) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.192+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 7.0 in stage 93.0 (TID 122) in 15 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:17:23.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 9.0 in stage 93.0 (TID 124) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 8.0 in stage 93.0 (TID 123) in 14 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:17:23.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 125) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 9.0 in stage 93.0 (TID 124) in 15 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:17:23.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-05-06T13:17:23.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO DAGScheduler: ShuffleMapStage 93 (map at GraphFrame.scala:187) finished in 0.968 s
[2025-05-06T13:17:23.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:23.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO DAGScheduler: running: Set(ShuffleMapStage 99)
[2025-05-06T13:17:23.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103, ShuffleMapStage 100, ShuffleMapStage 101)
[2025-05-06T13:17:23.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:23.228+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.18.0.4:44293 (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T13:17:23.259+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.18.0.4:59552
[2025-05-06T13:17:23.267+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 016737cbcc7e:32777 in memory (size: 27.6 KiB, free: 434.2 MiB)
[2025-05-06T13:17:23.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.18.0.4:44293 in memory (size: 27.6 KiB, free: 434.2 MiB)
[2025-05-06T13:17:23.779+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 126) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:23.780+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:23 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 125) in 559 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:17:24.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 127) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:24.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 126) in 364 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:17:24.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Starting task 3.0 in stage 99.0 (TID 128) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:24.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 127) in 183 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:17:24.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Starting task 4.0 in stage 99.0 (TID 129) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:24.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Finished task 3.0 in stage 99.0 (TID 128) in 119 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:17:24.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Starting task 5.0 in stage 99.0 (TID 130) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:24.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Finished task 4.0 in stage 99.0 (TID 129) in 102 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:17:24.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Starting task 6.0 in stage 99.0 (TID 131) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:24.700+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Finished task 5.0 in stage 99.0 (TID 130) in 156 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:17:24.874+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Starting task 7.0 in stage 99.0 (TID 132) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:24.875+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Finished task 6.0 in stage 99.0 (TID 131) in 176 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:17:24.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Starting task 8.0 in stage 99.0 (TID 133) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:24.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:24 INFO TaskSetManager: Finished task 7.0 in stage 99.0 (TID 132) in 119 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:17:25.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 9.0 in stage 99.0 (TID 134) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.116+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 8.0 in stage 99.0 (TID 133) in 123 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:17:25.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 9.0 in stage 99.0 (TID 134) in 182 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:17:25.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool
[2025-05-06T13:17:25.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: ShuffleMapStage 99 (mapPartitions at VertexRDD.scala:356) finished in 3.024 s
[2025-05-06T13:17:25.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:25.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:25.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103, ShuffleMapStage 100, ShuffleMapStage 101)
[2025-05-06T13:17:25.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:25.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: Submitting ShuffleMapStage 100 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[219] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:17:25.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 10.3 KiB, free 425.8 MiB)
[2025-05-06T13:17:25.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 425.8 MiB)
[2025-05-06T13:17:25.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 016737cbcc7e:32777 (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:25.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 100 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[219] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:17:25.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSchedulerImpl: Adding task set 100.0 with 10 tasks resource profile 0
[2025-05-06T13:17:25.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: Submitting ShuffleMapStage 101 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[223] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:17:25.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 135) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 9.9 KiB, free 425.8 MiB)
[2025-05-06T13:17:25.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 425.8 MiB)
[2025-05-06T13:17:25.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 016737cbcc7e:32777 (size: 4.9 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:25.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 101 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[223] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:17:25.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSchedulerImpl: Adding task set 101.0 with 10 tasks resource profile 0
[2025-05-06T13:17:25.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.18.0.4:44293 (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.388+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.18.0.4:59552
[2025-05-06T13:17:25.399+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 016737cbcc7e:32777 in memory (size: 45.9 KiB, free: 434.3 MiB)
[2025-05-06T13:17:25.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.18.0.4:44293 in memory (size: 45.9 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.18.0.4:59552
[2025-05-06T13:17:25.446+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_0 in memory on 172.18.0.4:44293 (size: 27.8 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_0 in memory on 172.18.0.4:44293 (size: 13.9 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 136) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.500+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 135) in 177 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:17:25.530+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_1 in memory on 172.18.0.4:44293 (size: 27.4 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_1 in memory on 172.18.0.4:44293 (size: 13.8 KiB, free: 434.1 MiB)
[2025-05-06T13:17:25.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 434.1 MiB)
[2025-05-06T13:17:25.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 434.1 MiB)
[2025-05-06T13:17:25.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 2.0 in stage 100.0 (TID 137) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 136) in 51 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:17:25.566+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_2 in memory on 172.18.0.4:44293 (size: 26.8 KiB, free: 434.1 MiB)
[2025-05-06T13:17:25.570+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_2 in memory on 172.18.0.4:44293 (size: 13.6 KiB, free: 434.1 MiB)
[2025-05-06T13:17:25.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 434.1 MiB)
[2025-05-06T13:17:25.576+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 434.0 MiB)
[2025-05-06T13:17:25.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 3.0 in stage 100.0 (TID 138) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 2.0 in stage 100.0 (TID 137) in 34 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:17:25.601+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_3 in memory on 172.18.0.4:44293 (size: 26.7 KiB, free: 434.0 MiB)
[2025-05-06T13:17:25.604+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_3 in memory on 172.18.0.4:44293 (size: 13.6 KiB, free: 434.0 MiB)
[2025-05-06T13:17:25.607+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 434.0 MiB)
[2025-05-06T13:17:25.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 434.0 MiB)
[2025-05-06T13:17:25.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 4.0 in stage 100.0 (TID 139) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 3.0 in stage 100.0 (TID 138) in 36 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:17:25.636+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_4 in memory on 172.18.0.4:44293 (size: 26.9 KiB, free: 433.9 MiB)
[2025-05-06T13:17:25.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_4 in memory on 172.18.0.4:44293 (size: 13.7 KiB, free: 433.9 MiB)
[2025-05-06T13:17:25.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 433.9 MiB)
[2025-05-06T13:17:25.646+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 433.9 MiB)
[2025-05-06T13:17:25.651+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 5.0 in stage 100.0 (TID 140) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.651+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 4.0 in stage 100.0 (TID 139) in 33 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:17:25.665+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_5 in memory on 172.18.0.4:44293 (size: 26.9 KiB, free: 433.9 MiB)
[2025-05-06T13:17:25.667+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_5 in memory on 172.18.0.4:44293 (size: 13.7 KiB, free: 433.9 MiB)
[2025-05-06T13:17:25.669+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 433.9 MiB)
[2025-05-06T13:17:25.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 433.8 MiB)
[2025-05-06T13:17:25.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 6.0 in stage 100.0 (TID 141) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 5.0 in stage 100.0 (TID 140) in 28 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:17:25.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_6 in memory on 172.18.0.4:44293 (size: 26.8 KiB, free: 433.8 MiB)
[2025-05-06T13:17:25.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_6 in memory on 172.18.0.4:44293 (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-06T13:17:25.696+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 433.8 MiB)
[2025-05-06T13:17:25.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 433.8 MiB)
[2025-05-06T13:17:25.703+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 7.0 in stage 100.0 (TID 142) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.703+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 6.0 in stage 100.0 (TID 141) in 25 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:17:25.720+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_7 in memory on 172.18.0.4:44293 (size: 26.7 KiB, free: 433.7 MiB)
[2025-05-06T13:17:25.722+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_7 in memory on 172.18.0.4:44293 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-06T13:17:25.724+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 433.7 MiB)
[2025-05-06T13:17:25.728+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 433.7 MiB)
[2025-05-06T13:17:25.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 8.0 in stage 100.0 (TID 143) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.734+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 7.0 in stage 100.0 (TID 142) in 31 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:17:25.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_8 in memory on 172.18.0.4:44293 (size: 26.4 KiB, free: 433.7 MiB)
[2025-05-06T13:17:25.752+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_8 in memory on 172.18.0.4:44293 (size: 13.3 KiB, free: 433.7 MiB)
[2025-05-06T13:17:25.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 433.7 MiB)
[2025-05-06T13:17:25.760+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 433.6 MiB)
[2025-05-06T13:17:25.767+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 9.0 in stage 100.0 (TID 144) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.768+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 8.0 in stage 100.0 (TID 143) in 34 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:17:25.784+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_200_9 in memory on 172.18.0.4:44293 (size: 25.7 KiB, free: 433.6 MiB)
[2025-05-06T13:17:25.786+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_205_9 in memory on 172.18.0.4:44293 (size: 13.0 KiB, free: 433.6 MiB)
[2025-05-06T13:17:25.788+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_211_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 433.6 MiB)
[2025-05-06T13:17:25.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added rdd_215_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 433.6 MiB)
[2025-05-06T13:17:25.798+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 145) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.799+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 9.0 in stage 100.0 (TID 144) in 32 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:17:25.799+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-05-06T13:17:25.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: ShuffleMapStage 100 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.499 s
[2025-05-06T13:17:25.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:25.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: running: Set(ShuffleMapStage 101)
[2025-05-06T13:17:25.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103)
[2025-05-06T13:17:25.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:25.807+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.4:44293 (size: 4.9 KiB, free: 433.6 MiB)
[2025-05-06T13:17:25.817+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 146) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.818+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 145) in 19 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:17:25.824+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 147) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.825+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 146) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:17:25.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 148) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 147) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:17:25.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 4.0 in stage 101.0 (TID 149) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 148) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:17:25.849+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 5.0 in stage 101.0 (TID 150) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.850+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 4.0 in stage 101.0 (TID 149) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:17:25.857+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 6.0 in stage 101.0 (TID 151) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.857+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 5.0 in stage 101.0 (TID 150) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:17:25.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 7.0 in stage 101.0 (TID 152) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 6.0 in stage 101.0 (TID 151) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:17:25.869+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 8.0 in stage 101.0 (TID 153) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.870+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 7.0 in stage 101.0 (TID 152) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:17:25.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 9.0 in stage 101.0 (TID 154) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 8.0 in stage 101.0 (TID 153) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:17:25.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Finished task 9.0 in stage 101.0 (TID 154) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:17:25.885+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool
[2025-05-06T13:17:25.885+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: ShuffleMapStage 101 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.562 s
[2025-05-06T13:17:25.885+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:17:25.885+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: running: Set()
[2025-05-06T13:17:25.885+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ResultStage 103)
[2025-05-06T13:17:25.885+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: failed: Set()
[2025-05-06T13:17:25.885+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: Submitting ShuffleMapStage 102 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[227] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:17:25.892+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 119.3 KiB, free 425.8 MiB)
[2025-05-06T13:17:25.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 016737cbcc7e:32777 in memory (size: 5.0 KiB, free: 434.3 MiB)
[2025-05-06T13:17:25.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 425.8 MiB)
[2025-05-06T13:17:25.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 016737cbcc7e:32777 (size: 47.3 KiB, free: 434.2 MiB)
[2025-05-06T13:17:25.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:17:25.902+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 102 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[227] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:17:25.903+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSchedulerImpl: Adding task set 102.0 with 10 tasks resource profile 0
[2025-05-06T13:17:25.904+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 155) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:25.904+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.18.0.4:44293 in memory (size: 5.0 KiB, free: 433.6 MiB)
[2025-05-06T13:17:25.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.18.0.4:44293 (size: 47.3 KiB, free: 433.5 MiB)
[2025-05-06T13:17:25.935+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.18.0.4:59552
[2025-05-06T13:17:26.019+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:26 INFO BlockManagerInfo: Added rdd_203_0 in memory on 172.18.0.4:44293 (size: 10.7 MiB, free: 422.8 MiB)
[2025-05-06T13:17:26.024+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:26 INFO BlockManagerInfo: Added rdd_207_0 in memory on 172.18.0.4:44293 (size: 10.7 MiB, free: 412.1 MiB)
[2025-05-06T13:17:26.030+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:26 INFO BlockManagerInfo: Added rdd_213_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 411.6 MiB)
[2025-05-06T13:17:26.031+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.18.0.4:59552
[2025-05-06T13:17:26.037+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:26 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 016737cbcc7e:32777 in memory (size: 4.9 KiB, free: 434.2 MiB)
[2025-05-06T13:17:26.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:26 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.4:44293 in memory (size: 4.9 KiB, free: 411.6 MiB)
[2025-05-06T13:17:26.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:26 INFO BlockManagerInfo: Added rdd_221_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 411.1 MiB)
[2025-05-06T13:17:26.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.18.0.4:59552
[2025-05-06T13:17:34.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:34 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 156) (172.18.0.4, executor 0, partition 1, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:34.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:34 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 155) in 8122 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:17:34.103+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:34 INFO BlockManagerInfo: Added rdd_203_1 in memory on 172.18.0.4:44293 (size: 13.9 MiB, free: 397.2 MiB)
[2025-05-06T13:17:34.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:34 INFO BlockManagerInfo: Added rdd_207_1 in memory on 172.18.0.4:44293 (size: 13.9 MiB, free: 383.3 MiB)
[2025-05-06T13:17:34.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:34 INFO BlockManagerInfo: Added rdd_213_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 382.7 MiB)
[2025-05-06T13:17:34.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:34 INFO BlockManagerInfo: Added rdd_221_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 382.1 MiB)
[2025-05-06T13:17:44.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:44 INFO TaskSetManager: Starting task 2.0 in stage 102.0 (TID 157) (172.18.0.4, executor 0, partition 2, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:44.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:44 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 156) in 10871 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:17:44.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:44 INFO BlockManagerInfo: Added rdd_203_2 in memory on 172.18.0.4:44293 (size: 12.5 MiB, free: 369.6 MiB)
[2025-05-06T13:17:44.981+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:44 INFO BlockManagerInfo: Added rdd_207_2 in memory on 172.18.0.4:44293 (size: 12.5 MiB, free: 357.2 MiB)
[2025-05-06T13:17:44.983+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:44 INFO BlockManagerInfo: Added rdd_213_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 356.6 MiB)
[2025-05-06T13:17:44.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:44 INFO BlockManagerInfo: Added rdd_221_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 356.1 MiB)
[2025-05-06T13:17:54.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:54 INFO TaskSetManager: Starting task 3.0 in stage 102.0 (TID 158) (172.18.0.4, executor 0, partition 3, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:17:54.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:54 INFO TaskSetManager: Finished task 2.0 in stage 102.0 (TID 157) in 9799 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:17:54.780+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:54 INFO BlockManagerInfo: Added rdd_203_3 in memory on 172.18.0.4:44293 (size: 11.7 MiB, free: 344.3 MiB)
[2025-05-06T13:17:54.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:54 INFO BlockManagerInfo: Added rdd_207_3 in memory on 172.18.0.4:44293 (size: 11.7 MiB, free: 332.6 MiB)
[2025-05-06T13:17:54.788+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:54 INFO BlockManagerInfo: Added rdd_213_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 332.0 MiB)
[2025-05-06T13:17:54.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:17:54 INFO BlockManagerInfo: Added rdd_221_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 331.5 MiB)
[2025-05-06T13:18:02.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:02 INFO TaskSetManager: Starting task 4.0 in stage 102.0 (TID 159) (172.18.0.4, executor 0, partition 4, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:02.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:02 INFO TaskSetManager: Finished task 3.0 in stage 102.0 (TID 158) in 8150 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:18:02.900+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:02 INFO BlockManagerInfo: Added rdd_203_4 in memory on 172.18.0.4:44293 (size: 9.6 MiB, free: 321.9 MiB)
[2025-05-06T13:18:02.902+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:02 INFO BlockManagerInfo: Added rdd_207_4 in memory on 172.18.0.4:44293 (size: 9.6 MiB, free: 312.3 MiB)
[2025-05-06T13:18:02.904+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:02 INFO BlockManagerInfo: Added rdd_213_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 311.8 MiB)
[2025-05-06T13:18:02.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:02 INFO BlockManagerInfo: Added rdd_221_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 311.4 MiB)
[2025-05-06T13:18:09.304+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:09 INFO TaskSetManager: Starting task 5.0 in stage 102.0 (TID 160) (172.18.0.4, executor 0, partition 5, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:09.305+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:09 INFO TaskSetManager: Finished task 4.0 in stage 102.0 (TID 159) in 6463 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:18:09.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:09 INFO BlockManagerInfo: Added rdd_203_5 in memory on 172.18.0.4:44293 (size: 11.5 MiB, free: 299.8 MiB)
[2025-05-06T13:18:09.368+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:09 INFO BlockManagerInfo: Added rdd_207_5 in memory on 172.18.0.4:44293 (size: 11.5 MiB, free: 288.3 MiB)
[2025-05-06T13:18:09.370+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:09 INFO BlockManagerInfo: Added rdd_213_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 287.8 MiB)
[2025-05-06T13:18:09.373+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:09 INFO BlockManagerInfo: Added rdd_221_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 287.3 MiB)
[2025-05-06T13:18:17.561+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:17 INFO TaskSetManager: Starting task 6.0 in stage 102.0 (TID 161) (172.18.0.4, executor 0, partition 6, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:17.561+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:17 INFO TaskSetManager: Finished task 5.0 in stage 102.0 (TID 160) in 8257 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:18:17.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:17 INFO BlockManagerInfo: Added rdd_203_6 in memory on 172.18.0.4:44293 (size: 11.6 MiB, free: 275.6 MiB)
[2025-05-06T13:18:17.629+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:17 INFO BlockManagerInfo: Added rdd_207_6 in memory on 172.18.0.4:44293 (size: 11.6 MiB, free: 264.0 MiB)
[2025-05-06T13:18:17.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:17 INFO BlockManagerInfo: Added rdd_213_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 263.5 MiB)
[2025-05-06T13:18:17.634+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:17 INFO BlockManagerInfo: Added rdd_221_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 263.0 MiB)
[2025-05-06T13:18:25.856+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:25 INFO TaskSetManager: Starting task 7.0 in stage 102.0 (TID 162) (172.18.0.4, executor 0, partition 7, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:25.856+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:25 INFO TaskSetManager: Finished task 6.0 in stage 102.0 (TID 161) in 8296 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:18:25.929+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:25 INFO BlockManagerInfo: Added rdd_203_7 in memory on 172.18.0.4:44293 (size: 13.2 MiB, free: 249.8 MiB)
[2025-05-06T13:18:25.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:25 INFO BlockManagerInfo: Added rdd_207_7 in memory on 172.18.0.4:44293 (size: 13.2 MiB, free: 236.5 MiB)
[2025-05-06T13:18:25.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:25 INFO BlockManagerInfo: Added rdd_213_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 236.0 MiB)
[2025-05-06T13:18:25.936+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:25 INFO BlockManagerInfo: Added rdd_221_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 235.4 MiB)
[2025-05-06T13:18:35.785+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:35 INFO TaskSetManager: Starting task 8.0 in stage 102.0 (TID 163) (172.18.0.4, executor 0, partition 8, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:35.785+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:35 INFO TaskSetManager: Finished task 7.0 in stage 102.0 (TID 162) in 9930 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:18:35.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:35 INFO BlockManagerInfo: Added rdd_203_8 in memory on 172.18.0.4:44293 (size: 12.1 MiB, free: 223.3 MiB)
[2025-05-06T13:18:35.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:35 INFO BlockManagerInfo: Added rdd_207_8 in memory on 172.18.0.4:44293 (size: 12.1 MiB, free: 211.2 MiB)
[2025-05-06T13:18:35.881+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:35 INFO BlockManagerInfo: Added rdd_213_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 210.6 MiB)
[2025-05-06T13:18:35.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:35 INFO BlockManagerInfo: Added rdd_221_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 210.1 MiB)
[2025-05-06T13:18:44.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:44 INFO TaskSetManager: Starting task 9.0 in stage 102.0 (TID 164) (172.18.0.4, executor 0, partition 9, NODE_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:44.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:44 INFO TaskSetManager: Finished task 8.0 in stage 102.0 (TID 163) in 8677 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:18:44.533+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:44 INFO BlockManagerInfo: Added rdd_203_9 in memory on 172.18.0.4:44293 (size: 13.7 MiB, free: 196.4 MiB)
[2025-05-06T13:18:44.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:44 INFO BlockManagerInfo: Added rdd_207_9 in memory on 172.18.0.4:44293 (size: 13.7 MiB, free: 182.7 MiB)
[2025-05-06T13:18:44.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:44 INFO BlockManagerInfo: Added rdd_213_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 182.1 MiB)
[2025-05-06T13:18:44.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:44 INFO BlockManagerInfo: Added rdd_221_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 181.5 MiB)
[2025-05-06T13:18:54.976+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO TaskSetManager: Finished task 9.0 in stage 102.0 (TID 164) in 10514 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:18:54.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool
[2025-05-06T13:18:54.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO DAGScheduler: ShuffleMapStage 102 (mapPartitions at GraphImpl.scala:208) finished in 89.089 s
[2025-05-06T13:18:54.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:18:54.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO DAGScheduler: running: Set()
[2025-05-06T13:18:54.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO DAGScheduler: waiting: Set(ResultStage 103)
[2025-05-06T13:18:54.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO DAGScheduler: failed: Set()
[2025-05-06T13:18:54.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[231] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:18:54.979+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 11.2 KiB, free 425.8 MiB)
[2025-05-06T13:18:54.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 425.8 MiB)
[2025-05-06T13:18:54.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 016737cbcc7e:32777 (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T13:18:54.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:18:54.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 103 (MapPartitionsRDD[231] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:18:54.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO TaskSchedulerImpl: Adding task set 103.0 with 10 tasks resource profile 0
[2025-05-06T13:18:54.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 165) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:54.991+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.18.0.4:44293 (size: 5.3 KiB, free: 181.5 MiB)
[2025-05-06T13:18:54.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.18.0.4:59552
[2025-05-06T13:18:55.409+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:55 INFO BlockManagerInfo: Added rdd_229_0 in memory on 172.18.0.4:44293 (size: 3.6 MiB, free: 177.9 MiB)
[2025-05-06T13:18:55.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:55 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 166) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:55.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:55 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 165) in 425 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:18:55.798+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:55 INFO BlockManagerInfo: Added rdd_229_1 in memory on 172.18.0.4:44293 (size: 3.7 MiB, free: 174.2 MiB)
[2025-05-06T13:18:55.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:55 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 167) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:55.801+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:55 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 166) in 390 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:18:56.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:56 INFO BlockManagerInfo: Added rdd_229_2 in memory on 172.18.0.4:44293 (size: 3.4 MiB, free: 170.7 MiB)
[2025-05-06T13:18:56.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:56 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 168) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:56.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:56 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 167) in 335 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:18:56.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:56 INFO BlockManagerInfo: Added rdd_229_3 in memory on 172.18.0.4:44293 (size: 3.4 MiB, free: 167.3 MiB)
[2025-05-06T13:18:56.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:56 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 169) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:56.458+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:56 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 168) in 323 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:18:56.824+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:56 INFO BlockManagerInfo: Added rdd_229_4 in memory on 172.18.0.4:44293 (size: 3.5 MiB, free: 163.8 MiB)
[2025-05-06T13:18:56.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:56 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 170) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:56.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:56 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 169) in 369 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:18:57.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:57 INFO BlockManagerInfo: Added rdd_229_5 in memory on 172.18.0.4:44293 (size: 3.6 MiB, free: 160.2 MiB)
[2025-05-06T13:18:57.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:57 INFO TaskSetManager: Starting task 6.0 in stage 103.0 (TID 171) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:57.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:57 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 170) in 353 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:18:57.503+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:57 INFO BlockManagerInfo: Added rdd_229_6 in memory on 172.18.0.4:44293 (size: 3.4 MiB, free: 156.8 MiB)
[2025-05-06T13:18:57.505+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:57 INFO TaskSetManager: Starting task 7.0 in stage 103.0 (TID 172) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:57.506+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:57 INFO TaskSetManager: Finished task 6.0 in stage 103.0 (TID 171) in 326 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:18:57.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:57 INFO BlockManagerInfo: Added rdd_229_7 in memory on 172.18.0.4:44293 (size: 3.6 MiB, free: 153.2 MiB)
[2025-05-06T13:18:57.872+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:57 INFO TaskSetManager: Starting task 8.0 in stage 103.0 (TID 173) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:57.873+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:57 INFO TaskSetManager: Finished task 7.0 in stage 103.0 (TID 172) in 367 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:18:58.217+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_229_8 in memory on 172.18.0.4:44293 (size: 3.5 MiB, free: 149.7 MiB)
[2025-05-06T13:18:58.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 9.0 in stage 103.0 (TID 174) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 8.0 in stage 103.0 (TID 173) in 347 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:18:58.546+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_229_9 in memory on 172.18.0.4:44293 (size: 3.3 MiB, free: 146.3 MiB)
[2025-05-06T13:18:58.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 9.0 in stage 103.0 (TID 174) in 329 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:18:58.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-05-06T13:18:58.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: ResultStage 103 (fold at VertexRDDImpl.scala:90) finished in 3.570 s
[2025-05-06T13:18:58.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:18:58.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
[2025-05-06T13:18:58.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Job 42 finished: fold at VertexRDDImpl.scala:90, took 96.300321 s
[2025-05-06T13:18:58.561+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:18:58.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Registering RDD 240 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 31
[2025-05-06T13:18:58.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Registering RDD 236 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 30
[2025-05-06T13:18:58.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Registering RDD 244 (mapPartitions at GraphImpl.scala:208) as input to shuffle 32
[2025-05-06T13:18:58.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Got job 43 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:18:58.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Final stage: ResultStage 118 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:18:58.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 114, ShuffleMapStage 111, ShuffleMapStage 105)
[2025-05-06T13:18:58.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 117)
[2025-05-06T13:18:58.564+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Submitting ShuffleMapStage 115 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[240] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:18:58.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 10.5 KiB, free 425.8 MiB)
[2025-05-06T13:18:58.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 425.8 MiB)
[2025-05-06T13:18:58.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 016737cbcc7e:32777 (size: 5.1 KiB, free: 434.2 MiB)
[2025-05-06T13:18:58.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:18:58.573+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 115 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[240] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:18:58.573+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSchedulerImpl: Adding task set 115.0 with 10 tasks resource profile 0
[2025-05-06T13:18:58.575+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Submitting ShuffleMapStage 116 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[236] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:18:58.576+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 175) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 016737cbcc7e:32777 in memory (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T13:18:58.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 11.7 KiB, free 425.8 MiB)
[2025-05-06T13:18:58.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.18.0.4:44293 in memory (size: 5.3 KiB, free: 146.3 MiB)
[2025-05-06T13:18:58.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 425.8 MiB)
[2025-05-06T13:18:58.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 016737cbcc7e:32777 (size: 5.4 KiB, free: 434.2 MiB)
[2025-05-06T13:18:58.579+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:18:58.580+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 116 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[236] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:18:58.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSchedulerImpl: Adding task set 116.0 with 10 tasks resource profile 0
[2025-05-06T13:18:58.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.18.0.4:44293 (size: 5.1 KiB, free: 146.3 MiB)
[2025-05-06T13:18:58.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 016737cbcc7e:32777 in memory (size: 47.3 KiB, free: 434.3 MiB)
[2025-05-06T13:18:58.584+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.18.0.4:44293 in memory (size: 47.3 KiB, free: 146.4 MiB)
[2025-05-06T13:18:58.602+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 176) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.602+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 175) in 29 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:18:58.625+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 2.0 in stage 115.0 (TID 177) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.625+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 176) in 23 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:18:58.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 3.0 in stage 115.0 (TID 178) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 2.0 in stage 115.0 (TID 177) in 17 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:18:58.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 4.0 in stage 115.0 (TID 179) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 3.0 in stage 115.0 (TID 178) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:18:58.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 5.0 in stage 115.0 (TID 180) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 4.0 in stage 115.0 (TID 179) in 18 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:18:58.685+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 6.0 in stage 115.0 (TID 181) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.685+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 5.0 in stage 115.0 (TID 180) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:18:58.697+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 7.0 in stage 115.0 (TID 182) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.698+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 6.0 in stage 115.0 (TID 181) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:18:58.714+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 8.0 in stage 115.0 (TID 183) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.715+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 7.0 in stage 115.0 (TID 182) in 17 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:18:58.727+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 9.0 in stage 115.0 (TID 184) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.727+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 8.0 in stage 115.0 (TID 183) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:18:58.744+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 185) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 9.0 in stage 115.0 (TID 184) in 17 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:18:58.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool
[2025-05-06T13:18:58.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: ShuffleMapStage 115 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.181 s
[2025-05-06T13:18:58.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:18:58.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: running: Set(ShuffleMapStage 116)
[2025-05-06T13:18:58.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 117, ResultStage 118)
[2025-05-06T13:18:58.745+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: failed: Set()
[2025-05-06T13:18:58.749+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.18.0.4:44293 (size: 5.4 KiB, free: 146.4 MiB)
[2025-05-06T13:18:58.767+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 146.4 MiB)
[2025-05-06T13:18:58.771+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 1.0 in stage 116.0 (TID 186) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.772+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 185) in 27 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:18:58.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 146.4 MiB)
[2025-05-06T13:18:58.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 2.0 in stage 116.0 (TID 187) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 1.0 in stage 116.0 (TID 186) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:18:58.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 146.3 MiB)
[2025-05-06T13:18:58.794+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 3.0 in stage 116.0 (TID 188) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.795+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 2.0 in stage 116.0 (TID 187) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:18:58.802+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 146.3 MiB)
[2025-05-06T13:18:58.806+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 4.0 in stage 116.0 (TID 189) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.806+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 3.0 in stage 116.0 (TID 188) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:18:58.811+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 146.3 MiB)
[2025-05-06T13:18:58.815+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 5.0 in stage 116.0 (TID 190) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.816+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 4.0 in stage 116.0 (TID 189) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:18:58.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 146.3 MiB)
[2025-05-06T13:18:58.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 6.0 in stage 116.0 (TID 191) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 5.0 in stage 116.0 (TID 190) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:18:58.834+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 146.3 MiB)
[2025-05-06T13:18:58.839+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 7.0 in stage 116.0 (TID 192) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 6.0 in stage 116.0 (TID 191) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:18:58.849+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 146.3 MiB)
[2025-05-06T13:18:58.853+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 8.0 in stage 116.0 (TID 193) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.854+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 7.0 in stage 116.0 (TID 192) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:18:58.861+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 146.3 MiB)
[2025-05-06T13:18:58.867+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 9.0 in stage 116.0 (TID 194) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.867+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 8.0 in stage 116.0 (TID 193) in 14 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:18:58.872+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_232_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 146.2 MiB)
[2025-05-06T13:18:58.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Finished task 9.0 in stage 116.0 (TID 194) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:18:58.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool
[2025-05-06T13:18:58.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: ShuffleMapStage 116 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.303 s
[2025-05-06T13:18:58.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:18:58.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: running: Set()
[2025-05-06T13:18:58.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 117, ResultStage 118)
[2025-05-06T13:18:58.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: failed: Set()
[2025-05-06T13:18:58.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Submitting ShuffleMapStage 117 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[244] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:18:58.880+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 120.4 KiB, free 425.8 MiB)
[2025-05-06T13:18:58.886+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 47.8 KiB, free 425.8 MiB)
[2025-05-06T13:18:58.887+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 016737cbcc7e:32777 in memory (size: 5.1 KiB, free: 434.3 MiB)
[2025-05-06T13:18:58.887+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 016737cbcc7e:32777 (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T13:18:58.887+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:18:58.887+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 117 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[244] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:18:58.887+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSchedulerImpl: Adding task set 117.0 with 10 tasks resource profile 0
[2025-05-06T13:18:58.888+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.18.0.4:44293 in memory (size: 5.1 KiB, free: 146.2 MiB)
[2025-05-06T13:18:58.888+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 195) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:58.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.18.0.4:44293 (size: 47.8 KiB, free: 146.2 MiB)
[2025-05-06T13:18:58.900+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.18.0.4:59552
[2025-05-06T13:18:58.902+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.18.0.4:59552
[2025-05-06T13:18:58.906+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO BlockManagerInfo: Added rdd_238_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 145.7 MiB)
[2025-05-06T13:18:58.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.18.0.4:59552
[2025-05-06T13:18:59.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:59 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 196) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:59.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:59 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 195) in 285 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:18:59.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:59 INFO BlockManagerInfo: Added rdd_238_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 145.1 MiB)
[2025-05-06T13:18:59.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:59 INFO TaskSetManager: Starting task 2.0 in stage 117.0 (TID 197) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:59.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:59 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 196) in 289 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:18:59.469+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:59 INFO BlockManagerInfo: Added rdd_238_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 144.6 MiB)
[2025-05-06T13:18:59.742+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:59 INFO TaskSetManager: Starting task 3.0 in stage 117.0 (TID 198) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:18:59.743+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:59 INFO TaskSetManager: Finished task 2.0 in stage 117.0 (TID 197) in 282 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:18:59.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:18:59 INFO BlockManagerInfo: Added rdd_238_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 144.0 MiB)
[2025-05-06T13:19:00.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO TaskSetManager: Starting task 4.0 in stage 117.0 (TID 199) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:00.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO TaskSetManager: Finished task 3.0 in stage 117.0 (TID 198) in 285 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:00.037+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO BlockManagerInfo: Added rdd_238_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 143.6 MiB)
[2025-05-06T13:19:00.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO TaskSetManager: Starting task 5.0 in stage 117.0 (TID 200) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:00.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO TaskSetManager: Finished task 4.0 in stage 117.0 (TID 199) in 222 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:00.259+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO BlockManagerInfo: Added rdd_238_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 143.1 MiB)
[2025-05-06T13:19:00.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO TaskSetManager: Starting task 6.0 in stage 117.0 (TID 201) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:00.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO TaskSetManager: Finished task 5.0 in stage 117.0 (TID 200) in 267 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:00.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO BlockManagerInfo: Added rdd_238_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 142.5 MiB)
[2025-05-06T13:19:00.788+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO TaskSetManager: Starting task 7.0 in stage 117.0 (TID 202) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:00.788+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO TaskSetManager: Finished task 6.0 in stage 117.0 (TID 201) in 273 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:00.796+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:00 INFO BlockManagerInfo: Added rdd_238_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 142.0 MiB)
[2025-05-06T13:19:01.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 8.0 in stage 117.0 (TID 203) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 7.0 in stage 117.0 (TID 202) in 301 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:01.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_238_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 141.4 MiB)
[2025-05-06T13:19:01.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 9.0 in stage 117.0 (TID 204) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.354+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 8.0 in stage 117.0 (TID 203) in 266 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:01.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_238_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 140.8 MiB)
[2025-05-06T13:19:01.684+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 9.0 in stage 117.0 (TID 204) in 331 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:01.684+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-05-06T13:19:01.684+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: ShuffleMapStage 117 (mapPartitions at GraphImpl.scala:208) finished in 2.806 s
[2025-05-06T13:19:01.684+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:01.684+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:01.684+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: waiting: Set(ResultStage 118)
[2025-05-06T13:19:01.685+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:01.685+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[248] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:01.686+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 12.3 KiB, free 425.8 MiB)
[2025-05-06T13:19:01.691+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 425.8 MiB)
[2025-05-06T13:19:01.691+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 016737cbcc7e:32777 (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:01.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 016737cbcc7e:32777 in memory (size: 5.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:01.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:01.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 118 (MapPartitionsRDD[248] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:01.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSchedulerImpl: Adding task set 118.0 with 10 tasks resource profile 0
[2025-05-06T13:19:01.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 205) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.693+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.18.0.4:44293 in memory (size: 5.4 KiB, free: 140.8 MiB)
[2025-05-06T13:19:01.697+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.18.0.4:44293 (size: 5.6 KiB, free: 140.8 MiB)
[2025-05-06T13:19:01.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.18.0.4:59552
[2025-05-06T13:19:01.716+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_0 in memory on 172.18.0.4:44293 (size: 90.8 KiB, free: 140.7 MiB)
[2025-05-06T13:19:01.719+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 206) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.719+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 205) in 26 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:01.740+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_1 in memory on 172.18.0.4:44293 (size: 89.4 KiB, free: 140.6 MiB)
[2025-05-06T13:19:01.742+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 207) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.742+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 206) in 23 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:01.759+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_2 in memory on 172.18.0.4:44293 (size: 86.5 KiB, free: 140.6 MiB)
[2025-05-06T13:19:01.761+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 208) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.761+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 207) in 20 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:01.789+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_3 in memory on 172.18.0.4:44293 (size: 85.4 KiB, free: 140.5 MiB)
[2025-05-06T13:19:01.791+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 209) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 208) in 31 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:01.817+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_4 in memory on 172.18.0.4:44293 (size: 87.3 KiB, free: 140.4 MiB)
[2025-05-06T13:19:01.820+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 210) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.820+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 209) in 29 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:01.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_5 in memory on 172.18.0.4:44293 (size: 87.0 KiB, free: 140.3 MiB)
[2025-05-06T13:19:01.848+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 211) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.848+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 210) in 29 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:01.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_6 in memory on 172.18.0.4:44293 (size: 85.5 KiB, free: 140.2 MiB)
[2025-05-06T13:19:01.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 212) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 211) in 17 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:01.880+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_7 in memory on 172.18.0.4:44293 (size: 86.6 KiB, free: 140.1 MiB)
[2025-05-06T13:19:01.882+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 8.0 in stage 118.0 (TID 213) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 212) in 18 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:01.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_8 in memory on 172.18.0.4:44293 (size: 84.8 KiB, free: 140.1 MiB)
[2025-05-06T13:19:01.899+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 9.0 in stage 118.0 (TID 214) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.899+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 8.0 in stage 118.0 (TID 213) in 17 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:01.913+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_246_9 in memory on 172.18.0.4:44293 (size: 82.6 KiB, free: 140.0 MiB)
[2025-05-06T13:19:01.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 9.0 in stage 118.0 (TID 214) in 17 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:01.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-05-06T13:19:01.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: ResultStage 118 (fold at VertexRDDImpl.scala:90) finished in 0.230 s
[2025-05-06T13:19:01.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:01.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 118: Stage finished
[2025-05-06T13:19:01.915+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Job 43 finished: fold at VertexRDDImpl.scala:90, took 3.354034 s
[2025-05-06T13:19:01.916+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO Pregel: Pregel finished iteration 0
[2025-05-06T13:19:01.916+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO ZippedPartitionsRDD2: Removing RDD 229 from persistence list
[2025-05-06T13:19:01.919+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManager: Removing RDD 229
[2025-05-06T13:19:01.920+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO MapPartitionsRDD: Removing RDD 215 from persistence list
[2025-05-06T13:19:01.921+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManager: Removing RDD 215
[2025-05-06T13:19:01.922+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO ZippedPartitionsRDD2: Removing RDD 221 from persistence list
[2025-05-06T13:19:01.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManager: Removing RDD 221
[2025-05-06T13:19:01.932+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:01.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Registering RDD 253 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 33
[2025-05-06T13:19:01.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Registering RDD 257 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 34
[2025-05-06T13:19:01.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Registering RDD 261 (mapPartitions at GraphImpl.scala:208) as input to shuffle 35
[2025-05-06T13:19:01.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Got job 44 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:01.935+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Final stage: ResultStage 136 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:01.935+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135, ShuffleMapStage 132, ShuffleMapStage 129, ShuffleMapStage 126, ShuffleMapStage 120)
[2025-05-06T13:19:01.935+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 135)
[2025-05-06T13:19:01.935+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Submitting ShuffleMapStage 133 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[253] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:01.936+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 12.3 KiB, free 425.8 MiB)
[2025-05-06T13:19:01.943+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 425.8 MiB)
[2025-05-06T13:19:01.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 016737cbcc7e:32777 (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:01.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:01.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 133 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[253] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:01.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSchedulerImpl: Adding task set 133.0 with 10 tasks resource profile 0
[2025-05-06T13:19:01.944+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Submitting ShuffleMapStage 134 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[257] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:19:01.945+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 016737cbcc7e:32777 in memory (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:01.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 11.6 KiB, free 425.8 MiB)
[2025-05-06T13:19:01.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 215) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 425.8 MiB)
[2025-05-06T13:19:01.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 016737cbcc7e:32777 (size: 5.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:01.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.18.0.4:44293 in memory (size: 5.6 KiB, free: 180.6 MiB)
[2025-05-06T13:19:01.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:01.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 134 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[257] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:01.951+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSchedulerImpl: Adding task set 134.0 with 10 tasks resource profile 0
[2025-05-06T13:19:01.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 016737cbcc7e:32777 in memory (size: 47.8 KiB, free: 434.3 MiB)
[2025-05-06T13:19:01.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.18.0.4:44293 (size: 5.6 KiB, free: 180.6 MiB)
[2025-05-06T13:19:01.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.18.0.4:44293 in memory (size: 47.8 KiB, free: 180.7 MiB)
[2025-05-06T13:19:01.959+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_249_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 180.7 MiB)
[2025-05-06T13:19:01.963+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 1.0 in stage 133.0 (TID 216) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.964+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 215) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:01.967+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_249_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 180.7 MiB)
[2025-05-06T13:19:01.971+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 2.0 in stage 133.0 (TID 217) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.971+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 1.0 in stage 133.0 (TID 216) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:01.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_249_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 180.6 MiB)
[2025-05-06T13:19:01.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 3.0 in stage 133.0 (TID 218) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 2.0 in stage 133.0 (TID 217) in 16 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:01.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_249_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 180.6 MiB)
[2025-05-06T13:19:01.995+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Starting task 4.0 in stage 133.0 (TID 219) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:01.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO TaskSetManager: Finished task 3.0 in stage 133.0 (TID 218) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:02.000+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:01 INFO BlockManagerInfo: Added rdd_249_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 180.6 MiB)
[2025-05-06T13:19:02.003+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 5.0 in stage 133.0 (TID 220) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.004+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 4.0 in stage 133.0 (TID 219) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:02.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_249_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 180.6 MiB)
[2025-05-06T13:19:02.011+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 6.0 in stage 133.0 (TID 221) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.012+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 5.0 in stage 133.0 (TID 220) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:02.015+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_249_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 180.6 MiB)
[2025-05-06T13:19:02.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 7.0 in stage 133.0 (TID 222) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 6.0 in stage 133.0 (TID 221) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:02.023+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_249_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 180.6 MiB)
[2025-05-06T13:19:02.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 8.0 in stage 133.0 (TID 223) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 7.0 in stage 133.0 (TID 222) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:02.030+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_249_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 180.6 MiB)
[2025-05-06T13:19:02.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 9.0 in stage 133.0 (TID 224) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 8.0 in stage 133.0 (TID 223) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:02.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_249_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 180.5 MiB)
[2025-05-06T13:19:02.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 225) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 9.0 in stage 133.0 (TID 224) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:02.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool
[2025-05-06T13:19:02.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: ShuffleMapStage 133 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.106 s
[2025-05-06T13:19:02.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:02.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: running: Set(ShuffleMapStage 134)
[2025-05-06T13:19:02.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 135, ResultStage 136)
[2025-05-06T13:19:02.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:02.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.18.0.4:44293 (size: 5.4 KiB, free: 180.5 MiB)
[2025-05-06T13:19:02.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 226) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 225) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:02.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 227) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 226) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:02.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 228) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.078+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 227) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:02.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 4.0 in stage 134.0 (TID 229) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 228) in 19 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:02.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 5.0 in stage 134.0 (TID 230) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 4.0 in stage 134.0 (TID 229) in 15 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:02.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 6.0 in stage 134.0 (TID 231) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 5.0 in stage 134.0 (TID 230) in 15 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:02.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 7.0 in stage 134.0 (TID 232) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 6.0 in stage 134.0 (TID 231) in 16 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:02.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 8.0 in stage 134.0 (TID 233) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 7.0 in stage 134.0 (TID 232) in 15 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:02.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 9.0 in stage 134.0 (TID 234) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 8.0 in stage 134.0 (TID 233) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:02.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 9.0 in stage 134.0 (TID 234) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:02.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool
[2025-05-06T13:19:02.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: ShuffleMapStage 134 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.236 s
[2025-05-06T13:19:02.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:02.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:02.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 135, ResultStage 136)
[2025-05-06T13:19:02.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:02.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: Submitting ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[261] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:02.184+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 120.7 KiB, free 425.8 MiB)
[2025-05-06T13:19:02.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 47.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:02.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 016737cbcc7e:32777 in memory (size: 5.6 KiB, free: 434.3 MiB)
[2025-05-06T13:19:02.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 016737cbcc7e:32777 (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:02.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:02.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[261] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:02.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSchedulerImpl: Adding task set 135.0 with 10 tasks resource profile 0
[2025-05-06T13:19:02.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 235) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.197+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.18.0.4:44293 in memory (size: 5.6 KiB, free: 180.5 MiB)
[2025-05-06T13:19:02.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.18.0.4:44293 (size: 47.8 KiB, free: 180.5 MiB)
[2025-05-06T13:19:02.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.18.0.4:59552
[2025-05-06T13:19:02.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 180.0 MiB)
[2025-05-06T13:19:02.217+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.18.0.4:59552
[2025-05-06T13:19:02.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 236) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 235) in 84 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:02.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 179.4 MiB)
[2025-05-06T13:19:02.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 237) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 236) in 75 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:02.359+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 178.8 MiB)
[2025-05-06T13:19:02.418+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 238) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.418+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 237) in 66 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:02.424+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 178.3 MiB)
[2025-05-06T13:19:02.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 4.0 in stage 135.0 (TID 239) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 238) in 66 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:02.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 177.9 MiB)
[2025-05-06T13:19:02.561+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 5.0 in stage 135.0 (TID 240) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.562+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 4.0 in stage 135.0 (TID 239) in 78 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:02.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 177.4 MiB)
[2025-05-06T13:19:02.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 6.0 in stage 135.0 (TID 241) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.629+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 5.0 in stage 135.0 (TID 240) in 67 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:02.635+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 176.8 MiB)
[2025-05-06T13:19:02.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 7.0 in stage 135.0 (TID 242) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 6.0 in stage 135.0 (TID 241) in 67 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:02.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 176.3 MiB)
[2025-05-06T13:19:02.769+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 8.0 in stage 135.0 (TID 243) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.770+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 7.0 in stage 135.0 (TID 242) in 75 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:02.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 175.7 MiB)
[2025-05-06T13:19:02.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 9.0 in stage 135.0 (TID 244) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 8.0 in stage 135.0 (TID 243) in 72 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:02.850+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_255_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 175.1 MiB)
[2025-05-06T13:19:02.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 9.0 in stage 135.0 (TID 244) in 77 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:02.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool
[2025-05-06T13:19:02.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: ShuffleMapStage 135 (mapPartitions at GraphImpl.scala:208) finished in 0.736 s
[2025-05-06T13:19:02.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:02.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:02.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: waiting: Set(ResultStage 136)
[2025-05-06T13:19:02.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:02.919+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[265] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:02.920+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 12.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:02.924+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:02.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 016737cbcc7e:32777 (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:02.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 016737cbcc7e:32777 in memory (size: 5.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:02.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:02.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 136 (MapPartitionsRDD[265] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:02.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSchedulerImpl: Adding task set 136.0 with 10 tasks resource profile 0
[2025-05-06T13:19:02.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 245) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.18.0.4:44293 in memory (size: 5.4 KiB, free: 175.1 MiB)
[2025-05-06T13:19:02.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.18.0.4:44293 (size: 5.8 KiB, free: 175.1 MiB)
[2025-05-06T13:19:02.934+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.18.0.4:59552
[2025-05-06T13:19:02.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_263_0 in memory on 172.18.0.4:44293 (size: 37.2 KiB, free: 175.1 MiB)
[2025-05-06T13:19:02.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 246) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 245) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:02.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_263_1 in memory on 172.18.0.4:44293 (size: 36.8 KiB, free: 175.0 MiB)
[2025-05-06T13:19:02.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 2.0 in stage 136.0 (TID 247) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 246) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:02.968+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_263_2 in memory on 172.18.0.4:44293 (size: 35.9 KiB, free: 175.0 MiB)
[2025-05-06T13:19:02.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 3.0 in stage 136.0 (TID 248) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.970+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 2.0 in stage 136.0 (TID 247) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:02.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_263_3 in memory on 172.18.0.4:44293 (size: 35.9 KiB, free: 175.0 MiB)
[2025-05-06T13:19:02.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 4.0 in stage 136.0 (TID 249) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 3.0 in stage 136.0 (TID 248) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:02.988+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_263_4 in memory on 172.18.0.4:44293 (size: 36.2 KiB, free: 174.9 MiB)
[2025-05-06T13:19:02.989+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Starting task 5.0 in stage 136.0 (TID 250) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:02.990+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO TaskSetManager: Finished task 4.0 in stage 136.0 (TID 249) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:02.998+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:02 INFO BlockManagerInfo: Added rdd_263_5 in memory on 172.18.0.4:44293 (size: 35.9 KiB, free: 174.9 MiB)
[2025-05-06T13:19:03.000+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 6.0 in stage 136.0 (TID 251) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.000+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 5.0 in stage 136.0 (TID 250) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:03.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_263_6 in memory on 172.18.0.4:44293 (size: 35.7 KiB, free: 174.9 MiB)
[2025-05-06T13:19:03.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 7.0 in stage 136.0 (TID 252) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 6.0 in stage 136.0 (TID 251) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:03.018+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_263_7 in memory on 172.18.0.4:44293 (size: 35.7 KiB, free: 174.8 MiB)
[2025-05-06T13:19:03.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 8.0 in stage 136.0 (TID 253) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 7.0 in stage 136.0 (TID 252) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:03.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_263_8 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 174.8 MiB)
[2025-05-06T13:19:03.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 9.0 in stage 136.0 (TID 254) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.030+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 8.0 in stage 136.0 (TID 253) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:03.037+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_263_9 in memory on 172.18.0.4:44293 (size: 34.2 KiB, free: 174.8 MiB)
[2025-05-06T13:19:03.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 9.0 in stage 136.0 (TID 254) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:03.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-05-06T13:19:03.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: ResultStage 136 (fold at VertexRDDImpl.scala:90) finished in 0.121 s
[2025-05-06T13:19:03.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:03.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished
[2025-05-06T13:19:03.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Job 44 finished: fold at VertexRDDImpl.scala:90, took 1.108173 s
[2025-05-06T13:19:03.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO Pregel: Pregel finished iteration 1
[2025-05-06T13:19:03.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO ZippedPartitionsRDD2: Removing RDD 246 from persistence list
[2025-05-06T13:19:03.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO ZippedPartitionsRDD2: Removing RDD 232 from persistence list
[2025-05-06T13:19:03.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManager: Removing RDD 246
[2025-05-06T13:19:03.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO ZippedPartitionsRDD2: Removing RDD 238 from persistence list
[2025-05-06T13:19:03.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManager: Removing RDD 232
[2025-05-06T13:19:03.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManager: Removing RDD 238
[2025-05-06T13:19:03.050+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MapPartitionsRDD: Removing RDD 215 from persistence list
[2025-05-06T13:19:03.051+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO ZippedPartitionsRDD2: Removing RDD 225 from persistence list
[2025-05-06T13:19:03.051+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManager: Removing RDD 215
[2025-05-06T13:19:03.052+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManager: Removing RDD 225
[2025-05-06T13:19:03.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO ZippedPartitionsRDD2: Removing RDD 229 from persistence list
[2025-05-06T13:19:03.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManager: Removing RDD 229
[2025-05-06T13:19:03.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:03.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Registering RDD 270 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 36
[2025-05-06T13:19:03.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Registering RDD 274 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 37
[2025-05-06T13:19:03.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Registering RDD 278 (mapPartitions at GraphImpl.scala:208) as input to shuffle 38
[2025-05-06T13:19:03.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Got job 45 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:03.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Final stage: ResultStage 157 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:03.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 153, ShuffleMapStage 150, ShuffleMapStage 147, ShuffleMapStage 144, ShuffleMapStage 138, ShuffleMapStage 156)
[2025-05-06T13:19:03.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 156)
[2025-05-06T13:19:03.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Submitting ShuffleMapStage 154 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[270] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:03.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 12.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:03.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 425.8 MiB)
[2025-05-06T13:19:03.076+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 016737cbcc7e:32777 (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:03.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:03.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 154 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[270] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:03.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSchedulerImpl: Adding task set 154.0 with 10 tasks resource profile 0
[2025-05-06T13:19:03.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Submitting ShuffleMapStage 155 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[274] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:19:03.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 255) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 016737cbcc7e:32777 in memory (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:03.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 12.2 KiB, free 425.8 MiB)
[2025-05-06T13:19:03.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.18.0.4:44293 in memory (size: 5.8 KiB, free: 181.1 MiB)
[2025-05-06T13:19:03.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 425.8 MiB)
[2025-05-06T13:19:03.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 016737cbcc7e:32777 (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:03.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:03.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 155 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[274] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:03.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSchedulerImpl: Adding task set 155.0 with 10 tasks resource profile 0
[2025-05-06T13:19:03.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 016737cbcc7e:32777 in memory (size: 47.8 KiB, free: 434.3 MiB)
[2025-05-06T13:19:03.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.18.0.4:44293 in memory (size: 47.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:03.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.18.0.4:44293 (size: 5.7 KiB, free: 181.2 MiB)
[2025-05-06T13:19:03.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:03.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 256) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 255) in 27 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:03.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 181.1 MiB)
[2025-05-06T13:19:03.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 257) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 256) in 18 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:03.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:19:03.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 258) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 257) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:03.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:03.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 259) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 258) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:03.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:03.154+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 5.0 in stage 154.0 (TID 260) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 259) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:03.159+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:03.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 6.0 in stage 154.0 (TID 261) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 5.0 in stage 154.0 (TID 260) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:03.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:03.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 7.0 in stage 154.0 (TID 262) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 6.0 in stage 154.0 (TID 261) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:03.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:19:03.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 8.0 in stage 154.0 (TID 263) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 7.0 in stage 154.0 (TID 262) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:03.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 181.0 MiB)
[2025-05-06T13:19:03.182+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 9.0 in stage 154.0 (TID 264) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 8.0 in stage 154.0 (TID 263) in 6 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:03.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_266_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:03.189+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 265) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 9.0 in stage 154.0 (TID 264) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:03.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool
[2025-05-06T13:19:03.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: ShuffleMapStage 154 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.123 s
[2025-05-06T13:19:03.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:03.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: running: Set(ShuffleMapStage 155)
[2025-05-06T13:19:03.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: waiting: Set(ResultStage 157, ShuffleMapStage 156)
[2025-05-06T13:19:03.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:03.193+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.18.0.4:44293 (size: 5.6 KiB, free: 181.0 MiB)
[2025-05-06T13:19:03.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 266) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 265) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:03.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 267) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 266) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:03.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 268) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 267) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:03.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 4.0 in stage 155.0 (TID 269) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 268) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:03.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 5.0 in stage 155.0 (TID 270) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 4.0 in stage 155.0 (TID 269) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:03.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 6.0 in stage 155.0 (TID 271) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 5.0 in stage 155.0 (TID 270) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:03.261+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 7.0 in stage 155.0 (TID 272) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 6.0 in stage 155.0 (TID 271) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:03.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 8.0 in stage 155.0 (TID 273) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 7.0 in stage 155.0 (TID 272) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:03.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 9.0 in stage 155.0 (TID 274) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 8.0 in stage 155.0 (TID 273) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:03.290+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 9.0 in stage 155.0 (TID 274) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:03.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool
[2025-05-06T13:19:03.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: ShuffleMapStage 155 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.212 s
[2025-05-06T13:19:03.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:03.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:03.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: waiting: Set(ResultStage 157, ShuffleMapStage 156)
[2025-05-06T13:19:03.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:03.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Submitting ShuffleMapStage 156 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[278] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:03.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 121.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:03.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:03.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 016737cbcc7e:32777 in memory (size: 5.7 KiB, free: 434.3 MiB)
[2025-05-06T13:19:03.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 016737cbcc7e:32777 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:03.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:03.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 156 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[278] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:03.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSchedulerImpl: Adding task set 156.0 with 10 tasks resource profile 0
[2025-05-06T13:19:03.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.18.0.4:44293 in memory (size: 5.7 KiB, free: 181.0 MiB)
[2025-05-06T13:19:03.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 275) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.305+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.18.0.4:44293 (size: 47.9 KiB, free: 181.0 MiB)
[2025-05-06T13:19:03.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.18.0.4:59552
[2025-05-06T13:19:03.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:19:03.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.18.0.4:59552
[2025-05-06T13:19:03.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 276) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 275) in 85 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:03.391+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:19:03.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 277) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 276) in 71 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:03.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 179.3 MiB)
[2025-05-06T13:19:03.525+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 278) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 277) in 69 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:03.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:19:03.588+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 4.0 in stage 156.0 (TID 279) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.588+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 278) in 63 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:03.594+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:19:03.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 5.0 in stage 156.0 (TID 280) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.640+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 4.0 in stage 156.0 (TID 279) in 52 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:03.646+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:19:03.701+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 6.0 in stage 156.0 (TID 281) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.701+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 5.0 in stage 156.0 (TID 280) in 62 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:03.707+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:19:03.762+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 7.0 in stage 156.0 (TID 282) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 6.0 in stage 156.0 (TID 281) in 62 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:03.769+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:19:03.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 8.0 in stage 156.0 (TID 283) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 7.0 in stage 156.0 (TID 282) in 79 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:03.847+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:19:03.903+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 9.0 in stage 156.0 (TID 284) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.903+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 8.0 in stage 156.0 (TID 283) in 63 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:03.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_272_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:03.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 9.0 in stage 156.0 (TID 284) in 70 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:03.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool
[2025-05-06T13:19:03.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: ShuffleMapStage 156 (mapPartitions at GraphImpl.scala:208) finished in 0.681 s
[2025-05-06T13:19:03.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:03.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:03.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: waiting: Set(ResultStage 157)
[2025-05-06T13:19:03.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:03.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[282] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:03.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 13.5 KiB, free 425.8 MiB)
[2025-05-06T13:19:03.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:03.979+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 016737cbcc7e:32777 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:03.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 016737cbcc7e:32777 in memory (size: 5.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:03.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:03.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 157 (MapPartitionsRDD[282] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:03.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSchedulerImpl: Adding task set 157.0 with 10 tasks resource profile 0
[2025-05-06T13:19:03.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.18.0.4:44293 in memory (size: 5.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:03.981+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 285) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.984+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.18.0.4:44293 (size: 5.9 KiB, free: 175.6 MiB)
[2025-05-06T13:19:03.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.18.0.4:59552
[2025-05-06T13:19:03.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO BlockManagerInfo: Added rdd_280_0 in memory on 172.18.0.4:44293 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:03.994+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 286) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:03.994+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:03 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 285) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:04.001+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_280_1 in memory on 172.18.0.4:44293 (size: 35.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:04.003+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 2.0 in stage 157.0 (TID 287) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.003+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 286) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:04.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_280_2 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:04.019+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 3.0 in stage 157.0 (TID 288) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 2.0 in stage 157.0 (TID 287) in 17 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:04.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_280_3 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:04.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 4.0 in stage 157.0 (TID 289) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 3.0 in stage 157.0 (TID 288) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:04.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_280_4 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:04.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 5.0 in stage 157.0 (TID 290) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 4.0 in stage 157.0 (TID 289) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:04.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_280_5 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:04.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 6.0 in stage 157.0 (TID 291) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 5.0 in stage 157.0 (TID 290) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:04.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_280_6 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:19:04.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 7.0 in stage 157.0 (TID 292) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 6.0 in stage 157.0 (TID 291) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:04.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_280_7 in memory on 172.18.0.4:44293 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:19:04.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 8.0 in stage 157.0 (TID 293) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 7.0 in stage 157.0 (TID 292) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:04.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_280_8 in memory on 172.18.0.4:44293 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:19:04.072+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 9.0 in stage 157.0 (TID 294) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.073+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 8.0 in stage 157.0 (TID 293) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:04.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_280_9 in memory on 172.18.0.4:44293 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:19:04.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 9.0 in stage 157.0 (TID 294) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:04.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool
[2025-05-06T13:19:04.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: ResultStage 157 (fold at VertexRDDImpl.scala:90) finished in 0.108 s
[2025-05-06T13:19:04.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:04.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 157: Stage finished
[2025-05-06T13:19:04.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Job 45 finished: fold at VertexRDDImpl.scala:90, took 1.020065 s
[2025-05-06T13:19:04.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO Pregel: Pregel finished iteration 2
[2025-05-06T13:19:04.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO ZippedPartitionsRDD2: Removing RDD 263 from persistence list
[2025-05-06T13:19:04.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO ZippedPartitionsRDD2: Removing RDD 249 from persistence list
[2025-05-06T13:19:04.083+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManager: Removing RDD 263
[2025-05-06T13:19:04.083+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO ZippedPartitionsRDD2: Removing RDD 255 from persistence list
[2025-05-06T13:19:04.083+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManager: Removing RDD 249
[2025-05-06T13:19:04.084+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManager: Removing RDD 255
[2025-05-06T13:19:04.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO ZippedPartitionsRDD2: Removing RDD 232 from persistence list
[2025-05-06T13:19:04.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO ZippedPartitionsRDD2: Removing RDD 238 from persistence list
[2025-05-06T13:19:04.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManager: Removing RDD 232
[2025-05-06T13:19:04.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManager: Removing RDD 238
[2025-05-06T13:19:04.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO ZippedPartitionsRDD2: Removing RDD 246 from persistence list
[2025-05-06T13:19:04.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManager: Removing RDD 246
[2025-05-06T13:19:04.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:04.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Registering RDD 291 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 40
[2025-05-06T13:19:04.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Registering RDD 287 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 39
[2025-05-06T13:19:04.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Registering RDD 295 (mapPartitions at GraphImpl.scala:208) as input to shuffle 41
[2025-05-06T13:19:04.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Got job 46 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:04.100+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Final stage: ResultStage 181 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:04.100+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 171, ShuffleMapStage 168, ShuffleMapStage 165, ShuffleMapStage 180, ShuffleMapStage 159, ShuffleMapStage 177, ShuffleMapStage 174)
[2025-05-06T13:19:04.100+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 180)
[2025-05-06T13:19:04.100+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Submitting ShuffleMapStage 178 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[291] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:19:04.102+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 12.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:04.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 425.8 MiB)
[2025-05-06T13:19:04.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 016737cbcc7e:32777 (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:04.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:04.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 178 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[291] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:04.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSchedulerImpl: Adding task set 178.0 with 10 tasks resource profile 0
[2025-05-06T13:19:04.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 016737cbcc7e:32777 in memory (size: 47.9 KiB, free: 434.3 MiB)
[2025-05-06T13:19:04.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Submitting ShuffleMapStage 179 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[287] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:04.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 295) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.18.0.4:44293 in memory (size: 47.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:04.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 13.6 KiB, free 425.9 MiB)
[2025-05-06T13:19:04.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 425.9 MiB)
[2025-05-06T13:19:04.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 016737cbcc7e:32777 (size: 5.8 KiB, free: 434.3 MiB)
[2025-05-06T13:19:04.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:04.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 016737cbcc7e:32777 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-05-06T13:19:04.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 179 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[287] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:04.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSchedulerImpl: Adding task set 179.0 with 10 tasks resource profile 0
[2025-05-06T13:19:04.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.18.0.4:44293 in memory (size: 5.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:04.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.18.0.4:44293 (size: 5.7 KiB, free: 181.2 MiB)
[2025-05-06T13:19:04.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 1.0 in stage 178.0 (TID 296) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 295) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:04.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 2.0 in stage 178.0 (TID 297) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 1.0 in stage 178.0 (TID 296) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:04.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 3.0 in stage 178.0 (TID 298) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 2.0 in stage 178.0 (TID 297) in 17 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:04.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 4.0 in stage 178.0 (TID 299) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 3.0 in stage 178.0 (TID 298) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:04.171+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 5.0 in stage 178.0 (TID 300) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.171+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 4.0 in stage 178.0 (TID 299) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:04.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 6.0 in stage 178.0 (TID 301) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 5.0 in stage 178.0 (TID 300) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:04.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 7.0 in stage 178.0 (TID 302) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 6.0 in stage 178.0 (TID 301) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:04.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 8.0 in stage 178.0 (TID 303) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 7.0 in stage 178.0 (TID 302) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:04.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 9.0 in stage 178.0 (TID 304) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 8.0 in stage 178.0 (TID 303) in 10 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:04.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 305) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 9.0 in stage 178.0 (TID 304) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:04.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool
[2025-05-06T13:19:04.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: ShuffleMapStage 178 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.119 s
[2025-05-06T13:19:04.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:04.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: running: Set(ShuffleMapStage 179)
[2025-05-06T13:19:04.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 180, ResultStage 181)
[2025-05-06T13:19:04.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:04.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.18.0.4:44293 (size: 5.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:04.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:04.228+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 1.0 in stage 179.0 (TID 306) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 305) in 10 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:04.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:04.236+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 2.0 in stage 179.0 (TID 307) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.236+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 1.0 in stage 179.0 (TID 306) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:04.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:19:04.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 3.0 in stage 179.0 (TID 308) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 2.0 in stage 179.0 (TID 307) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:04.246+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:04.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 4.0 in stage 179.0 (TID 309) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 3.0 in stage 179.0 (TID 308) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:04.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:04.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 5.0 in stage 179.0 (TID 310) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 4.0 in stage 179.0 (TID 309) in 6 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:04.261+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:04.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 6.0 in stage 179.0 (TID 311) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 5.0 in stage 179.0 (TID 310) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:04.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:04.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 7.0 in stage 179.0 (TID 312) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 6.0 in stage 179.0 (TID 311) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:04.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:19:04.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 8.0 in stage 179.0 (TID 313) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 7.0 in stage 179.0 (TID 312) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:04.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:19:04.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 9.0 in stage 179.0 (TID 314) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 8.0 in stage 179.0 (TID 313) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:04.291+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_283_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:04.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 9.0 in stage 179.0 (TID 314) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:04.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool
[2025-05-06T13:19:04.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: ShuffleMapStage 179 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.186 s
[2025-05-06T13:19:04.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:04.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:04.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 180, ResultStage 181)
[2025-05-06T13:19:04.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:04.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Submitting ShuffleMapStage 180 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[295] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:04.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 121.3 KiB, free 425.8 MiB)
[2025-05-06T13:19:04.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:04.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 016737cbcc7e:32777 in memory (size: 5.7 KiB, free: 434.3 MiB)
[2025-05-06T13:19:04.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 016737cbcc7e:32777 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:04.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:04.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 180 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[295] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:04.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSchedulerImpl: Adding task set 180.0 with 10 tasks resource profile 0
[2025-05-06T13:19:04.304+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.18.0.4:44293 in memory (size: 5.7 KiB, free: 181.0 MiB)
[2025-05-06T13:19:04.304+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 315) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.18.0.4:44293 (size: 48.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:04.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.18.0.4:59552
[2025-05-06T13:19:04.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:19:04.318+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.18.0.4:59552
[2025-05-06T13:19:04.373+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 1.0 in stage 180.0 (TID 316) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 315) in 69 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:04.380+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:19:04.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 2.0 in stage 180.0 (TID 317) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 1.0 in stage 180.0 (TID 316) in 71 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:04.450+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:19:04.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 3.0 in stage 180.0 (TID 318) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 2.0 in stage 180.0 (TID 317) in 73 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:04.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:19:04.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 4.0 in stage 180.0 (TID 319) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 3.0 in stage 180.0 (TID 318) in 66 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:04.588+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:19:04.635+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 5.0 in stage 180.0 (TID 320) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.635+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 4.0 in stage 180.0 (TID 319) in 53 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:04.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:19:04.695+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 6.0 in stage 180.0 (TID 321) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.696+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 5.0 in stage 180.0 (TID 320) in 60 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:04.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:19:04.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 7.0 in stage 180.0 (TID 322) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 6.0 in stage 180.0 (TID 321) in 62 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:04.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:19:04.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 8.0 in stage 180.0 (TID 323) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 7.0 in stage 180.0 (TID 322) in 70 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:04.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:19:04.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 9.0 in stage 180.0 (TID 324) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 8.0 in stage 180.0 (TID 323) in 62 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:04.897+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_289_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:04.959+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 9.0 in stage 180.0 (TID 324) in 70 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:04.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool
[2025-05-06T13:19:04.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: ShuffleMapStage 180 (mapPartitions at GraphImpl.scala:208) finished in 0.665 s
[2025-05-06T13:19:04.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:04.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:04.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: waiting: Set(ResultStage 181)
[2025-05-06T13:19:04.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:04.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[299] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:04.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 14.2 KiB, free 425.8 MiB)
[2025-05-06T13:19:04.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:04.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 016737cbcc7e:32777 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:04.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 016737cbcc7e:32777 in memory (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:04.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:04.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 181 (MapPartitionsRDD[299] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:04.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSchedulerImpl: Adding task set 181.0 with 10 tasks resource profile 0
[2025-05-06T13:19:04.967+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 325) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.967+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.18.0.4:44293 in memory (size: 5.8 KiB, free: 175.6 MiB)
[2025-05-06T13:19:04.971+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.18.0.4:44293 (size: 6.0 KiB, free: 175.6 MiB)
[2025-05-06T13:19:04.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.18.0.4:59552
[2025-05-06T13:19:04.979+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_297_0 in memory on 172.18.0.4:44293 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:04.980+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 1.0 in stage 181.0 (TID 326) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.981+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 325) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:04.988+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_297_1 in memory on 172.18.0.4:44293 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:19:04.989+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Starting task 2.0 in stage 181.0 (TID 327) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:04.989+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO TaskSetManager: Finished task 1.0 in stage 181.0 (TID 326) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:04.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:04 INFO BlockManagerInfo: Added rdd_297_2 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:05.004+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 3.0 in stage 181.0 (TID 328) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 2.0 in stage 181.0 (TID 327) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:05.012+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_297_3 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:05.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 4.0 in stage 181.0 (TID 329) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 3.0 in stage 181.0 (TID 328) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:05.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_297_4 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.5 MiB)
[2025-05-06T13:19:05.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 5.0 in stage 181.0 (TID 330) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.023+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 4.0 in stage 181.0 (TID 329) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:05.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_297_5 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:05.030+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 6.0 in stage 181.0 (TID 331) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.031+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 5.0 in stage 181.0 (TID 330) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:05.037+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_297_6 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:19:05.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 7.0 in stage 181.0 (TID 332) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 6.0 in stage 181.0 (TID 331) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:05.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_297_7 in memory on 172.18.0.4:44293 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:19:05.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 8.0 in stage 181.0 (TID 333) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 7.0 in stage 181.0 (TID 332) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:05.053+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_297_8 in memory on 172.18.0.4:44293 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:19:05.054+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 9.0 in stage 181.0 (TID 334) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 8.0 in stage 181.0 (TID 333) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:05.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_297_9 in memory on 172.18.0.4:44293 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:19:05.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 9.0 in stage 181.0 (TID 334) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:05.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool
[2025-05-06T13:19:05.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: ResultStage 181 (fold at VertexRDDImpl.scala:90) finished in 0.103 s
[2025-05-06T13:19:05.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:05.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished
[2025-05-06T13:19:05.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Job 46 finished: fold at VertexRDDImpl.scala:90, took 0.967258 s
[2025-05-06T13:19:05.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO Pregel: Pregel finished iteration 3
[2025-05-06T13:19:05.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO ZippedPartitionsRDD2: Removing RDD 280 from persistence list
[2025-05-06T13:19:05.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO ZippedPartitionsRDD2: Removing RDD 266 from persistence list
[2025-05-06T13:19:05.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManager: Removing RDD 280
[2025-05-06T13:19:05.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManager: Removing RDD 266
[2025-05-06T13:19:05.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO ZippedPartitionsRDD2: Removing RDD 272 from persistence list
[2025-05-06T13:19:05.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManager: Removing RDD 272
[2025-05-06T13:19:05.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO ZippedPartitionsRDD2: Removing RDD 249 from persistence list
[2025-05-06T13:19:05.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManager: Removing RDD 249
[2025-05-06T13:19:05.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO ZippedPartitionsRDD2: Removing RDD 255 from persistence list
[2025-05-06T13:19:05.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManager: Removing RDD 255
[2025-05-06T13:19:05.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO ZippedPartitionsRDD2: Removing RDD 263 from persistence list
[2025-05-06T13:19:05.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManager: Removing RDD 263
[2025-05-06T13:19:05.078+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:05.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Registering RDD 308 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 43
[2025-05-06T13:19:05.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Registering RDD 304 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 42
[2025-05-06T13:19:05.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Registering RDD 312 (mapPartitions at GraphImpl.scala:208) as input to shuffle 44
[2025-05-06T13:19:05.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Got job 47 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:05.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Final stage: ResultStage 208 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:05.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 204, ShuffleMapStage 183, ShuffleMapStage 201, ShuffleMapStage 198, ShuffleMapStage 195, ShuffleMapStage 192, ShuffleMapStage 189, ShuffleMapStage 207)
[2025-05-06T13:19:05.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 207)
[2025-05-06T13:19:05.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Submitting ShuffleMapStage 205 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[308] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:19:05.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 13.5 KiB, free 425.8 MiB)
[2025-05-06T13:19:05.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:05.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 016737cbcc7e:32777 in memory (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:05.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 016737cbcc7e:32777 (size: 5.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:05.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:05.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 205 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[308] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:05.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSchedulerImpl: Adding task set 205.0 with 10 tasks resource profile 0
[2025-05-06T13:19:05.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Submitting ShuffleMapStage 206 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[304] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:05.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 335) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.18.0.4:44293 in memory (size: 6.0 KiB, free: 181.1 MiB)
[2025-05-06T13:19:05.090+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 14.2 KiB, free 425.8 MiB)
[2025-05-06T13:19:05.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:05.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 016737cbcc7e:32777 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:05.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:05.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 206 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[304] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:05.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSchedulerImpl: Adding task set 206.0 with 10 tasks resource profile 0
[2025-05-06T13:19:05.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.18.0.4:44293 in memory (size: 48.0 KiB, free: 181.2 MiB)
[2025-05-06T13:19:05.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 016737cbcc7e:32777 in memory (size: 48.0 KiB, free: 434.3 MiB)
[2025-05-06T13:19:05.094+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.18.0.4:44293 (size: 5.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:05.104+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 1.0 in stage 205.0 (TID 336) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.104+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 335) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:05.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 2.0 in stage 205.0 (TID 337) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 1.0 in stage 205.0 (TID 336) in 17 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:05.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 3.0 in stage 205.0 (TID 338) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 2.0 in stage 205.0 (TID 337) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:05.141+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 4.0 in stage 205.0 (TID 339) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.141+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 3.0 in stage 205.0 (TID 338) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:05.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 5.0 in stage 205.0 (TID 340) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 4.0 in stage 205.0 (TID 339) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:05.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 6.0 in stage 205.0 (TID 341) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 5.0 in stage 205.0 (TID 340) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:05.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 7.0 in stage 205.0 (TID 342) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 6.0 in stage 205.0 (TID 341) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:05.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 8.0 in stage 205.0 (TID 343) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 7.0 in stage 205.0 (TID 342) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:05.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 9.0 in stage 205.0 (TID 344) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 8.0 in stage 205.0 (TID 343) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:05.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 345) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 9.0 in stage 205.0 (TID 344) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:05.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool
[2025-05-06T13:19:05.200+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: ShuffleMapStage 205 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.118 s
[2025-05-06T13:19:05.200+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:05.200+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: running: Set(ShuffleMapStage 206)
[2025-05-06T13:19:05.200+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: waiting: Set(ResultStage 208, ShuffleMapStage 207)
[2025-05-06T13:19:05.200+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:05.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.18.0.4:44293 (size: 6.0 KiB, free: 181.2 MiB)
[2025-05-06T13:19:05.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:05.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 1.0 in stage 206.0 (TID 346) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.209+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 345) in 10 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:05.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:05.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 2.0 in stage 206.0 (TID 347) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 1.0 in stage 206.0 (TID 346) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:05.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:19:05.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 3.0 in stage 206.0 (TID 348) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.222+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 2.0 in stage 206.0 (TID 347) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:05.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:05.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 4.0 in stage 206.0 (TID 349) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 3.0 in stage 206.0 (TID 348) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:05.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:05.235+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 5.0 in stage 206.0 (TID 350) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.236+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 4.0 in stage 206.0 (TID 349) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:05.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:05.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 6.0 in stage 206.0 (TID 351) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.244+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 5.0 in stage 206.0 (TID 350) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:05.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:05.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 7.0 in stage 206.0 (TID 352) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 6.0 in stage 206.0 (TID 351) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:05.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:19:05.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 8.0 in stage 206.0 (TID 353) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 7.0 in stage 206.0 (TID 352) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:05.261+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:19:05.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 9.0 in stage 206.0 (TID 354) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 8.0 in stage 206.0 (TID 353) in 6 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:05.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_300_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:05.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 9.0 in stage 206.0 (TID 354) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:05.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool
[2025-05-06T13:19:05.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: ShuffleMapStage 206 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.183 s
[2025-05-06T13:19:05.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:05.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:05.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: waiting: Set(ResultStage 208, ShuffleMapStage 207)
[2025-05-06T13:19:05.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:05.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Submitting ShuffleMapStage 207 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[312] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:05.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 121.5 KiB, free 425.8 MiB)
[2025-05-06T13:19:05.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 016737cbcc7e:32777 in memory (size: 5.8 KiB, free: 434.3 MiB)
[2025-05-06T13:19:05.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:05.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 016737cbcc7e:32777 (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:05.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:05.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 207 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[312] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:05.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSchedulerImpl: Adding task set 207.0 with 10 tasks resource profile 0
[2025-05-06T13:19:05.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.18.0.4:44293 in memory (size: 5.8 KiB, free: 181.0 MiB)
[2025-05-06T13:19:05.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 355) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.18.0.4:44293 (size: 48.1 KiB, free: 181.0 MiB)
[2025-05-06T13:19:05.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.18.0.4:59552
[2025-05-06T13:19:05.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:19:05.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.18.0.4:59552
[2025-05-06T13:19:05.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 1.0 in stage 207.0 (TID 356) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 355) in 70 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:05.359+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:19:05.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 2.0 in stage 207.0 (TID 357) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.423+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 1.0 in stage 207.0 (TID 356) in 70 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:05.429+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:19:05.492+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 3.0 in stage 207.0 (TID 358) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.493+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 2.0 in stage 207.0 (TID 357) in 70 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:05.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:19:05.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 4.0 in stage 207.0 (TID 359) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.561+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 3.0 in stage 207.0 (TID 358) in 68 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:05.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:19:05.617+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 5.0 in stage 207.0 (TID 360) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.617+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 4.0 in stage 207.0 (TID 359) in 57 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:05.623+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:19:05.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 6.0 in stage 207.0 (TID 361) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.682+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 5.0 in stage 207.0 (TID 360) in 66 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:05.689+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:19:05.742+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 7.0 in stage 207.0 (TID 362) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.742+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 6.0 in stage 207.0 (TID 361) in 60 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:05.748+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:19:05.813+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 8.0 in stage 207.0 (TID 363) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.813+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 7.0 in stage 207.0 (TID 362) in 71 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:05.820+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:19:05.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 9.0 in stage 207.0 (TID 364) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 8.0 in stage 207.0 (TID 363) in 80 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:05.899+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_306_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:05.965+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 9.0 in stage 207.0 (TID 364) in 72 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:05.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool
[2025-05-06T13:19:05.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: ShuffleMapStage 207 (mapPartitions at GraphImpl.scala:208) finished in 0.693 s
[2025-05-06T13:19:05.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:05.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:05.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: waiting: Set(ResultStage 208)
[2025-05-06T13:19:05.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:05.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Submitting ResultStage 208 (MapPartitionsRDD[316] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:05.967+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 14.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:05.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:05.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 016737cbcc7e:32777 in memory (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:05.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 016737cbcc7e:32777 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:05.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:05.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 208 (MapPartitionsRDD[316] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:05.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSchedulerImpl: Adding task set 208.0 with 10 tasks resource profile 0
[2025-05-06T13:19:05.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.18.0.4:44293 in memory (size: 6.0 KiB, free: 175.6 MiB)
[2025-05-06T13:19:05.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 365) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.979+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.18.0.4:44293 (size: 6.1 KiB, free: 175.6 MiB)
[2025-05-06T13:19:05.983+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.18.0.4:59552
[2025-05-06T13:19:05.989+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_314_0 in memory on 172.18.0.4:44293 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:05.991+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Starting task 1.0 in stage 208.0 (TID 366) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:05.991+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 365) in 18 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:05.998+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:05 INFO BlockManagerInfo: Added rdd_314_1 in memory on 172.18.0.4:44293 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:19:06.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 2.0 in stage 208.0 (TID 367) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 1.0 in stage 208.0 (TID 366) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:06.018+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_314_2 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:06.019+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 3.0 in stage 208.0 (TID 368) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 2.0 in stage 208.0 (TID 367) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:06.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_314_3 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:06.030+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 4.0 in stage 208.0 (TID 369) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.031+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 3.0 in stage 208.0 (TID 368) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:06.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_314_4 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.5 MiB)
[2025-05-06T13:19:06.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 5.0 in stage 208.0 (TID 370) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 4.0 in stage 208.0 (TID 369) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:06.050+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_314_5 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:06.052+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 6.0 in stage 208.0 (TID 371) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.052+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 5.0 in stage 208.0 (TID 370) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:06.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_314_6 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:19:06.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 7.0 in stage 208.0 (TID 372) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 6.0 in stage 208.0 (TID 371) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:06.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_314_7 in memory on 172.18.0.4:44293 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:19:06.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 8.0 in stage 208.0 (TID 373) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 7.0 in stage 208.0 (TID 372) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:06.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_314_8 in memory on 172.18.0.4:44293 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:19:06.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 9.0 in stage 208.0 (TID 374) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.079+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 8.0 in stage 208.0 (TID 373) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:06.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_314_9 in memory on 172.18.0.4:44293 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:19:06.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 9.0 in stage 208.0 (TID 374) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:06.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool
[2025-05-06T13:19:06.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: ResultStage 208 (fold at VertexRDDImpl.scala:90) finished in 0.123 s
[2025-05-06T13:19:06.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:06.090+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 208: Stage finished
[2025-05-06T13:19:06.090+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Job 47 finished: fold at VertexRDDImpl.scala:90, took 1.011858 s
[2025-05-06T13:19:06.090+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO Pregel: Pregel finished iteration 4
[2025-05-06T13:19:06.090+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO ZippedPartitionsRDD2: Removing RDD 297 from persistence list
[2025-05-06T13:19:06.090+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManager: Removing RDD 297
[2025-05-06T13:19:06.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO ZippedPartitionsRDD2: Removing RDD 283 from persistence list
[2025-05-06T13:19:06.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManager: Removing RDD 283
[2025-05-06T13:19:06.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO ZippedPartitionsRDD2: Removing RDD 289 from persistence list
[2025-05-06T13:19:06.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManager: Removing RDD 289
[2025-05-06T13:19:06.095+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO ZippedPartitionsRDD2: Removing RDD 266 from persistence list
[2025-05-06T13:19:06.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManager: Removing RDD 266
[2025-05-06T13:19:06.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO ZippedPartitionsRDD2: Removing RDD 272 from persistence list
[2025-05-06T13:19:06.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManager: Removing RDD 272
[2025-05-06T13:19:06.101+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO ZippedPartitionsRDD2: Removing RDD 280 from persistence list
[2025-05-06T13:19:06.101+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManager: Removing RDD 280
[2025-05-06T13:19:06.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:06.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Registering RDD 325 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 46
[2025-05-06T13:19:06.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Registering RDD 321 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 45
[2025-05-06T13:19:06.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Registering RDD 329 (mapPartitions at GraphImpl.scala:208) as input to shuffle 47
[2025-05-06T13:19:06.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Got job 48 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:06.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Final stage: ResultStage 238 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:06.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 222, ShuffleMapStage 219, ShuffleMapStage 237, ShuffleMapStage 216, ShuffleMapStage 234, ShuffleMapStage 231, ShuffleMapStage 210, ShuffleMapStage 228, ShuffleMapStage 225)
[2025-05-06T13:19:06.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 237)
[2025-05-06T13:19:06.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Submitting ShuffleMapStage 235 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[325] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:19:06.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 14.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:06.116+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:06.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 016737cbcc7e:32777 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:06.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 016737cbcc7e:32777 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:06.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:06.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 235 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[325] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:06.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSchedulerImpl: Adding task set 235.0 with 10 tasks resource profile 0
[2025-05-06T13:19:06.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Submitting ShuffleMapStage 236 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[321] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:06.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 375) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.18.0.4:44293 in memory (size: 6.1 KiB, free: 181.1 MiB)
[2025-05-06T13:19:06.122+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 14.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:06.122+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:06.124+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 016737cbcc7e:32777 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:06.124+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:06.124+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 016737cbcc7e:32777 in memory (size: 48.1 KiB, free: 434.3 MiB)
[2025-05-06T13:19:06.124+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 236 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[321] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:06.124+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSchedulerImpl: Adding task set 236.0 with 10 tasks resource profile 0
[2025-05-06T13:19:06.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.18.0.4:44293 in memory (size: 48.1 KiB, free: 181.2 MiB)
[2025-05-06T13:19:06.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.18.0.4:44293 (size: 5.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:06.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 1.0 in stage 235.0 (TID 376) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 375) in 23 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:06.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 2.0 in stage 235.0 (TID 377) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 1.0 in stage 235.0 (TID 376) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:06.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 3.0 in stage 235.0 (TID 378) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 2.0 in stage 235.0 (TID 377) in 19 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:06.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 4.0 in stage 235.0 (TID 379) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 3.0 in stage 235.0 (TID 378) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:06.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 5.0 in stage 235.0 (TID 380) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 4.0 in stage 235.0 (TID 379) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:06.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 6.0 in stage 235.0 (TID 381) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.210+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 5.0 in stage 235.0 (TID 380) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:06.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 7.0 in stage 235.0 (TID 382) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 6.0 in stage 235.0 (TID 381) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:06.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 8.0 in stage 235.0 (TID 383) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 7.0 in stage 235.0 (TID 382) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:06.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 9.0 in stage 235.0 (TID 384) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 8.0 in stage 235.0 (TID 383) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:06.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 385) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 9.0 in stage 235.0 (TID 384) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:06.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool
[2025-05-06T13:19:06.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: ShuffleMapStage 235 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.140 s
[2025-05-06T13:19:06.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:06.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: running: Set(ShuffleMapStage 236)
[2025-05-06T13:19:06.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: waiting: Set(ShuffleMapStage 237, ResultStage 238)
[2025-05-06T13:19:06.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:06.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.18.0.4:44293 (size: 6.0 KiB, free: 181.2 MiB)
[2025-05-06T13:19:06.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:06.259+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 1.0 in stage 236.0 (TID 386) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 385) in 10 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:06.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:06.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 2.0 in stage 236.0 (TID 387) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 1.0 in stage 236.0 (TID 386) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:06.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:19:06.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 3.0 in stage 236.0 (TID 388) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 2.0 in stage 236.0 (TID 387) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:06.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:06.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 4.0 in stage 236.0 (TID 389) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 3.0 in stage 236.0 (TID 388) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:06.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:06.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 5.0 in stage 236.0 (TID 390) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 4.0 in stage 236.0 (TID 389) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:06.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:06.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 6.0 in stage 236.0 (TID 391) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 5.0 in stage 236.0 (TID 390) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:06.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:06.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 7.0 in stage 236.0 (TID 392) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 6.0 in stage 236.0 (TID 391) in 12 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:06.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:19:06.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 8.0 in stage 236.0 (TID 393) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 7.0 in stage 236.0 (TID 392) in 6 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:06.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:19:06.318+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 9.0 in stage 236.0 (TID 394) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 8.0 in stage 236.0 (TID 393) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:06.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_317_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:06.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 9.0 in stage 236.0 (TID 394) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:06.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool
[2025-05-06T13:19:06.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: ShuffleMapStage 236 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.205 s
[2025-05-06T13:19:06.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:06.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:06.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: waiting: Set(ShuffleMapStage 237, ResultStage 238)
[2025-05-06T13:19:06.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:06.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Submitting ShuffleMapStage 237 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[329] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:06.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 121.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:06.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 016737cbcc7e:32777 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-05-06T13:19:06.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:06.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 016737cbcc7e:32777 (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:06.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:06.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 237 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[329] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:06.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSchedulerImpl: Adding task set 237.0 with 10 tasks resource profile 0
[2025-05-06T13:19:06.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 0.0 in stage 237.0 (TID 395) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.18.0.4:44293 in memory (size: 5.9 KiB, free: 181.0 MiB)
[2025-05-06T13:19:06.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.18.0.4:44293 (size: 48.1 KiB, free: 181.0 MiB)
[2025-05-06T13:19:06.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.18.0.4:59552
[2025-05-06T13:19:06.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:19:06.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.18.0.4:59552
[2025-05-06T13:19:06.409+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 1.0 in stage 237.0 (TID 396) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.409+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 0.0 in stage 237.0 (TID 395) in 74 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:06.415+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:19:06.482+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 2.0 in stage 237.0 (TID 397) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.482+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 1.0 in stage 237.0 (TID 396) in 73 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:06.490+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:19:06.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 3.0 in stage 237.0 (TID 398) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 2.0 in stage 237.0 (TID 397) in 83 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:06.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:19:06.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 4.0 in stage 237.0 (TID 399) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 3.0 in stage 237.0 (TID 398) in 67 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:06.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:19:06.685+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 5.0 in stage 237.0 (TID 400) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.685+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 4.0 in stage 237.0 (TID 399) in 55 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:06.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:19:06.749+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 6.0 in stage 237.0 (TID 401) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.749+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 5.0 in stage 237.0 (TID 400) in 65 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:06.756+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:19:06.814+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 7.0 in stage 237.0 (TID 402) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.815+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 6.0 in stage 237.0 (TID 401) in 65 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:06.823+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:19:06.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 8.0 in stage 237.0 (TID 403) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 7.0 in stage 237.0 (TID 402) in 75 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:06.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:19:06.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Starting task 9.0 in stage 237.0 (TID 404) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:06.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO TaskSetManager: Finished task 8.0 in stage 237.0 (TID 403) in 64 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:06.960+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:06 INFO BlockManagerInfo: Added rdd_323_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:07.031+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 9.0 in stage 237.0 (TID 404) in 79 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:07.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSchedulerImpl: Removed TaskSet 237.0, whose tasks have all completed, from pool
[2025-05-06T13:19:07.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: ShuffleMapStage 237 (mapPartitions at GraphImpl.scala:208) finished in 0.706 s
[2025-05-06T13:19:07.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:07.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:07.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: waiting: Set(ResultStage 238)
[2025-05-06T13:19:07.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:07.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Submitting ResultStage 238 (MapPartitionsRDD[333] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:07.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 15.4 KiB, free 425.8 MiB)
[2025-05-06T13:19:07.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 425.8 MiB)
[2025-05-06T13:19:07.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 016737cbcc7e:32777 in memory (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:07.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 016737cbcc7e:32777 (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T13:19:07.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:07.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.18.0.4:44293 in memory (size: 6.0 KiB, free: 175.6 MiB)
[2025-05-06T13:19:07.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 238 (MapPartitionsRDD[333] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:07.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSchedulerImpl: Adding task set 238.0 with 10 tasks resource profile 0
[2025-05-06T13:19:07.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 0.0 in stage 238.0 (TID 405) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.18.0.4:44293 (size: 6.2 KiB, free: 175.6 MiB)
[2025-05-06T13:19:07.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.18.0.4:59552
[2025-05-06T13:19:07.053+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_0 in memory on 172.18.0.4:44293 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:07.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 1.0 in stage 238.0 (TID 406) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 0.0 in stage 238.0 (TID 405) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:07.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_1 in memory on 172.18.0.4:44293 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:19:07.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 2.0 in stage 238.0 (TID 407) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 1.0 in stage 238.0 (TID 406) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:07.073+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_2 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:07.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 3.0 in stage 238.0 (TID 408) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.083+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 2.0 in stage 238.0 (TID 407) in 18 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:07.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_3 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:07.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 4.0 in stage 238.0 (TID 409) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 3.0 in stage 238.0 (TID 408) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:07.101+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_4 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.5 MiB)
[2025-05-06T13:19:07.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 5.0 in stage 238.0 (TID 410) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 4.0 in stage 238.0 (TID 409) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:07.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_5 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:07.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 6.0 in stage 238.0 (TID 411) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 5.0 in stage 238.0 (TID 410) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:07.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_6 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:19:07.122+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 7.0 in stage 238.0 (TID 412) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 6.0 in stage 238.0 (TID 411) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:07.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_7 in memory on 172.18.0.4:44293 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:19:07.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 8.0 in stage 238.0 (TID 413) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 7.0 in stage 238.0 (TID 412) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:07.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_8 in memory on 172.18.0.4:44293 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:19:07.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 9.0 in stage 238.0 (TID 414) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 8.0 in stage 238.0 (TID 413) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:07.145+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_331_9 in memory on 172.18.0.4:44293 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:19:07.146+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 9.0 in stage 238.0 (TID 414) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:07.146+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool
[2025-05-06T13:19:07.146+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: ResultStage 238 (fold at VertexRDDImpl.scala:90) finished in 0.114 s
[2025-05-06T13:19:07.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:07.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 238: Stage finished
[2025-05-06T13:19:07.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Job 48 finished: fold at VertexRDDImpl.scala:90, took 1.041860 s
[2025-05-06T13:19:07.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO Pregel: Pregel finished iteration 5
[2025-05-06T13:19:07.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO ZippedPartitionsRDD2: Removing RDD 314 from persistence list
[2025-05-06T13:19:07.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManager: Removing RDD 314
[2025-05-06T13:19:07.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO ZippedPartitionsRDD2: Removing RDD 300 from persistence list
[2025-05-06T13:19:07.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManager: Removing RDD 300
[2025-05-06T13:19:07.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO ZippedPartitionsRDD2: Removing RDD 306 from persistence list
[2025-05-06T13:19:07.149+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManager: Removing RDD 306
[2025-05-06T13:19:07.154+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO ZippedPartitionsRDD2: Removing RDD 283 from persistence list
[2025-05-06T13:19:07.154+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManager: Removing RDD 283
[2025-05-06T13:19:07.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO ZippedPartitionsRDD2: Removing RDD 289 from persistence list
[2025-05-06T13:19:07.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManager: Removing RDD 289
[2025-05-06T13:19:07.159+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO ZippedPartitionsRDD2: Removing RDD 297 from persistence list
[2025-05-06T13:19:07.159+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManager: Removing RDD 297
[2025-05-06T13:19:07.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:07.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Registering RDD 342 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 49
[2025-05-06T13:19:07.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Registering RDD 338 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 48
[2025-05-06T13:19:07.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Registering RDD 346 (mapPartitions at GraphImpl.scala:208) as input to shuffle 50
[2025-05-06T13:19:07.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Got job 49 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:07.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Final stage: ResultStage 271 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:07.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 255, ShuffleMapStage 270, ShuffleMapStage 249, ShuffleMapStage 267, ShuffleMapStage 252, ShuffleMapStage 246, ShuffleMapStage 261, ShuffleMapStage 240, ShuffleMapStage 258, ShuffleMapStage 264)
[2025-05-06T13:19:07.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 270)
[2025-05-06T13:19:07.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Submitting ShuffleMapStage 268 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[342] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:19:07.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 14.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:07.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:07.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 016737cbcc7e:32777 (size: 6.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:07.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 016737cbcc7e:32777 in memory (size: 48.1 KiB, free: 434.3 MiB)
[2025-05-06T13:19:07.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:07.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 268 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[342] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:07.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSchedulerImpl: Adding task set 268.0 with 10 tasks resource profile 0
[2025-05-06T13:19:07.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Submitting ShuffleMapStage 269 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:07.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 0.0 in stage 268.0 (TID 415) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.18.0.4:44293 in memory (size: 48.1 KiB, free: 181.2 MiB)
[2025-05-06T13:19:07.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 15.5 KiB, free 425.9 MiB)
[2025-05-06T13:19:07.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 425.9 MiB)
[2025-05-06T13:19:07.182+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 016737cbcc7e:32777 (size: 6.2 KiB, free: 434.3 MiB)
[2025-05-06T13:19:07.182+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:07.182+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 269 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[338] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:07.183+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSchedulerImpl: Adding task set 269.0 with 10 tasks resource profile 0
[2025-05-06T13:19:07.184+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 016737cbcc7e:32777 in memory (size: 6.2 KiB, free: 434.3 MiB)
[2025-05-06T13:19:07.184+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.18.0.4:44293 in memory (size: 6.2 KiB, free: 181.2 MiB)
[2025-05-06T13:19:07.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.18.0.4:44293 (size: 6.0 KiB, free: 181.2 MiB)
[2025-05-06T13:19:07.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 1.0 in stage 268.0 (TID 416) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 0.0 in stage 268.0 (TID 415) in 18 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:07.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 2.0 in stage 268.0 (TID 417) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 1.0 in stage 268.0 (TID 416) in 16 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:07.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 3.0 in stage 268.0 (TID 418) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 2.0 in stage 268.0 (TID 417) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:07.237+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 4.0 in stage 268.0 (TID 419) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.237+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 3.0 in stage 268.0 (TID 418) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:07.245+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 5.0 in stage 268.0 (TID 420) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.246+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 4.0 in stage 268.0 (TID 419) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:07.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 6.0 in stage 268.0 (TID 421) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 5.0 in stage 268.0 (TID 420) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:07.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 7.0 in stage 268.0 (TID 422) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 6.0 in stage 268.0 (TID 421) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:07.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 8.0 in stage 268.0 (TID 423) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 7.0 in stage 268.0 (TID 422) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:07.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 9.0 in stage 268.0 (TID 424) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 8.0 in stage 268.0 (TID 423) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:07.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 0.0 in stage 269.0 (TID 425) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 9.0 in stage 268.0 (TID 424) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:07.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool
[2025-05-06T13:19:07.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: ShuffleMapStage 268 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.124 s
[2025-05-06T13:19:07.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:07.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: running: Set(ShuffleMapStage 269)
[2025-05-06T13:19:07.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: waiting: Set(ShuffleMapStage 270, ResultStage 271)
[2025-05-06T13:19:07.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:07.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.18.0.4:44293 (size: 6.2 KiB, free: 181.2 MiB)
[2025-05-06T13:19:07.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:07.302+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 1.0 in stage 269.0 (TID 426) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 0.0 in stage 269.0 (TID 425) in 10 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:07.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:07.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 2.0 in stage 269.0 (TID 427) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 1.0 in stage 269.0 (TID 426) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:07.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:19:07.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 3.0 in stage 269.0 (TID 428) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 2.0 in stage 269.0 (TID 427) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:07.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:07.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 4.0 in stage 269.0 (TID 429) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 3.0 in stage 269.0 (TID 428) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:07.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:07.329+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 5.0 in stage 269.0 (TID 430) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.330+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 4.0 in stage 269.0 (TID 429) in 6 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:07.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:07.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 6.0 in stage 269.0 (TID 431) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 5.0 in stage 269.0 (TID 430) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:07.342+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:07.346+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 7.0 in stage 269.0 (TID 432) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.346+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 6.0 in stage 269.0 (TID 431) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:07.349+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:19:07.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 8.0 in stage 269.0 (TID 433) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 7.0 in stage 269.0 (TID 432) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:07.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:19:07.359+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 9.0 in stage 269.0 (TID 434) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.359+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 8.0 in stage 269.0 (TID 433) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:07.361+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_334_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:07.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 9.0 in stage 269.0 (TID 434) in 6 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:07.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool
[2025-05-06T13:19:07.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: ShuffleMapStage 269 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.186 s
[2025-05-06T13:19:07.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:07.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:07.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: waiting: Set(ShuffleMapStage 270, ResultStage 271)
[2025-05-06T13:19:07.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:07.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Submitting ShuffleMapStage 270 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[346] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:07.367+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 122.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:07.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 016737cbcc7e:32777 in memory (size: 6.0 KiB, free: 434.3 MiB)
[2025-05-06T13:19:07.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 425.8 MiB)
[2025-05-06T13:19:07.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 016737cbcc7e:32777 (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T13:19:07.374+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:07.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 270 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[346] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:07.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSchedulerImpl: Adding task set 270.0 with 10 tasks resource profile 0
[2025-05-06T13:19:07.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.18.0.4:44293 in memory (size: 6.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:07.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 0.0 in stage 270.0 (TID 435) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.18.0.4:44293 (size: 48.2 KiB, free: 181.0 MiB)
[2025-05-06T13:19:07.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.18.0.4:59552
[2025-05-06T13:19:07.387+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:19:07.388+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.18.0.4:59552
[2025-05-06T13:19:07.445+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 1.0 in stage 270.0 (TID 436) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.445+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 0.0 in stage 270.0 (TID 435) in 70 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:07.452+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:19:07.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 2.0 in stage 270.0 (TID 437) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 1.0 in stage 270.0 (TID 436) in 77 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:07.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:19:07.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 3.0 in stage 270.0 (TID 438) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 2.0 in stage 270.0 (TID 437) in 69 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:07.596+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:19:07.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 4.0 in stage 270.0 (TID 439) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 3.0 in stage 270.0 (TID 438) in 65 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:07.661+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:19:07.707+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 5.0 in stage 270.0 (TID 440) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.707+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 4.0 in stage 270.0 (TID 439) in 52 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:07.713+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:19:07.768+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 6.0 in stage 270.0 (TID 441) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.769+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 5.0 in stage 270.0 (TID 440) in 62 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:07.776+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:19:07.834+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 7.0 in stage 270.0 (TID 442) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.834+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 6.0 in stage 270.0 (TID 441) in 66 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:07.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:19:07.905+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 8.0 in stage 270.0 (TID 443) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.905+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 7.0 in stage 270.0 (TID 442) in 71 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:07.911+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:19:07.968+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Starting task 9.0 in stage 270.0 (TID 444) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:07.968+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO TaskSetManager: Finished task 8.0 in stage 270.0 (TID 443) in 64 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:07.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:07 INFO BlockManagerInfo: Added rdd_340_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:08.037+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 9.0 in stage 270.0 (TID 444) in 70 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:08.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool
[2025-05-06T13:19:08.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: ShuffleMapStage 270 (mapPartitions at GraphImpl.scala:208) finished in 0.672 s
[2025-05-06T13:19:08.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:08.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:08.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: waiting: Set(ResultStage 271)
[2025-05-06T13:19:08.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:08.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[350] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:08.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 16.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:08.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.8 MiB)
[2025-05-06T13:19:08.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 016737cbcc7e:32777 in memory (size: 6.2 KiB, free: 434.2 MiB)
[2025-05-06T13:19:08.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 016737cbcc7e:32777 (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:08.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:08.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 271 (MapPartitionsRDD[350] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:08.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSchedulerImpl: Adding task set 271.0 with 10 tasks resource profile 0
[2025-05-06T13:19:08.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.18.0.4:44293 in memory (size: 6.2 KiB, free: 175.6 MiB)
[2025-05-06T13:19:08.044+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 0.0 in stage 271.0 (TID 445) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.18.0.4:44293 (size: 6.3 KiB, free: 175.6 MiB)
[2025-05-06T13:19:08.050+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.18.0.4:59552
[2025-05-06T13:19:08.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_0 in memory on 172.18.0.4:44293 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:08.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 1.0 in stage 271.0 (TID 446) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 0.0 in stage 271.0 (TID 445) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:08.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_1 in memory on 172.18.0.4:44293 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:19:08.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 2.0 in stage 271.0 (TID 447) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 1.0 in stage 271.0 (TID 446) in 17 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:08.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_2 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:08.083+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 3.0 in stage 271.0 (TID 448) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.084+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 2.0 in stage 271.0 (TID 447) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:08.090+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_3 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:08.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 4.0 in stage 271.0 (TID 449) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 3.0 in stage 271.0 (TID 448) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:08.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_4 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.5 MiB)
[2025-05-06T13:19:08.100+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 5.0 in stage 271.0 (TID 450) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.101+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 4.0 in stage 271.0 (TID 449) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:08.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_5 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:08.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 6.0 in stage 271.0 (TID 451) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 5.0 in stage 271.0 (TID 450) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:08.116+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_6 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:19:08.118+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 7.0 in stage 271.0 (TID 452) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.118+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 6.0 in stage 271.0 (TID 451) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:08.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_7 in memory on 172.18.0.4:44293 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:19:08.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 8.0 in stage 271.0 (TID 453) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 7.0 in stage 271.0 (TID 452) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:08.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_8 in memory on 172.18.0.4:44293 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:19:08.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 9.0 in stage 271.0 (TID 454) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 8.0 in stage 271.0 (TID 453) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:08.140+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_348_9 in memory on 172.18.0.4:44293 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:19:08.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 9.0 in stage 271.0 (TID 454) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:08.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool
[2025-05-06T13:19:08.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: ResultStage 271 (fold at VertexRDDImpl.scala:90) finished in 0.104 s
[2025-05-06T13:19:08.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:08.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 271: Stage finished
[2025-05-06T13:19:08.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Job 49 finished: fold at VertexRDDImpl.scala:90, took 0.980408 s
[2025-05-06T13:19:08.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO Pregel: Pregel finished iteration 6
[2025-05-06T13:19:08.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO ZippedPartitionsRDD2: Removing RDD 331 from persistence list
[2025-05-06T13:19:08.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManager: Removing RDD 331
[2025-05-06T13:19:08.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO ZippedPartitionsRDD2: Removing RDD 317 from persistence list
[2025-05-06T13:19:08.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManager: Removing RDD 317
[2025-05-06T13:19:08.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO ZippedPartitionsRDD2: Removing RDD 323 from persistence list
[2025-05-06T13:19:08.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManager: Removing RDD 323
[2025-05-06T13:19:08.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO ZippedPartitionsRDD2: Removing RDD 300 from persistence list
[2025-05-06T13:19:08.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManager: Removing RDD 300
[2025-05-06T13:19:08.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO ZippedPartitionsRDD2: Removing RDD 306 from persistence list
[2025-05-06T13:19:08.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManager: Removing RDD 306
[2025-05-06T13:19:08.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO ZippedPartitionsRDD2: Removing RDD 314 from persistence list
[2025-05-06T13:19:08.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManager: Removing RDD 314
[2025-05-06T13:19:08.154+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:08.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Registering RDD 359 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 52
[2025-05-06T13:19:08.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Registering RDD 355 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 51
[2025-05-06T13:19:08.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Registering RDD 363 (mapPartitions at GraphImpl.scala:208) as input to shuffle 53
[2025-05-06T13:19:08.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Got job 50 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:08.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Final stage: ResultStage 307 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:08.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 273, ShuffleMapStage 291, ShuffleMapStage 303, ShuffleMapStage 300, ShuffleMapStage 306, ShuffleMapStage 285, ShuffleMapStage 288, ShuffleMapStage 282, ShuffleMapStage 279, ShuffleMapStage 294, ShuffleMapStage 297)
[2025-05-06T13:19:08.158+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 306)
[2025-05-06T13:19:08.158+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Submitting ShuffleMapStage 304 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[359] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:19:08.159+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 15.4 KiB, free 425.8 MiB)
[2025-05-06T13:19:08.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:08.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 016737cbcc7e:32777 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:08.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 016737cbcc7e:32777 in memory (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:08.167+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.18.0.4:44293 in memory (size: 6.3 KiB, free: 181.1 MiB)
[2025-05-06T13:19:08.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:08.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 304 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[359] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:08.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSchedulerImpl: Adding task set 304.0 with 10 tasks resource profile 0
[2025-05-06T13:19:08.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Submitting ShuffleMapStage 305 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[355] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:08.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 455) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 16.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:08.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.8 MiB)
[2025-05-06T13:19:08.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 016737cbcc7e:32777 (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:08.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:08.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 305 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[355] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:08.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSchedulerImpl: Adding task set 305.0 with 10 tasks resource profile 0
[2025-05-06T13:19:08.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 016737cbcc7e:32777 in memory (size: 48.2 KiB, free: 434.3 MiB)
[2025-05-06T13:19:08.175+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.18.0.4:44293 in memory (size: 48.2 KiB, free: 181.2 MiB)
[2025-05-06T13:19:08.177+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.18.0.4:44293 (size: 6.1 KiB, free: 181.2 MiB)
[2025-05-06T13:19:08.192+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 1.0 in stage 304.0 (TID 456) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.192+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 455) in 24 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:08.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 2.0 in stage 304.0 (TID 457) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 1.0 in stage 304.0 (TID 456) in 24 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:08.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 3.0 in stage 304.0 (TID 458) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 2.0 in stage 304.0 (TID 457) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:08.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 4.0 in stage 304.0 (TID 459) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 3.0 in stage 304.0 (TID 458) in 12 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:08.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 5.0 in stage 304.0 (TID 460) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 4.0 in stage 304.0 (TID 459) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:08.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 6.0 in stage 304.0 (TID 461) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 5.0 in stage 304.0 (TID 460) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:08.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 7.0 in stage 304.0 (TID 462) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.275+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 6.0 in stage 304.0 (TID 461) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:08.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 8.0 in stage 304.0 (TID 463) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.284+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 7.0 in stage 304.0 (TID 462) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:08.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 9.0 in stage 304.0 (TID 464) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.298+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 8.0 in stage 304.0 (TID 463) in 15 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:08.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 0.0 in stage 305.0 (TID 465) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 9.0 in stage 304.0 (TID 464) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:08.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool
[2025-05-06T13:19:08.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: ShuffleMapStage 304 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.151 s
[2025-05-06T13:19:08.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:08.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: running: Set(ShuffleMapStage 305)
[2025-05-06T13:19:08.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 306, ResultStage 307)
[2025-05-06T13:19:08.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:08.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.18.0.4:44293 (size: 6.3 KiB, free: 181.2 MiB)
[2025-05-06T13:19:08.316+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:08.318+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 1.0 in stage 305.0 (TID 466) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 0.0 in stage 305.0 (TID 465) in 9 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:08.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:08.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 2.0 in stage 305.0 (TID 467) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 1.0 in stage 305.0 (TID 466) in 6 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:08.327+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:19:08.330+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 3.0 in stage 305.0 (TID 468) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.330+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 2.0 in stage 305.0 (TID 467) in 6 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:08.333+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:08.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 4.0 in stage 305.0 (TID 469) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 3.0 in stage 305.0 (TID 468) in 6 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:08.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:08.342+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 5.0 in stage 305.0 (TID 470) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.342+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 4.0 in stage 305.0 (TID 469) in 6 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:08.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:08.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 6.0 in stage 305.0 (TID 471) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 5.0 in stage 305.0 (TID 470) in 6 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:08.350+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:08.355+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 7.0 in stage 305.0 (TID 472) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.355+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 6.0 in stage 305.0 (TID 471) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:08.358+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:19:08.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 8.0 in stage 305.0 (TID 473) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 7.0 in stage 305.0 (TID 472) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:08.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:19:08.370+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 9.0 in stage 305.0 (TID 474) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.370+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 8.0 in stage 305.0 (TID 473) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:08.373+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_351_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:08.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 9.0 in stage 305.0 (TID 474) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:08.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSchedulerImpl: Removed TaskSet 305.0, whose tasks have all completed, from pool
[2025-05-06T13:19:08.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: ShuffleMapStage 305 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.207 s
[2025-05-06T13:19:08.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:08.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:08.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 306, ResultStage 307)
[2025-05-06T13:19:08.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:08.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Submitting ShuffleMapStage 306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[363] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:08.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 122.4 KiB, free 425.8 MiB)
[2025-05-06T13:19:08.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 016737cbcc7e:32777 in memory (size: 6.1 KiB, free: 434.3 MiB)
[2025-05-06T13:19:08.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 48.5 KiB, free 425.8 MiB)
[2025-05-06T13:19:08.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 016737cbcc7e:32777 (size: 48.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:08.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:08.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[363] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:08.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSchedulerImpl: Adding task set 306.0 with 10 tasks resource profile 0
[2025-05-06T13:19:08.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.18.0.4:44293 in memory (size: 6.1 KiB, free: 181.0 MiB)
[2025-05-06T13:19:08.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 0.0 in stage 306.0 (TID 475) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.18.0.4:44293 (size: 48.5 KiB, free: 181.0 MiB)
[2025-05-06T13:19:08.393+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.18.0.4:59552
[2025-05-06T13:19:08.396+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:19:08.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.18.0.4:59552
[2025-05-06T13:19:08.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 1.0 in stage 306.0 (TID 476) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 0.0 in stage 306.0 (TID 475) in 70 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:08.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:19:08.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 2.0 in stage 306.0 (TID 477) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 1.0 in stage 306.0 (TID 476) in 73 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:08.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:19:08.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 3.0 in stage 306.0 (TID 478) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 2.0 in stage 306.0 (TID 477) in 64 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:08.596+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:19:08.652+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 4.0 in stage 306.0 (TID 479) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.652+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 3.0 in stage 306.0 (TID 478) in 62 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:08.657+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:19:08.703+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 5.0 in stage 306.0 (TID 480) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.704+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 4.0 in stage 306.0 (TID 479) in 51 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:08.709+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:19:08.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 6.0 in stage 306.0 (TID 481) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 5.0 in stage 306.0 (TID 480) in 60 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:08.768+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:19:08.824+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 7.0 in stage 306.0 (TID 482) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.824+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 6.0 in stage 306.0 (TID 481) in 62 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:08.830+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:19:08.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 8.0 in stage 306.0 (TID 483) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 7.0 in stage 306.0 (TID 482) in 67 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:08.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:19:08.952+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Starting task 9.0 in stage 306.0 (TID 484) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:08.952+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO TaskSetManager: Finished task 8.0 in stage 306.0 (TID 483) in 62 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:08.958+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:08 INFO BlockManagerInfo: Added rdd_357_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:09.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 9.0 in stage 306.0 (TID 484) in 70 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:09.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool
[2025-05-06T13:19:09.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: ShuffleMapStage 306 (mapPartitions at GraphImpl.scala:208) finished in 0.645 s
[2025-05-06T13:19:09.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:09.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:09.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: waiting: Set(ResultStage 307)
[2025-05-06T13:19:09.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:09.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Submitting ResultStage 307 (MapPartitionsRDD[367] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:09.023+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 16.7 KiB, free 425.8 MiB)
[2025-05-06T13:19:09.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 425.8 MiB)
[2025-05-06T13:19:09.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 016737cbcc7e:32777 in memory (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:09.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 016737cbcc7e:32777 (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:09.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:09.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 307 (MapPartitionsRDD[367] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:09.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSchedulerImpl: Adding task set 307.0 with 10 tasks resource profile 0
[2025-05-06T13:19:09.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.18.0.4:44293 in memory (size: 6.3 KiB, free: 175.6 MiB)
[2025-05-06T13:19:09.030+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 0.0 in stage 307.0 (TID 485) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.18.0.4:44293 (size: 6.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:09.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.18.0.4:59552
[2025-05-06T13:19:09.041+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_0 in memory on 172.18.0.4:44293 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:09.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 1.0 in stage 307.0 (TID 486) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 0.0 in stage 307.0 (TID 485) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:09.050+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_1 in memory on 172.18.0.4:44293 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:19:09.052+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 2.0 in stage 307.0 (TID 487) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.052+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 1.0 in stage 307.0 (TID 486) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:09.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_2 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:09.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 3.0 in stage 307.0 (TID 488) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 2.0 in stage 307.0 (TID 487) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:09.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_3 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:09.076+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 4.0 in stage 307.0 (TID 489) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.076+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 3.0 in stage 307.0 (TID 488) in 16 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:09.083+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_4 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:09.084+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 5.0 in stage 307.0 (TID 490) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.085+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 4.0 in stage 307.0 (TID 489) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:09.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_5 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:09.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 6.0 in stage 307.0 (TID 491) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 5.0 in stage 307.0 (TID 490) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:09.101+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_6 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:19:09.102+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 7.0 in stage 307.0 (TID 492) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.102+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 6.0 in stage 307.0 (TID 491) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:09.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_7 in memory on 172.18.0.4:44293 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:19:09.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 8.0 in stage 307.0 (TID 493) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 7.0 in stage 307.0 (TID 492) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:09.117+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_8 in memory on 172.18.0.4:44293 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:19:09.118+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 9.0 in stage 307.0 (TID 494) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 8.0 in stage 307.0 (TID 493) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:09.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_365_9 in memory on 172.18.0.4:44293 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:19:09.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 9.0 in stage 307.0 (TID 494) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:09.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSchedulerImpl: Removed TaskSet 307.0, whose tasks have all completed, from pool
[2025-05-06T13:19:09.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: ResultStage 307 (fold at VertexRDDImpl.scala:90) finished in 0.104 s
[2025-05-06T13:19:09.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:09.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 307: Stage finished
[2025-05-06T13:19:09.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Job 50 finished: fold at VertexRDDImpl.scala:90, took 0.972704 s
[2025-05-06T13:19:09.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO Pregel: Pregel finished iteration 7
[2025-05-06T13:19:09.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO ZippedPartitionsRDD2: Removing RDD 348 from persistence list
[2025-05-06T13:19:09.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManager: Removing RDD 348
[2025-05-06T13:19:09.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO ZippedPartitionsRDD2: Removing RDD 334 from persistence list
[2025-05-06T13:19:09.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManager: Removing RDD 334
[2025-05-06T13:19:09.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO ZippedPartitionsRDD2: Removing RDD 340 from persistence list
[2025-05-06T13:19:09.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManager: Removing RDD 340
[2025-05-06T13:19:09.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO ZippedPartitionsRDD2: Removing RDD 317 from persistence list
[2025-05-06T13:19:09.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManager: Removing RDD 317
[2025-05-06T13:19:09.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO ZippedPartitionsRDD2: Removing RDD 323 from persistence list
[2025-05-06T13:19:09.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManager: Removing RDD 323
[2025-05-06T13:19:09.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO ZippedPartitionsRDD2: Removing RDD 331 from persistence list
[2025-05-06T13:19:09.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManager: Removing RDD 331
[2025-05-06T13:19:09.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:09.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Registering RDD 376 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 55
[2025-05-06T13:19:09.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Registering RDD 372 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 54
[2025-05-06T13:19:09.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Registering RDD 380 (mapPartitions at GraphImpl.scala:208) as input to shuffle 56
[2025-05-06T13:19:09.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Got job 51 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:09.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Final stage: ResultStage 346 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:09.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 342, ShuffleMapStage 339, ShuffleMapStage 318, ShuffleMapStage 336, ShuffleMapStage 321, ShuffleMapStage 324, ShuffleMapStage 315, ShuffleMapStage 330, ShuffleMapStage 309, ShuffleMapStage 345, ShuffleMapStage 327, ShuffleMapStage 333)
[2025-05-06T13:19:09.148+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 345)
[2025-05-06T13:19:09.149+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Submitting ShuffleMapStage 343 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[376] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:19:09.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 16.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:09.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 425.8 MiB)
[2025-05-06T13:19:09.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 016737cbcc7e:32777 in memory (size: 48.5 KiB, free: 434.3 MiB)
[2025-05-06T13:19:09.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 016737cbcc7e:32777 (size: 6.2 KiB, free: 434.3 MiB)
[2025-05-06T13:19:09.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:09.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 343 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[376] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:09.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSchedulerImpl: Adding task set 343.0 with 10 tasks resource profile 0
[2025-05-06T13:19:09.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Submitting ShuffleMapStage 344 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[372] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:09.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 0.0 in stage 343.0 (TID 495) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.18.0.4:44293 in memory (size: 48.5 KiB, free: 181.2 MiB)
[2025-05-06T13:19:09.158+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 16.7 KiB, free 425.9 MiB)
[2025-05-06T13:19:09.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 425.9 MiB)
[2025-05-06T13:19:09.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 016737cbcc7e:32777 (size: 6.4 KiB, free: 434.3 MiB)
[2025-05-06T13:19:09.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:09.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 344 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[372] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:09.160+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSchedulerImpl: Adding task set 344.0 with 10 tasks resource profile 0
[2025-05-06T13:19:09.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 016737cbcc7e:32777 in memory (size: 6.4 KiB, free: 434.3 MiB)
[2025-05-06T13:19:09.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.18.0.4:44293 in memory (size: 6.4 KiB, free: 181.2 MiB)
[2025-05-06T13:19:09.163+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.18.0.4:44293 (size: 6.2 KiB, free: 181.2 MiB)
[2025-05-06T13:19:09.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 1.0 in stage 343.0 (TID 496) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 0.0 in stage 343.0 (TID 495) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:09.181+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 2.0 in stage 343.0 (TID 497) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.182+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 1.0 in stage 343.0 (TID 496) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:09.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 3.0 in stage 343.0 (TID 498) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 2.0 in stage 343.0 (TID 497) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:09.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 4.0 in stage 343.0 (TID 499) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.208+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 3.0 in stage 343.0 (TID 498) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:09.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 5.0 in stage 343.0 (TID 500) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 4.0 in stage 343.0 (TID 499) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:09.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 6.0 in stage 343.0 (TID 501) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 5.0 in stage 343.0 (TID 500) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:09.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 7.0 in stage 343.0 (TID 502) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.233+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 6.0 in stage 343.0 (TID 501) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:09.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 8.0 in stage 343.0 (TID 503) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 7.0 in stage 343.0 (TID 502) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:09.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 9.0 in stage 343.0 (TID 504) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 8.0 in stage 343.0 (TID 503) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:09.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 0.0 in stage 344.0 (TID 505) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 9.0 in stage 343.0 (TID 504) in 14 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:09.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSchedulerImpl: Removed TaskSet 343.0, whose tasks have all completed, from pool
[2025-05-06T13:19:09.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: ShuffleMapStage 343 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.113 s
[2025-05-06T13:19:09.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:09.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: running: Set(ShuffleMapStage 344)
[2025-05-06T13:19:09.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 345, ResultStage 346)
[2025-05-06T13:19:09.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:09.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.18.0.4:44293 (size: 6.4 KiB, free: 181.2 MiB)
[2025-05-06T13:19:09.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:09.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 1.0 in stage 344.0 (TID 506) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 0.0 in stage 344.0 (TID 505) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:09.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:09.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 2.0 in stage 344.0 (TID 507) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 1.0 in stage 344.0 (TID 506) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:09.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:19:09.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 3.0 in stage 344.0 (TID 508) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 2.0 in stage 344.0 (TID 507) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:09.290+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:09.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 4.0 in stage 344.0 (TID 509) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 3.0 in stage 344.0 (TID 508) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:09.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:09.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 5.0 in stage 344.0 (TID 510) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 4.0 in stage 344.0 (TID 509) in 7 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:09.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:09.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 6.0 in stage 344.0 (TID 511) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 5.0 in stage 344.0 (TID 510) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:09.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:09.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 7.0 in stage 344.0 (TID 512) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 6.0 in stage 344.0 (TID 511) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:09.318+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:19:09.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 8.0 in stage 344.0 (TID 513) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 7.0 in stage 344.0 (TID 512) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:09.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:19:09.329+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 9.0 in stage 344.0 (TID 514) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.330+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 8.0 in stage 344.0 (TID 513) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:09.333+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_368_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:09.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 9.0 in stage 344.0 (TID 514) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:09.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool
[2025-05-06T13:19:09.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: ShuffleMapStage 344 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.179 s
[2025-05-06T13:19:09.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:09.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:09.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 345, ResultStage 346)
[2025-05-06T13:19:09.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:09.337+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Submitting ShuffleMapStage 345 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[380] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:09.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 122.7 KiB, free 425.8 MiB)
[2025-05-06T13:19:09.346+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 48.4 KiB, free 425.8 MiB)
[2025-05-06T13:19:09.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 016737cbcc7e:32777 in memory (size: 6.2 KiB, free: 434.3 MiB)
[2025-05-06T13:19:09.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 016737cbcc7e:32777 (size: 48.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:09.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.18.0.4:44293 in memory (size: 6.2 KiB, free: 181.0 MiB)
[2025-05-06T13:19:09.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:09.347+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 345 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[380] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:09.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSchedulerImpl: Adding task set 345.0 with 10 tasks resource profile 0
[2025-05-06T13:19:09.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 0.0 in stage 345.0 (TID 515) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.18.0.4:44293 (size: 48.4 KiB, free: 181.0 MiB)
[2025-05-06T13:19:09.360+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.18.0.4:59552
[2025-05-06T13:19:09.363+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:19:09.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.18.0.4:59552
[2025-05-06T13:19:09.431+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 1.0 in stage 345.0 (TID 516) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.431+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 0.0 in stage 345.0 (TID 515) in 83 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:09.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:19:09.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 2.0 in stage 345.0 (TID 517) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 1.0 in stage 345.0 (TID 516) in 78 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:09.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:19:09.573+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 3.0 in stage 345.0 (TID 518) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.573+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 2.0 in stage 345.0 (TID 517) in 65 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:09.579+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:19:09.632+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 4.0 in stage 345.0 (TID 519) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.632+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 3.0 in stage 345.0 (TID 518) in 59 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:09.640+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:19:09.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 5.0 in stage 345.0 (TID 520) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 4.0 in stage 345.0 (TID 519) in 52 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:09.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:19:09.741+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 6.0 in stage 345.0 (TID 521) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.742+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 5.0 in stage 345.0 (TID 520) in 58 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:09.747+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:19:09.801+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 7.0 in stage 345.0 (TID 522) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.802+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 6.0 in stage 345.0 (TID 521) in 60 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:09.807+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:19:09.868+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 8.0 in stage 345.0 (TID 523) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.868+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 7.0 in stage 345.0 (TID 522) in 67 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:09.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:19:09.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Starting task 9.0 in stage 345.0 (TID 524) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5286 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:09.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO TaskSetManager: Finished task 8.0 in stage 345.0 (TID 523) in 63 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:09.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:09 INFO BlockManagerInfo: Added rdd_374_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.006+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 9.0 in stage 345.0 (TID 524) in 76 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:10.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Removed TaskSet 345.0, whose tasks have all completed, from pool
[2025-05-06T13:19:10.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: ShuffleMapStage 345 (mapPartitions at GraphImpl.scala:208) finished in 0.669 s
[2025-05-06T13:19:10.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:10.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:10.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: waiting: Set(ResultStage 346)
[2025-05-06T13:19:10.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:10.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting ResultStage 346 (MapPartitionsRDD[384] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:10.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 17.3 KiB, free 425.8 MiB)
[2025-05-06T13:19:10.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 425.8 MiB)
[2025-05-06T13:19:10.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 016737cbcc7e:32777 in memory (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:10.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 016737cbcc7e:32777 (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:10.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:10.013+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 346 (MapPartitionsRDD[384] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:10.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Adding task set 346.0 with 10 tasks resource profile 0
[2025-05-06T13:19:10.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.18.0.4:44293 in memory (size: 6.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 0.0 in stage 346.0 (TID 525) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.018+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.18.0.4:44293 (size: 6.5 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.18.0.4:59552
[2025-05-06T13:19:10.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_0 in memory on 172.18.0.4:44293 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.026+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 1.0 in stage 346.0 (TID 526) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 0.0 in stage 346.0 (TID 525) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:10.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_1 in memory on 172.18.0.4:44293 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 2.0 in stage 346.0 (TID 527) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.035+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 1.0 in stage 346.0 (TID 526) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:10.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_2 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:10.050+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 3.0 in stage 346.0 (TID 528) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.051+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 2.0 in stage 346.0 (TID 527) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:10.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_3 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:10.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 4.0 in stage 346.0 (TID 529) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 3.0 in stage 346.0 (TID 528) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:10.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_4 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:10.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 5.0 in stage 346.0 (TID 530) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 4.0 in stage 346.0 (TID 529) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:10.073+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_5 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:10.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 6.0 in stage 346.0 (TID 531) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 5.0 in stage 346.0 (TID 530) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:10.080+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_6 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:19:10.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 7.0 in stage 346.0 (TID 532) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.082+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 6.0 in stage 346.0 (TID 531) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:10.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_7 in memory on 172.18.0.4:44293 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:19:10.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 8.0 in stage 346.0 (TID 533) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.090+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 7.0 in stage 346.0 (TID 532) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:10.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_8 in memory on 172.18.0.4:44293 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:19:10.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 9.0 in stage 346.0 (TID 534) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 8.0 in stage 346.0 (TID 533) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:10.103+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_382_9 in memory on 172.18.0.4:44293 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:19:10.104+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 9.0 in stage 346.0 (TID 534) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:10.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool
[2025-05-06T13:19:10.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: ResultStage 346 (fold at VertexRDDImpl.scala:90) finished in 0.097 s
[2025-05-06T13:19:10.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:10.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 346: Stage finished
[2025-05-06T13:19:10.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Job 51 finished: fold at VertexRDDImpl.scala:90, took 0.961380 s
[2025-05-06T13:19:10.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO Pregel: Pregel finished iteration 8
[2025-05-06T13:19:10.105+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO ZippedPartitionsRDD2: Removing RDD 365 from persistence list
[2025-05-06T13:19:10.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManager: Removing RDD 365
[2025-05-06T13:19:10.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO ZippedPartitionsRDD2: Removing RDD 351 from persistence list
[2025-05-06T13:19:10.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManager: Removing RDD 351
[2025-05-06T13:19:10.107+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO ZippedPartitionsRDD2: Removing RDD 357 from persistence list
[2025-05-06T13:19:10.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManager: Removing RDD 357
[2025-05-06T13:19:10.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO ZippedPartitionsRDD2: Removing RDD 334 from persistence list
[2025-05-06T13:19:10.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManager: Removing RDD 334
[2025-05-06T13:19:10.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO ZippedPartitionsRDD2: Removing RDD 340 from persistence list
[2025-05-06T13:19:10.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManager: Removing RDD 340
[2025-05-06T13:19:10.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO ZippedPartitionsRDD2: Removing RDD 348 from persistence list
[2025-05-06T13:19:10.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManager: Removing RDD 348
[2025-05-06T13:19:10.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:10.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Registering RDD 393 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 58
[2025-05-06T13:19:10.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Registering RDD 389 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 57
[2025-05-06T13:19:10.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Registering RDD 397 (mapPartitions at GraphImpl.scala:208) as input to shuffle 59
[2025-05-06T13:19:10.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Got job 52 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:10.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Final stage: ResultStage 388 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:10.124+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 357, ShuffleMapStage 375, ShuffleMapStage 369, ShuffleMapStage 387, ShuffleMapStage 354, ShuffleMapStage 372, ShuffleMapStage 348, ShuffleMapStage 384, ShuffleMapStage 378, ShuffleMapStage 366, ShuffleMapStage 381, ShuffleMapStage 360, ShuffleMapStage 363)
[2025-05-06T13:19:10.124+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 387)
[2025-05-06T13:19:10.124+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting ShuffleMapStage 385 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[393] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-06T13:19:10.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 16.7 KiB, free 425.8 MiB)
[2025-05-06T13:19:10.132+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.7 MiB)
[2025-05-06T13:19:10.132+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 016737cbcc7e:32777 (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:10.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 016737cbcc7e:32777 in memory (size: 48.4 KiB, free: 434.3 MiB)
[2025-05-06T13:19:10.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:10.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 385 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[393] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:10.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Adding task set 385.0 with 10 tasks resource profile 0
[2025-05-06T13:19:10.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting ShuffleMapStage 386 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[389] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:10.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.18.0.4:44293 in memory (size: 48.4 KiB, free: 181.2 MiB)
[2025-05-06T13:19:10.134+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 0.0 in stage 385.0 (TID 535) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 17.4 KiB, free 425.9 MiB)
[2025-05-06T13:19:10.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 425.9 MiB)
[2025-05-06T13:19:10.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 016737cbcc7e:32777 (size: 6.5 KiB, free: 434.3 MiB)
[2025-05-06T13:19:10.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 016737cbcc7e:32777 in memory (size: 6.5 KiB, free: 434.3 MiB)
[2025-05-06T13:19:10.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:10.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.18.0.4:44293 in memory (size: 6.5 KiB, free: 181.2 MiB)
[2025-05-06T13:19:10.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 386 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[389] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:10.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Adding task set 386.0 with 10 tasks resource profile 0
[2025-05-06T13:19:10.144+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.18.0.4:44293 (size: 6.3 KiB, free: 181.2 MiB)
[2025-05-06T13:19:10.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 1.0 in stage 385.0 (TID 536) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 0.0 in stage 385.0 (TID 535) in 22 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:10.170+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 2.0 in stage 385.0 (TID 537) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.171+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 1.0 in stage 385.0 (TID 536) in 14 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:10.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 3.0 in stage 385.0 (TID 538) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.180+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 2.0 in stage 385.0 (TID 537) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:10.188+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 4.0 in stage 385.0 (TID 539) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.188+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 3.0 in stage 385.0 (TID 538) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:10.197+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 5.0 in stage 385.0 (TID 540) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.197+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 4.0 in stage 385.0 (TID 539) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:10.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 6.0 in stage 385.0 (TID 541) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 5.0 in stage 385.0 (TID 540) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:10.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 7.0 in stage 385.0 (TID 542) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 6.0 in stage 385.0 (TID 541) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:10.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 8.0 in stage 385.0 (TID 543) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 7.0 in stage 385.0 (TID 542) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:10.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 9.0 in stage 385.0 (TID 544) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.233+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 8.0 in stage 385.0 (TID 543) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:10.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 0.0 in stage 386.0 (TID 545) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 9.0 in stage 385.0 (TID 544) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:10.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Removed TaskSet 385.0, whose tasks have all completed, from pool
[2025-05-06T13:19:10.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: ShuffleMapStage 385 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.116 s
[2025-05-06T13:19:10.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:10.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: running: Set(ShuffleMapStage 386)
[2025-05-06T13:19:10.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 387, ResultStage 388)
[2025-05-06T13:19:10.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:10.245+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.18.0.4:44293 (size: 6.5 KiB, free: 181.2 MiB)
[2025-05-06T13:19:10.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 181.2 MiB)
[2025-05-06T13:19:10.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 1.0 in stage 386.0 (TID 546) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 0.0 in stage 386.0 (TID 545) in 9 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:10.253+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 181.2 MiB)
[2025-05-06T13:19:10.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 2.0 in stage 386.0 (TID 547) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 1.0 in stage 386.0 (TID 546) in 5 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:10.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 181.1 MiB)
[2025-05-06T13:19:10.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 3.0 in stage 386.0 (TID 548) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.260+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 2.0 in stage 386.0 (TID 547) in 5 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:10.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:10.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 4.0 in stage 386.0 (TID 549) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 3.0 in stage 386.0 (TID 548) in 6 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:10.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:10.271+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 5.0 in stage 386.0 (TID 550) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.272+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 4.0 in stage 386.0 (TID 549) in 5 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:10.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 181.1 MiB)
[2025-05-06T13:19:10.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 6.0 in stage 386.0 (TID 551) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 5.0 in stage 386.0 (TID 550) in 6 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:10.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 181.1 MiB)
[2025-05-06T13:19:10.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 7.0 in stage 386.0 (TID 552) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 6.0 in stage 386.0 (TID 551) in 6 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:10.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 181.1 MiB)
[2025-05-06T13:19:10.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 8.0 in stage 386.0 (TID 553) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 7.0 in stage 386.0 (TID 552) in 5 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:10.290+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 181.1 MiB)
[2025-05-06T13:19:10.292+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 9.0 in stage 386.0 (TID 554) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.293+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 8.0 in stage 386.0 (TID 553) in 5 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:10.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_385_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 181.0 MiB)
[2025-05-06T13:19:10.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 9.0 in stage 386.0 (TID 554) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:10.299+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool
[2025-05-06T13:19:10.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: ShuffleMapStage 386 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.165 s
[2025-05-06T13:19:10.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:10.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:10.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 387, ResultStage 388)
[2025-05-06T13:19:10.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:10.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting ShuffleMapStage 387 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[397] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:10.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 123.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:10.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 016737cbcc7e:32777 in memory (size: 6.3 KiB, free: 434.3 MiB)
[2025-05-06T13:19:10.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 48.5 KiB, free 425.8 MiB)
[2025-05-06T13:19:10.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 016737cbcc7e:32777 (size: 48.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:10.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:10.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.18.0.4:44293 in memory (size: 6.3 KiB, free: 181.0 MiB)
[2025-05-06T13:19:10.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 387 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[397] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:10.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Adding task set 387.0 with 10 tasks resource profile 0
[2025-05-06T13:19:10.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 0.0 in stage 387.0 (TID 555) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.314+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.18.0.4:44293 (size: 48.5 KiB, free: 181.0 MiB)
[2025-05-06T13:19:10.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 172.18.0.4:59552
[2025-05-06T13:19:10.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_0 in memory on 172.18.0.4:44293 (size: 498.7 KiB, free: 180.5 MiB)
[2025-05-06T13:19:10.322+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.18.0.4:59552
[2025-05-06T13:19:10.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 1.0 in stage 387.0 (TID 556) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 0.0 in stage 387.0 (TID 555) in 76 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:10.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_1 in memory on 172.18.0.4:44293 (size: 622.4 KiB, free: 179.9 MiB)
[2025-05-06T13:19:10.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 2.0 in stage 387.0 (TID 557) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 1.0 in stage 387.0 (TID 556) in 69 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:10.459+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_2 in memory on 172.18.0.4:44293 (size: 563.5 KiB, free: 179.4 MiB)
[2025-05-06T13:19:10.518+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 3.0 in stage 387.0 (TID 558) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.518+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 2.0 in stage 387.0 (TID 557) in 65 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:10.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_3 in memory on 172.18.0.4:44293 (size: 540.2 KiB, free: 178.8 MiB)
[2025-05-06T13:19:10.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 4.0 in stage 387.0 (TID 559) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 3.0 in stage 387.0 (TID 558) in 63 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:10.587+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_4 in memory on 172.18.0.4:44293 (size: 452.3 KiB, free: 178.4 MiB)
[2025-05-06T13:19:10.635+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 5.0 in stage 387.0 (TID 560) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.635+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 4.0 in stage 387.0 (TID 559) in 54 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:10.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_5 in memory on 172.18.0.4:44293 (size: 526.8 KiB, free: 177.9 MiB)
[2025-05-06T13:19:10.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 6.0 in stage 387.0 (TID 561) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.694+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 5.0 in stage 387.0 (TID 560) in 59 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:10.700+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_6 in memory on 172.18.0.4:44293 (size: 534.2 KiB, free: 177.3 MiB)
[2025-05-06T13:19:10.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 7.0 in stage 387.0 (TID 562) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.755+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 6.0 in stage 387.0 (TID 561) in 61 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:10.760+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_7 in memory on 172.18.0.4:44293 (size: 601.0 KiB, free: 176.8 MiB)
[2025-05-06T13:19:10.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 8.0 in stage 387.0 (TID 563) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.828+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 7.0 in stage 387.0 (TID 562) in 73 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:10.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_8 in memory on 172.18.0.4:44293 (size: 548.7 KiB, free: 176.2 MiB)
[2025-05-06T13:19:10.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 9.0 in stage 387.0 (TID 564) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5327 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 8.0 in stage 387.0 (TID 563) in 62 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:10.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_391_9 in memory on 172.18.0.4:44293 (size: 614.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 9.0 in stage 387.0 (TID 564) in 65 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:10.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Removed TaskSet 387.0, whose tasks have all completed, from pool
[2025-05-06T13:19:10.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: ShuffleMapStage 387 (mapPartitions at GraphImpl.scala:208) finished in 0.654 s
[2025-05-06T13:19:10.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:10.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:10.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: waiting: Set(ResultStage 388)
[2025-05-06T13:19:10.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:10.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting ResultStage 388 (MapPartitionsRDD[401] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:10.956+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 18.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:10.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 425.8 MiB)
[2025-05-06T13:19:10.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 016737cbcc7e:32777 in memory (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:10.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 016737cbcc7e:32777 (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:10.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:10.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 388 (MapPartitionsRDD[401] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:10.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSchedulerImpl: Adding task set 388.0 with 10 tasks resource profile 0
[2025-05-06T13:19:10.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.18.0.4:44293 in memory (size: 6.5 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.962+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 0.0 in stage 388.0 (TID 565) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.18.0.4:44293 (size: 6.6 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.969+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.18.0.4:59552
[2025-05-06T13:19:10.976+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_399_0 in memory on 172.18.0.4:44293 (size: 36.4 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 1.0 in stage 388.0 (TID 566) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 0.0 in stage 388.0 (TID 565) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:10.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_399_1 in memory on 172.18.0.4:44293 (size: 35.8 KiB, free: 175.6 MiB)
[2025-05-06T13:19:10.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Starting task 2.0 in stage 388.0 (TID 567) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:10.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO TaskSetManager: Finished task 1.0 in stage 388.0 (TID 566) in 15 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:11.000+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:10 INFO BlockManagerInfo: Added rdd_399_2 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:11.001+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 3.0 in stage 388.0 (TID 568) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.001+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 2.0 in stage 388.0 (TID 567) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:11.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_399_3 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.5 MiB)
[2025-05-06T13:19:11.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 4.0 in stage 388.0 (TID 569) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 3.0 in stage 388.0 (TID 568) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:11.015+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_399_4 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:11.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 5.0 in stage 388.0 (TID 570) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 4.0 in stage 388.0 (TID 569) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:11.023+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_399_5 in memory on 172.18.0.4:44293 (size: 35.1 KiB, free: 175.4 MiB)
[2025-05-06T13:19:11.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 6.0 in stage 388.0 (TID 571) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 5.0 in stage 388.0 (TID 570) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:11.031+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_399_6 in memory on 172.18.0.4:44293 (size: 34.8 KiB, free: 175.4 MiB)
[2025-05-06T13:19:11.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 7.0 in stage 388.0 (TID 572) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.033+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 6.0 in stage 388.0 (TID 571) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:11.039+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_399_7 in memory on 172.18.0.4:44293 (size: 34.9 KiB, free: 175.3 MiB)
[2025-05-06T13:19:11.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 8.0 in stage 388.0 (TID 573) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 7.0 in stage 388.0 (TID 572) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:11.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_399_8 in memory on 172.18.0.4:44293 (size: 34.4 KiB, free: 175.3 MiB)
[2025-05-06T13:19:11.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 9.0 in stage 388.0 (TID 574) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 8.0 in stage 388.0 (TID 573) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:11.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_399_9 in memory on 172.18.0.4:44293 (size: 33.3 KiB, free: 175.3 MiB)
[2025-05-06T13:19:11.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 9.0 in stage 388.0 (TID 574) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:11.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Removed TaskSet 388.0, whose tasks have all completed, from pool
[2025-05-06T13:19:11.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: ResultStage 388 (fold at VertexRDDImpl.scala:90) finished in 0.101 s
[2025-05-06T13:19:11.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:11.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 388: Stage finished
[2025-05-06T13:19:11.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Job 52 finished: fold at VertexRDDImpl.scala:90, took 0.938238 s
[2025-05-06T13:19:11.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO Pregel: Pregel finished iteration 9
[2025-05-06T13:19:11.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO ZippedPartitionsRDD2: Removing RDD 382 from persistence list
[2025-05-06T13:19:11.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManager: Removing RDD 382
[2025-05-06T13:19:11.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO ZippedPartitionsRDD2: Removing RDD 368 from persistence list
[2025-05-06T13:19:11.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManager: Removing RDD 368
[2025-05-06T13:19:11.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO ZippedPartitionsRDD2: Removing RDD 374 from persistence list
[2025-05-06T13:19:11.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManager: Removing RDD 374
[2025-05-06T13:19:11.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO ZippedPartitionsRDD2: Removing RDD 365 from persistence list
[2025-05-06T13:19:11.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManager: Removing RDD 365
[2025-05-06T13:19:11.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO ZippedPartitionsRDD2: Removing RDD 382 from persistence list
[2025-05-06T13:19:11.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManager: Removing RDD 382
[2025-05-06T13:19:11.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO ZippedPartitionsRDD2: Removing RDD 399 from persistence list
[2025-05-06T13:19:11.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManager: Removing RDD 399
[2025-05-06T13:19:11.188+0000] {spark_submit.py:571} INFO - 2025-05-06 13:19:11,188 [INFO] Вычисляем PageRank для определения влиятельности клиентов
[2025-05-06T13:19:11.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManager: Removing RDD 399
[2025-05-06T13:19:11.218+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:11.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 016737cbcc7e:32777 in memory (size: 48.5 KiB, free: 434.3 MiB)
[2025-05-06T13:19:11.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Registering RDD 404 (mapPartitions at GraphImpl.scala:208) as input to shuffle 61
[2025-05-06T13:19:11.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Registering RDD 422 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 62
[2025-05-06T13:19:11.220+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Registering RDD 412 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 60
[2025-05-06T13:19:11.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.18.0.4:44293 in memory (size: 48.5 KiB, free: 181.5 MiB)
[2025-05-06T13:19:11.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Registering RDD 426 (mapPartitions at GraphImpl.scala:208) as input to shuffle 64
[2025-05-06T13:19:11.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Registering RDD 434 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 63
[2025-05-06T13:19:11.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Got job 53 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:11.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Final stage: ResultStage 402 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:11.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 401, ShuffleMapStage 394, ShuffleMapStage 398, ShuffleMapStage 392, ShuffleMapStage 399)
[2025-05-06T13:19:11.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 016737cbcc7e:32777 in memory (size: 6.6 KiB, free: 434.3 MiB)
[2025-05-06T13:19:11.221+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 401, ShuffleMapStage 398, ShuffleMapStage 399)
[2025-05-06T13:19:11.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.18.0.4:44293 in memory (size: 6.6 KiB, free: 181.5 MiB)
[2025-05-06T13:19:11.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting ShuffleMapStage 397 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[404] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:11.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 117.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:11.231+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:11.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 016737cbcc7e:32777 (size: 46.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:11.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:11.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 397 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[404] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:11.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Adding task set 397.0 with 10 tasks resource profile 0
[2025-05-06T13:19:11.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 0.0 in stage 397.0 (TID 575) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.236+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.18.0.4:44293 (size: 46.9 KiB, free: 181.5 MiB)
[2025-05-06T13:19:11.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 1.0 in stage 397.0 (TID 576) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 0.0 in stage 397.0 (TID 575) in 32 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:11.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 2.0 in stage 397.0 (TID 577) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 1.0 in stage 397.0 (TID 576) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:11.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 3.0 in stage 397.0 (TID 578) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 2.0 in stage 397.0 (TID 577) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:11.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 4.0 in stage 397.0 (TID 579) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 3.0 in stage 397.0 (TID 578) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:11.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 5.0 in stage 397.0 (TID 580) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 4.0 in stage 397.0 (TID 579) in 17 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:11.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 6.0 in stage 397.0 (TID 581) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 5.0 in stage 397.0 (TID 580) in 16 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:11.350+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 7.0 in stage 397.0 (TID 582) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.350+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 6.0 in stage 397.0 (TID 581) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:11.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 8.0 in stage 397.0 (TID 583) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 7.0 in stage 397.0 (TID 582) in 14 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:11.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 9.0 in stage 397.0 (TID 584) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4728 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 8.0 in stage 397.0 (TID 583) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:11.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 9.0 in stage 397.0 (TID 584) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:11.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Removed TaskSet 397.0, whose tasks have all completed, from pool
[2025-05-06T13:19:11.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: ShuffleMapStage 397 (mapPartitions at GraphImpl.scala:208) finished in 0.163 s
[2025-05-06T13:19:11.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:11.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:11.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ShuffleMapStage 398, ResultStage 402, ShuffleMapStage 399, ShuffleMapStage 400)
[2025-05-06T13:19:11.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:11.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting ShuffleMapStage 398 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[422] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:11.387+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 10.7 KiB, free 425.8 MiB)
[2025-05-06T13:19:11.392+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 425.8 MiB)
[2025-05-06T13:19:11.392+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManager: Removing RDD 391
[2025-05-06T13:19:11.392+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 016737cbcc7e:32777 (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:11.392+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:11.393+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 398 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[422] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:11.393+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Adding task set 398.0 with 10 tasks resource profile 0
[2025-05-06T13:19:11.393+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting ShuffleMapStage 399 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[412] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:11.394+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 0.0 in stage 398.0 (TID 585) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.395+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 10.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:11.396+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:11.396+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 016737cbcc7e:32777 (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:11.396+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:11.396+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 399 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[412] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:11.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Adding task set 399.0 with 10 tasks resource profile 0
[2025-05-06T13:19:11.400+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.18.0.4:44293 (size: 5.3 KiB, free: 186.9 MiB)
[2025-05-06T13:19:11.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.18.0.4:59552
[2025-05-06T13:19:11.440+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_0 in memory on 172.18.0.4:44293 (size: 13.9 KiB, free: 186.8 MiB)
[2025-05-06T13:19:11.442+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 186.8 MiB)
[2025-05-06T13:19:11.450+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 1.0 in stage 398.0 (TID 586) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.450+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 0.0 in stage 398.0 (TID 585) in 57 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:11.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_1 in memory on 172.18.0.4:44293 (size: 13.8 KiB, free: 186.8 MiB)
[2025-05-06T13:19:11.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 186.8 MiB)
[2025-05-06T13:19:11.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 2.0 in stage 398.0 (TID 587) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 1.0 in stage 398.0 (TID 586) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:11.467+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_2 in memory on 172.18.0.4:44293 (size: 13.6 KiB, free: 186.8 MiB)
[2025-05-06T13:19:11.468+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 186.8 MiB)
[2025-05-06T13:19:11.471+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 3.0 in stage 398.0 (TID 588) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 2.0 in stage 398.0 (TID 587) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:11.477+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_3 in memory on 172.18.0.4:44293 (size: 13.5 KiB, free: 186.8 MiB)
[2025-05-06T13:19:11.478+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 186.7 MiB)
[2025-05-06T13:19:11.482+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 4.0 in stage 398.0 (TID 589) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.482+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 3.0 in stage 398.0 (TID 588) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:11.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_4 in memory on 172.18.0.4:44293 (size: 13.7 KiB, free: 186.7 MiB)
[2025-05-06T13:19:11.493+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 186.7 MiB)
[2025-05-06T13:19:11.497+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 5.0 in stage 398.0 (TID 590) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.498+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 4.0 in stage 398.0 (TID 589) in 16 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:11.504+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_5 in memory on 172.18.0.4:44293 (size: 13.7 KiB, free: 186.7 MiB)
[2025-05-06T13:19:11.506+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 186.7 MiB)
[2025-05-06T13:19:11.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 6.0 in stage 398.0 (TID 591) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.510+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 5.0 in stage 398.0 (TID 590) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:11.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_6 in memory on 172.18.0.4:44293 (size: 13.5 KiB, free: 186.7 MiB)
[2025-05-06T13:19:11.516+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 186.7 MiB)
[2025-05-06T13:19:11.520+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 7.0 in stage 398.0 (TID 592) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 6.0 in stage 398.0 (TID 591) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:11.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_7 in memory on 172.18.0.4:44293 (size: 13.4 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 8.0 in stage 398.0 (TID 593) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 7.0 in stage 398.0 (TID 592) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:11.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_8 in memory on 172.18.0.4:44293 (size: 13.3 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.542+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 9.0 in stage 398.0 (TID 594) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.542+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 8.0 in stage 398.0 (TID 593) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:11.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_408_9 in memory on 172.18.0.4:44293 (size: 13.0 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_418_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.552+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 0.0 in stage 399.0 (TID 595) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.552+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 9.0 in stage 398.0 (TID 594) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:11.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Removed TaskSet 398.0, whose tasks have all completed, from pool
[2025-05-06T13:19:11.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: ShuffleMapStage 398 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.166 s
[2025-05-06T13:19:11.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:11.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: running: Set(ShuffleMapStage 399)
[2025-05-06T13:19:11.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ResultStage 402, ShuffleMapStage 400)
[2025-05-06T13:19:11.553+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:11.559+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.18.0.4:44293 (size: 5.0 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.566+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 1.0 in stage 399.0 (TID 596) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.566+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 0.0 in stage 399.0 (TID 595) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:11.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 2.0 in stage 399.0 (TID 597) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 1.0 in stage 399.0 (TID 596) in 6 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:11.577+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 3.0 in stage 399.0 (TID 598) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.578+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 2.0 in stage 399.0 (TID 597) in 6 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:11.585+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 4.0 in stage 399.0 (TID 599) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.586+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 3.0 in stage 399.0 (TID 598) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:11.594+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 5.0 in stage 399.0 (TID 600) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.594+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 4.0 in stage 399.0 (TID 599) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:11.601+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 6.0 in stage 399.0 (TID 601) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.602+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 5.0 in stage 399.0 (TID 600) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:11.609+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 7.0 in stage 399.0 (TID 602) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.609+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 6.0 in stage 399.0 (TID 601) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:11.616+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 7.0 in stage 399.0 (TID 602) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:11.617+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 8.0 in stage 399.0 (TID 603) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 9.0 in stage 399.0 (TID 604) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 8.0 in stage 399.0 (TID 603) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:11.633+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 9.0 in stage 399.0 (TID 604) in 4 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:11.633+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool
[2025-05-06T13:19:11.633+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: ShuffleMapStage 399 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.239 s
[2025-05-06T13:19:11.634+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:11.634+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:11.634+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ResultStage 402, ShuffleMapStage 400)
[2025-05-06T13:19:11.634+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:11.634+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting ShuffleMapStage 400 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[426] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:11.637+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 120.2 KiB, free 425.7 MiB)
[2025-05-06T13:19:11.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 016737cbcc7e:32777 in memory (size: 5.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:11.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 47.5 KiB, free 425.6 MiB)
[2025-05-06T13:19:11.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 016737cbcc7e:32777 (size: 47.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:11.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:11.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 400 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[426] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:11.646+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Adding task set 400.0 with 10 tasks resource profile 0
[2025-05-06T13:19:11.646+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.18.0.4:44293 in memory (size: 5.3 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.647+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 0.0 in stage 400.0 (TID 605) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.652+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 016737cbcc7e:32777 in memory (size: 46.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:11.653+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.18.0.4:44293 in memory (size: 46.9 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.18.0.4:44293 (size: 47.5 KiB, free: 186.6 MiB)
[2025-05-06T13:19:11.665+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_0 in memory on 172.18.0.4:44293 (size: 494.4 KiB, free: 186.1 MiB)
[2025-05-06T13:19:11.665+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 172.18.0.4:59552
[2025-05-06T13:19:11.677+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 185.5 MiB)
[2025-05-06T13:19:11.678+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.18.0.4:59552
[2025-05-06T13:19:11.705+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 1.0 in stage 400.0 (TID 606) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.706+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 0.0 in stage 400.0 (TID 605) in 59 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:11.716+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_1 in memory on 172.18.0.4:44293 (size: 618.0 KiB, free: 184.9 MiB)
[2025-05-06T13:19:11.719+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 184.1 MiB)
[2025-05-06T13:19:11.730+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 2.0 in stage 400.0 (TID 607) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.730+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 1.0 in stage 400.0 (TID 606) in 25 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:11.736+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_2 in memory on 172.18.0.4:44293 (size: 559.2 KiB, free: 183.5 MiB)
[2025-05-06T13:19:11.739+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 182.8 MiB)
[2025-05-06T13:19:11.749+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 3.0 in stage 400.0 (TID 608) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.749+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 2.0 in stage 400.0 (TID 607) in 20 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:11.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_3 in memory on 172.18.0.4:44293 (size: 535.8 KiB, free: 182.3 MiB)
[2025-05-06T13:19:11.760+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 181.6 MiB)
[2025-05-06T13:19:11.774+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 4.0 in stage 400.0 (TID 609) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.774+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 3.0 in stage 400.0 (TID 608) in 25 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:11.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_4 in memory on 172.18.0.4:44293 (size: 448.0 KiB, free: 181.2 MiB)
[2025-05-06T13:19:11.786+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 180.6 MiB)
[2025-05-06T13:19:11.797+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 5.0 in stage 400.0 (TID 610) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.797+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 4.0 in stage 400.0 (TID 609) in 24 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:11.807+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_5 in memory on 172.18.0.4:44293 (size: 522.5 KiB, free: 180.1 MiB)
[2025-05-06T13:19:11.812+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 179.4 MiB)
[2025-05-06T13:19:11.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 6.0 in stage 400.0 (TID 611) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.827+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 5.0 in stage 400.0 (TID 610) in 31 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:11.847+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_6 in memory on 172.18.0.4:44293 (size: 529.8 KiB, free: 178.9 MiB)
[2025-05-06T13:19:11.854+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 178.3 MiB)
[2025-05-06T13:19:11.875+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 7.0 in stage 400.0 (TID 612) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 6.0 in stage 400.0 (TID 611) in 48 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:11.884+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_7 in memory on 172.18.0.4:44293 (size: 596.6 KiB, free: 177.7 MiB)
[2025-05-06T13:19:11.889+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 176.9 MiB)
[2025-05-06T13:19:11.904+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 8.0 in stage 400.0 (TID 613) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.905+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 7.0 in stage 400.0 (TID 612) in 29 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:11.910+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_8 in memory on 172.18.0.4:44293 (size: 544.3 KiB, free: 176.4 MiB)
[2025-05-06T13:19:11.913+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 175.7 MiB)
[2025-05-06T13:19:11.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 9.0 in stage 400.0 (TID 614) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4876 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 8.0 in stage 400.0 (TID 613) in 21 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:11.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_410_9 in memory on 172.18.0.4:44293 (size: 610.2 KiB, free: 175.1 MiB)
[2025-05-06T13:19:11.936+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_420_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:11.952+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 9.0 in stage 400.0 (TID 614) in 28 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:11.952+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Removed TaskSet 400.0, whose tasks have all completed, from pool
[2025-05-06T13:19:11.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: ShuffleMapStage 400 (mapPartitions at GraphImpl.scala:208) finished in 0.318 s
[2025-05-06T13:19:11.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:11.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:11.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 401, ResultStage 402)
[2025-05-06T13:19:11.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:11.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting ShuffleMapStage 401 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[434] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:11.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 12.0 KiB, free 425.8 MiB)
[2025-05-06T13:19:11.963+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 425.8 MiB)
[2025-05-06T13:19:11.964+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 016737cbcc7e:32777 in memory (size: 5.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:11.964+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 016737cbcc7e:32777 (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:11.964+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:11.964+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 401 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[434] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:11.964+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSchedulerImpl: Adding task set 401.0 with 10 tasks resource profile 0
[2025-05-06T13:19:11.965+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 0.0 in stage 401.0 (TID 615) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.968+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.18.0.4:44293 in memory (size: 5.0 KiB, free: 174.3 MiB)
[2025-05-06T13:19:11.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.18.0.4:44293 (size: 5.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:11.979+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.18.0.4:59552
[2025-05-06T13:19:11.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO BlockManagerInfo: Added rdd_430_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:11.993+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Starting task 1.0 in stage 401.0 (TID 616) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:11.994+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:11 INFO TaskSetManager: Finished task 0.0 in stage 401.0 (TID 615) in 28 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:12.011+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_430_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 2.0 in stage 401.0 (TID 617) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.018+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 1.0 in stage 401.0 (TID 616) in 25 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:12.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_430_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 3.0 in stage 401.0 (TID 618) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 2.0 in stage 401.0 (TID 617) in 12 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:12.036+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_430_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 4.0 in stage 401.0 (TID 619) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.040+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 3.0 in stage 401.0 (TID 618) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:12.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_430_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 5.0 in stage 401.0 (TID 620) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 4.0 in stage 401.0 (TID 619) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:12.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_430_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 6.0 in stage 401.0 (TID 621) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 5.0 in stage 401.0 (TID 620) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:12.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_430_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 7.0 in stage 401.0 (TID 622) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 6.0 in stage 401.0 (TID 621) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:12.072+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_430_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 8.0 in stage 401.0 (TID 623) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 7.0 in stage 401.0 (TID 622) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:12.085+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_430_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 9.0 in stage 401.0 (TID 624) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 8.0 in stage 401.0 (TID 623) in 14 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:12.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_430_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 9.0 in stage 401.0 (TID 624) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:12.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Removed TaskSet 401.0, whose tasks have all completed, from pool
[2025-05-06T13:19:12.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: ShuffleMapStage 401 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.142 s
[2025-05-06T13:19:12.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:12.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:12.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: waiting: Set(ResultStage 402)
[2025-05-06T13:19:12.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:12.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting ResultStage 402 (EdgeRDDImpl[437] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:12.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 120.0 KiB, free 425.7 MiB)
[2025-05-06T13:19:12.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 016737cbcc7e:32777 in memory (size: 47.5 KiB, free: 434.3 MiB)
[2025-05-06T13:19:12.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 425.7 MiB)
[2025-05-06T13:19:12.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 016737cbcc7e:32777 (size: 47.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:12.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 402 (EdgeRDDImpl[437] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:12.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Adding task set 402.0 with 10 tasks resource profile 0
[2025-05-06T13:19:12.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.18.0.4:44293 in memory (size: 47.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 0.0 in stage 402.0 (TID 625) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.18.0.4:44293 (size: 47.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.118+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.18.0.4:59552
[2025-05-06T13:19:12.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 63 to 172.18.0.4:59552
[2025-05-06T13:19:12.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:19:12.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 1.0 in stage 402.0 (TID 626) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 0.0 in stage 402.0 (TID 625) in 20 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:12.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:19:12.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 2.0 in stage 402.0 (TID 627) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 1.0 in stage 402.0 (TID 626) in 27 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:12.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:19:12.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 3.0 in stage 402.0 (TID 628) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 2.0 in stage 402.0 (TID 627) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:12.176+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:19:12.178+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 4.0 in stage 402.0 (TID 629) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 3.0 in stage 402.0 (TID 628) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:12.188+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:12.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 5.0 in stage 402.0 (TID 630) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 4.0 in stage 402.0 (TID 629) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:12.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:12.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 6.0 in stage 402.0 (TID 631) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 5.0 in stage 402.0 (TID 630) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:12.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:19:12.216+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 7.0 in stage 402.0 (TID 632) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.217+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 6.0 in stage 402.0 (TID 631) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:12.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:12.246+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 8.0 in stage 402.0 (TID 633) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 7.0 in stage 402.0 (TID 632) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:12.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:12.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 9.0 in stage 402.0 (TID 634) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4928 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 8.0 in stage 402.0 (TID 633) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:12.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_436_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:12.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 9.0 in stage 402.0 (TID 634) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:12.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool
[2025-05-06T13:19:12.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: ResultStage 402 (foreachPartition at PageRank.scala:199) finished in 0.153 s
[2025-05-06T13:19:12.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:12.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 402: Stage finished
[2025-05-06T13:19:12.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Job 53 finished: foreachPartition at PageRank.scala:199, took 1.032118 s
[2025-05-06T13:19:12.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO PageRank: PageRank finished iteration 0.
[2025-05-06T13:19:12.252+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MapPartitionsRDD: Removing RDD 418 from persistence list
[2025-05-06T13:19:12.253+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManager: Removing RDD 418
[2025-05-06T13:19:12.253+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MapPartitionsRDD: Removing RDD 420 from persistence list
[2025-05-06T13:19:12.253+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManager: Removing RDD 420
[2025-05-06T13:19:12.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:12.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Registering RDD 438 (mapPartitions at GraphImpl.scala:208) as input to shuffle 66
[2025-05-06T13:19:12.263+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Registering RDD 446 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 65
[2025-05-06T13:19:12.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Got job 54 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:12.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Final stage: ResultStage 418 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:12.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 408, ShuffleMapStage 412, ShuffleMapStage 406, ShuffleMapStage 413, ShuffleMapStage 417, ShuffleMapStage 415)
[2025-05-06T13:19:12.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 417)
[2025-05-06T13:19:12.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting ShuffleMapStage 416 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[438] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:12.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 120.5 KiB, free 425.7 MiB)
[2025-05-06T13:19:12.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 016737cbcc7e:32777 in memory (size: 5.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.276+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.6 MiB)
[2025-05-06T13:19:12.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 016737cbcc7e:32777 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:12.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 416 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[438] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:12.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Adding task set 416.0 with 10 tasks resource profile 0
[2025-05-06T13:19:12.277+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.18.0.4:44293 in memory (size: 5.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.278+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 0.0 in stage 416.0 (TID 635) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 016737cbcc7e:32777 in memory (size: 47.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.279+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.18.0.4:44293 in memory (size: 47.3 KiB, free: 174.4 MiB)
[2025-05-06T13:19:12.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.18.0.4:44293 (size: 47.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 1.0 in stage 416.0 (TID 636) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 0.0 in stage 416.0 (TID 635) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:12.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 2.0 in stage 416.0 (TID 637) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 1.0 in stage 416.0 (TID 636) in 15 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:12.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 3.0 in stage 416.0 (TID 638) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 2.0 in stage 416.0 (TID 637) in 24 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:12.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 4.0 in stage 416.0 (TID 639) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 3.0 in stage 416.0 (TID 638) in 15 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:12.361+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 5.0 in stage 416.0 (TID 640) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.361+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 4.0 in stage 416.0 (TID 639) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:12.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 6.0 in stage 416.0 (TID 641) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.375+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 5.0 in stage 416.0 (TID 640) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:12.387+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 7.0 in stage 416.0 (TID 642) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.387+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 6.0 in stage 416.0 (TID 641) in 13 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:12.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 8.0 in stage 416.0 (TID 643) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 7.0 in stage 416.0 (TID 642) in 15 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:12.412+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 9.0 in stage 416.0 (TID 644) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.413+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 8.0 in stage 416.0 (TID 643) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:12.424+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 9.0 in stage 416.0 (TID 644) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:12.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Removed TaskSet 416.0, whose tasks have all completed, from pool
[2025-05-06T13:19:12.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: ShuffleMapStage 416 (mapPartitions at GraphImpl.scala:208) finished in 0.159 s
[2025-05-06T13:19:12.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:12.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:12.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 417, ResultStage 418)
[2025-05-06T13:19:12.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:12.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting ShuffleMapStage 417 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[446] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:12.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 12.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:12.431+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:12.431+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 016737cbcc7e:32777 (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.431+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:12.431+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 417 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[446] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:12.431+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Adding task set 417.0 with 10 tasks resource profile 0
[2025-05-06T13:19:12.432+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 0.0 in stage 417.0 (TID 645) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.436+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.18.0.4:44293 (size: 5.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.439+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 66 to 172.18.0.4:59552
[2025-05-06T13:19:12.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 1.0 in stage 417.0 (TID 646) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 0.0 in stage 417.0 (TID 645) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:12.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.459+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 2.0 in stage 417.0 (TID 647) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 1.0 in stage 417.0 (TID 646) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:12.475+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.479+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 3.0 in stage 417.0 (TID 648) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.479+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 2.0 in stage 417.0 (TID 647) in 20 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:12.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 4.0 in stage 417.0 (TID 649) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.489+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 3.0 in stage 417.0 (TID 648) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:12.493+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.498+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 5.0 in stage 417.0 (TID 650) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 4.0 in stage 417.0 (TID 649) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:12.505+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 6.0 in stage 417.0 (TID 651) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 5.0 in stage 417.0 (TID 650) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:12.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.518+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 7.0 in stage 417.0 (TID 652) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.519+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 6.0 in stage 417.0 (TID 651) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:12.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.528+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 8.0 in stage 417.0 (TID 653) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.528+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 7.0 in stage 417.0 (TID 652) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:12.532+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.535+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 9.0 in stage 417.0 (TID 654) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.535+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 8.0 in stage 417.0 (TID 653) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:12.541+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_442_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.543+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 9.0 in stage 417.0 (TID 654) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:12.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Removed TaskSet 417.0, whose tasks have all completed, from pool
[2025-05-06T13:19:12.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: ShuffleMapStage 417 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.118 s
[2025-05-06T13:19:12.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:12.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:12.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: waiting: Set(ResultStage 418)
[2025-05-06T13:19:12.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:12.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting ResultStage 418 (EdgeRDDImpl[449] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:12.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 120.3 KiB, free 425.7 MiB)
[2025-05-06T13:19:12.555+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 016737cbcc7e:32777 in memory (size: 47.7 KiB, free: 434.3 MiB)
[2025-05-06T13:19:12.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 47.6 KiB, free 425.8 MiB)
[2025-05-06T13:19:12.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 016737cbcc7e:32777 (size: 47.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:12.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 418 (EdgeRDDImpl[449] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:12.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Adding task set 418.0 with 10 tasks resource profile 0
[2025-05-06T13:19:12.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 172.18.0.4:44293 in memory (size: 47.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 0.0 in stage 418.0 (TID 655) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.561+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.18.0.4:44293 (size: 47.6 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.567+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 65 to 172.18.0.4:59552
[2025-05-06T13:19:12.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:19:12.574+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 1.0 in stage 418.0 (TID 656) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.574+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 0.0 in stage 418.0 (TID 655) in 18 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:12.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:19:12.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 2.0 in stage 418.0 (TID 657) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 1.0 in stage 418.0 (TID 656) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:12.602+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:19:12.606+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 3.0 in stage 418.0 (TID 658) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.607+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 2.0 in stage 418.0 (TID 657) in 24 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:12.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:19:12.622+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 4.0 in stage 418.0 (TID 659) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.622+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 3.0 in stage 418.0 (TID 658) in 17 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:12.629+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:12.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 5.0 in stage 418.0 (TID 660) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 4.0 in stage 418.0 (TID 659) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:12.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:12.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 6.0 in stage 418.0 (TID 661) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 5.0 in stage 418.0 (TID 660) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:12.647+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:19:12.649+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 7.0 in stage 418.0 (TID 662) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.649+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 6.0 in stage 418.0 (TID 661) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:12.657+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:12.659+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 8.0 in stage 418.0 (TID 663) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.659+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 7.0 in stage 418.0 (TID 662) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:12.668+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:12.670+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 9.0 in stage 418.0 (TID 664) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 8.0 in stage 418.0 (TID 663) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:12.677+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_448_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:12.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 9.0 in stage 418.0 (TID 664) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:12.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Removed TaskSet 418.0, whose tasks have all completed, from pool
[2025-05-06T13:19:12.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: ResultStage 418 (foreachPartition at PageRank.scala:199) finished in 0.135 s
[2025-05-06T13:19:12.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:12.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 418: Stage finished
[2025-05-06T13:19:12.679+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Job 54 finished: foreachPartition at PageRank.scala:199, took 0.417064 s
[2025-05-06T13:19:12.680+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO PageRank: PageRank finished iteration 1.
[2025-05-06T13:19:12.680+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO ZippedPartitionsRDD2: Removing RDD 430 from persistence list
[2025-05-06T13:19:12.680+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManager: Removing RDD 430
[2025-05-06T13:19:12.680+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO ZippedPartitionsRDD2: Removing RDD 436 from persistence list
[2025-05-06T13:19:12.680+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManager: Removing RDD 436
[2025-05-06T13:19:12.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:12.689+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Registering RDD 450 (mapPartitions at GraphImpl.scala:208) as input to shuffle 68
[2025-05-06T13:19:12.689+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Registering RDD 458 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 67
[2025-05-06T13:19:12.689+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Got job 55 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:12.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Final stage: ResultStage 436 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:12.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 422, ShuffleMapStage 424, ShuffleMapStage 431, ShuffleMapStage 428, ShuffleMapStage 435, ShuffleMapStage 429, ShuffleMapStage 433)
[2025-05-06T13:19:12.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 435)
[2025-05-06T13:19:12.690+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting ShuffleMapStage 434 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[450] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:12.692+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 120.8 KiB, free 425.7 MiB)
[2025-05-06T13:19:12.698+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.6 MiB)
[2025-05-06T13:19:12.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 016737cbcc7e:32777 in memory (size: 5.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 016737cbcc7e:32777 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:12.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 434 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[450] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:12.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Adding task set 434.0 with 10 tasks resource profile 0
[2025-05-06T13:19:12.699+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.18.0.4:44293 in memory (size: 5.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.700+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 0.0 in stage 434.0 (TID 665) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.701+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 016737cbcc7e:32777 in memory (size: 47.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 172.18.0.4:44293 in memory (size: 47.6 KiB, free: 174.4 MiB)
[2025-05-06T13:19:12.705+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.18.0.4:44293 (size: 47.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.723+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 1.0 in stage 434.0 (TID 666) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.724+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 0.0 in stage 434.0 (TID 665) in 24 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:12.743+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 2.0 in stage 434.0 (TID 667) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.744+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 1.0 in stage 434.0 (TID 666) in 21 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:12.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 3.0 in stage 434.0 (TID 668) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.757+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 2.0 in stage 434.0 (TID 667) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:12.772+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 4.0 in stage 434.0 (TID 669) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.773+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 3.0 in stage 434.0 (TID 668) in 15 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:12.788+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 5.0 in stage 434.0 (TID 670) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.788+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 4.0 in stage 434.0 (TID 669) in 19 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:12.807+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 6.0 in stage 434.0 (TID 671) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.807+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 5.0 in stage 434.0 (TID 670) in 20 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:12.818+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 7.0 in stage 434.0 (TID 672) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.819+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 6.0 in stage 434.0 (TID 671) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:12.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 8.0 in stage 434.0 (TID 673) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 7.0 in stage 434.0 (TID 672) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:12.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 9.0 in stage 434.0 (TID 674) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 8.0 in stage 434.0 (TID 673) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:12.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 9.0 in stage 434.0 (TID 674) in 15 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:12.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Removed TaskSet 434.0, whose tasks have all completed, from pool
[2025-05-06T13:19:12.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: ShuffleMapStage 434 (mapPartitions at GraphImpl.scala:208) finished in 0.169 s
[2025-05-06T13:19:12.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:12.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:12.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 435, ResultStage 436)
[2025-05-06T13:19:12.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:12.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting ShuffleMapStage 435 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[458] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:12.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 13.5 KiB, free 425.8 MiB)
[2025-05-06T13:19:12.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:12.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 016737cbcc7e:32777 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:12.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 435 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[458] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:12.866+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Adding task set 435.0 with 10 tasks resource profile 0
[2025-05-06T13:19:12.867+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 0.0 in stage 435.0 (TID 675) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.872+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.18.0.4:44293 (size: 6.1 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.875+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 68 to 172.18.0.4:59552
[2025-05-06T13:19:12.878+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.881+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 1.0 in stage 435.0 (TID 676) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.882+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 0.0 in stage 435.0 (TID 675) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:12.887+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.891+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 2.0 in stage 435.0 (TID 677) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.891+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 1.0 in stage 435.0 (TID 676) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:12.905+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 3.0 in stage 435.0 (TID 678) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 2.0 in stage 435.0 (TID 677) in 18 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:12.913+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:12.917+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 4.0 in stage 435.0 (TID 679) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.917+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 3.0 in stage 435.0 (TID 678) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:12.924+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.927+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 5.0 in stage 435.0 (TID 680) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.928+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 4.0 in stage 435.0 (TID 679) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:12.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.938+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 6.0 in stage 435.0 (TID 681) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 5.0 in stage 435.0 (TID 680) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:12.945+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 7.0 in stage 435.0 (TID 682) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 6.0 in stage 435.0 (TID 681) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:12.955+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.958+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 8.0 in stage 435.0 (TID 683) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.959+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 7.0 in stage 435.0 (TID 682) in 10 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:12.963+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 9.0 in stage 435.0 (TID 684) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 8.0 in stage 435.0 (TID 683) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:12.972+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added rdd_454_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Finished task 9.0 in stage 435.0 (TID 684) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:12.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Removed TaskSet 435.0, whose tasks have all completed, from pool
[2025-05-06T13:19:12.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: ShuffleMapStage 435 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.115 s
[2025-05-06T13:19:12.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:12.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:12.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: waiting: Set(ResultStage 436)
[2025-05-06T13:19:12.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:12.975+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting ResultStage 436 (EdgeRDDImpl[461] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:12.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 120.6 KiB, free 425.7 MiB)
[2025-05-06T13:19:12.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 016737cbcc7e:32777 in memory (size: 47.7 KiB, free: 434.3 MiB)
[2025-05-06T13:19:12.985+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 47.6 KiB, free 425.7 MiB)
[2025-05-06T13:19:12.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 016737cbcc7e:32777 (size: 47.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:12.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:12.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 436 (EdgeRDDImpl[461] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:12.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSchedulerImpl: Adding task set 436.0 with 10 tasks resource profile 0
[2025-05-06T13:19:12.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.18.0.4:44293 in memory (size: 47.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.988+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO TaskSetManager: Starting task 0.0 in stage 436.0 (TID 685) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:12.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.18.0.4:44293 (size: 47.6 KiB, free: 174.2 MiB)
[2025-05-06T13:19:12.998+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 67 to 172.18.0.4:59552
[2025-05-06T13:19:13.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:19:13.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 1.0 in stage 436.0 (TID 686) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.006+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 0.0 in stage 436.0 (TID 685) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:13.015+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:19:13.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 2.0 in stage 436.0 (TID 687) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.017+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 1.0 in stage 436.0 (TID 686) in 12 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:13.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:19:13.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 3.0 in stage 436.0 (TID 688) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.038+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 2.0 in stage 436.0 (TID 687) in 22 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:13.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:19:13.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 4.0 in stage 436.0 (TID 689) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 3.0 in stage 436.0 (TID 688) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:13.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:13.060+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 5.0 in stage 436.0 (TID 690) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 4.0 in stage 436.0 (TID 689) in 12 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:13.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:13.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 6.0 in stage 436.0 (TID 691) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 5.0 in stage 436.0 (TID 690) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:13.076+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:19:13.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 7.0 in stage 436.0 (TID 692) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 6.0 in stage 436.0 (TID 691) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:13.084+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:13.085+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 8.0 in stage 436.0 (TID 693) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.086+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 7.0 in stage 436.0 (TID 692) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:13.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:13.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 9.0 in stage 436.0 (TID 694) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5010 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.098+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 8.0 in stage 436.0 (TID 693) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:13.106+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_460_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:13.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 9.0 in stage 436.0 (TID 694) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:13.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Removed TaskSet 436.0, whose tasks have all completed, from pool
[2025-05-06T13:19:13.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: ResultStage 436 (foreachPartition at PageRank.scala:199) finished in 0.132 s
[2025-05-06T13:19:13.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:13.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 436: Stage finished
[2025-05-06T13:19:13.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Job 55 finished: foreachPartition at PageRank.scala:199, took 0.420776 s
[2025-05-06T13:19:13.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO PageRank: PageRank finished iteration 2.
[2025-05-06T13:19:13.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO ZippedPartitionsRDD2: Removing RDD 442 from persistence list
[2025-05-06T13:19:13.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManager: Removing RDD 442
[2025-05-06T13:19:13.110+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO ZippedPartitionsRDD2: Removing RDD 448 from persistence list
[2025-05-06T13:19:13.111+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManager: Removing RDD 448
[2025-05-06T13:19:13.125+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:13.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Registering RDD 462 (mapPartitions at GraphImpl.scala:208) as input to shuffle 70
[2025-05-06T13:19:13.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Registering RDD 470 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 69
[2025-05-06T13:19:13.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Got job 56 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:13.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Final stage: ResultStage 456 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:13.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 440, ShuffleMapStage 455, ShuffleMapStage 442, ShuffleMapStage 449, ShuffleMapStage 446, ShuffleMapStage 453, ShuffleMapStage 447, ShuffleMapStage 451)
[2025-05-06T13:19:13.127+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 455)
[2025-05-06T13:19:13.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting ShuffleMapStage 454 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[462] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:13.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 121.1 KiB, free 425.7 MiB)
[2025-05-06T13:19:13.141+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 016737cbcc7e:32777 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.141+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 47.8 KiB, free 425.6 MiB)
[2025-05-06T13:19:13.141+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 016737cbcc7e:32777 (size: 47.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:13.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 454 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[462] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:13.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Adding task set 454.0 with 10 tasks resource profile 0
[2025-05-06T13:19:13.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 0.0 in stage 454.0 (TID 695) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.18.0.4:44293 in memory (size: 6.1 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.146+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 016737cbcc7e:32777 in memory (size: 47.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.18.0.4:44293 in memory (size: 47.6 KiB, free: 174.4 MiB)
[2025-05-06T13:19:13.149+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.18.0.4:44293 (size: 47.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.172+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 1.0 in stage 454.0 (TID 696) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 0.0 in stage 454.0 (TID 695) in 31 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:13.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 2.0 in stage 454.0 (TID 697) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.195+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 1.0 in stage 454.0 (TID 696) in 22 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:13.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 3.0 in stage 454.0 (TID 698) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 2.0 in stage 454.0 (TID 697) in 20 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:13.229+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 4.0 in stage 454.0 (TID 699) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 3.0 in stage 454.0 (TID 698) in 16 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:13.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 5.0 in stage 454.0 (TID 700) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.243+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 4.0 in stage 454.0 (TID 699) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:13.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 6.0 in stage 454.0 (TID 701) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 5.0 in stage 454.0 (TID 700) in 12 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:13.269+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 7.0 in stage 454.0 (TID 702) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.270+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 6.0 in stage 454.0 (TID 701) in 14 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:13.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 8.0 in stage 454.0 (TID 703) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 7.0 in stage 454.0 (TID 702) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:13.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 9.0 in stage 454.0 (TID 704) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4999 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.294+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 8.0 in stage 454.0 (TID 703) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:13.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 9.0 in stage 454.0 (TID 704) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:13.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Removed TaskSet 454.0, whose tasks have all completed, from pool
[2025-05-06T13:19:13.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: ShuffleMapStage 454 (mapPartitions at GraphImpl.scala:208) finished in 0.178 s
[2025-05-06T13:19:13.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:13.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:13.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 455, ResultStage 456)
[2025-05-06T13:19:13.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:13.306+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting ShuffleMapStage 455 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[470] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:13.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 14.2 KiB, free 425.8 MiB)
[2025-05-06T13:19:13.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:13.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 016737cbcc7e:32777 (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:13.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 455 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[470] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:13.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Adding task set 455.0 with 10 tasks resource profile 0
[2025-05-06T13:19:13.313+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 0.0 in stage 455.0 (TID 705) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.18.0.4:44293 (size: 6.1 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 70 to 172.18.0.4:59552
[2025-05-06T13:19:13.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.328+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 1.0 in stage 455.0 (TID 706) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.329+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 0.0 in stage 455.0 (TID 705) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:13.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 2.0 in stage 455.0 (TID 707) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 1.0 in stage 455.0 (TID 706) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:13.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.358+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 3.0 in stage 455.0 (TID 708) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.358+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 2.0 in stage 455.0 (TID 707) in 19 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:13.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.367+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 4.0 in stage 455.0 (TID 709) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.367+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 3.0 in stage 455.0 (TID 708) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:13.373+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 5.0 in stage 455.0 (TID 710) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.376+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 4.0 in stage 455.0 (TID 709) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:13.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 6.0 in stage 455.0 (TID 711) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 5.0 in stage 455.0 (TID 710) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:13.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.394+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 7.0 in stage 455.0 (TID 712) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.395+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 6.0 in stage 455.0 (TID 711) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:13.398+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 8.0 in stage 455.0 (TID 713) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 7.0 in stage 455.0 (TID 712) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:13.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 9.0 in stage 455.0 (TID 714) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.410+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 8.0 in stage 455.0 (TID 713) in 9 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:13.414+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_466_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 9.0 in stage 455.0 (TID 714) in 6 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:13.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Removed TaskSet 455.0, whose tasks have all completed, from pool
[2025-05-06T13:19:13.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: ShuffleMapStage 455 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.111 s
[2025-05-06T13:19:13.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:13.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:13.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: waiting: Set(ResultStage 456)
[2025-05-06T13:19:13.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:13.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting ResultStage 456 (EdgeRDDImpl[473] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:13.420+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 120.9 KiB, free 425.7 MiB)
[2025-05-06T13:19:13.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 016737cbcc7e:32777 in memory (size: 47.8 KiB, free: 434.3 MiB)
[2025-05-06T13:19:13.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.7 MiB)
[2025-05-06T13:19:13.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 016737cbcc7e:32777 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:13.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 456 (EdgeRDDImpl[473] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:13.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Adding task set 456.0 with 10 tasks resource profile 0
[2025-05-06T13:19:13.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.18.0.4:44293 in memory (size: 47.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 0.0 in stage 456.0 (TID 715) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.430+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.18.0.4:44293 (size: 47.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.434+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 69 to 172.18.0.4:59552
[2025-05-06T13:19:13.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:19:13.440+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 1.0 in stage 456.0 (TID 716) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.440+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 0.0 in stage 456.0 (TID 715) in 14 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:13.446+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:19:13.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 2.0 in stage 456.0 (TID 717) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 1.0 in stage 456.0 (TID 716) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:13.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:19:13.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 3.0 in stage 456.0 (TID 718) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 2.0 in stage 456.0 (TID 717) in 17 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:13.470+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:19:13.474+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 4.0 in stage 456.0 (TID 719) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.474+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 3.0 in stage 456.0 (TID 718) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:13.482+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:13.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 5.0 in stage 456.0 (TID 720) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.484+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 4.0 in stage 456.0 (TID 719) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:13.493+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:13.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 6.0 in stage 456.0 (TID 721) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.495+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 5.0 in stage 456.0 (TID 720) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:13.501+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:19:13.503+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 7.0 in stage 456.0 (TID 722) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.503+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 6.0 in stage 456.0 (TID 721) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:13.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:13.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 8.0 in stage 456.0 (TID 723) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 7.0 in stage 456.0 (TID 722) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:13.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:13.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 9.0 in stage 456.0 (TID 724) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5051 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.526+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 8.0 in stage 456.0 (TID 723) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:13.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_472_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:13.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 9.0 in stage 456.0 (TID 724) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:13.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Removed TaskSet 456.0, whose tasks have all completed, from pool
[2025-05-06T13:19:13.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: ResultStage 456 (foreachPartition at PageRank.scala:199) finished in 0.119 s
[2025-05-06T13:19:13.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:13.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 456: Stage finished
[2025-05-06T13:19:13.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Job 56 finished: foreachPartition at PageRank.scala:199, took 0.410598 s
[2025-05-06T13:19:13.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO PageRank: PageRank finished iteration 3.
[2025-05-06T13:19:13.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO ZippedPartitionsRDD2: Removing RDD 454 from persistence list
[2025-05-06T13:19:13.537+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManager: Removing RDD 454
[2025-05-06T13:19:13.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO ZippedPartitionsRDD2: Removing RDD 460 from persistence list
[2025-05-06T13:19:13.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManager: Removing RDD 460
[2025-05-06T13:19:13.550+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:13.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Registering RDD 474 (mapPartitions at GraphImpl.scala:208) as input to shuffle 72
[2025-05-06T13:19:13.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Registering RDD 482 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 71
[2025-05-06T13:19:13.551+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Got job 57 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:13.552+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Final stage: ResultStage 478 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:13.552+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 466, ShuffleMapStage 473, ShuffleMapStage 462, ShuffleMapStage 477, ShuffleMapStage 460, ShuffleMapStage 475, ShuffleMapStage 467, ShuffleMapStage 471, ShuffleMapStage 469)
[2025-05-06T13:19:13.552+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 477)
[2025-05-06T13:19:13.552+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting ShuffleMapStage 476 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[474] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:13.556+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 121.4 KiB, free 425.7 MiB)
[2025-05-06T13:19:13.564+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.6 MiB)
[2025-05-06T13:19:13.564+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 016737cbcc7e:32777 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.564+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 016737cbcc7e:32777 in memory (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:13.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 476 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[474] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:13.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Adding task set 476.0 with 10 tasks resource profile 0
[2025-05-06T13:19:13.566+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.18.0.4:44293 in memory (size: 47.7 KiB, free: 174.4 MiB)
[2025-05-06T13:19:13.566+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 0.0 in stage 476.0 (TID 725) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.570+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 172.18.0.4:44293 in memory (size: 6.1 KiB, free: 174.4 MiB)
[2025-05-06T13:19:13.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 016737cbcc7e:32777 in memory (size: 6.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.575+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.18.0.4:44293 (size: 47.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.588+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 1.0 in stage 476.0 (TID 726) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.588+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 0.0 in stage 476.0 (TID 725) in 23 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:13.608+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 2.0 in stage 476.0 (TID 727) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.609+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 1.0 in stage 476.0 (TID 726) in 22 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:13.629+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 3.0 in stage 476.0 (TID 728) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.629+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 2.0 in stage 476.0 (TID 727) in 21 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:13.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 4.0 in stage 476.0 (TID 729) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 3.0 in stage 476.0 (TID 728) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:13.652+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 5.0 in stage 476.0 (TID 730) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.652+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 4.0 in stage 476.0 (TID 729) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:13.665+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 6.0 in stage 476.0 (TID 731) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.666+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 5.0 in stage 476.0 (TID 730) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:13.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 7.0 in stage 476.0 (TID 732) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.683+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 6.0 in stage 476.0 (TID 731) in 18 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:13.696+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 8.0 in stage 476.0 (TID 733) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.697+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 7.0 in stage 476.0 (TID 732) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:13.712+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 9.0 in stage 476.0 (TID 734) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5040 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.712+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 8.0 in stage 476.0 (TID 733) in 16 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:13.724+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 9.0 in stage 476.0 (TID 734) in 13 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:13.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Removed TaskSet 476.0, whose tasks have all completed, from pool
[2025-05-06T13:19:13.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: ShuffleMapStage 476 (mapPartitions at GraphImpl.scala:208) finished in 0.173 s
[2025-05-06T13:19:13.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:13.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:13.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 477, ResultStage 478)
[2025-05-06T13:19:13.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:13.725+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting ShuffleMapStage 477 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[482] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:13.726+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 14.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:13.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 425.8 MiB)
[2025-05-06T13:19:13.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 016737cbcc7e:32777 (size: 6.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:13.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 477 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[482] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:13.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Adding task set 477.0 with 10 tasks resource profile 0
[2025-05-06T13:19:13.733+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 0.0 in stage 477.0 (TID 735) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.739+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.18.0.4:44293 (size: 6.3 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.742+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.18.0.4:59552
[2025-05-06T13:19:13.746+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 1.0 in stage 477.0 (TID 736) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.750+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 0.0 in stage 477.0 (TID 735) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:13.756+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.760+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 2.0 in stage 477.0 (TID 737) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.760+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 1.0 in stage 477.0 (TID 736) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:13.775+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.779+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 3.0 in stage 477.0 (TID 738) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.779+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 2.0 in stage 477.0 (TID 737) in 19 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:13.785+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 4.0 in stage 477.0 (TID 739) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.790+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 3.0 in stage 477.0 (TID 738) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:13.795+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.798+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 5.0 in stage 477.0 (TID 740) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.798+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 4.0 in stage 477.0 (TID 739) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:13.802+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.806+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 6.0 in stage 477.0 (TID 741) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.806+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 5.0 in stage 477.0 (TID 740) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:13.810+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.813+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 7.0 in stage 477.0 (TID 742) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.813+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 6.0 in stage 477.0 (TID 741) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:13.817+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.820+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 8.0 in stage 477.0 (TID 743) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.821+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 7.0 in stage 477.0 (TID 742) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:13.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 9.0 in stage 477.0 (TID 744) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 8.0 in stage 477.0 (TID 743) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:13.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_478_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.841+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 9.0 in stage 477.0 (TID 744) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:13.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Removed TaskSet 477.0, whose tasks have all completed, from pool
[2025-05-06T13:19:13.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: ShuffleMapStage 477 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.116 s
[2025-05-06T13:19:13.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:13.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:13.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: waiting: Set(ResultStage 478)
[2025-05-06T13:19:13.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:13.842+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting ResultStage 478 (EdgeRDDImpl[485] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:13.844+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 121.2 KiB, free 425.7 MiB)
[2025-05-06T13:19:13.851+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 47.7 KiB, free 425.7 MiB)
[2025-05-06T13:19:13.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 016737cbcc7e:32777 in memory (size: 47.9 KiB, free: 434.3 MiB)
[2025-05-06T13:19:13.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 016737cbcc7e:32777 (size: 47.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.18.0.4:44293 in memory (size: 47.9 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:13.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 478 (EdgeRDDImpl[485] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:13.852+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Adding task set 478.0 with 10 tasks resource profile 0
[2025-05-06T13:19:13.853+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 0.0 in stage 478.0 (TID 745) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.858+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.18.0.4:44293 (size: 47.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:13.865+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.18.0.4:59552
[2025-05-06T13:19:13.868+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:19:13.869+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 1.0 in stage 478.0 (TID 746) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.870+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 0.0 in stage 478.0 (TID 745) in 17 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:13.877+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:19:13.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 2.0 in stage 478.0 (TID 747) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 1.0 in stage 478.0 (TID 746) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:13.890+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:19:13.892+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 3.0 in stage 478.0 (TID 748) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.892+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 2.0 in stage 478.0 (TID 747) in 14 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:13.898+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:19:13.900+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 4.0 in stage 478.0 (TID 749) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.900+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 3.0 in stage 478.0 (TID 748) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:13.906+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:13.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 5.0 in stage 478.0 (TID 750) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 4.0 in stage 478.0 (TID 749) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:13.914+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:13.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 6.0 in stage 478.0 (TID 751) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.918+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 5.0 in stage 478.0 (TID 750) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:13.924+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:19:13.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 7.0 in stage 478.0 (TID 752) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 6.0 in stage 478.0 (TID 751) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:13.931+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:13.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 8.0 in stage 478.0 (TID 753) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.933+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 7.0 in stage 478.0 (TID 752) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:13.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:13.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 9.0 in stage 478.0 (TID 754) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5092 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 8.0 in stage 478.0 (TID 753) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:13.946+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added rdd_484_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:13.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 9.0 in stage 478.0 (TID 754) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:13.947+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Removed TaskSet 478.0, whose tasks have all completed, from pool
[2025-05-06T13:19:13.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: ResultStage 478 (foreachPartition at PageRank.scala:199) finished in 0.105 s
[2025-05-06T13:19:13.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:13.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 478: Stage finished
[2025-05-06T13:19:13.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Job 57 finished: foreachPartition at PageRank.scala:199, took 0.397960 s
[2025-05-06T13:19:13.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO PageRank: PageRank finished iteration 4.
[2025-05-06T13:19:13.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO ZippedPartitionsRDD2: Removing RDD 466 from persistence list
[2025-05-06T13:19:13.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManager: Removing RDD 466
[2025-05-06T13:19:13.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO ZippedPartitionsRDD2: Removing RDD 472 from persistence list
[2025-05-06T13:19:13.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManager: Removing RDD 472
[2025-05-06T13:19:13.959+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:13.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Registering RDD 486 (mapPartitions at GraphImpl.scala:208) as input to shuffle 74
[2025-05-06T13:19:13.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Registering RDD 494 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 73
[2025-05-06T13:19:13.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Got job 58 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:13.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Final stage: ResultStage 502 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:13.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 484, ShuffleMapStage 491, ShuffleMapStage 488, ShuffleMapStage 495, ShuffleMapStage 489, ShuffleMapStage 499, ShuffleMapStage 493, ShuffleMapStage 482, ShuffleMapStage 497, ShuffleMapStage 501)
[2025-05-06T13:19:13.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 501)
[2025-05-06T13:19:13.961+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting ShuffleMapStage 500 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[486] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:13.965+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 121.7 KiB, free 425.7 MiB)
[2025-05-06T13:19:13.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.6 MiB)
[2025-05-06T13:19:13.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 016737cbcc7e:32777 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:13.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:13.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 500 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[486] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:13.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSchedulerImpl: Adding task set 500.0 with 10 tasks resource profile 0
[2025-05-06T13:19:13.967+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 0.0 in stage 500.0 (TID 755) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.971+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.18.0.4:44293 (size: 48.0 KiB, free: 174.3 MiB)
[2025-05-06T13:19:13.991+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Starting task 1.0 in stage 500.0 (TID 756) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:13.992+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:13 INFO TaskSetManager: Finished task 0.0 in stage 500.0 (TID 755) in 24 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 500.0 (TID 757) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.006+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 500.0 (TID 756) in 15 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 500.0 (TID 758) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.023+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 500.0 (TID 757) in 17 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.033+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 500.0 (TID 759) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 500.0 (TID 758) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:14.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 5.0 in stage 500.0 (TID 760) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.048+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 4.0 in stage 500.0 (TID 759) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:14.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 6.0 in stage 500.0 (TID 761) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.059+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 5.0 in stage 500.0 (TID 760) in 11 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:14.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 7.0 in stage 500.0 (TID 762) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 6.0 in stage 500.0 (TID 761) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:14.085+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 8.0 in stage 500.0 (TID 763) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.085+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 7.0 in stage 500.0 (TID 762) in 16 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:14.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 9.0 in stage 500.0 (TID 764) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5081 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 8.0 in stage 500.0 (TID 763) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:14.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 9.0 in stage 500.0 (TID 764) in 17 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:14.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Removed TaskSet 500.0, whose tasks have all completed, from pool
[2025-05-06T13:19:14.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: ShuffleMapStage 500 (mapPartitions at GraphImpl.scala:208) finished in 0.150 s
[2025-05-06T13:19:14.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:14.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:14.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: waiting: Set(ResultStage 502, ShuffleMapStage 501)
[2025-05-06T13:19:14.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:14.113+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting ShuffleMapStage 501 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[494] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:14.114+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 15.6 KiB, free 425.6 MiB)
[2025-05-06T13:19:14.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 425.6 MiB)
[2025-05-06T13:19:14.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 016737cbcc7e:32777 (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:14.116+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 501 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[494] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:14.116+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Adding task set 501.0 with 10 tasks resource profile 0
[2025-05-06T13:19:14.116+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 0.0 in stage 501.0 (TID 765) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.18.0.4:44293 (size: 6.4 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.123+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.18.0.4:59552
[2025-05-06T13:19:14.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 016737cbcc7e:32777 in memory (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.130+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 172.18.0.4:44293 in memory (size: 48.0 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.131+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 016737cbcc7e:32777 in memory (size: 47.7 KiB, free: 434.3 MiB)
[2025-05-06T13:19:14.132+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 172.18.0.4:44293 in memory (size: 47.7 KiB, free: 174.4 MiB)
[2025-05-06T13:19:14.132+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 016737cbcc7e:32777 in memory (size: 6.3 KiB, free: 434.3 MiB)
[2025-05-06T13:19:14.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.18.0.4:44293 in memory (size: 6.3 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 1.0 in stage 501.0 (TID 766) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 0.0 in stage 501.0 (TID 765) in 19 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.145+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 501.0 (TID 767) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.146+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 501.0 (TID 766) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.156+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 501.0 (TID 768) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 501.0 (TID 767) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.162+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 501.0 (TID 769) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.174+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 501.0 (TID 768) in 17 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:14.179+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.182+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 5.0 in stage 501.0 (TID 770) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.182+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 4.0 in stage 501.0 (TID 769) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:14.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 6.0 in stage 501.0 (TID 771) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 5.0 in stage 501.0 (TID 770) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:14.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.200+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 7.0 in stage 501.0 (TID 772) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.200+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 6.0 in stage 501.0 (TID 771) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:14.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 8.0 in stage 501.0 (TID 773) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.207+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 7.0 in stage 501.0 (TID 772) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:14.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.214+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 9.0 in stage 501.0 (TID 774) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.215+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 8.0 in stage 501.0 (TID 773) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:14.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_490_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 9.0 in stage 501.0 (TID 774) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:14.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Removed TaskSet 501.0, whose tasks have all completed, from pool
[2025-05-06T13:19:14.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: ShuffleMapStage 501 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.110 s
[2025-05-06T13:19:14.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:14.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:14.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: waiting: Set(ResultStage 502)
[2025-05-06T13:19:14.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:14.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting ResultStage 502 (EdgeRDDImpl[497] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:14.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 121.5 KiB, free 425.8 MiB)
[2025-05-06T13:19:14.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:14.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 016737cbcc7e:32777 (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:14.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 502 (EdgeRDDImpl[497] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:14.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Adding task set 502.0 with 10 tasks resource profile 0
[2025-05-06T13:19:14.227+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 0.0 in stage 502.0 (TID 775) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.18.0.4:44293 (size: 47.9 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.234+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.18.0.4:59552
[2025-05-06T13:19:14.236+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:19:14.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 1.0 in stage 502.0 (TID 776) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 0.0 in stage 502.0 (TID 775) in 11 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.246+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:19:14.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 502.0 (TID 777) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 502.0 (TID 776) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.257+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:19:14.259+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 502.0 (TID 778) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.259+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 502.0 (TID 777) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.265+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:19:14.266+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 502.0 (TID 779) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.267+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 502.0 (TID 778) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:14.273+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:14.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 5.0 in stage 502.0 (TID 780) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.274+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 4.0 in stage 502.0 (TID 779) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:14.281+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:14.282+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 6.0 in stage 502.0 (TID 781) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.283+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 5.0 in stage 502.0 (TID 780) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:14.288+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:19:14.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 7.0 in stage 502.0 (TID 782) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 6.0 in stage 502.0 (TID 781) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:14.295+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:14.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 8.0 in stage 502.0 (TID 783) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 7.0 in stage 502.0 (TID 782) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:14.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:14.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 9.0 in stage 502.0 (TID 784) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5133 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 8.0 in stage 502.0 (TID 783) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:14.308+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_496_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:14.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 9.0 in stage 502.0 (TID 784) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:14.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Removed TaskSet 502.0, whose tasks have all completed, from pool
[2025-05-06T13:19:14.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: ResultStage 502 (foreachPartition at PageRank.scala:199) finished in 0.087 s
[2025-05-06T13:19:14.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:14.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 502: Stage finished
[2025-05-06T13:19:14.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Job 58 finished: foreachPartition at PageRank.scala:199, took 0.351127 s
[2025-05-06T13:19:14.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO PageRank: PageRank finished iteration 5.
[2025-05-06T13:19:14.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO ZippedPartitionsRDD2: Removing RDD 478 from persistence list
[2025-05-06T13:19:14.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManager: Removing RDD 478
[2025-05-06T13:19:14.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO ZippedPartitionsRDD2: Removing RDD 484 from persistence list
[2025-05-06T13:19:14.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManager: Removing RDD 484
[2025-05-06T13:19:14.319+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:14.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Registering RDD 498 (mapPartitions at GraphImpl.scala:208) as input to shuffle 76
[2025-05-06T13:19:14.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Registering RDD 506 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 75
[2025-05-06T13:19:14.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Got job 59 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:14.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Final stage: ResultStage 528 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:14.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 527, ShuffleMapStage 506, ShuffleMapStage 521, ShuffleMapStage 513, ShuffleMapStage 525, ShuffleMapStage 517, ShuffleMapStage 515, ShuffleMapStage 512, ShuffleMapStage 519, ShuffleMapStage 508, ShuffleMapStage 523)
[2025-05-06T13:19:14.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 527)
[2025-05-06T13:19:14.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting ShuffleMapStage 526 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[498] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:14.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 122.0 KiB, free 425.7 MiB)
[2025-05-06T13:19:14.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 48.1 KiB, free 425.6 MiB)
[2025-05-06T13:19:14.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 016737cbcc7e:32777 (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:14.325+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 526 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[498] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:14.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Adding task set 526.0 with 10 tasks resource profile 0
[2025-05-06T13:19:14.326+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 0.0 in stage 526.0 (TID 785) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.329+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.18.0.4:44293 (size: 48.1 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 1.0 in stage 526.0 (TID 786) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.340+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 0.0 in stage 526.0 (TID 785) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 526.0 (TID 787) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 526.0 (TID 786) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 526.0 (TID 788) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.362+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 526.0 (TID 787) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.372+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 526.0 (TID 789) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.372+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 526.0 (TID 788) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:14.383+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 5.0 in stage 526.0 (TID 790) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.383+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 4.0 in stage 526.0 (TID 789) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:14.393+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 6.0 in stage 526.0 (TID 791) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.394+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 5.0 in stage 526.0 (TID 790) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:14.403+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 7.0 in stage 526.0 (TID 792) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.404+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 6.0 in stage 526.0 (TID 791) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:14.416+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 8.0 in stage 526.0 (TID 793) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.416+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 7.0 in stage 526.0 (TID 792) in 13 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:14.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 9.0 in stage 526.0 (TID 794) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5122 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.426+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 8.0 in stage 526.0 (TID 793) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:14.436+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 9.0 in stage 526.0 (TID 794) in 11 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:14.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Removed TaskSet 526.0, whose tasks have all completed, from pool
[2025-05-06T13:19:14.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: ShuffleMapStage 526 (mapPartitions at GraphImpl.scala:208) finished in 0.115 s
[2025-05-06T13:19:14.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:14.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:14.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: waiting: Set(ShuffleMapStage 527, ResultStage 528)
[2025-05-06T13:19:14.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:14.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting ShuffleMapStage 527 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[506] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:14.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 16.4 KiB, free 425.6 MiB)
[2025-05-06T13:19:14.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 425.6 MiB)
[2025-05-06T13:19:14.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 016737cbcc7e:32777 (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 016737cbcc7e:32777 in memory (size: 6.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:14.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 527 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[506] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:14.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Adding task set 527.0 with 10 tasks resource profile 0
[2025-05-06T13:19:14.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 172.18.0.4:44293 in memory (size: 6.4 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.444+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 0.0 in stage 527.0 (TID 795) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.445+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 016737cbcc7e:32777 in memory (size: 47.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.445+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.18.0.4:44293 in memory (size: 47.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.448+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.18.0.4:44293 (size: 6.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.450+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.18.0.4:59552
[2025-05-06T13:19:14.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 1.0 in stage 527.0 (TID 796) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 0.0 in stage 527.0 (TID 795) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.462+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.465+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 527.0 (TID 797) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.465+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 527.0 (TID 796) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.469+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 527.0 (TID 798) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.472+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 527.0 (TID 797) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.476+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 527.0 (TID 799) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.487+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 527.0 (TID 798) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:14.491+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.494+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 5.0 in stage 527.0 (TID 800) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.494+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 4.0 in stage 527.0 (TID 799) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:14.499+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.501+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 6.0 in stage 527.0 (TID 801) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.502+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 5.0 in stage 527.0 (TID 800) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:14.506+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.508+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 7.0 in stage 527.0 (TID 802) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 6.0 in stage 527.0 (TID 801) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:14.513+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.517+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 8.0 in stage 527.0 (TID 803) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.517+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 7.0 in stage 527.0 (TID 802) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:14.521+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 9.0 in stage 527.0 (TID 804) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 8.0 in stage 527.0 (TID 803) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:14.528+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_502_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.530+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 9.0 in stage 527.0 (TID 804) in 6 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:14.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Removed TaskSet 527.0, whose tasks have all completed, from pool
[2025-05-06T13:19:14.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: ShuffleMapStage 527 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.093 s
[2025-05-06T13:19:14.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:14.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:14.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: waiting: Set(ResultStage 528)
[2025-05-06T13:19:14.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:14.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting ResultStage 528 (EdgeRDDImpl[509] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:14.533+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 121.8 KiB, free 425.7 MiB)
[2025-05-06T13:19:14.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.6 MiB)
[2025-05-06T13:19:14.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 016737cbcc7e:32777 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:14.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 528 (EdgeRDDImpl[509] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:14.534+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Adding task set 528.0 with 10 tasks resource profile 0
[2025-05-06T13:19:14.535+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 0.0 in stage 528.0 (TID 805) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.540+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.18.0.4:44293 (size: 48.0 KiB, free: 174.1 MiB)
[2025-05-06T13:19:14.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.18.0.4:59552
[2025-05-06T13:19:14.546+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:19:14.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 1.0 in stage 528.0 (TID 806) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.547+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 0.0 in stage 528.0 (TID 805) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.555+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.7 MiB)
[2025-05-06T13:19:14.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 528.0 (TID 807) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 528.0 (TID 806) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.563+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:19:14.564+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 528.0 (TID 808) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 528.0 (TID 807) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.3 MiB)
[2025-05-06T13:19:14.574+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 528.0 (TID 809) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.574+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 528.0 (TID 808) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:14.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:14.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 5.0 in stage 528.0 (TID 810) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.584+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 4.0 in stage 528.0 (TID 809) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:14.589+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:14.591+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 6.0 in stage 528.0 (TID 811) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.591+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 5.0 in stage 528.0 (TID 810) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:14.597+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.4 MiB)
[2025-05-06T13:19:14.598+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 7.0 in stage 528.0 (TID 812) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.598+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 6.0 in stage 528.0 (TID 811) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:14.603+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:14.605+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 8.0 in stage 528.0 (TID 813) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.605+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 7.0 in stage 528.0 (TID 812) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:14.611+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:14.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 9.0 in stage 528.0 (TID 814) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5174 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.612+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 8.0 in stage 528.0 (TID 813) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:14.618+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_508_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:14.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 9.0 in stage 528.0 (TID 814) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:14.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Removed TaskSet 528.0, whose tasks have all completed, from pool
[2025-05-06T13:19:14.620+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: ResultStage 528 (foreachPartition at PageRank.scala:199) finished in 0.088 s
[2025-05-06T13:19:14.620+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:14.620+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 528: Stage finished
[2025-05-06T13:19:14.620+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Job 59 finished: foreachPartition at PageRank.scala:199, took 0.300588 s
[2025-05-06T13:19:14.620+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO PageRank: PageRank finished iteration 6.
[2025-05-06T13:19:14.620+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO ZippedPartitionsRDD2: Removing RDD 490 from persistence list
[2025-05-06T13:19:14.620+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManager: Removing RDD 490
[2025-05-06T13:19:14.620+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO ZippedPartitionsRDD2: Removing RDD 496 from persistence list
[2025-05-06T13:19:14.621+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManager: Removing RDD 496
[2025-05-06T13:19:14.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:14.629+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Registering RDD 510 (mapPartitions at GraphImpl.scala:208) as input to shuffle 78
[2025-05-06T13:19:14.629+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Registering RDD 518 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 77
[2025-05-06T13:19:14.630+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Got job 60 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:14.630+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Final stage: ResultStage 556 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:14.630+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 538, ShuffleMapStage 553, ShuffleMapStage 545, ShuffleMapStage 539, ShuffleMapStage 543, ShuffleMapStage 532, ShuffleMapStage 547, ShuffleMapStage 551, ShuffleMapStage 555, ShuffleMapStage 534, ShuffleMapStage 549, ShuffleMapStage 541)
[2025-05-06T13:19:14.630+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 555)
[2025-05-06T13:19:14.630+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting ShuffleMapStage 554 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[510] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:14.632+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 122.3 KiB, free 425.5 MiB)
[2025-05-06T13:19:14.637+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 016737cbcc7e:32777 in memory (size: 48.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 48.3 KiB, free 425.6 MiB)
[2025-05-06T13:19:14.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 016737cbcc7e:32777 (size: 48.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:14.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 554 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[510] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:14.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Adding task set 554.0 with 10 tasks resource profile 0
[2025-05-06T13:19:14.638+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 172.18.0.4:44293 in memory (size: 48.1 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 0.0 in stage 554.0 (TID 815) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 016737cbcc7e:32777 in memory (size: 6.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.640+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.18.0.4:44293 in memory (size: 6.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.641+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 016737cbcc7e:32777 in memory (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 172.18.0.4:44293 in memory (size: 48.0 KiB, free: 174.4 MiB)
[2025-05-06T13:19:14.643+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.18.0.4:44293 (size: 48.3 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 1.0 in stage 554.0 (TID 816) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.654+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 0.0 in stage 554.0 (TID 815) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 554.0 (TID 817) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.673+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 554.0 (TID 816) in 19 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 554.0 (TID 818) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.688+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 554.0 (TID 817) in 16 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.701+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 554.0 (TID 819) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.702+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 554.0 (TID 818) in 13 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:14.711+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 5.0 in stage 554.0 (TID 820) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.712+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 4.0 in stage 554.0 (TID 819) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:14.721+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 6.0 in stage 554.0 (TID 821) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.722+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 5.0 in stage 554.0 (TID 820) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:14.731+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 7.0 in stage 554.0 (TID 822) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.732+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 6.0 in stage 554.0 (TID 821) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:14.742+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 8.0 in stage 554.0 (TID 823) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.742+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 7.0 in stage 554.0 (TID 822) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:14.752+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 9.0 in stage 554.0 (TID 824) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5163 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.752+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 8.0 in stage 554.0 (TID 823) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:14.763+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 9.0 in stage 554.0 (TID 824) in 12 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:14.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Removed TaskSet 554.0, whose tasks have all completed, from pool
[2025-05-06T13:19:14.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: ShuffleMapStage 554 (mapPartitions at GraphImpl.scala:208) finished in 0.133 s
[2025-05-06T13:19:14.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:14.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:14.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: waiting: Set(ResultStage 556, ShuffleMapStage 555)
[2025-05-06T13:19:14.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:14.764+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting ShuffleMapStage 555 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[518] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:14.765+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 17.1 KiB, free 425.8 MiB)
[2025-05-06T13:19:14.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 425.8 MiB)
[2025-05-06T13:19:14.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 016737cbcc7e:32777 (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:14.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 555 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[518] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:14.766+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Adding task set 555.0 with 10 tasks resource profile 0
[2025-05-06T13:19:14.767+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 0.0 in stage 555.0 (TID 825) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.770+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 172.18.0.4:44293 (size: 6.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.772+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.18.0.4:59552
[2025-05-06T13:19:14.774+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.777+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 1.0 in stage 555.0 (TID 826) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.778+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 0.0 in stage 555.0 (TID 825) in 10 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.782+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.784+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 555.0 (TID 827) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.785+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 555.0 (TID 826) in 8 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.789+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.792+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 555.0 (TID 828) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.793+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 555.0 (TID 827) in 8 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.798+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 555.0 (TID 829) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.800+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 555.0 (TID 828) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:14.804+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.808+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 5.0 in stage 555.0 (TID 830) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.809+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 4.0 in stage 555.0 (TID 829) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:14.813+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.815+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 6.0 in stage 555.0 (TID 831) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.816+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 5.0 in stage 555.0 (TID 830) in 8 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:14.820+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.822+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 7.0 in stage 555.0 (TID 832) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.822+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 6.0 in stage 555.0 (TID 831) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:14.826+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 8.0 in stage 555.0 (TID 833) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 7.0 in stage 555.0 (TID 832) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:14.833+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 9.0 in stage 555.0 (TID 834) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 8.0 in stage 555.0 (TID 833) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:14.840+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_514_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 9.0 in stage 555.0 (TID 834) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:14.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Removed TaskSet 555.0, whose tasks have all completed, from pool
[2025-05-06T13:19:14.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: ShuffleMapStage 555 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.079 s
[2025-05-06T13:19:14.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:14.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:14.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: waiting: Set(ResultStage 556)
[2025-05-06T13:19:14.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:14.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting ResultStage 556 (EdgeRDDImpl[521] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:14.845+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 122.1 KiB, free 425.7 MiB)
[2025-05-06T13:19:14.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.6 MiB)
[2025-05-06T13:19:14.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 016737cbcc7e:32777 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:14.846+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 556 (EdgeRDDImpl[521] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:14.847+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Adding task set 556.0 with 10 tasks resource profile 0
[2025-05-06T13:19:14.847+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 0.0 in stage 556.0 (TID 835) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.850+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 172.18.0.4:44293 (size: 48.0 KiB, free: 174.1 MiB)
[2025-05-06T13:19:14.854+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.18.0.4:59552
[2025-05-06T13:19:14.858+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 016737cbcc7e:32777 in memory (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.859+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 172.18.0.4:44293 in memory (size: 6.6 KiB, free: 174.1 MiB)
[2025-05-06T13:19:14.860+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 016737cbcc7e:32777 in memory (size: 48.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.861+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 172.18.0.4:44293 in memory (size: 48.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:14.861+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.6 MiB)
[2025-05-06T13:19:14.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 1.0 in stage 556.0 (TID 836) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.863+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 0.0 in stage 556.0 (TID 835) in 16 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.870+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:19:14.872+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 556.0 (TID 837) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.872+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 556.0 (TID 836) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.1 MiB)
[2025-05-06T13:19:14.881+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 556.0 (TID 838) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.881+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 556.0 (TID 837) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.893+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:19:14.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 556.0 (TID 839) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 556.0 (TID 838) in 14 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:14.900+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:14.902+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 5.0 in stage 556.0 (TID 840) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.902+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 4.0 in stage 556.0 (TID 839) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:14.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:14.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 6.0 in stage 556.0 (TID 841) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.909+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 5.0 in stage 556.0 (TID 840) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:14.914+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:19:14.916+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 7.0 in stage 556.0 (TID 842) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.916+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 6.0 in stage 556.0 (TID 841) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:14.922+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:14.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 8.0 in stage 556.0 (TID 843) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.924+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 7.0 in stage 556.0 (TID 842) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:14.928+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:14.930+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 9.0 in stage 556.0 (TID 844) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5215 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.930+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 8.0 in stage 556.0 (TID 843) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:14.936+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added rdd_520_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:14.939+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 9.0 in stage 556.0 (TID 844) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:14.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Removed TaskSet 556.0, whose tasks have all completed, from pool
[2025-05-06T13:19:14.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: ResultStage 556 (foreachPartition at PageRank.scala:199) finished in 0.096 s
[2025-05-06T13:19:14.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:14.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 556: Stage finished
[2025-05-06T13:19:14.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Job 60 finished: foreachPartition at PageRank.scala:199, took 0.311740 s
[2025-05-06T13:19:14.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO PageRank: PageRank finished iteration 7.
[2025-05-06T13:19:14.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO ZippedPartitionsRDD2: Removing RDD 502 from persistence list
[2025-05-06T13:19:14.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManager: Removing RDD 502
[2025-05-06T13:19:14.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO ZippedPartitionsRDD2: Removing RDD 508 from persistence list
[2025-05-06T13:19:14.941+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManager: Removing RDD 508
[2025-05-06T13:19:14.948+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:14.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Registering RDD 522 (mapPartitions at GraphImpl.scala:208) as input to shuffle 80
[2025-05-06T13:19:14.949+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Registering RDD 530 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 79
[2025-05-06T13:19:14.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Got job 61 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:14.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Final stage: ResultStage 586 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:14.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 571, ShuffleMapStage 560, ShuffleMapStage 575, ShuffleMapStage 579, ShuffleMapStage 583, ShuffleMapStage 562, ShuffleMapStage 569, ShuffleMapStage 566, ShuffleMapStage 581, ShuffleMapStage 573, ShuffleMapStage 585, ShuffleMapStage 567, ShuffleMapStage 577)
[2025-05-06T13:19:14.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 585)
[2025-05-06T13:19:14.950+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting ShuffleMapStage 584 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[522] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:14.953+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 122.5 KiB, free 425.7 MiB)
[2025-05-06T13:19:14.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 425.6 MiB)
[2025-05-06T13:19:14.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 016737cbcc7e:32777 (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T13:19:14.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:14.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 584 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[522] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:14.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSchedulerImpl: Adding task set 584.0 with 10 tasks resource profile 0
[2025-05-06T13:19:14.954+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 0.0 in stage 584.0 (TID 845) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.958+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 172.18.0.4:44293 (size: 48.2 KiB, free: 174.3 MiB)
[2025-05-06T13:19:14.967+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 1.0 in stage 584.0 (TID 846) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.968+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 0.0 in stage 584.0 (TID 845) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:14.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 2.0 in stage 584.0 (TID 847) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 1.0 in stage 584.0 (TID 846) in 11 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:14.988+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 3.0 in stage 584.0 (TID 848) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.989+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 2.0 in stage 584.0 (TID 847) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:14.999+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Starting task 4.0 in stage 584.0 (TID 849) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:14.999+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:14 INFO TaskSetManager: Finished task 3.0 in stage 584.0 (TID 848) in 11 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:15.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 5.0 in stage 584.0 (TID 850) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 4.0 in stage 584.0 (TID 849) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:15.021+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 6.0 in stage 584.0 (TID 851) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 5.0 in stage 584.0 (TID 850) in 13 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:15.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 7.0 in stage 584.0 (TID 852) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 6.0 in stage 584.0 (TID 851) in 11 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:15.042+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 8.0 in stage 584.0 (TID 853) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.043+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 7.0 in stage 584.0 (TID 852) in 11 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:15.053+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 9.0 in stage 584.0 (TID 854) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5204 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.053+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 8.0 in stage 584.0 (TID 853) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:15.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 9.0 in stage 584.0 (TID 854) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:15.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Removed TaskSet 584.0, whose tasks have all completed, from pool
[2025-05-06T13:19:15.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: ShuffleMapStage 584 (mapPartitions at GraphImpl.scala:208) finished in 0.114 s
[2025-05-06T13:19:15.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:15.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:15.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: waiting: Set(ResultStage 586, ShuffleMapStage 585)
[2025-05-06T13:19:15.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:15.064+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting ShuffleMapStage 585 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[530] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:15.065+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 17.8 KiB, free 425.6 MiB)
[2025-05-06T13:19:15.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 425.6 MiB)
[2025-05-06T13:19:15.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 016737cbcc7e:32777 (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:15.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 585 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[530] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:15.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Adding task set 585.0 with 10 tasks resource profile 0
[2025-05-06T13:19:15.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 0.0 in stage 585.0 (TID 855) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 172.18.0.4:44293 (size: 6.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.072+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.18.0.4:59552
[2025-05-06T13:19:15.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 1.0 in stage 585.0 (TID 856) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 0.0 in stage 585.0 (TID 855) in 11 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:15.081+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.084+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 2.0 in stage 585.0 (TID 857) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.084+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 1.0 in stage 585.0 (TID 856) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:15.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 3.0 in stage 585.0 (TID 858) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 2.0 in stage 585.0 (TID 857) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:15.095+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.098+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 4.0 in stage 585.0 (TID 859) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.098+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 3.0 in stage 585.0 (TID 858) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:15.102+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 5.0 in stage 585.0 (TID 860) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.108+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 4.0 in stage 585.0 (TID 859) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:15.112+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 6.0 in stage 585.0 (TID 861) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 5.0 in stage 585.0 (TID 860) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:15.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.122+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 7.0 in stage 585.0 (TID 862) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.122+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 6.0 in stage 585.0 (TID 861) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:15.126+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.128+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 8.0 in stage 585.0 (TID 863) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.129+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 7.0 in stage 585.0 (TID 862) in 6 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:15.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.1 MiB)
[2025-05-06T13:19:15.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 9.0 in stage 585.0 (TID 864) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 8.0 in stage 585.0 (TID 863) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:15.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_526_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.1 MiB)
[2025-05-06T13:19:15.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 9.0 in stage 585.0 (TID 864) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:15.142+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Removed TaskSet 585.0, whose tasks have all completed, from pool
[2025-05-06T13:19:15.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: ShuffleMapStage 585 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.078 s
[2025-05-06T13:19:15.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:15.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:15.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: waiting: Set(ResultStage 586)
[2025-05-06T13:19:15.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:15.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting ResultStage 586 (EdgeRDDImpl[533] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:15.145+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 122.3 KiB, free 425.5 MiB)
[2025-05-06T13:19:15.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 016737cbcc7e:32777 in memory (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.150+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 425.5 MiB)
[2025-05-06T13:19:15.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 016737cbcc7e:32777 (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:15.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 586 (EdgeRDDImpl[533] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:15.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Adding task set 586.0 with 10 tasks resource profile 0
[2025-05-06T13:19:15.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 0.0 in stage 586.0 (TID 865) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.151+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 172.18.0.4:44293 in memory (size: 48.2 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 016737cbcc7e:32777 in memory (size: 48.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 172.18.0.4:44293 in memory (size: 48.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.155+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 172.18.0.4:44293 (size: 48.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.161+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.18.0.4:59552
[2025-05-06T13:19:15.164+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:19:15.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 1.0 in stage 586.0 (TID 866) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.166+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 0.0 in stage 586.0 (TID 865) in 15 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:15.173+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:19:15.175+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 2.0 in stage 586.0 (TID 867) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.175+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 1.0 in stage 586.0 (TID 866) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:15.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:19:15.188+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 3.0 in stage 586.0 (TID 868) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.189+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 2.0 in stage 586.0 (TID 867) in 13 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:15.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:19:15.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 4.0 in stage 586.0 (TID 869) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.196+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 3.0 in stage 586.0 (TID 868) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:15.204+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:15.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 5.0 in stage 586.0 (TID 870) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.205+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 4.0 in stage 586.0 (TID 869) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:15.211+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:15.212+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 6.0 in stage 586.0 (TID 871) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.213+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 5.0 in stage 586.0 (TID 870) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:15.217+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:19:15.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 7.0 in stage 586.0 (TID 872) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.219+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 6.0 in stage 586.0 (TID 871) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:15.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:15.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 8.0 in stage 586.0 (TID 873) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 7.0 in stage 586.0 (TID 872) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:15.230+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:15.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 9.0 in stage 586.0 (TID 874) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5256 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 8.0 in stage 586.0 (TID 873) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:15.239+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_532_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:15.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 9.0 in stage 586.0 (TID 874) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:15.240+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Removed TaskSet 586.0, whose tasks have all completed, from pool
[2025-05-06T13:19:15.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: ResultStage 586 (foreachPartition at PageRank.scala:199) finished in 0.097 s
[2025-05-06T13:19:15.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:15.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 586: Stage finished
[2025-05-06T13:19:15.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Job 61 finished: foreachPartition at PageRank.scala:199, took 0.292747 s
[2025-05-06T13:19:15.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO PageRank: PageRank finished iteration 8.
[2025-05-06T13:19:15.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO ZippedPartitionsRDD2: Removing RDD 514 from persistence list
[2025-05-06T13:19:15.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManager: Removing RDD 514
[2025-05-06T13:19:15.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO ZippedPartitionsRDD2: Removing RDD 520 from persistence list
[2025-05-06T13:19:15.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManager: Removing RDD 520
[2025-05-06T13:19:15.249+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-06T13:19:15.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Registering RDD 534 (mapPartitions at GraphImpl.scala:208) as input to shuffle 82
[2025-05-06T13:19:15.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Registering RDD 542 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 81
[2025-05-06T13:19:15.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Got job 62 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-06T13:19:15.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Final stage: ResultStage 618 (foreachPartition at PageRank.scala:199)
[2025-05-06T13:19:15.250+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 596, ShuffleMapStage 611, ShuffleMapStage 597, ShuffleMapStage 613, ShuffleMapStage 605, ShuffleMapStage 599, ShuffleMapStage 592, ShuffleMapStage 607, ShuffleMapStage 615, ShuffleMapStage 609, ShuffleMapStage 601, ShuffleMapStage 587, ShuffleMapStage 617, ShuffleMapStage 603)
[2025-05-06T13:19:15.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 617)
[2025-05-06T13:19:15.251+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting ShuffleMapStage 616 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[534] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-06T13:19:15.253+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 122.8 KiB, free 425.7 MiB)
[2025-05-06T13:19:15.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 48.4 KiB, free 425.6 MiB)
[2025-05-06T13:19:15.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 016737cbcc7e:32777 (size: 48.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:15.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 616 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[534] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:15.254+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Adding task set 616.0 with 10 tasks resource profile 0
[2025-05-06T13:19:15.255+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 0.0 in stage 616.0 (TID 875) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 172.18.0.4:44293 (size: 48.4 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.267+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 1.0 in stage 616.0 (TID 876) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.268+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 0.0 in stage 616.0 (TID 875) in 13 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:15.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 2.0 in stage 616.0 (TID 877) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.280+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 1.0 in stage 616.0 (TID 876) in 13 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:15.290+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 3.0 in stage 616.0 (TID 878) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.290+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 2.0 in stage 616.0 (TID 877) in 11 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:15.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 4.0 in stage 616.0 (TID 879) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.300+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 3.0 in stage 616.0 (TID 878) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:15.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 5.0 in stage 616.0 (TID 880) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 4.0 in stage 616.0 (TID 879) in 10 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:15.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 6.0 in stage 616.0 (TID 881) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.320+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 5.0 in stage 616.0 (TID 880) in 10 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:15.330+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 7.0 in stage 616.0 (TID 882) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.331+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 6.0 in stage 616.0 (TID 881) in 10 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:15.342+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 8.0 in stage 616.0 (TID 883) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.342+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 7.0 in stage 616.0 (TID 882) in 12 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:15.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 9.0 in stage 616.0 (TID 884) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.353+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 8.0 in stage 616.0 (TID 883) in 11 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:15.363+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 9.0 in stage 616.0 (TID 884) in 10 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:15.363+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Removed TaskSet 616.0, whose tasks have all completed, from pool
[2025-05-06T13:19:15.363+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: ShuffleMapStage 616 (mapPartitions at GraphImpl.scala:208) finished in 0.112 s
[2025-05-06T13:19:15.363+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:15.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:15.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: waiting: Set(ShuffleMapStage 617, ResultStage 618)
[2025-05-06T13:19:15.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:15.364+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting ShuffleMapStage 617 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[542] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-06T13:19:15.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 18.5 KiB, free 425.6 MiB)
[2025-05-06T13:19:15.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 425.6 MiB)
[2025-05-06T13:19:15.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:15.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 617 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[542] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:15.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Adding task set 617.0 with 10 tasks resource profile 0
[2025-05-06T13:19:15.366+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 0.0 in stage 617.0 (TID 885) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.369+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.371+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.18.0.4:59552
[2025-05-06T13:19:15.378+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 016737cbcc7e:32777 in memory (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.379+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 172.18.0.4:44293 in memory (size: 6.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.380+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 016737cbcc7e:32777 in memory (size: 48.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 172.18.0.4:44293 in memory (size: 48.4 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.381+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.383+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 016737cbcc7e:32777 in memory (size: 48.0 KiB, free: 434.3 MiB)
[2025-05-06T13:19:15.384+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 172.18.0.4:44293 in memory (size: 48.0 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 1.0 in stage 617.0 (TID 886) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 0.0 in stage 617.0 (TID 885) in 19 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:15.389+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.392+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 2.0 in stage 617.0 (TID 887) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.393+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 1.0 in stage 617.0 (TID 886) in 7 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:15.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.400+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 3.0 in stage 617.0 (TID 888) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.400+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 2.0 in stage 617.0 (TID 887) in 8 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:15.404+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 4.0 in stage 617.0 (TID 889) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.407+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 3.0 in stage 617.0 (TID 888) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:15.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.414+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 5.0 in stage 617.0 (TID 890) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 4.0 in stage 617.0 (TID 889) in 14 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:15.425+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.428+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 6.0 in stage 617.0 (TID 891) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.428+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 5.0 in stage 617.0 (TID 890) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:15.432+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.435+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 7.0 in stage 617.0 (TID 892) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.435+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 6.0 in stage 617.0 (TID 891) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:15.440+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 8.0 in stage 617.0 (TID 893) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.443+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 7.0 in stage 617.0 (TID 892) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:15.447+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.449+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 9.0 in stage 617.0 (TID 894) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.450+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 8.0 in stage 617.0 (TID 893) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:15.453+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_538_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 9.0 in stage 617.0 (TID 894) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:15.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Removed TaskSet 617.0, whose tasks have all completed, from pool
[2025-05-06T13:19:15.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: ShuffleMapStage 617 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.092 s
[2025-05-06T13:19:15.456+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:15.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:15.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: waiting: Set(ResultStage 618)
[2025-05-06T13:19:15.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:15.457+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting ResultStage 618 (EdgeRDDImpl[545] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-06T13:19:15.459+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 122.6 KiB, free 425.8 MiB)
[2025-05-06T13:19:15.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 425.8 MiB)
[2025-05-06T13:19:15.460+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 016737cbcc7e:32777 (size: 48.2 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:15.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 618 (EdgeRDDImpl[545] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:15.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Adding task set 618.0 with 10 tasks resource profile 0
[2025-05-06T13:19:15.461+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 0.0 in stage 618.0 (TID 895) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.464+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 172.18.0.4:44293 (size: 48.2 KiB, free: 174.2 MiB)
[2025-05-06T13:19:15.469+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.18.0.4:59552
[2025-05-06T13:19:15.471+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_0 in memory on 172.18.0.4:44293 (size: 641.5 KiB, free: 173.5 MiB)
[2025-05-06T13:19:15.473+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 1.0 in stage 618.0 (TID 896) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.473+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 0.0 in stage 618.0 (TID 895) in 12 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:15.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_1 in memory on 172.18.0.4:44293 (size: 806.3 KiB, free: 172.8 MiB)
[2025-05-06T13:19:15.482+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 2.0 in stage 618.0 (TID 897) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.482+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 1.0 in stage 618.0 (TID 896) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:15.488+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_2 in memory on 172.18.0.4:44293 (size: 727.9 KiB, free: 172.0 MiB)
[2025-05-06T13:19:15.489+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 3.0 in stage 618.0 (TID 898) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.489+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 2.0 in stage 618.0 (TID 897) in 7 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:15.494+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_3 in memory on 172.18.0.4:44293 (size: 696.7 KiB, free: 171.4 MiB)
[2025-05-06T13:19:15.496+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 4.0 in stage 618.0 (TID 899) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.496+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 3.0 in stage 618.0 (TID 898) in 7 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:15.502+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_4 in memory on 172.18.0.4:44293 (size: 579.6 KiB, free: 170.8 MiB)
[2025-05-06T13:19:15.503+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 5.0 in stage 618.0 (TID 900) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.504+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 4.0 in stage 618.0 (TID 899) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:15.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_5 in memory on 172.18.0.4:44293 (size: 678.9 KiB, free: 170.1 MiB)
[2025-05-06T13:19:15.510+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 6.0 in stage 618.0 (TID 901) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.510+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 5.0 in stage 618.0 (TID 900) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:15.515+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_6 in memory on 172.18.0.4:44293 (size: 688.7 KiB, free: 169.5 MiB)
[2025-05-06T13:19:15.517+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 7.0 in stage 618.0 (TID 902) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.517+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 6.0 in stage 618.0 (TID 901) in 7 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:15.522+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_7 in memory on 172.18.0.4:44293 (size: 777.7 KiB, free: 168.7 MiB)
[2025-05-06T13:19:15.523+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 8.0 in stage 618.0 (TID 903) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.524+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 7.0 in stage 618.0 (TID 902) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:15.529+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_8 in memory on 172.18.0.4:44293 (size: 708.0 KiB, free: 168.0 MiB)
[2025-05-06T13:19:15.530+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 9.0 in stage 618.0 (TID 904) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5297 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.531+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 8.0 in stage 618.0 (TID 903) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:15.536+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added rdd_544_9 in memory on 172.18.0.4:44293 (size: 795.9 KiB, free: 167.2 MiB)
[2025-05-06T13:19:15.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 9.0 in stage 618.0 (TID 904) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:15.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Removed TaskSet 618.0, whose tasks have all completed, from pool
[2025-05-06T13:19:15.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: ResultStage 618 (foreachPartition at PageRank.scala:199) finished in 0.081 s
[2025-05-06T13:19:15.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:15.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 618: Stage finished
[2025-05-06T13:19:15.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Job 62 finished: foreachPartition at PageRank.scala:199, took 0.289993 s
[2025-05-06T13:19:15.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO PageRank: PageRank finished iteration 9.
[2025-05-06T13:19:15.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO ZippedPartitionsRDD2: Removing RDD 526 from persistence list
[2025-05-06T13:19:15.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManager: Removing RDD 526
[2025-05-06T13:19:15.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO ZippedPartitionsRDD2: Removing RDD 532 from persistence list
[2025-05-06T13:19:15.540+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManager: Removing RDD 532
[2025-05-06T13:19:15.555+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Starting job: sum at PageRank.scala:503
[2025-05-06T13:19:15.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Got job 63 (sum at PageRank.scala:503) with 10 output partitions
[2025-05-06T13:19:15.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Final stage: ResultStage 649 (sum at PageRank.scala:503)
[2025-05-06T13:19:15.557+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 625, ShuffleMapStage 640, ShuffleMapStage 626, ShuffleMapStage 644, ShuffleMapStage 648, ShuffleMapStage 630, ShuffleMapStage 627, ShuffleMapStage 634, ShuffleMapStage 646, ShuffleMapStage 638, ShuffleMapStage 632, ShuffleMapStage 642, ShuffleMapStage 636)
[2025-05-06T13:19:15.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:15.558+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting ResultStage 649 (MapPartitionsRDD[546] at values at PageRank.scala:503), which has no missing parents
[2025-05-06T13:19:15.559+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 18.9 KiB, free 425.8 MiB)
[2025-05-06T13:19:15.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 425.7 MiB)
[2025-05-06T13:19:15.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 016737cbcc7e:32777 (size: 7.0 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:15.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 649 (MapPartitionsRDD[546] at values at PageRank.scala:503) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:15.560+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Adding task set 649.0 with 10 tasks resource profile 0
[2025-05-06T13:19:15.561+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 0.0 in stage 649.0 (TID 905) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 172.18.0.4:44293 (size: 7.0 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.587+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 1.0 in stage 649.0 (TID 906) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.587+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 0.0 in stage 649.0 (TID 905) in 26 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:15.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 2.0 in stage 649.0 (TID 907) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.590+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 1.0 in stage 649.0 (TID 906) in 3 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:15.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 3.0 in stage 649.0 (TID 908) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.593+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 2.0 in stage 649.0 (TID 907) in 3 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:15.596+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 4.0 in stage 649.0 (TID 909) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.596+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 3.0 in stage 649.0 (TID 908) in 4 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:15.598+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 5.0 in stage 649.0 (TID 910) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.599+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 4.0 in stage 649.0 (TID 909) in 3 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:15.601+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 6.0 in stage 649.0 (TID 911) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.601+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 5.0 in stage 649.0 (TID 910) in 3 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:15.604+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 7.0 in stage 649.0 (TID 912) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.604+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 6.0 in stage 649.0 (TID 911) in 3 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:15.607+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 8.0 in stage 649.0 (TID 913) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.607+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 7.0 in stage 649.0 (TID 912) in 3 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:15.610+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 9.0 in stage 649.0 (TID 914) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.611+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 8.0 in stage 649.0 (TID 913) in 3 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:15.614+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 9.0 in stage 649.0 (TID 914) in 4 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:15.614+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Removed TaskSet 649.0, whose tasks have all completed, from pool
[2025-05-06T13:19:15.614+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: ResultStage 649 (sum at PageRank.scala:503) finished in 0.056 s
[2025-05-06T13:19:15.614+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:15.614+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 649: Stage finished
[2025-05-06T13:19:15.615+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Job 63 finished: sum at PageRank.scala:503, took 0.059496 s
[2025-05-06T13:19:15.617+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-06T13:19:15.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Got job 64 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-06T13:19:15.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Final stage: ResultStage 680 (fold at VertexRDDImpl.scala:90)
[2025-05-06T13:19:15.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 679, ShuffleMapStage 661, ShuffleMapStage 673, ShuffleMapStage 658, ShuffleMapStage 665, ShuffleMapStage 677, ShuffleMapStage 663, ShuffleMapStage 667, ShuffleMapStage 656, ShuffleMapStage 671, ShuffleMapStage 657, ShuffleMapStage 675, ShuffleMapStage 669)
[2025-05-06T13:19:15.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:15.619+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting ResultStage 680 (MapPartitionsRDD[547] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-06T13:19:15.620+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 18.7 KiB, free 425.7 MiB)
[2025-05-06T13:19:15.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 425.7 MiB)
[2025-05-06T13:19:15.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.627+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 016737cbcc7e:32777 (size: 6.9 KiB, free: 434.2 MiB)
[2025-05-06T13:19:15.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:15.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 680 (MapPartitionsRDD[547] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:15.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Adding task set 680.0 with 10 tasks resource profile 0
[2025-05-06T13:19:15.628+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:15.629+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 0.0 in stage 680.0 (TID 915) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.629+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 016737cbcc7e:32777 in memory (size: 48.2 KiB, free: 434.3 MiB)
[2025-05-06T13:19:15.631+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 172.18.0.4:44293 in memory (size: 48.2 KiB, free: 174.4 MiB)
[2025-05-06T13:19:15.632+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 016737cbcc7e:32777 in memory (size: 7.0 KiB, free: 434.3 MiB)
[2025-05-06T13:19:15.633+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 172.18.0.4:44293 in memory (size: 7.0 KiB, free: 174.4 MiB)
[2025-05-06T13:19:15.633+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 172.18.0.4:44293 (size: 6.9 KiB, free: 174.4 MiB)
[2025-05-06T13:19:15.636+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 1.0 in stage 680.0 (TID 916) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.636+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 0.0 in stage 680.0 (TID 915) in 8 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:15.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 2.0 in stage 680.0 (TID 917) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.639+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 1.0 in stage 680.0 (TID 916) in 3 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:15.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 3.0 in stage 680.0 (TID 918) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.642+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 2.0 in stage 680.0 (TID 917) in 3 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:15.645+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 4.0 in stage 680.0 (TID 919) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.646+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 3.0 in stage 680.0 (TID 918) in 4 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:15.649+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 5.0 in stage 680.0 (TID 920) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.649+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 4.0 in stage 680.0 (TID 919) in 4 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:15.652+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 6.0 in stage 680.0 (TID 921) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.652+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 5.0 in stage 680.0 (TID 920) in 4 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:15.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 7.0 in stage 680.0 (TID 922) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.655+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 6.0 in stage 680.0 (TID 921) in 3 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:15.659+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 8.0 in stage 680.0 (TID 923) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.660+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 7.0 in stage 680.0 (TID 922) in 4 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:15.662+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Starting task 9.0 in stage 680.0 (TID 924) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:15.662+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 8.0 in stage 680.0 (TID 923) in 3 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:15.671+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSetManager: Finished task 9.0 in stage 680.0 (TID 924) in 9 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:15.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Removed TaskSet 680.0, whose tasks have all completed, from pool
[2025-05-06T13:19:15.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: ResultStage 680 (fold at VertexRDDImpl.scala:90) finished in 0.051 s
[2025-05-06T13:19:15.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:15.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 680: Stage finished
[2025-05-06T13:19:15.672+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:15 INFO DAGScheduler: Job 64 finished: fold at VertexRDDImpl.scala:90, took 0.054439 s
[2025-05-06T13:19:15.773+0000] {spark_submit.py:571} INFO - 2025-05-06 13:19:15,773 [INFO] Объединяем результаты анализа
[2025-05-06T13:19:15.862+0000] {spark_submit.py:571} INFO - 2025-05-06 13:19:15,862 [INFO] Сохраняем результаты в graph.client_communities
[2025-05-06T13:19:16.003+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:19:16.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Registering RDD 563 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 84
[2025-05-06T13:19:16.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got map stage job 65 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:19:16.007+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ShuffleMapStage 681 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:16.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List()
[2025-05-06T13:19:16.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 681 (MapPartitionsRDD[563] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:16.008+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 19.9 KiB, free 425.9 MiB)
[2025-05-06T13:19:16.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 425.9 MiB)
[2025-05-06T13:19:16.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 016737cbcc7e:32777 (size: 9.7 KiB, free: 434.3 MiB)
[2025-05-06T13:19:16.009+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 681 (MapPartitionsRDD[563] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:16.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 681.0 with 1 tasks resource profile 0
[2025-05-06T13:19:16.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 681.0 (TID 925) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.010+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 6.319354 ms
[2025-05-06T13:19:16.011+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#262) generates partition filter: ((id.count#1005 - id.nullCount#1004) > 0)
[2025-05-06T13:19:16.021+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 172.18.0.4:44293 (size: 9.7 KiB, free: 174.4 MiB)
[2025-05-06T13:19:16.022+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 016737cbcc7e:32777 in memory (size: 6.9 KiB, free: 434.3 MiB)
[2025-05-06T13:19:16.024+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 172.18.0.4:44293 in memory (size: 6.9 KiB, free: 174.4 MiB)
[2025-05-06T13:19:16.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:16.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got job 66 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 10 output partitions
[2025-05-06T13:19:16.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ResultStage 683 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:19:16.029+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 682)
[2025-05-06T13:19:16.030+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.030+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ResultStage 683 (MapPartitionsRDD[568] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:19:16.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 49.9 KiB, free 425.9 MiB)
[2025-05-06T13:19:16.033+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 425.9 MiB)
[2025-05-06T13:19:16.033+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 016737cbcc7e:32777 (size: 20.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 683 (MapPartitionsRDD[568] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:16.034+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 683.0 with 10 tasks resource profile 0
[2025-05-06T13:19:16.037+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 10.124626 ms
[2025-05-06T13:19:16.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 683.0 (TID 926) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 681.0 (TID 925) in 36 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:16.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 681.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Registering RDD 571 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 85
[2025-05-06T13:19:16.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got map stage job 67 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-06T13:19:16.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ShuffleMapStage 721 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:16.047+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 720, ShuffleMapStage 708, ShuffleMapStage 702, ShuffleMapStage 717, ShuffleMapStage 714, ShuffleMapStage 696, ShuffleMapStage 699, ShuffleMapStage 689, ShuffleMapStage 693, ShuffleMapStage 690, ShuffleMapStage 705, ShuffleMapStage 711)
[2025-05-06T13:19:16.049+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.051+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 721 (MapPartitionsRDD[571] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:16.053+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 172.18.0.4:44293 (size: 20.4 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.054+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 30.4 KiB, free 425.8 MiB)
[2025-05-06T13:19:16.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 425.8 MiB)
[2025-05-06T13:19:16.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 016737cbcc7e:32777 (size: 11.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.055+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 721 (MapPartitionsRDD[571] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:16.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 721.0 with 10 tasks resource profile 0
[2025-05-06T13:19:16.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ShuffleMapStage 681 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.049 s
[2025-05-06T13:19:16.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:16.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: running: Set(ShuffleMapStage 721, ResultStage 683)
[2025-05-06T13:19:16.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:16.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:16.058+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 12.895209 ms
[2025-05-06T13:19:16.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Registering RDD 574 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 86
[2025-05-06T13:19:16.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got map stage job 68 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-06T13:19:16.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ShuffleMapStage 744 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:16.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 727, ShuffleMapStage 731, ShuffleMapStage 743, ShuffleMapStage 735, ShuffleMapStage 729, ShuffleMapStage 739, ShuffleMapStage 733, ShuffleMapStage 725, ShuffleMapStage 722, ShuffleMapStage 737, ShuffleMapStage 689, ShuffleMapStage 690, ShuffleMapStage 741)
[2025-05-06T13:19:16.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.063+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 744 (MapPartitionsRDD[574] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:16.066+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 31.6 KiB, free 425.8 MiB)
[2025-05-06T13:19:16.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 1.0 in stage 683.0 (TID 927) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 425.8 MiB)
[2025-05-06T13:19:16.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 016737cbcc7e:32777 (size: 11.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 744 (MapPartitionsRDD[574] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:16.068+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 744.0 with 10 tasks resource profile 0
[2025-05-06T13:19:16.069+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 683.0 (TID 926) in 24 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:16.071+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 7.170343 ms
[2025-05-06T13:19:16.073+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Registering RDD 577 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 87
[2025-05-06T13:19:16.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got map stage job 69 (jdbc at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2025-05-06T13:19:16.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ShuffleMapStage 745 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:16.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 727, ShuffleMapStage 731, ShuffleMapStage 743, ShuffleMapStage 735, ShuffleMapStage 729, ShuffleMapStage 739, ShuffleMapStage 733, ShuffleMapStage 725, ShuffleMapStage 722, ShuffleMapStage 737, ShuffleMapStage 689, ShuffleMapStage 690, ShuffleMapStage 741)
[2025-05-06T13:19:16.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.074+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 745 (MapPartitionsRDD[577] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:16.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 2.0 in stage 683.0 (TID 928) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.075+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 1.0 in stage 683.0 (TID 927) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:16.077+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 26.7 KiB, free 425.8 MiB)
[2025-05-06T13:19:16.087+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 425.7 MiB)
[2025-05-06T13:19:16.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 3.0 in stage 683.0 (TID 929) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 016737cbcc7e:32777 (size: 10.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 2.0 in stage 683.0 (TID 928) in 15 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:16.088+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 745 (MapPartitionsRDD[577] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-06T13:19:16.089+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 745.0 with 10 tasks resource profile 0
[2025-05-06T13:19:16.091+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 016737cbcc7e:32777 in memory (size: 9.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.094+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 172.18.0.4:44293 in memory (size: 9.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 4.0 in stage 683.0 (TID 930) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.096+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 3.0 in stage 683.0 (TID 929) in 8 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:16.103+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 5.0 in stage 683.0 (TID 931) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.103+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 4.0 in stage 683.0 (TID 930) in 8 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:16.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 6.0 in stage 683.0 (TID 932) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.109+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 5.0 in stage 683.0 (TID 931) in 7 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:16.115+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 7.0 in stage 683.0 (TID 933) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.118+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 6.0 in stage 683.0 (TID 932) in 6 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:16.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 8.0 in stage 683.0 (TID 934) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 7.0 in stage 683.0 (TID 933) in 7 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:16.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 8.0 in stage 683.0 (TID 934) in 13 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:16.133+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 9.0 in stage 683.0 (TID 935) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 721.0 (TID 936) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 9.0 in stage 683.0 (TID 935) in 5 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:16.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 683.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.138+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ResultStage 683 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.108 s
[2025-05-06T13:19:16.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:16.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 683: Stage finished
[2025-05-06T13:19:16.139+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Job 66 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.110694 s
[2025-05-06T13:19:16.143+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 172.18.0.4:44293 (size: 11.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.147+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 5.322623 ms
[2025-05-06T13:19:16.152+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 2.1 MiB, free 423.7 MiB)
[2025-05-06T13:19:16.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 26.3 KiB, free 423.7 MiB)
[2025-05-06T13:19:16.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 016737cbcc7e:32777 (size: 26.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.153+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 139 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:16.165+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.168+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.169+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.171+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.174+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:19:16.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 11.991474 ms
[2025-05-06T13:19:16.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 1.0 in stage 721.0 (TID 937) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.191+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 721.0 (TID 936) in 53 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:16.199+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 2.0 in stage 721.0 (TID 938) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 1.0 in stage 721.0 (TID 937) in 9 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:16.201+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Registering RDD 580 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 88
[2025-05-06T13:19:16.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got map stage job 70 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:19:16.202+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ShuffleMapStage 747 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:16.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 746)
[2025-05-06T13:19:16.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.203+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 747 (MapPartitionsRDD[580] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:16.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 66.4 KiB, free 423.6 MiB)
[2025-05-06T13:19:16.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 3.0 in stage 721.0 (TID 939) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.223+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 423.6 MiB)
[2025-05-06T13:19:16.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 016737cbcc7e:32777 (size: 27.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 2.0 in stage 721.0 (TID 938) in 24 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:16.224+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 172.18.0.4:44293 in memory (size: 20.4 KiB, free: 174.4 MiB)
[2025-05-06T13:19:16.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 016737cbcc7e:32777 in memory (size: 20.4 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.225+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 747 (MapPartitionsRDD[580] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:16.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 747.0 with 1 tasks resource profile 0
[2025-05-06T13:19:16.238+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 4.0 in stage 721.0 (TID 940) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.241+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 3.0 in stage 721.0 (TID 939) in 18 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:16.247+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 5.0 in stage 721.0 (TID 941) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.248+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 4.0 in stage 721.0 (TID 940) in 11 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:16.258+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 6.0 in stage 721.0 (TID 942) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.261+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 5.0 in stage 721.0 (TID 941) in 14 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:16.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 7.0 in stage 721.0 (TID 943) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.289+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 6.0 in stage 721.0 (TID 942) in 29 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:16.296+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 8.0 in stage 721.0 (TID 944) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.297+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 7.0 in stage 721.0 (TID 943) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:16.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 9.0 in stage 721.0 (TID 945) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 8.0 in stage 721.0 (TID 944) in 7 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:16.309+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 744.0 (TID 946) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.310+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 9.0 in stage 721.0 (TID 945) in 7 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:16.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 721.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ShuffleMapStage 721 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.261 s
[2025-05-06T13:19:16.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:16.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: running: Set(ShuffleMapStage 745, ShuffleMapStage 747, ShuffleMapStage 744)
[2025-05-06T13:19:16.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:16.312+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:16.317+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 172.18.0.4:44293 (size: 11.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.321+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(85), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.323+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(85), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.324+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_0 in memory on 172.18.0.4:44293 (size: 14.9 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.334+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:16.335+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got job 71 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:19:16.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ResultStage 779 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:19:16.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 778)
[2025-05-06T13:19:16.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.336+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ResultStage 779 (MapPartitionsRDD[582] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:19:16.338+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 7.2 KiB, free 423.7 MiB)
[2025-05-06T13:19:16.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 423.7 MiB)
[2025-05-06T13:19:16.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 779 (MapPartitionsRDD[582] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:16.339+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 779.0 with 1 tasks resource profile 0
[2025-05-06T13:19:16.342+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 1.0 in stage 744.0 (TID 947) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.345+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 744.0 (TID 946) in 36 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:16.348+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_1 in memory on 172.18.0.4:44293 (size: 14.8 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 2.0 in stage 744.0 (TID 948) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.352+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 1.0 in stage 744.0 (TID 947) in 10 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:16.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_2 in memory on 172.18.0.4:44293 (size: 14.6 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.361+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 3.0 in stage 744.0 (TID 949) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.361+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 2.0 in stage 744.0 (TID 948) in 9 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:16.365+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_3 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.369+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 4.0 in stage 744.0 (TID 950) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.369+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 3.0 in stage 744.0 (TID 949) in 9 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:16.373+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_4 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.377+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 5.0 in stage 744.0 (TID 951) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.378+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 4.0 in stage 744.0 (TID 950) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:16.382+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_5 in memory on 172.18.0.4:44293 (size: 14.7 KiB, free: 174.3 MiB)
[2025-05-06T13:19:16.385+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 6.0 in stage 744.0 (TID 952) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.386+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 5.0 in stage 744.0 (TID 951) in 9 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:16.390+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_6 in memory on 172.18.0.4:44293 (size: 14.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.394+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 7.0 in stage 744.0 (TID 953) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.394+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 6.0 in stage 744.0 (TID 952) in 9 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:16.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_7 in memory on 172.18.0.4:44293 (size: 14.4 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 8.0 in stage 744.0 (TID 954) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.401+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 7.0 in stage 744.0 (TID 953) in 8 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:16.405+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_8 in memory on 172.18.0.4:44293 (size: 14.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.409+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 9.0 in stage 744.0 (TID 955) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.409+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 8.0 in stage 744.0 (TID 954) in 8 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:16.412+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added rdd_548_9 in memory on 172.18.0.4:44293 (size: 14.0 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.416+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 745.0 (TID 956) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.416+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 9.0 in stage 744.0 (TID 955) in 8 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:16.416+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 744.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ShuffleMapStage 744 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.353 s
[2025-05-06T13:19:16.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:16.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: running: Set(ShuffleMapStage 745, ResultStage 779, ShuffleMapStage 747)
[2025-05-06T13:19:16.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:16.417+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:16.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 172.18.0.4:44293 (size: 10.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.427+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(86), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:16.437+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got job 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:19:16.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ResultStage 781 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:19:16.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 780)
[2025-05-06T13:19:16.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.438+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ResultStage 781 (MapPartitionsRDD[584] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:19:16.439+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 7.2 KiB, free 423.6 MiB)
[2025-05-06T13:19:16.454+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 423.6 MiB)
[2025-05-06T13:19:16.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 1.0 in stage 745.0 (TID 957) (172.18.0.4, executor 0, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 745.0 (TID 956) in 39 ms on 172.18.0.4 (executor 0) (1/10)
[2025-05-06T13:19:16.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 781 (MapPartitionsRDD[584] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:16.455+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 781.0 with 1 tasks resource profile 0
[2025-05-06T13:19:16.459+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 172.18.0.4:44293 in memory (size: 11.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.463+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 016737cbcc7e:32777 in memory (size: 11.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.466+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 016737cbcc7e:32777 in memory (size: 11.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.467+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 2.0 in stage 745.0 (TID 958) (172.18.0.4, executor 0, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.469+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 172.18.0.4:44293 in memory (size: 11.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.469+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 1.0 in stage 745.0 (TID 957) in 16 ms on 172.18.0.4 (executor 0) (2/10)
[2025-05-06T13:19:16.477+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 3.0 in stage 745.0 (TID 959) (172.18.0.4, executor 0, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.477+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 2.0 in stage 745.0 (TID 958) in 10 ms on 172.18.0.4 (executor 0) (3/10)
[2025-05-06T13:19:16.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 4.0 in stage 745.0 (TID 960) (172.18.0.4, executor 0, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.486+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 3.0 in stage 745.0 (TID 959) in 10 ms on 172.18.0.4 (executor 0) (4/10)
[2025-05-06T13:19:16.494+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 5.0 in stage 745.0 (TID 961) (172.18.0.4, executor 0, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.494+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 4.0 in stage 745.0 (TID 960) in 9 ms on 172.18.0.4 (executor 0) (5/10)
[2025-05-06T13:19:16.510+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 6.0 in stage 745.0 (TID 962) (172.18.0.4, executor 0, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.510+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 5.0 in stage 745.0 (TID 961) in 17 ms on 172.18.0.4 (executor 0) (6/10)
[2025-05-06T13:19:16.518+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 7.0 in stage 745.0 (TID 963) (172.18.0.4, executor 0, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.519+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 6.0 in stage 745.0 (TID 962) in 8 ms on 172.18.0.4 (executor 0) (7/10)
[2025-05-06T13:19:16.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 8.0 in stage 745.0 (TID 964) (172.18.0.4, executor 0, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.527+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 7.0 in stage 745.0 (TID 963) in 9 ms on 172.18.0.4 (executor 0) (8/10)
[2025-05-06T13:19:16.538+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 9.0 in stage 745.0 (TID 965) (172.18.0.4, executor 0, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.539+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 8.0 in stage 745.0 (TID 964) in 12 ms on 172.18.0.4 (executor 0) (9/10)
[2025-05-06T13:19:16.544+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 747.0 (TID 966) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.545+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 9.0 in stage 745.0 (TID 965) in 6 ms on 172.18.0.4 (executor 0) (10/10)
[2025-05-06T13:19:16.545+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 745.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.545+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ShuffleMapStage 745 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.471 s
[2025-05-06T13:19:16.545+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:16.545+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: running: Set(ResultStage 781, ResultStage 779, ShuffleMapStage 747)
[2025-05-06T13:19:16.545+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:16.545+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:16.550+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 172.18.0.4:44293 (size: 27.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(87), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.555+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.18.0.4:59552
[2025-05-06T13:19:16.564+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:16.568+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got job 73 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:19:16.568+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ResultStage 783 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:19:16.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 782)
[2025-05-06T13:19:16.569+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.570+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ResultStage 783 (MapPartitionsRDD[586] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:19:16.570+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 7.2 KiB, free 423.7 MiB)
[2025-05-06T13:19:16.570+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 423.7 MiB)
[2025-05-06T13:19:16.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.571+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 783 (MapPartitionsRDD[586] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:16.572+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 172.18.0.4:44293 (size: 26.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.573+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 783.0 with 1 tasks resource profile 0
[2025-05-06T13:19:16.581+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 779.0 (TID 967) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.582+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 747.0 (TID 966) in 37 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:16.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 747.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ShuffleMapStage 747 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.379 s
[2025-05-06T13:19:16.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:16.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: running: Set(ResultStage 781, ResultStage 779, ResultStage 783)
[2025-05-06T13:19:16.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:16.583+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:16.812+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.814+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.18.0.4:59552
[2025-05-06T13:19:16.819+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 781.0 (TID 968) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.819+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 779.0 (TID 967) in 238 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:16.819+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 779.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.820+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ResultStage 779 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.483 s
[2025-05-06T13:19:16.820+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:16.821+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 779: Stage finished
[2025-05-06T13:19:16.821+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Job 71 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.487238 s
[2025-05-06T13:19:16.824+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.825+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.18.0.4:59552
[2025-05-06T13:19:16.828+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 783.0 (TID 969) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 781.0 (TID 968) in 10 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:16.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 781.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ResultStage 781 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.391 s
[2025-05-06T13:19:16.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:16.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 781: Stage finished
[2025-05-06T13:19:16.829+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Job 72 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.392371 s
[2025-05-06T13:19:16.831+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.832+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.18.0.4:59552
[2025-05-06T13:19:16.835+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 783.0 (TID 969) in 7 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:16.835+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 783.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ResultStage 783 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.269 s
[2025-05-06T13:19:16.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:16.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 783: Stage finished
[2025-05-06T13:19:16.836+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Job 73 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.272419 s
[2025-05-06T13:19:16.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 4.125188 ms
[2025-05-06T13:19:16.843+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 4.117876 ms
[2025-05-06T13:19:16.861+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 1088.0 KiB, free 420.5 MiB)
[2025-05-06T13:19:16.861+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 1088.0 KiB, free 420.5 MiB)
[2025-05-06T13:19:16.862+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 1088.0 KiB, free 420.5 MiB)
[2025-05-06T13:19:16.870+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 420.5 MiB)
[2025-05-06T13:19:16.870+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 32.1 KiB, free 420.5 MiB)
[2025-05-06T13:19:16.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 016737cbcc7e:32777 (size: 21.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 22.8 KiB, free 420.5 MiB)
[2025-05-06T13:19:16.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 016737cbcc7e:32777 (size: 32.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 016737cbcc7e:32777 (size: 22.8 KiB, free: 434.1 MiB)
[2025-05-06T13:19:16.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 146 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:16.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 144 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:16.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 145 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:16.871+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.872+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 016737cbcc7e:32777 in memory (size: 27.3 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.873+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 172.18.0.4:44293 in memory (size: 27.3 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.875+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.876+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.878+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.879+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 016737cbcc7e:32777 in memory (size: 10.5 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.880+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.881+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 172.18.0.4:44293 in memory (size: 10.5 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.881+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.883+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.891+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 5.962954 ms
[2025-05-06T13:19:16.895+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Registering RDD 589 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 89
[2025-05-06T13:19:16.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got map stage job 74 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:19:16.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ShuffleMapStage 786 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:16.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 785)
[2025-05-06T13:19:16.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.896+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 786 (MapPartitionsRDD[589] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:16.904+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 6.256015 ms
[2025-05-06T13:19:16.905+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 13.4 KiB, free 420.6 MiB)
[2025-05-06T13:19:16.906+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 420.6 MiB)
[2025-05-06T13:19:16.906+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 016737cbcc7e:32777 (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.906+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 786 (MapPartitionsRDD[589] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:16.907+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 786.0 with 1 tasks resource profile 0
[2025-05-06T13:19:16.908+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 786.0 (TID 970) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.921+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 172.18.0.4:44293 (size: 6.7 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Registering RDD 592 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 90
[2025-05-06T13:19:16.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got map stage job 75 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:19:16.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ShuffleMapStage 787 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:16.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 785)
[2025-05-06T13:19:16.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.923+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 787 (MapPartitionsRDD[592] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:16.924+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.924+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.18.0.4:59552
[2025-05-06T13:19:16.925+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 12.9 KiB, free 420.6 MiB)
[2025-05-06T13:19:16.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 420.6 MiB)
[2025-05-06T13:19:16.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 016737cbcc7e:32777 (size: 6.6 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.926+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 787 (MapPartitionsRDD[592] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:16.927+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 787.0 with 1 tasks resource profile 0
[2025-05-06T13:19:16.935+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO CodeGenerator: Code generated in 5.523903 ms
[2025-05-06T13:19:16.938+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Registering RDD 595 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 91
[2025-05-06T13:19:16.938+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got map stage job 76 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:19:16.938+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ShuffleMapStage 788 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:16.938+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 785)
[2025-05-06T13:19:16.938+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.938+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 788 (MapPartitionsRDD[595] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:16.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 13.5 KiB, free 420.6 MiB)
[2025-05-06T13:19:16.940+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 420.6 MiB)
[2025-05-06T13:19:16.941+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 016737cbcc7e:32777 (size: 6.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 788 (MapPartitionsRDD[595] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:16.942+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 788.0 with 1 tasks resource profile 0
[2025-05-06T13:19:16.966+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 172.18.0.4:44293 (size: 22.8 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.973+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Starting task 0.0 in stage 787.0 (TID 971) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:16.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSetManager: Finished task 0.0 in stage 786.0 (TID 970) in 66 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:16.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Removed TaskSet 786.0, whose tasks have all completed, from pool
[2025-05-06T13:19:16.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: ShuffleMapStage 786 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.078 s
[2025-05-06T13:19:16.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:16.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: running: Set(ShuffleMapStage 787, ShuffleMapStage 788)
[2025-05-06T13:19:16.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:16.974+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:16.977+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 172.18.0.4:44293 (size: 6.6 KiB, free: 174.2 MiB)
[2025-05-06T13:19:16.978+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(89), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.979+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO ShufflePartitionsUtil: For shuffle(89), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:16.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:16.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Got job 77 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:19:16.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Final stage: ResultStage 790 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:19:16.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 789)
[2025-05-06T13:19:16.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:16.986+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting ResultStage 790 (MapPartitionsRDD[597] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:19:16.987+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 7.2 KiB, free 420.5 MiB)
[2025-05-06T13:19:16.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 172.18.0.4:44293 (size: 21.7 KiB, free: 174.1 MiB)
[2025-05-06T13:19:16.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 420.5 MiB)
[2025-05-06T13:19:16.996+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 016737cbcc7e:32777 (size: 3.8 KiB, free: 434.2 MiB)
[2025-05-06T13:19:16.997+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:16.997+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 172.18.0.4:44293 in memory (size: 6.7 KiB, free: 174.1 MiB)
[2025-05-06T13:19:16.998+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 790 (MapPartitionsRDD[597] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:16.998+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO TaskSchedulerImpl: Adding task set 790.0 with 1 tasks resource profile 0
[2025-05-06T13:19:16.998+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:16 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 016737cbcc7e:32777 in memory (size: 6.7 KiB, free: 434.2 MiB)
[2025-05-06T13:19:17.001+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Starting task 0.0 in stage 788.0 (TID 972) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:17.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Finished task 0.0 in stage 787.0 (TID 971) in 28 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:17.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Removed TaskSet 787.0, whose tasks have all completed, from pool
[2025-05-06T13:19:17.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: ShuffleMapStage 787 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.079 s
[2025-05-06T13:19:17.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:17.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: running: Set(ResultStage 790, ShuffleMapStage 788)
[2025-05-06T13:19:17.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:17.002+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:17.005+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 172.18.0.4:44293 (size: 6.8 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.014+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 172.18.0.4:44293 (size: 32.1 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.019+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Starting task 0.0 in stage 790.0 (TID 973) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:17.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Finished task 0.0 in stage 788.0 (TID 972) in 18 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:17.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Removed TaskSet 788.0, whose tasks have all completed, from pool
[2025-05-06T13:19:17.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: ShuffleMapStage 788 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.081 s
[2025-05-06T13:19:17.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:17.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: running: Set(ResultStage 790)
[2025-05-06T13:19:17.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:17.020+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:17.023+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 172.18.0.4:44293 (size: 3.8 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.025+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.18.0.4:59552
[2025-05-06T13:19:17.027+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Finished task 0.0 in stage 790.0 (TID 973) in 8 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:17.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Removed TaskSet 790.0, whose tasks have all completed, from pool
[2025-05-06T13:19:17.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: ResultStage 790 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.041 s
[2025-05-06T13:19:17.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:17.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 790: Stage finished
[2025-05-06T13:19:17.028+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Job 77 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.042303 s
[2025-05-06T13:19:17.031+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 2.1 MiB, free 418.5 MiB)
[2025-05-06T13:19:17.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 418.5 MiB)
[2025-05-06T13:19:17.032+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 016737cbcc7e:32777 (size: 19.8 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.033+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkContext: Created broadcast 151 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:17.045+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO ShufflePartitionsUtil: For shuffle(91), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:17.046+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO ShufflePartitionsUtil: For shuffle(90), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:17.054+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO CodeGenerator: Code generated in 4.855707 ms
[2025-05-06T13:19:17.056+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Registering RDD 600 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 92
[2025-05-06T13:19:17.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Got map stage job 78 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:19:17.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Final stage: ShuffleMapStage 794 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:17.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 793)
[2025-05-06T13:19:17.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:17.057+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Submitting ShuffleMapStage 794 (MapPartitionsRDD[600] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:17.061+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 14.1 KiB, free 418.5 MiB)
[2025-05-06T13:19:17.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 418.5 MiB)
[2025-05-06T13:19:17.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 016737cbcc7e:32777 (size: 7.1 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:17.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 794 (MapPartitionsRDD[600] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:17.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Adding task set 794.0 with 1 tasks resource profile 0
[2025-05-06T13:19:17.062+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Starting task 0.0 in stage 794.0 (TID 974) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:17.067+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 172.18.0.4:44293 (size: 7.1 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.070+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.18.0.4:59552
[2025-05-06T13:19:17.086+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 016737cbcc7e:32777 in memory (size: 6.6 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.090+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 172.18.0.4:44293 in memory (size: 6.6 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO CodeGenerator: Code generated in 30.098454 ms
[2025-05-06T13:19:17.092+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 016737cbcc7e:32777 in memory (size: 3.8 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.093+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 172.18.0.4:44293 in memory (size: 3.8 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.097+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 016737cbcc7e:32777 in memory (size: 6.8 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.099+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 172.18.0.4:44293 in memory (size: 6.8 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.100+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 172.18.0.4:44293 (size: 19.8 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.119+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Finished task 0.0 in stage 794.0 (TID 974) in 57 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:17.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Removed TaskSet 794.0, whose tasks have all completed, from pool
[2025-05-06T13:19:17.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: ShuffleMapStage 794 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.062 s
[2025-05-06T13:19:17.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:17.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:17.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:17.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:17.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Registering RDD 603 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 93
[2025-05-06T13:19:17.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Got map stage job 79 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:19:17.120+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Final stage: ShuffleMapStage 798 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:17.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 797)
[2025-05-06T13:19:17.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:17.121+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Submitting ShuffleMapStage 798 (MapPartitionsRDD[603] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:17.135+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 116.2 KiB, free 418.4 MiB)
[2025-05-06T13:19:17.136+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 45.6 KiB, free 418.4 MiB)
[2025-05-06T13:19:17.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 016737cbcc7e:32777 (size: 45.6 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:17.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 798 (MapPartitionsRDD[603] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:17.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Adding task set 798.0 with 1 tasks resource profile 0
[2025-05-06T13:19:17.137+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Starting task 0.0 in stage 798.0 (TID 975) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4465 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:17.141+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 172.18.0.4:44293 (size: 45.6 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.157+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.18.0.4:59552
[2025-05-06T13:19:17.186+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Finished task 0.0 in stage 798.0 (TID 975) in 49 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:17.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Removed TaskSet 798.0, whose tasks have all completed, from pool
[2025-05-06T13:19:17.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: ShuffleMapStage 798 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.065 s
[2025-05-06T13:19:17.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-06T13:19:17.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: running: Set()
[2025-05-06T13:19:17.187+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: waiting: Set()
[2025-05-06T13:19:17.188+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: failed: Set()
[2025-05-06T13:19:17.190+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO ShufflePartitionsUtil: For shuffle(93), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:17.194+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-06T13:19:17.206+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO CodeGenerator: Code generated in 10.207893 ms
[2025-05-06T13:19:17.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:17.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Got job 80 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-06T13:19:17.226+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Final stage: ResultStage 803 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-06T13:19:17.227+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 802)
[2025-05-06T13:19:17.227+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:17.227+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Submitting ResultStage 803 (MapPartitionsRDD[606] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-06T13:19:17.231+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 113.1 KiB, free 418.2 MiB)
[2025-05-06T13:19:17.231+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 42.8 KiB, free 418.2 MiB)
[2025-05-06T13:19:17.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 016737cbcc7e:32777 (size: 42.8 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:17.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 803 (MapPartitionsRDD[606] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:17.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Adding task set 803.0 with 1 tasks resource profile 0
[2025-05-06T13:19:17.232+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Starting task 0.0 in stage 803.0 (TID 976) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:17.237+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 172.18.0.4:44293 (size: 42.8 KiB, free: 174.0 MiB)
[2025-05-06T13:19:17.242+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.18.0.4:59552
[2025-05-06T13:19:17.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Finished task 0.0 in stage 803.0 (TID 976) in 23 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:17.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Removed TaskSet 803.0, whose tasks have all completed, from pool
[2025-05-06T13:19:17.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: ResultStage 803 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.029 s
[2025-05-06T13:19:17.256+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:17.257+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 803: Stage finished
[2025-05-06T13:19:17.257+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Job 80 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.030339 s
[2025-05-06T13:19:17.262+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO CodeGenerator: Code generated in 3.368129 ms
[2025-05-06T13:19:17.264+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 1024.0 KiB, free 417.2 MiB)
[2025-05-06T13:19:17.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 209.0 B, free 417.2 MiB)
[2025-05-06T13:19:17.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 016737cbcc7e:32777 (size: 209.0 B, free: 434.1 MiB)
[2025-05-06T13:19:17.285+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkContext: Created broadcast 155 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-06T13:19:17.286+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO ShufflePartitionsUtil: For shuffle(92), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-06T13:19:17.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 172.18.0.4:44293 in memory (size: 45.6 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.287+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 016737cbcc7e:32777 in memory (size: 45.6 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.301+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 016737cbcc7e:32777 in memory (size: 42.8 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.303+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO CodeGenerator: Code generated in 10.593473 ms
[2025-05-06T13:19:17.307+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 172.18.0.4:44293 in memory (size: 42.8 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.311+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 016737cbcc7e:32777 in memory (size: 7.1 KiB, free: 434.2 MiB)
[2025-05-06T13:19:17.315+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 172.18.0.4:44293 in memory (size: 7.1 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.355+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-05-06T13:19:17.356+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Got job 81 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-06T13:19:17.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Final stage: ResultStage 808 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-05-06T13:19:17.357+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 807)
[2025-05-06T13:19:17.358+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Missing parents: List()
[2025-05-06T13:19:17.358+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Submitting ResultStage 808 (MapPartitionsRDD[611] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-06T13:19:17.396+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 128.0 KiB, free 417.4 MiB)
[2025-05-06T13:19:17.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 417.4 MiB)
[2025-05-06T13:19:17.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 016737cbcc7e:32777 (size: 48.2 KiB, free: 434.1 MiB)
[2025-05-06T13:19:17.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1474
[2025-05-06T13:19:17.397+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 808 (MapPartitionsRDD[611] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-06T13:19:17.398+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Adding task set 808.0 with 1 tasks resource profile 0
[2025-05-06T13:19:17.398+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Starting task 0.0 in stage 808.0 (TID 977) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-06T13:19:17.402+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 172.18.0.4:44293 (size: 48.2 KiB, free: 174.1 MiB)
[2025-05-06T13:19:17.411+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.18.0.4:59552
[2025-05-06T13:19:17.421+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 172.18.0.4:44293 (size: 209.0 B, free: 174.1 MiB)
[2025-05-06T13:19:17.477+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSetManager: Finished task 0.0 in stage 808.0 (TID 977) in 79 ms on 172.18.0.4 (executor 0) (1/1)
[2025-05-06T13:19:17.477+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Removed TaskSet 808.0, whose tasks have all completed, from pool
[2025-05-06T13:19:17.480+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: ResultStage 808 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.121 s
[2025-05-06T13:19:17.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-06T13:19:17.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 808: Stage finished
[2025-05-06T13:19:17.481+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO DAGScheduler: Job 81 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.124525 s
[2025-05-06T13:19:17.496+0000] {spark_submit.py:571} INFO - 2025-05-06 13:19:17,496 [INFO] Анализ графа успешно завершен
[2025-05-06T13:19:17.506+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkUI: Stopped Spark web UI at http://016737cbcc7e:4040
[2025-05-06T13:19:17.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-05-06T13:19:17.509+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2025-05-06T13:19:17.523+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-06T13:19:17.548+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO MemoryStore: MemoryStore cleared
[2025-05-06T13:19:17.549+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManager: BlockManager stopped
[2025-05-06T13:19:17.550+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-06T13:19:17.554+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-06T13:19:17.565+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO SparkContext: Successfully stopped SparkContext
[2025-05-06T13:19:17.878+0000] {spark_submit.py:571} INFO - 2025-05-06 13:19:17,878 [INFO] SparkSession остановлена
[2025-05-06T13:19:17.916+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO ShutdownHookManager: Shutdown hook called
[2025-05-06T13:19:17.917+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-2399efd9-b3ac-480d-8fec-d0b0db6b3ccd/pyspark-4e187843-09bd-4fad-aae2-22af103113b4
[2025-05-06T13:19:17.919+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-16501551-8d2e-4b2c-afd0-61903dacdc42
[2025-05-06T13:19:17.922+0000] {spark_submit.py:571} INFO - 25/05/06 13:19:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-2399efd9-b3ac-480d-8fec-d0b0db6b3ccd
[2025-05-06T13:19:18.008+0000] {taskinstance.py:1345} INFO - Marking task as SUCCESS. dag_id=graph_analysis, task_id=build_graph, execution_date=20250506T131653, start_date=20250506T131700, end_date=20250506T131918
[2025-05-06T13:19:18.049+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2025-05-06T13:19:18.086+0000] {taskinstance.py:2653} INFO - 1 downstream tasks scheduled from follow-on schedule check
